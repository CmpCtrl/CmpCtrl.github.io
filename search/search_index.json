{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to MkDocs For full documentation visit mkdocs.org . Commands mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Welcome to MkDocs"},{"location":"#welcome-to-mkdocs","text":"For full documentation visit mkdocs.org .","title":"Welcome to MkDocs"},{"location":"#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"data/","text":"CCG Time Series data module. Frame Collection of Time Series data. Parameters: data ( Sig | list [ Sig ] | None , default: None ) \u2013 TS Data, by default None. References to Sig will be broken. name ( str | None , default: None ) \u2013 Frame name, by default None math_tline ( TLine | None , default: None ) \u2013 TLine for Frame wide math, by default None Attributes: sigs ( dict [ str , Sig ] ) \u2013 dictionary of Sigs tlines ( TLineCollection ) \u2013 Collection of timelines, referenced by Sigs name ( str ) \u2013 Frame Name nsigs ( int ) \u2013 nsamples ( int ) \u2013 tend ( float | None ) \u2013 tstart ( float | None ) \u2013 tline ( TLine | None ) \u2013 Source code in ccg\\data\\tsdata.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 class Frame : \"\"\"Collection of Time Series data. Parameters ---------- data : Sig | list[Sig] | None, optional TS Data, by default None. References to Sig will be broken. name : str | None, optional Frame name, by default None math_tline : TLine | None, optional TLine for Frame wide math, by default None Attributes ------- sigs : dict[str, Sig] dictionary of Sigs tlines: TLineCollection Collection of timelines, referenced by Sigs name: str Frame Name nsigs nsamples tend tstart tline \"\"\" CUTOFF = 0.5 # For difflib compares def __init__ ( self , data : Sig | list [ Sig ] | None = None , name : str | None = None , math_tline : TLine | None = None , ) -> None : self . sigs : dict [ str , Sig ] = {} self . tlines = TLineCollection ( self ) self . name = name sigs = [] self . math_tline = math_tline # if isinstance(data, pd.DataFrame): # tline = TLine(data) # for col in data: # sig = Sig( # data=data[col], # tline=tline, # name=col, # frame=self, # ) # sigs.append(sig) if isinstance ( data , Sig ): sigs . append ( data ) elif isinstance ( data , list ): for sig in data : sigs . append ( sig ) elif data is None : pass else : raise NotImplementedError ( f \"Frame generation from { type ( data ) } is not implemented.\" ) self . append ( sigs ) @property def nsigs ( self ) -> int : \"\"\"Number of Sigs in collection.\"\"\" return len ( self . sigs ) @property def nsamples ( self ) -> int : \"\"\"Cumulative samples (counting unique timelines as well).\"\"\" nsamples = self . tlines . nsamples for _ , sig in self . sigs . items (): nsamples += sig . nsamples return nsamples @property def tend ( self ) -> float | None : \"\"\"Latest end time from TLine collection. Returns ------- float Time in unix. \"\"\" return self . tlines . tend @property def tstart ( self ) -> float | None : \"\"\"Earliest start time from TLine collection. Returns ------- float Time in unix. \"\"\" return self . tlines . tstart @property def tend_iso ( self ) -> npt . NDArray [ np . datetime64 ]: \"\"\"Latest end time from TLine collection. Returns ------- float Time in iso. \"\"\" return self . tlines . tend_iso @property def tstart_iso ( self ): \"\"\"Earliest start time from TLine collection. Returns ------- float Time in iso. \"\"\" return self . tlines . tstart_iso # def calc_idn(self): # \"\"\"Calculate hash for IDN.\"\"\" # tic = datetime.now() # idn = xxhash.xxh3_64(self.sigs).intdigest() # toc = datetime.now() - tic # _LOGGER.debug(\"IDN calc'd for %s in %.3f\", self.name, toc.total_seconds()) # return idn def resample ( self , sample_to : TLine , sigs : str | list [ str ] | None = None , inplace : bool | None = False , prefix : str | None = None , suffix : str | None = None , ** kwargs , ): \"\"\"Resample Frame to a `sample_to` TLine. Parameters ---------- sample_to : TLine TLine to resample to sigs : str | list[str] | None, optional list of sigs to resample, full frame if None, by default None inplace : bool | None, optional if True, will resample signals and append (id prefix or suffix is not None) or replace inplace. By default False prefix : str | None, optional prefix to signame, by default None suffix : str | None, optional suffix to signame, by default None **kwargs Additional arguments passed to `Sig.resample()` Returns ------- Frame Returns Self if inplace, else a new Frame \"\"\" if inplace : res = self else : res = Frame () if sigs is not None : if isinstance ( sigs , str ): sigs = [ sigs ] else : sigs = list ( self . sigs . keys ()) for sig in sigs : newsig = self . sigs [ sig ] . resample ( sample_to , ** kwargs ) if prefix is not None : newsig . name = prefix + newsig . name if suffix is not None : newsig . name = newsig . name + suffix if inplace and prefix is None and suffix is None : res . remove ( sig ) res . append ( newsig ) return res def append ( self , item : Sig | Frame | list [ Sig ], append_existing_signals : bool = False , interweave_tlines : bool = False , ): \"\"\"Append to CCG Frame in place.\"\"\" if isinstance ( item , Frame ): sigs_to_apnd = list ( item . sigs . keys ()) for _ , new_sigs in item . tlines . sigs . items (): for sig in new_sigs : if append_existing_signals and sig in self and sig in sigs_to_apnd : check_overlap ( self [ sig ], item [ sig ], interweave_tlines ) old_idn = self . tlines . idns [ sig ] new_tline = self . tlines [ old_idn ] . append_to_new ( item [ sig ]) if new_tline . is_monotonic_increasing : for old_sig in list ( self . tlines . sigs [ old_idn ]): if old_sig in item : self . tlines . remove ( old_sig ) self [ old_sig ] . tline = new_tline self . tlines . append ( self [ old_sig ]) # for references self [ old_sig ] . _data . append ( item [ old_sig ] . _data ) # get the rest of the attributes if item [ old_sig ] . connect_gaps is not None : self [ old_sig ] . connect_gaps = item [ old_sig ] . connect_gaps if item [ old_sig ] . data_enum is not None : self [ old_sig ] . data_enum = item [ old_sig ] . data_enum if item [ old_sig ] . interp_method is not None : self [ old_sig ] . interp_method = item [ old_sig ] . interp_method if item [ old_sig ] . unit is not None : self [ old_sig ] . unit = item [ old_sig ] . unit # Check for unknown attributes. the new signal value will overide the original. for key , val in item [ old_sig ] . __dict__ . items (): if ( not key . startswith ( \"_\" ) and key not in SIG_ATTRS ): setattr ( self [ old_sig ], key , val ) sigs_to_apnd . remove ( old_sig ) else : raise NotImplementedError ( \"batch appends not implemented for non-monoton\" ) for signame in sigs_to_apnd : sig = item [ signame ] self . _append_sig ( sig , append_existing_signals , interweave_tlines ) elif isinstance ( item , list ): for sig in item : self . _append_sig ( sig , append_existing_signals , interweave_tlines ) else : self . _append_sig ( item , append_existing_signals , interweave_tlines ) @profile def _append_sig ( self , sig : Sig , append_existing_signals : bool = False , interweave_tlines : bool = False , ): \"\"\"Append a signal to Frame.\"\"\" # create a new sig to break references to existing sig_copy = Sig ( sig ) # Check for matching name if sig_copy . name in self . sigs : if append_existing_signals : self . sigs [ sig_copy . name ] . append ( sig_copy , interweave_tlines = interweave_tlines , remove_duplicates = False , ) else : _LOGGER . warning ( \"Sig %s already exists, use append_existing_signals=True.\" , sig . name , ) else : self . tlines . append ( sig_copy ) # sig_copy.tline = tlref # replace with the tline reference # 2/10/24 now in tlines.append() sig_copy . parent = self self . sigs [ sig_copy . name ] = sig_copy def _rename_sig ( self , oldname , newname ): \"\"\" Rename signal references in frame. Use `frm['oldname'].name = newname` to rename signal and update frame references together. \"\"\" self . sigs [ newname ] = self . sigs . pop ( oldname ) self . tlines . idns [ newname ] = self . tlines . idns . pop ( oldname ) ind = self . tlines . sigs [ self . tlines . idns [ newname ]] . index ( oldname ) self . tlines . sigs [ self . tlines . idns [ newname ]][ ind ] = newname def sort ( self , remove_safe_duplicates = False , remove_all_duplicates = False ): \"\"\"Sort signals by timeline for monoton increasing.\"\"\" for _ , sig in self . sigs . items (): sig . sort_tline ( inplace = True , remove_safe_duplicates = remove_safe_duplicates , remove_all_duplicates = remove_all_duplicates , ) # def to_pandas(self) -> pd.DataFrame: # \"\"\"Convert CCGFrame to pd.DataFrame.\"\"\" # serieslist = [] # for sig in self: # serieslist.append(sig.to_pandas()) # pddf = pd.concat(serieslist, join=\"outer\", axis=1) # return pddf def clear ( self ): \"\"\"Clears frame in place.\"\"\" self . sigs : dict [ str , Sig ] = {} self . tlines = TLineCollection ( self ) def clean_names ( self ): \"\"\"Cleans signal names.\"\"\" rename_list = {} for signame , _ in self . sigs . items (): clean_name = ccg . util . clean_name ( signame ) if clean_name != signame : rename_list . update ({ signame : clean_name }) for signame , clean_name in rename_list . items (): _LOGGER . debug ( \" %s renamed to %s \" , signame , clean_name ) self [ signame ] . name = clean_name def remove ( self , signames : str | list [ str ]): \"\"\"Removes sigs from frame.\"\"\" if not isinstance ( signames , list ): signames = [ signames ] for signame in signames : if signame in self : self . tlines . remove ( signame ) self . sigs . pop ( signame , None ) def plot ( self ): \"\"\"Plot data frame.\"\"\" from ccg.ui.plot import Plot plt = Plot ( self ) plt . plot () def valid ( self , gatecoll : GateColl , tline : TLine | None = None ) -> Frame : \"\"\"Returns a new Frame, invalid data replaced with nan. calc'd on `tline` or combined TLine if None Parameters ---------- gatecoll : GateColl Collection of gating conditions tline : TLine | None, optional TLine to calculate validity on, by default None Returns ------- Frame New instance of Frame \"\"\" res = Frame ( name = self . name ) # if tline is None: # tline = self.tlines.get_fastest() valid_sig = gatecoll . validate ( self , tline ) for tmp_tline in self . tlines : if tmp_tline . nsamples > 1 : b_valid = valid_sig . interp ( tmp_tline ) . data for sig in self . tlines . sigs [ tmp_tline . idn ]: newsig = Sig ( self [ sig ]) nan = np . NaN if newsig . data . dtype . kind in [ \"i\" , \"u\" ]: newsig . data = newsig . data . astype ( \"float\" ) elif newsig . data . dtype . kind in [ \"U\" , \"S\" ]: nan = \"\" newsig . data [ ~ b_valid ] = nan res . append ( newsig ) return res @property def tline ( self ) -> TLine | None : \"\"\"If frame has only one tline, return it.\"\"\" if self . tlines . n_tlines == 1 : return list ( self . tlines . tlines . values ())[ 0 ] else : raise ValueError ( f \" { 'frame' if self . name is None else self . name } has more than one tline,\" + f \" { 'frame' if self . name is None else self . name } .tline() invalid.\" ) @profile def from_excel ( self , filename : str | Path , tline_col : int | str = None , signame_row : int = None , signame_regex : str = None , filedata : BytesIO | StringIO | bytes = None , sigunit_row : int = None , sigdata_row : int = None , ) -> Frame : \"\"\"Generate frame from excel file. Parameters ---------- filename tline_col Column to use for an index signame_row Row with names to parse with _regex signame_regex regex string to parse signal names. Use named groups for parameters to pass into Sig instatiation, for example name, units, etc. example here: https://regex101.com/r/bfBrdf/6 filedata string or bytes io. filename will only be used for ext, name, etc. \"\"\" tic = datetime . now () if isinstance ( filename , str ): filename = Path ( filename ) if signame_row is None : signame_row = 0 if tline_col is None : tline_col = 0 if signame_regex is None : signame_regex = r \"(?P<name>^.*?)(?:(?:\\s?\\((?P<unit>(?!.*\\().*)\\))|$)\" # Default regex `signal name (unit)`-> `{'name':'signal name','unit':'unit'` # https://regex101.com/r/bfBrdf/6 regex = re . compile ( signame_regex ) data = self . read_filedata ( filename , filedata ) toc = datetime . now () - tic _LOGGER . debug ( \"read %s in %.3f .\" , filename , toc . total_seconds ()) tic = datetime . now () if isinstance ( signame_row , str ): for i , row in enumerate ( data ): if row [ 0 ] == signame_row : signame_row = i break else : raise ValueError ( f \"Signal Name Row: { signame_row } not found in first column of data file.\" ) signames = data [ signame_row , :] . astype ( \"str\" ) signames = np . char . strip ( signames ) if sigunit_row is not None : sigunits = data [ sigunit_row , :] . astype ( \"str\" ) sig_args = [ { \"name\" : name , \"unit\" : unit } for name , unit in zip ( signames , sigunits ) ] else : sig_args = [ regex . match ( signame ) . groupdict () for signame in signames ] # Check for duplicate names and add _dup existing = [] for sig in sig_args : if sig [ \"name\" ] not in existing : existing . append ( sig [ \"name\" ]) else : existing . append ( sig [ \"name\" ] + \"_dup\" ) sig [ \"name\" ] = sig [ \"name\" ] + \"_dup\" if isinstance ( tline_col , str ): tline_col = np . where ( signames == tline_col ) if tline_col [ 0 ] . size == 0 : raise ValueError ( \"tline_col is not in signames.\" ) else : tline_col = [ tline_col ] if sigdata_row is None : sigdata_row = signame_row + 1 tmp : npt . NDArray = data [ sigdata_row :, tline_col ] . ravel () try : tmp = tmp . astype ( \"float\" ) except ValueError : tmp = tmp . astype ( type ( tmp [ 0 ])) tline = TLine ( tmp ) for i , kwargs in enumerate ( sig_args ): if i != tline_col [ 0 ]: sigtype = type ( data [ sigdata_row , i ]) sigdata = data [ sigdata_row :, i ] . ravel () . astype ( sigtype ) if sigtype is str : try : sigdata = sigdata . astype ( float ) except ValueError : pass new_sig = Sig ( data = sigdata , tline = tline , ** kwargs , ) self . append ( new_sig ) toc = datetime . now () - tic _LOGGER . debug ( \"built frame in %.3f .\" , toc . total_seconds ()) tic = datetime . now () return self @profile def read_filedata ( self , filename : Path , filedata : BytesIO | StringIO | bytes | None = None ): \"\"\"Reads file data for building frame from file\"\"\" ext = filename . suffix if ext in [ \".xlsx\" , \".xlsm\" , \".XLSX\" , \".XLSM\" ]: # Use openpyxl if filedata is None : wb = openpyxl . load_workbook ( filename = filename , read_only = True , data_only = True ) else : wb = openpyxl . load_workbook ( filename = filedata , read_only = True , data_only = True ) ws = wb . active data = ws . values data = np . array ( list ( data )) wb . close () elif ext in [ \".xls\" , \".XLS\" ]: # Use xlrd wb_xls : xlrd . book . Book = xlrd . open_workbook ( filename = filename , file_contents = filedata ) ws = wb_xls . sheet_by_index ( 0 ) # data = np.array(ws._cell_values) data = np . empty ( shape = ( ws . nrows , ws . ncols ), dtype = \"O\" ) for i in range ( ws . ncols ): data [:, i ] = ws . col_values ( i ) elif ext in [ \".csv\" , \".CSV\" ]: if filedata is None : with open ( filename , \"r\" , encoding = \"utf8\" ) as file : csvreader = csv . reader ( file , dialect = \"excel\" ) tmp = list ( csvreader ) max_col = max ( map ( len , tmp )) data = np . array ( [ tmp_row + [ None ] * ( max_col - len ( tmp_row )) for tmp_row in tmp ], dtype = \"O\" , ) else : if isinstance ( filedata , bytes ): csvreader = csv . reader ( io . StringIO ( filedata . decode ( \"utf-8\" ))) else : csvreader = csv . reader ( filedata ) tmp = list ( csvreader ) max_col = max ( map ( len , tmp )) data = np . array ( [ tmp_row + [ None ] * ( max_col - len ( tmp_row )) for tmp_row in tmp ], dtype = \"O\" , ) else : raise NotImplementedError ( f \"Frame from Excel not implemented for ext: { ext } \" ) return data # async def read_filedata_async( # self, filename: Path, filedata: BytesIO | StringIO | bytes = None # ): # \"\"\"Reads file data for building frame from file\"\"\" # ext = filename.suffix # if ext in [\".xlsx\", \".xlsm\", \".XLSX\", \".XLSM\"]: # # Use openpyxl # if filedata is None: # wb = openpyxl.load_workbook( # filename=filename, read_only=True, data_only=True # ) # else: # wb = openpyxl.load_workbook( # filename=filedata, read_only=True, data_only=True # ) # ws = wb.active # data = ws.values # data = np.array(list(data)) # wb.close() # elif ext in [\".xls\", \".XLS\"]: # # Use xlrd # wb_xls: xlrd.book.Book = xlrd.open_workbook( # filename=filename, file_contents=filedata # ) # ws = wb_xls.sheet_by_index(0) # # data = np.array(ws._cell_values) # data = np.empty(shape=(ws.nrows, ws.ncols), dtype=\"O\") # for i in range(ws.ncols): # data[:, i] = ws.col_values(i) # elif ext in [\".csv\", \".CSV\"]: # if filedata is None: # async with aiofiles.open(filename, \"r\", encoding=\"utf8\") as file: # csvreader = aiocsv.AsyncReader(file, dialect=\"excel\") # tmp = await list(csvreader) # max_col = max(map(len, tmp)) # data = np.array( # [ # tmp_row + [None] * (max_col - len(tmp_row)) # for tmp_row in tmp # ], # dtype=\"O\", # ) # else: # if isinstance(filedata, bytes): # csvreader = aiocsv.AsyncReader( # io.StringIO(filedata.decode(\"utf-8\")) # ) # else: # csvreader = aiocsv.AsyncReader(filedata) # tmp = await list(csvreader) # max_col = max(map(len, tmp)) # data = np.array( # [tmp_row + [None] * (max_col - len(tmp_row)) for tmp_row in tmp], # dtype=\"O\", # ) # else: # raise NotImplementedError( # f\"Frame from Excel not implemented for ext: {ext}\" # ) # return data def __getattr__ ( self , signame : str ) -> Sig : \"\"\"Provides dot notation access to Sigs if their names conform to dot notation. Parameters ---------- signame : str Must conform to dot notation (no spaces or special characters, starts with non numeric char, etc.) Returns ------- Sig Reference to Sig in Self \"\"\" if signame . startswith ( \"_\" ): raise AttributeError # Probably dont want to let it return _** return self . __getitem__ ( signame ) @overload def __getitem__ ( self , index : str ) -> Sig : pass @overload def __getitem__ ( self , index : Frame | list [ str ] | slice | set [ str ] | tuple [ str ] ) -> Frame : pass @profile def __getitem__ ( self , index : Frame | list [ str ] | set [ str ] | tuple [ str ] | str | slice ) -> Frame | Sig : \"\"\"Frame item getter. Parameters ---------- index : Frame | list[str] | slice | set[str] | str Frame, list of Sig names, slice of Returns ------- Frame | Sig New instance of Frame if index is Frame, list[str], slice. Reference to the Sig if str is a sig name. Examples -------- >>>TEST_LIST = [1.0, 2.0, 3.0] >>>TEST_ARR = np.array(TEST_LIST) >>>TEST_TIME = [0.0, 1.0, 2.0] >>>TEST_TLINE = TLine(TEST_TIME) >>>TEST_SIG = Sig(data=TEST_ARR, tline=TEST_TLINE, name=\"TestSig\") >>>assert frm[\"TestSig\"] == TEST_SIG # The reference to TEST_SIG was broken when appended to frm >>>assert frm[\"TestSig\"] is frm.sigs[\"TestSig\"] # The reference is preserved to the Sig in frm >>>assert frm[[\"TestSig\", \"TestSig2\"]] is not frm # The reference is broken to frm >>>assert frm[[\"TestSig\", \"TestSig2\"]] == frm >>>slicedfrm = frm[0:1.1] # sliced in time, with no step there is no resample >>>assert slicedfrm.tstart == 0.0 >>>assert slicedfrm.tend == 1.0 >>>assert slicedfrm.TestSig.nsamples == 2 # note 2 samples since no step was defined in slice >>>sliced_w_resample = frm[0:1.1:0.1] # Sliced in time, resamples to slice since step was defined. >>>assert sliced_w_resample.tstart == 0.0 >>>assert sliced_w_resample.tend == 1.0 >>>assert sliced_w_resample.TestSig.nsamples == 11 # note 2 samples since no step was defined in slice \"\"\" res = Frame ( name = self . name ) if isinstance ( index , Frame ): # This should be a boolean frame with indices that should be returned raise NotImplementedError ( \"Get item by boolean index is not implemented.\" ) if isinstance ( index , str ): self . _check_dot ( index ) if index not in self . sigs : index = self . check_for_alt ( index ) return self . sigs [ index ] if isinstance ( index , list | set | tuple ): if not index : # if empty return all sigs index = list ( self . sigs . keys ()) for signame in index : # Check for _dot notation, calculate derivatives if not present self . _check_dot ( signame ) if signame not in self . sigs : signame = self . check_for_alt ( signame ) res . append ( self . sigs [ signame ]) # improve to slice instead of re-build? elif isinstance ( index , slice ): # slicing is in time axis. if isinstance ( index . start , datetime ): ind_start = index . start . timestamp () else : ind_start = index . start if isinstance ( index . stop , datetime ): ind_stop = index . stop . timestamp () else : ind_stop = index . stop if isinstance ( index . step , timedelta ): step = index . step . total_seconds () else : step = index . step if index . step is None : # No step, so dont resample for tline in self . tlines : if index . start is None : start = tline . tstart else : start = ind_start if index . stop is None : # Since python is r-worded, this is a special case. # Need to make sure the last sample is included. stop = tline . tend + 0.000001 else : stop = ind_stop inds = np . logical_and ( tline . unix >= start , tline . unix < stop ) if np . any ( inds ): new_tline = TLine ( tline [ inds ]) for signame in self . tlines . sigs [ tline . idn ]: unks = {} old_sig = self . sigs [ signame ] for key , val in old_sig . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : unks . update ({ key : val }) new_sig = Sig ( data = old_sig . data [ inds ], tline = new_tline , name = old_sig . name , unit = old_sig . unit , interp_method = old_sig . interp_method , connect_gaps = old_sig . connect_gaps , data_enum = old_sig . data_enum , ** unks , ) res . append ( new_sig ) else : # Step was defined so we need to resample for tline in self . tlines : if index . start is None : start = tline . tstart else : start = ind_start if index . stop is None : stop = tline . tend else : stop = ind_stop new_tline = TLine ( tstart = start , tend = stop , period = step ) for signame in self . tlines . sigs [ tline . idn ]: res . append ( self . sigs [ signame ] . resample ( sample_to = new_tline )) else : raise NotImplementedError ( f \"Get item for index of type { type ( index ) } not implemented\" ) return res @profile def check_for_alt ( self , index ): \"\"\"Check for alternate name in case of missing dot notation\"\"\" # alt = difflib.get_close_matches( # index, self.sigs.keys(), n=1, cutoff=self.CUTOFF # ) alt = extractOne ( index , self . sigs . keys ()) if alt : if len ( alt [ 0 ]) != len ( index ): raise KeyError ( f \"' { index } ' is not in frame: { self . name } \" ) deltas_ok = [ x == \".\" or x == \" \" if x != y else True for x , y in zip ( index , alt [ 0 ]) ] if all ( deltas_ok ): index = alt [ 0 ] else : raise KeyError ( f \"' { index } ' is not in frame: { self . name } \" ) else : raise KeyError ( f \"' { index } ' is not in frame: { self . name } \" ) return index def __contains__ ( self , key ): \"\"\"Checks if key is a signame in frame\"\"\" self . _check_dot ( key ) res = key in self . sigs if res : return True else : try : _ = self . check_for_alt ( key ) return True except KeyError : return False def _check_dot ( self , signame : str ): \"\"\"Check if signame is _dot and calc deriv if needed.\"\"\" if signame not in self . sigs : if \"_dot\" in signame : n_dot = signame . count ( \"dot\" ) base_name = signame [ 0 : signame . index ( \"_dot\" )] if base_name not in self . sigs : base_name = self . check_for_alt ( base_name ) if base_name + \"_\" + \"dot\" * n_dot not in self . sigs : new_sig = self [ base_name ] . dot ( n_dot ) self . append ( new_sig ) @profile def subset ( self , index : slice , sigs : list [ str ] = None ): \"\"\"Get a subset of frame. Allows slicing by signals and in timeline.\"\"\" res = Frame ( name = self . name ) if sigs is None or not sigs : sigs = self . sigs . keys () if isinstance ( index . start , datetime ): ind_start = index . start . timestamp () else : ind_start = index . start if isinstance ( index . stop , datetime ): ind_stop = index . stop . timestamp () else : ind_stop = index . stop if isinstance ( index . step , timedelta ): step = index . step . total_seconds () else : step = index . step if index . step is None : # No step, so dont resample for tline in self . tlines : if any ( x in sigs for x in self . tlines . sigs [ tline . idn ]): if index . start is None : start = tline . tstart else : start = ind_start if index . stop is None : # Since python is r-worded, this is a special case. # Need to make sure the last sample is included. stop = tline . tend + 0.000001 else : stop = ind_stop inds = np . logical_and ( tline . unix >= start , tline . unix < stop ) if np . any ( inds ): new_tline = TLine ( tline [ inds ]) for signame in self . tlines . sigs [ tline . idn ]: if signame in sigs : old_sig = self . sigs [ signame ] new_sig = Sig ( old_sig ) new_sig . data = old_sig . data [ inds ] new_sig . tline = new_tline res . append ( new_sig ) else : # Step was defined so we need to resample for tline in self . tlines : if index . start is None : start = tline . tstart else : start = ind_start if index . stop is None : stop = tline . tend else : stop = ind_stop new_tline = TLine ( tstart = start , tend = stop , period = step ) for signame in self . tlines . sigs [ tline . idn ]: if signame in sigs : res . append ( self . sigs [ signame ] . resample ( sample_to = new_tline )) return res def __iter__ ( self ): \"\"\"Iterate.\"\"\" return iter ( self . sigs . values ()) def __repr__ ( self ) -> str : \"\"\"Return repr string.\"\"\" sigs = self . sigs . keys () reprstr = f \" { self . __class__ . __qualname__ } ([ { ', ' . join ( sigs ) } ])\" return reprstr def __eq__ ( self , other : Self ) -> bool : \"\"\"Check equality.\"\"\" if isinstance ( other , self . __class__ ): iseq = self . sigs == other . sigs and self . tlines == other . tlines return iseq return False nsamples : int property Cumulative samples (counting unique timelines as well). nsigs : int property Number of Sigs in collection. tend : float | None property Latest end time from TLine collection. Returns: float \u2013 Time in unix. tend_iso : npt . NDArray [ np . datetime64 ] property Latest end time from TLine collection. Returns: float \u2013 Time in iso. tline : TLine | None property If frame has only one tline, return it. tstart : float | None property Earliest start time from TLine collection. Returns: float \u2013 Time in unix. tstart_iso property Earliest start time from TLine collection. Returns: float \u2013 Time in iso. __contains__ ( key ) Checks if key is a signame in frame Source code in ccg\\data\\tsdata.py 858 859 860 861 862 863 864 865 866 867 868 869 def __contains__ ( self , key ): \"\"\"Checks if key is a signame in frame\"\"\" self . _check_dot ( key ) res = key in self . sigs if res : return True else : try : _ = self . check_for_alt ( key ) return True except KeyError : return False __eq__ ( other ) Check equality. Source code in ccg\\data\\tsdata.py 955 956 957 958 959 960 961 def __eq__ ( self , other : Self ) -> bool : \"\"\"Check equality.\"\"\" if isinstance ( other , self . __class__ ): iseq = self . sigs == other . sigs and self . tlines == other . tlines return iseq return False __getattr__ ( signame ) Provides dot notation access to Sigs if their names conform to dot notation. Parameters: signame ( str ) \u2013 Must conform to dot notation (no spaces or special characters, starts with non numeric char, etc.) Returns: Sig \u2013 Reference to Sig in Self Source code in ccg\\data\\tsdata.py 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 def __getattr__ ( self , signame : str ) -> Sig : \"\"\"Provides dot notation access to Sigs if their names conform to dot notation. Parameters ---------- signame : str Must conform to dot notation (no spaces or special characters, starts with non numeric char, etc.) Returns ------- Sig Reference to Sig in Self \"\"\" if signame . startswith ( \"_\" ): raise AttributeError # Probably dont want to let it return _** return self . __getitem__ ( signame ) __getitem__ ( index ) Frame item getter. Parameters: index ( Frame | list [ str ] | slice | set [ str ] | str ) \u2013 Frame, list of Sig names, slice of Returns: Frame | Sig \u2013 New instance of Frame if index is Frame, list[str], slice. Reference to the Sig if str is a sig name. Examples: >>>TEST_LIST = [1.0, 2.0, 3.0] >>>TEST_ARR = np.array(TEST_LIST) >>>TEST_TIME = [0.0, 1.0, 2.0] >>>TEST_TLINE = TLine(TEST_TIME) >>>TEST_SIG = Sig(data=TEST_ARR, tline=TEST_TLINE, name=\"TestSig\") >>>assert frm[\"TestSig\"] == TEST_SIG # The reference to TEST_SIG was broken when appended to frm >>>assert frm[\"TestSig\"] is frm.sigs[\"TestSig\"] # The reference is preserved to the Sig in frm >>>assert frm[[\"TestSig\", \"TestSig2\"]] is not frm # The reference is broken to frm >>>assert frm[[\"TestSig\", \"TestSig2\"]] == frm >>>slicedfrm = frm[0:1.1] # sliced in time, with no step there is no resample >>>assert slicedfrm.tstart == 0.0 >>>assert slicedfrm.tend == 1.0 >>>assert slicedfrm.TestSig.nsamples == 2 # note 2 samples since no step was defined in slice >>>sliced_w_resample = frm[0:1.1:0.1] # Sliced in time, resamples to slice since step was defined. >>>assert sliced_w_resample.tstart == 0.0 >>>assert sliced_w_resample.tend == 1.0 >>>assert sliced_w_resample.TestSig.nsamples == 11 # note 2 samples since no step was defined in slice Source code in ccg\\data\\tsdata.py 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 @profile def __getitem__ ( self , index : Frame | list [ str ] | set [ str ] | tuple [ str ] | str | slice ) -> Frame | Sig : \"\"\"Frame item getter. Parameters ---------- index : Frame | list[str] | slice | set[str] | str Frame, list of Sig names, slice of Returns ------- Frame | Sig New instance of Frame if index is Frame, list[str], slice. Reference to the Sig if str is a sig name. Examples -------- >>>TEST_LIST = [1.0, 2.0, 3.0] >>>TEST_ARR = np.array(TEST_LIST) >>>TEST_TIME = [0.0, 1.0, 2.0] >>>TEST_TLINE = TLine(TEST_TIME) >>>TEST_SIG = Sig(data=TEST_ARR, tline=TEST_TLINE, name=\"TestSig\") >>>assert frm[\"TestSig\"] == TEST_SIG # The reference to TEST_SIG was broken when appended to frm >>>assert frm[\"TestSig\"] is frm.sigs[\"TestSig\"] # The reference is preserved to the Sig in frm >>>assert frm[[\"TestSig\", \"TestSig2\"]] is not frm # The reference is broken to frm >>>assert frm[[\"TestSig\", \"TestSig2\"]] == frm >>>slicedfrm = frm[0:1.1] # sliced in time, with no step there is no resample >>>assert slicedfrm.tstart == 0.0 >>>assert slicedfrm.tend == 1.0 >>>assert slicedfrm.TestSig.nsamples == 2 # note 2 samples since no step was defined in slice >>>sliced_w_resample = frm[0:1.1:0.1] # Sliced in time, resamples to slice since step was defined. >>>assert sliced_w_resample.tstart == 0.0 >>>assert sliced_w_resample.tend == 1.0 >>>assert sliced_w_resample.TestSig.nsamples == 11 # note 2 samples since no step was defined in slice \"\"\" res = Frame ( name = self . name ) if isinstance ( index , Frame ): # This should be a boolean frame with indices that should be returned raise NotImplementedError ( \"Get item by boolean index is not implemented.\" ) if isinstance ( index , str ): self . _check_dot ( index ) if index not in self . sigs : index = self . check_for_alt ( index ) return self . sigs [ index ] if isinstance ( index , list | set | tuple ): if not index : # if empty return all sigs index = list ( self . sigs . keys ()) for signame in index : # Check for _dot notation, calculate derivatives if not present self . _check_dot ( signame ) if signame not in self . sigs : signame = self . check_for_alt ( signame ) res . append ( self . sigs [ signame ]) # improve to slice instead of re-build? elif isinstance ( index , slice ): # slicing is in time axis. if isinstance ( index . start , datetime ): ind_start = index . start . timestamp () else : ind_start = index . start if isinstance ( index . stop , datetime ): ind_stop = index . stop . timestamp () else : ind_stop = index . stop if isinstance ( index . step , timedelta ): step = index . step . total_seconds () else : step = index . step if index . step is None : # No step, so dont resample for tline in self . tlines : if index . start is None : start = tline . tstart else : start = ind_start if index . stop is None : # Since python is r-worded, this is a special case. # Need to make sure the last sample is included. stop = tline . tend + 0.000001 else : stop = ind_stop inds = np . logical_and ( tline . unix >= start , tline . unix < stop ) if np . any ( inds ): new_tline = TLine ( tline [ inds ]) for signame in self . tlines . sigs [ tline . idn ]: unks = {} old_sig = self . sigs [ signame ] for key , val in old_sig . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : unks . update ({ key : val }) new_sig = Sig ( data = old_sig . data [ inds ], tline = new_tline , name = old_sig . name , unit = old_sig . unit , interp_method = old_sig . interp_method , connect_gaps = old_sig . connect_gaps , data_enum = old_sig . data_enum , ** unks , ) res . append ( new_sig ) else : # Step was defined so we need to resample for tline in self . tlines : if index . start is None : start = tline . tstart else : start = ind_start if index . stop is None : stop = tline . tend else : stop = ind_stop new_tline = TLine ( tstart = start , tend = stop , period = step ) for signame in self . tlines . sigs [ tline . idn ]: res . append ( self . sigs [ signame ] . resample ( sample_to = new_tline )) else : raise NotImplementedError ( f \"Get item for index of type { type ( index ) } not implemented\" ) return res __iter__ () Iterate. Source code in ccg\\data\\tsdata.py 945 946 947 def __iter__ ( self ): \"\"\"Iterate.\"\"\" return iter ( self . sigs . values ()) __repr__ () Return repr string. Source code in ccg\\data\\tsdata.py 949 950 951 952 953 def __repr__ ( self ) -> str : \"\"\"Return repr string.\"\"\" sigs = self . sigs . keys () reprstr = f \" { self . __class__ . __qualname__ } ([ { ', ' . join ( sigs ) } ])\" return reprstr append ( item , append_existing_signals = False , interweave_tlines = False ) Append to CCG Frame in place. Source code in ccg\\data\\tsdata.py 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 def append ( self , item : Sig | Frame | list [ Sig ], append_existing_signals : bool = False , interweave_tlines : bool = False , ): \"\"\"Append to CCG Frame in place.\"\"\" if isinstance ( item , Frame ): sigs_to_apnd = list ( item . sigs . keys ()) for _ , new_sigs in item . tlines . sigs . items (): for sig in new_sigs : if append_existing_signals and sig in self and sig in sigs_to_apnd : check_overlap ( self [ sig ], item [ sig ], interweave_tlines ) old_idn = self . tlines . idns [ sig ] new_tline = self . tlines [ old_idn ] . append_to_new ( item [ sig ]) if new_tline . is_monotonic_increasing : for old_sig in list ( self . tlines . sigs [ old_idn ]): if old_sig in item : self . tlines . remove ( old_sig ) self [ old_sig ] . tline = new_tline self . tlines . append ( self [ old_sig ]) # for references self [ old_sig ] . _data . append ( item [ old_sig ] . _data ) # get the rest of the attributes if item [ old_sig ] . connect_gaps is not None : self [ old_sig ] . connect_gaps = item [ old_sig ] . connect_gaps if item [ old_sig ] . data_enum is not None : self [ old_sig ] . data_enum = item [ old_sig ] . data_enum if item [ old_sig ] . interp_method is not None : self [ old_sig ] . interp_method = item [ old_sig ] . interp_method if item [ old_sig ] . unit is not None : self [ old_sig ] . unit = item [ old_sig ] . unit # Check for unknown attributes. the new signal value will overide the original. for key , val in item [ old_sig ] . __dict__ . items (): if ( not key . startswith ( \"_\" ) and key not in SIG_ATTRS ): setattr ( self [ old_sig ], key , val ) sigs_to_apnd . remove ( old_sig ) else : raise NotImplementedError ( \"batch appends not implemented for non-monoton\" ) for signame in sigs_to_apnd : sig = item [ signame ] self . _append_sig ( sig , append_existing_signals , interweave_tlines ) elif isinstance ( item , list ): for sig in item : self . _append_sig ( sig , append_existing_signals , interweave_tlines ) else : self . _append_sig ( item , append_existing_signals , interweave_tlines ) check_for_alt ( index ) Check for alternate name in case of missing dot notation Source code in ccg\\data\\tsdata.py 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 @profile def check_for_alt ( self , index ): \"\"\"Check for alternate name in case of missing dot notation\"\"\" # alt = difflib.get_close_matches( # index, self.sigs.keys(), n=1, cutoff=self.CUTOFF # ) alt = extractOne ( index , self . sigs . keys ()) if alt : if len ( alt [ 0 ]) != len ( index ): raise KeyError ( f \"' { index } ' is not in frame: { self . name } \" ) deltas_ok = [ x == \".\" or x == \" \" if x != y else True for x , y in zip ( index , alt [ 0 ]) ] if all ( deltas_ok ): index = alt [ 0 ] else : raise KeyError ( f \"' { index } ' is not in frame: { self . name } \" ) else : raise KeyError ( f \"' { index } ' is not in frame: { self . name } \" ) return index clean_names () Cleans signal names. Source code in ccg\\data\\tsdata.py 363 364 365 366 367 368 369 370 371 372 373 def clean_names ( self ): \"\"\"Cleans signal names.\"\"\" rename_list = {} for signame , _ in self . sigs . items (): clean_name = ccg . util . clean_name ( signame ) if clean_name != signame : rename_list . update ({ signame : clean_name }) for signame , clean_name in rename_list . items (): _LOGGER . debug ( \" %s renamed to %s \" , signame , clean_name ) self [ signame ] . name = clean_name clear () Clears frame in place. Source code in ccg\\data\\tsdata.py 358 359 360 361 def clear ( self ): \"\"\"Clears frame in place.\"\"\" self . sigs : dict [ str , Sig ] = {} self . tlines = TLineCollection ( self ) from_excel ( filename , tline_col = None , signame_row = None , signame_regex = None , filedata = None , sigunit_row = None , sigdata_row = None ) Generate frame from excel file. Parameters: filename ( str | Path ) \u2013 tline_col ( int | str , default: None ) \u2013 Column to use for an index signame_row ( int , default: None ) \u2013 Row with names to parse with _regex signame_regex ( str , default: None ) \u2013 regex string to parse signal names. Use named groups for parameters to pass into Sig instatiation, for example name, units, etc. example here: https://regex101.com/r/bfBrdf/6 filedata ( BytesIO | StringIO | bytes , default: None ) \u2013 string or bytes io. filename will only be used for ext, name, etc. Source code in ccg\\data\\tsdata.py 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 @profile def from_excel ( self , filename : str | Path , tline_col : int | str = None , signame_row : int = None , signame_regex : str = None , filedata : BytesIO | StringIO | bytes = None , sigunit_row : int = None , sigdata_row : int = None , ) -> Frame : \"\"\"Generate frame from excel file. Parameters ---------- filename tline_col Column to use for an index signame_row Row with names to parse with _regex signame_regex regex string to parse signal names. Use named groups for parameters to pass into Sig instatiation, for example name, units, etc. example here: https://regex101.com/r/bfBrdf/6 filedata string or bytes io. filename will only be used for ext, name, etc. \"\"\" tic = datetime . now () if isinstance ( filename , str ): filename = Path ( filename ) if signame_row is None : signame_row = 0 if tline_col is None : tline_col = 0 if signame_regex is None : signame_regex = r \"(?P<name>^.*?)(?:(?:\\s?\\((?P<unit>(?!.*\\().*)\\))|$)\" # Default regex `signal name (unit)`-> `{'name':'signal name','unit':'unit'` # https://regex101.com/r/bfBrdf/6 regex = re . compile ( signame_regex ) data = self . read_filedata ( filename , filedata ) toc = datetime . now () - tic _LOGGER . debug ( \"read %s in %.3f .\" , filename , toc . total_seconds ()) tic = datetime . now () if isinstance ( signame_row , str ): for i , row in enumerate ( data ): if row [ 0 ] == signame_row : signame_row = i break else : raise ValueError ( f \"Signal Name Row: { signame_row } not found in first column of data file.\" ) signames = data [ signame_row , :] . astype ( \"str\" ) signames = np . char . strip ( signames ) if sigunit_row is not None : sigunits = data [ sigunit_row , :] . astype ( \"str\" ) sig_args = [ { \"name\" : name , \"unit\" : unit } for name , unit in zip ( signames , sigunits ) ] else : sig_args = [ regex . match ( signame ) . groupdict () for signame in signames ] # Check for duplicate names and add _dup existing = [] for sig in sig_args : if sig [ \"name\" ] not in existing : existing . append ( sig [ \"name\" ]) else : existing . append ( sig [ \"name\" ] + \"_dup\" ) sig [ \"name\" ] = sig [ \"name\" ] + \"_dup\" if isinstance ( tline_col , str ): tline_col = np . where ( signames == tline_col ) if tline_col [ 0 ] . size == 0 : raise ValueError ( \"tline_col is not in signames.\" ) else : tline_col = [ tline_col ] if sigdata_row is None : sigdata_row = signame_row + 1 tmp : npt . NDArray = data [ sigdata_row :, tline_col ] . ravel () try : tmp = tmp . astype ( \"float\" ) except ValueError : tmp = tmp . astype ( type ( tmp [ 0 ])) tline = TLine ( tmp ) for i , kwargs in enumerate ( sig_args ): if i != tline_col [ 0 ]: sigtype = type ( data [ sigdata_row , i ]) sigdata = data [ sigdata_row :, i ] . ravel () . astype ( sigtype ) if sigtype is str : try : sigdata = sigdata . astype ( float ) except ValueError : pass new_sig = Sig ( data = sigdata , tline = tline , ** kwargs , ) self . append ( new_sig ) toc = datetime . now () - tic _LOGGER . debug ( \"built frame in %.3f .\" , toc . total_seconds ()) tic = datetime . now () return self plot () Plot data frame. Source code in ccg\\data\\tsdata.py 384 385 386 387 388 389 def plot ( self ): \"\"\"Plot data frame.\"\"\" from ccg.ui.plot import Plot plt = Plot ( self ) plt . plot () read_filedata ( filename , filedata = None ) Reads file data for building frame from file Source code in ccg\\data\\tsdata.py 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 @profile def read_filedata ( self , filename : Path , filedata : BytesIO | StringIO | bytes | None = None ): \"\"\"Reads file data for building frame from file\"\"\" ext = filename . suffix if ext in [ \".xlsx\" , \".xlsm\" , \".XLSX\" , \".XLSM\" ]: # Use openpyxl if filedata is None : wb = openpyxl . load_workbook ( filename = filename , read_only = True , data_only = True ) else : wb = openpyxl . load_workbook ( filename = filedata , read_only = True , data_only = True ) ws = wb . active data = ws . values data = np . array ( list ( data )) wb . close () elif ext in [ \".xls\" , \".XLS\" ]: # Use xlrd wb_xls : xlrd . book . Book = xlrd . open_workbook ( filename = filename , file_contents = filedata ) ws = wb_xls . sheet_by_index ( 0 ) # data = np.array(ws._cell_values) data = np . empty ( shape = ( ws . nrows , ws . ncols ), dtype = \"O\" ) for i in range ( ws . ncols ): data [:, i ] = ws . col_values ( i ) elif ext in [ \".csv\" , \".CSV\" ]: if filedata is None : with open ( filename , \"r\" , encoding = \"utf8\" ) as file : csvreader = csv . reader ( file , dialect = \"excel\" ) tmp = list ( csvreader ) max_col = max ( map ( len , tmp )) data = np . array ( [ tmp_row + [ None ] * ( max_col - len ( tmp_row )) for tmp_row in tmp ], dtype = \"O\" , ) else : if isinstance ( filedata , bytes ): csvreader = csv . reader ( io . StringIO ( filedata . decode ( \"utf-8\" ))) else : csvreader = csv . reader ( filedata ) tmp = list ( csvreader ) max_col = max ( map ( len , tmp )) data = np . array ( [ tmp_row + [ None ] * ( max_col - len ( tmp_row )) for tmp_row in tmp ], dtype = \"O\" , ) else : raise NotImplementedError ( f \"Frame from Excel not implemented for ext: { ext } \" ) return data remove ( signames ) Removes sigs from frame. Source code in ccg\\data\\tsdata.py 375 376 377 378 379 380 381 382 def remove ( self , signames : str | list [ str ]): \"\"\"Removes sigs from frame.\"\"\" if not isinstance ( signames , list ): signames = [ signames ] for signame in signames : if signame in self : self . tlines . remove ( signame ) self . sigs . pop ( signame , None ) resample ( sample_to , sigs = None , inplace = False , prefix = None , suffix = None , ** kwargs ) Resample Frame to a sample_to TLine. Parameters: sample_to ( TLine ) \u2013 TLine to resample to sigs ( str | list [ str ] | None , default: None ) \u2013 list of sigs to resample, full frame if None, by default None inplace ( bool | None , default: False ) \u2013 if True, will resample signals and append (id prefix or suffix is not None) or replace inplace. By default False prefix ( str | None , default: None ) \u2013 prefix to signame, by default None suffix ( str | None , default: None ) \u2013 suffix to signame, by default None **kwargs \u2013 Additional arguments passed to Sig.resample() Returns: Frame \u2013 Returns Self if inplace, else a new Frame Source code in ccg\\data\\tsdata.py 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 def resample ( self , sample_to : TLine , sigs : str | list [ str ] | None = None , inplace : bool | None = False , prefix : str | None = None , suffix : str | None = None , ** kwargs , ): \"\"\"Resample Frame to a `sample_to` TLine. Parameters ---------- sample_to : TLine TLine to resample to sigs : str | list[str] | None, optional list of sigs to resample, full frame if None, by default None inplace : bool | None, optional if True, will resample signals and append (id prefix or suffix is not None) or replace inplace. By default False prefix : str | None, optional prefix to signame, by default None suffix : str | None, optional suffix to signame, by default None **kwargs Additional arguments passed to `Sig.resample()` Returns ------- Frame Returns Self if inplace, else a new Frame \"\"\" if inplace : res = self else : res = Frame () if sigs is not None : if isinstance ( sigs , str ): sigs = [ sigs ] else : sigs = list ( self . sigs . keys ()) for sig in sigs : newsig = self . sigs [ sig ] . resample ( sample_to , ** kwargs ) if prefix is not None : newsig . name = prefix + newsig . name if suffix is not None : newsig . name = newsig . name + suffix if inplace and prefix is None and suffix is None : res . remove ( sig ) res . append ( newsig ) return res sort ( remove_safe_duplicates = False , remove_all_duplicates = False ) Sort signals by timeline for monoton increasing. Source code in ccg\\data\\tsdata.py 339 340 341 342 343 344 345 346 def sort ( self , remove_safe_duplicates = False , remove_all_duplicates = False ): \"\"\"Sort signals by timeline for monoton increasing.\"\"\" for _ , sig in self . sigs . items (): sig . sort_tline ( inplace = True , remove_safe_duplicates = remove_safe_duplicates , remove_all_duplicates = remove_all_duplicates , ) subset ( index , sigs = None ) Get a subset of frame. Allows slicing by signals and in timeline. Source code in ccg\\data\\tsdata.py 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 @profile def subset ( self , index : slice , sigs : list [ str ] = None ): \"\"\"Get a subset of frame. Allows slicing by signals and in timeline.\"\"\" res = Frame ( name = self . name ) if sigs is None or not sigs : sigs = self . sigs . keys () if isinstance ( index . start , datetime ): ind_start = index . start . timestamp () else : ind_start = index . start if isinstance ( index . stop , datetime ): ind_stop = index . stop . timestamp () else : ind_stop = index . stop if isinstance ( index . step , timedelta ): step = index . step . total_seconds () else : step = index . step if index . step is None : # No step, so dont resample for tline in self . tlines : if any ( x in sigs for x in self . tlines . sigs [ tline . idn ]): if index . start is None : start = tline . tstart else : start = ind_start if index . stop is None : # Since python is r-worded, this is a special case. # Need to make sure the last sample is included. stop = tline . tend + 0.000001 else : stop = ind_stop inds = np . logical_and ( tline . unix >= start , tline . unix < stop ) if np . any ( inds ): new_tline = TLine ( tline [ inds ]) for signame in self . tlines . sigs [ tline . idn ]: if signame in sigs : old_sig = self . sigs [ signame ] new_sig = Sig ( old_sig ) new_sig . data = old_sig . data [ inds ] new_sig . tline = new_tline res . append ( new_sig ) else : # Step was defined so we need to resample for tline in self . tlines : if index . start is None : start = tline . tstart else : start = ind_start if index . stop is None : stop = tline . tend else : stop = ind_stop new_tline = TLine ( tstart = start , tend = stop , period = step ) for signame in self . tlines . sigs [ tline . idn ]: if signame in sigs : res . append ( self . sigs [ signame ] . resample ( sample_to = new_tline )) return res valid ( gatecoll , tline = None ) Returns a new Frame, invalid data replaced with nan. calc'd on tline or combined TLine if None Parameters: gatecoll ( GateColl ) \u2013 Collection of gating conditions tline ( TLine | None , default: None ) \u2013 TLine to calculate validity on, by default None Returns: Frame \u2013 New instance of Frame Source code in ccg\\data\\tsdata.py 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 def valid ( self , gatecoll : GateColl , tline : TLine | None = None ) -> Frame : \"\"\"Returns a new Frame, invalid data replaced with nan. calc'd on `tline` or combined TLine if None Parameters ---------- gatecoll : GateColl Collection of gating conditions tline : TLine | None, optional TLine to calculate validity on, by default None Returns ------- Frame New instance of Frame \"\"\" res = Frame ( name = self . name ) # if tline is None: # tline = self.tlines.get_fastest() valid_sig = gatecoll . validate ( self , tline ) for tmp_tline in self . tlines : if tmp_tline . nsamples > 1 : b_valid = valid_sig . interp ( tmp_tline ) . data for sig in self . tlines . sigs [ tmp_tline . idn ]: newsig = Sig ( self [ sig ]) nan = np . NaN if newsig . data . dtype . kind in [ \"i\" , \"u\" ]: newsig . data = newsig . data . astype ( \"float\" ) elif newsig . data . dtype . kind in [ \"U\" , \"S\" ]: nan = \"\" newsig . data [ ~ b_valid ] = nan res . append ( newsig ) return res SgCoef Store Savitzky Golay coeficients. Source code in ccg\\data\\tsdata.py 2601 2602 2603 2604 2605 2606 2607 2608 2609 2610 2611 2612 2613 2614 2615 2616 2617 2618 2619 2620 2621 2622 2623 2624 2625 2626 2627 2628 2629 2630 2631 2632 2633 2634 2635 2636 2637 2638 2639 2640 2641 2642 2643 2644 class SgCoef : \"\"\"Store Savitzky Golay coeficients.\"\"\" __slots__ = ( \"orig_index\" , \"sample_to_index\" , \"n_win_orig\" , \"n_ord\" , \"conv\" , \"uniqinvs\" , \"n_uniq\" , \"inds\" , ) def __init__ ( self , orig_index : int = None , sample_to_index : int = None , n_win_orig : int = None , n_ord : int = None , conv : npt . NDArray = None , uniqinvs : npt . NDArray = None , n_uniq : int = None , inds : npt . NDArray = None , ): self . orig_index = orig_index self . sample_to_index = sample_to_index self . n_win_orig = n_win_orig self . n_ord = n_ord self . conv = conv self . uniqinvs = uniqinvs self . n_uniq = n_uniq self . inds = inds def clear ( self ): \"\"\"Clear SgCoef.\"\"\" self . orig_index = None self . sample_to_index = None self . n_win_orig = None self . n_ord = None self . conv = None self . uniqinvs = None self . n_uniq = None self . inds : npt . NDArray = None clear () Clear SgCoef. Source code in ccg\\data\\tsdata.py 2635 2636 2637 2638 2639 2640 2641 2642 2643 2644 def clear ( self ): \"\"\"Clear SgCoef.\"\"\" self . orig_index = None self . sample_to_index = None self . n_win_orig = None self . n_ord = None self . conv = None self . uniqinvs = None self . n_uniq = None self . inds : npt . NDArray = None Sig CCG Sig class. Contains signal data and timeline. Parameters: data ( Sig | NDArray | list | None , default: None ) \u2013 Data source for the signal. tline ( TLine | None , default: None ) \u2013 Timeline instance for signal. Must be same length as data. name ( str | None , default: None ) \u2013 Signal name, must be unique in a Frame . unit ( str | None , default: None ) \u2013 Optional unit. interp_method ( InterpMethod | None , default: None ) \u2013 interpolation method for signal. parent ( Frame | None , default: None ) \u2013 Reference to the 'Frame' if this is in a frame. connect_gaps ( bool | None , default: None ) \u2013 Option for plotting using Plot data_enum ( SigEnum | None , default: None ) \u2013 Enumeration definition to alias values, used for plotting string data. data_range ( list [ float ] | None , default: None ) \u2013 Used for plot scaling. **kwargs \u2013 Argument for inserting unknown attributes. Source code in ccg\\data\\tsdata.py 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622 1623 1624 1625 1626 1627 1628 1629 1630 1631 1632 1633 1634 1635 1636 1637 1638 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 1649 1650 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664 1665 1666 1667 1668 1669 1670 1671 1672 1673 1674 1675 1676 1677 1678 1679 1680 1681 1682 1683 1684 1685 1686 1687 1688 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699 1700 1701 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711 1712 1713 1714 1715 1716 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741 1742 1743 1744 1745 1746 1747 1748 1749 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 1767 1768 1769 1770 1771 1772 1773 1774 1775 1776 1777 1778 1779 1780 1781 1782 1783 1784 1785 1786 1787 1788 1789 1790 1791 1792 1793 1794 1795 1796 1797 1798 1799 1800 1801 1802 1803 1804 1805 1806 1807 1808 1809 1810 1811 1812 1813 class Sig : \"\"\" CCG Sig class. Contains signal data and timeline. Parameters ---------- data Data source for the signal. tline Timeline instance for signal. Must be same length as data. name Signal name, must be unique in a `Frame`. unit Optional unit. interp_method interpolation method for signal. parent Reference to the 'Frame' if this is in a frame. connect_gaps Option for plotting using `Plot` data_enum Enumeration definition to alias values, used for plotting string data. data_range Used for plot scaling. **kwargs Argument for inserting unknown attributes. \"\"\" _FGAP = 5 @profile def __init__ ( self , data : Sig | npt . NDArray | list | None = None , tline : TLine | None = None , name : str | None = None , unit : str | None = None , interp_method : InterpMethod | None = None , parent : Frame | None = None , connect_gaps : bool | None = None , data_enum : SigEnum | None = None , nsamples : int | None = None , dtype : npt . DTypeLike = None , data_range : list [ float ] | None = None , ** kwargs , ) -> None : self . parent = parent self . connect_gaps = connect_gaps self . data_enum = data_enum self . base_data = None self . _name = None self . _dtype = dtype self . _data : AllocData = None self . interp_method = None if nsamples is None : self . _shape = None else : self . _shape = ( nsamples ,) if tline is not None : self . tline = tline self . unit = unit self . data_range = data_range for key , value in kwargs . items (): setattr ( self , key , value ) if isinstance ( data , Sig ): # This is here to break references safely self . _dtype = data . _dtype self . _shape = data . _shape self . tline = TLine ( data . tline , nsamples = self . _shape ) self . data = data . _data self . data_range = data . data_range self . interp_method = data . interp_method if unit is None : self . unit = data . unit self . _name = data . name if data_enum is None : self . data_enum = data . data_enum if connect_gaps is None : self . connect_gaps = data . connect_gaps if data_range is not None : self . data_range = data_range for key , val in data . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : setattr ( self , key , val ) elif isinstance ( data , list ): self . data = np . array ( data ) elif isinstance ( data , np . ndarray ): self . data = data elif isinstance ( data , ( float , int , np . number )): if tline is not None : self . data = np . ones ( shape = tline . _unix . shape , dtype = type ( data )) * data # self.data = np.array([data] * tline.unix.size, dtype=type(data)) else : self . data = data elif isinstance ( data , str ): if tline is not None : self . data = np . array ([ data ] * tline . nsamples , dtype = type ( data )) else : self . data = data elif data is None : self . data = None # for pre-allocation else : raise NotImplementedError ( f \"Sig gen from { type ( data ) } is not implemented.\" ) if name is not None : self . _name = name if self . _data is None or self . _dtype . type is np . str_ : # This is a string type so make sure interp is nearest self . interp_method = InterpMethod . NEAREST else : if interp_method is not None : self . interp_method = interp_method if self . nsamples and self . nsamples != self . tline . nsamples : _LOGGER . warning ( \"Length of %s 's TLine: %i doesnt match length of it's data: %i \" , self . name , self . tline . nsamples , self . nsamples , ) @property def name ( self ) -> str : \"\"\"Return signal name.\"\"\" return self . _name @name . setter def name ( self , new_name ): if self . parent is not None : self . parent . _rename_sig ( # pylint: disable=access-member-before-definition self . _name , new_name ) self . _name = new_name @property def data ( self ) -> npt . NDArray : \"\"\"data getter\"\"\" return self . _data [:] @data . setter @profile def data ( self , value : npt . NDArray | AllocData | None ): if self . _data is None : # pre-allocate self . _data = AllocData ( data = value , shape = self . _shape , dtype = self . _dtype ) if self . _shape is None : self . _shape = self . _data . shape if self . _dtype is None : self . _dtype = self . _data . data . dtype if not hasattr ( self , \"tline\" ): self . tline = TLine ( nsamples = self . _shape ) else : self . _data . replace ( value ) @property def max ( self ) -> npt . NBitBase | None : \"\"\"Max value.\"\"\" if np . issubdtype ( self . data . dtype , np . number ): try : return np . nanmax ( self . data ) except ValueError : pass return None @property def min ( self ) -> npt . NBitBase | None : \"\"\"Min value.\"\"\" if np . issubdtype ( self . data . dtype , np . number ): try : return np . nanmin ( self . data ) except ValueError : pass return None @property def nsamples ( self ): return self . _data . nsamples @property def appx_bytes ( self ): \"\"\"Estimated size of data [bytes]. Excludes tline.\"\"\" return self . _data . appx_bytes @property def tstart ( self ): \"\"\"Start if tline.\"\"\" return self . tline . tstart @property def tend ( self ): \"\"\"End of tline.\"\"\" return self . tline . tend @property def tstart_iso ( self ): \"\"\"Start if tline.\"\"\" return self . tline . tstart_iso @property def tend_iso ( self ): \"\"\"End of tline.\"\"\" return self . tline . tend_iso @property def period ( self ): \"\"\"apprx period.\"\"\" return self . tline . period def calc_idn ( self ): \"\"\"Calculate hash for IDN.\"\"\" # tic = datetime.now() idn = xxhash . xxh3_64_intdigest ( self . _data . tobytes ()) # toc = datetime.now() - tic # _LOGGER.debug(\"IDN calc'd for %s in %.3f\", self.name, toc.total_seconds()) return idn + self . tline . idn @profile def append ( self , sig : Sig , interweave_tlines = False , remove_duplicates = False ): \"\"\"Append sig to signal.\"\"\" # Check if timelimes overlap check_overlap ( self , sig , interweave_tlines ) if self . parent is None : self . tline . append_inplace ( sig ) else : nshared = len ( self . parent . tlines . sigs [ self . tline . idn ]) if nshared == 1 : self . tline . append_inplace ( sig ) else : self . tline = self . tline . append_to_new ( sig ) self . _data . append ( sig . _data ) # pylint: disable=access-member-before-definition if not self . tline . is_monotonic_increasing : self . sort_tline ( inplace = True , remove_safe_duplicates = remove_duplicates ) if self . parent is not None : self . parent . tlines . remove ( self . name ) self . parent . tlines . append ( self ) # self.tline = tlref # 2/10/24 now in tlines.append() # get the rest of the attributes if sig . connect_gaps is not None : self . connect_gaps = sig . connect_gaps if sig . data_enum is not None : self . data_enum = sig . data_enum if sig . interp_method is not None : self . interp_method = sig . interp_method if sig . unit is not None : self . unit = sig . unit # Check for unknown attributes. the new signal value will overide the original. for key , val in sig . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : setattr ( self , key , val ) def convert_units ( self , unit : str ) -> Sig : \"\"\"Convert units in place\"\"\" if unit != self . unit : self . data = ccg . util . convert_units ( value = self . data , from_unit = self . unit , to_unit = unit ) if self . data_range : self . data_range = ccg . util . convert_units ( value = self . data_range , from_unit = self . unit , to_unit = unit ) self . unit = unit return self def as_unit ( self , unit : str ) -> Sig : \"\"\"return new sig converted to unit\"\"\" sig = Sig ( self ) sig . convert_units ( unit ) return sig def sort_tline ( self , inplace = True , remove_safe_duplicates = False , remove_all_duplicates = False , ): \"\"\"Sort signal by timeline. Parameters ---------- inplace Sorts signal in place, returns None. remove_duplicates Will remove duplicate timestamps if signal is also duplicated. Returns ------- Sig self if `inplace=True`. \"\"\" inds = np . argsort ( self . tline . unix , kind = \"stable\" ) if inplace : self . tline = TLine ( self . tline . unix [ inds ]) if self . nsamples > 0 : self . data = self . data [ inds ] if remove_safe_duplicates : self . _remove_duplicates ( remove_all_duplicates ) if self . parent is not None : self . parent . tlines . remove ( self . name ) self . parent . tlines . append ( self ) # self.tline = tlref # 2/10/24 now in tlines.append() return self sig = Sig ( self ) # TODO: clean this up to not define, then edit. sig . name = sig . name + \"_sorted\" sig . tline = TLine ( self . tline . unix [ inds ]) if self . nsamples > 0 : sig . data = sig . data [ inds ] if remove_safe_duplicates : sig . _remove_duplicates ( remove_all_duplicates ) # pylint: disable=access-member-before-definition return sig def _remove_duplicates ( self , remove_all_duplicates = False ): \"\"\"Removes duplicate samples if both time and data match. If `remove_all_duplicates=True`, will remove duplicates even if values dont match. **Must be sorted first** Use `self.sort_tline(remove_safe_duplicates=True, remove_all_duplicates=True)` \"\"\" # Check if its monoton increasing now. if not self . tline . is_monotonic_increasing : # find duplicate timestamps inds = self . tline . dt == 0 if self . data . dtype . kind in [ \"i\" , \"u\" , \"f\" ]: data_dt = np . diff ( self . data ) data_dt = data_dt == 0 else : data_dt = self . data [ 1 :] == self . data [ 0 : - 1 ] dups = inds & data_dt dups = np . append ( False , dups ) if np . any ( dups ): _LOGGER . debug ( \"Removed %i duplicates from %s .\" , np . sum ( dups ), self . name ) self . tline = TLine ( self . tline . unix [ ~ dups ]) self . data = self . data [ ~ dups ] # If there are still duplicates, there are different values at the same timestep. if remove_all_duplicates and not self . tline . is_monotonic_increasing : inds = self . tline . dt == 0 dups = inds dups = np . append ( False , dups ) if np . any ( dups ): _LOGGER . warning ( \"Removed %i duplicate timestamps with different values from %s .\" , np . sum ( dups ), self . name , ) self . tline = TLine ( self . tline . unix [ ~ dups ]) self . data = self . data [ ~ dups ] @profile def plot_prep ( self ) -> Sig : \"\"\"Prepare for plotting. Sorts tline and removes duplicates. Inserts NaNs in gaps if `connect_gaps=False | None`. Applies enum if it exists. \"\"\" res = self if not self . tline . is_monotonic_increasing : self . sort_tline ( remove_safe_duplicates = True ) if self . connect_gaps is None or not self . connect_gaps : gaps = np . greater ( self . tline . dt , self . _FGAP * self . tline . period , ) if np . sum ( gaps ) > 0 : res = Sig ( self ) # Make a copy before resampling. tline = TLine ( self . tline . unix [ np . append ( gaps , False )] + ( self . tline . dt [ gaps ] / 2 ) ) if self . _data . data . dtype . kind in ( \"i\" , \"u\" , \"b\" , \"M\" ): # Since numpy is r-worded and cant use a nan in an int, we need to convert to float self . _data . replace ( self . data . astype ( \"float\" , copy = False )) self . _dtype = self . _data . dtype nans = np . empty ( np . sum ( gaps ), dtype = self . _dtype ) nans [:] = np . nan res . append ( Sig ( data = nans , tline = tline ), interweave_tlines = True ) if res . data_enum is not None : res . base_data = res . data res . data = res . data_enum . data_to_enum ( res . data ) return res def interp ( self , points : npt . NDArray | TLine , extrapolate : bool = False ) -> Sig : \"\"\"Interpolate signal to points.\"\"\" if isinstance ( points , TLine ): points = points . unix if self . interp_method is None or self . interp_method == InterpMethod . LINEAR : new = ccg . util . linearinterp ( self . tline . unix , self . data , points , extrapolate ) elif self . interp_method == InterpMethod . ZOH : new = self . data [ np . maximum ( np . minimum ( np . searchsorted ( self . tline . unix , points , side = \"right\" ) - 1 , self . nsamples - 1 , ), 0 , ) ] else : # TODO: Implement other interp methods. raise NotImplementedError ( f \" { self . interp_method } not implemented.\" ) res = Sig ( self ) # To create a copy first res . data = new res . tline = TLine ( points ) return res @profile def resample ( self : Sig , sample_to : TLine , n_win : int = None , n_ord : int = None , gap_fraction : float = None , interp_gaps = False , ) -> Sig : \"\"\"Resample with Savitzky Golay filter. Parameters ---------- sample_to TLine to resample to n_win window size, should be odd. Is relative to the sample_to index n_ord order of the fit gap_fraction size of a gap relative to the window size to interpolate between Returns ------- New resampled Sig \"\"\" # Skip if the same and default window/order if ( sample_to != self . tline or n_win is not None or n_ord is not None or gap_fraction is not None ): tic = datetime . now () if n_win is None : n_win = 5 if n_ord is None : n_ord = 3 if gap_fraction is None : gap_fraction = 0.5 if self . data . dtype . kind in { \"U\" , \"S\" }: # This is a string type raise NotImplementedError ( \"Cant resample string type.\" ) if not sample_to . is_monotonic_increasing : sample_to = sample_to . sort () if not self . tline . is_monotonic_increasing : self . sort_tline () nsamplesnew = len ( sample_to ) # dt_new = sample_to.dt dtm_new = np . maximum ( sample_to . period , 0.001 ) dt_orig = self . tline . dt dtm_orig = np . maximum ( self . tline . period , 0.001 ) n_win_orig = int ( np . ceil ( max ( n_win , round ( n_win * dtm_new / dtm_orig ))) // 2 * 2 + 1 ) # Detect gaps larger than gap_fraction windows gaps = np . flatnonzero ( dt_orig > n_win_orig * dtm_orig * gap_fraction ) # interpolate between gaps ind_in_gap = [] for gap in gaps : origx = self . tline . unix [ gap : gap + 2 ] ind_in_gap . extend ( * np . where (( sample_to . unix > origx [ 0 ]) & ( sample_to . unix < origx [ 1 ])) ) if interp_gaps and len ( gaps ) > 0 : newx = np . concatenate ( ( self . tline . unix , sample_to . unix [ ind_in_gap ], ), ) newx . sort () orig = self . interp ( newx ) invalid = [] else : orig = self invalid = ind_in_gap inds , convs = orig . tline . savgol_coef ( sample_to , n_ord , n_win_orig , ) ys0 = np . empty (( nsamplesnew , n_win_orig )) ys0 [:, :] = np . reshape ( orig . data [ inds . ravel ()], ( nsamplesnew , n_win_orig ), ) # Calc diaganol only of dot product result = np . einsum ( \"ij,ji->i\" , ys0 [:, :], convs ) if np . any ( invalid ): result [ invalid ] = np . NaN res = Sig ( self ) # To get all attr of inital # then update to new values res . data = result res . tline = sample_to toc = datetime . now () - tic _LOGGER . debug ( \"Resampled %s from %s to %s samples in %.3f [s]\" , self . name , format ( self . nsamples , \",\" ), format ( res . nsamples , \",\" ), toc . total_seconds (), ) else : res = Sig ( self ) return res def dot ( self , n_dot : int = 1 , n_win : int = 5 , n_ord : int = 3 , ): \"\"\"Calculate Derivative of signal. Returns new sig.\"\"\" tic = datetime . now () inds , convs = self . tline . savgol_coef ( self . tline , n_ord , n_win , n_dot , ) ys0 = np . empty (( self . nsamples , n_win )) ys0 [:, :] = np . reshape ( self . data [ inds . ravel ()], ( self . nsamples , n_win ), ) # Calc diaganol only of dot product result = np . einsum ( \"ij,ji->i\" , ys0 [:, :], convs ) res = Sig ( self ) # To get all attr of inital # then update to new values res . name = f ' { res . name } _ { \"\" . join ([ \"dot\" ] * n_dot ) } ' res . unit = ( f ' { res . unit if res . unit else \"\" } /s { \"\" if n_dot == 1 else \"^\" + n_dot } ' ) res . data = result toc = datetime . now () - tic _LOGGER . debug ( \"Deriv of %s in %.3f [s]\" , self . name , toc . total_seconds (), ) return res def valid ( self , gatecoll : GateColl , frame : Frame = None ): \"\"\"Return new signal with invalid data replaced with nan's\"\"\" # tic = datetime.now() if frame is None and self . parent is None : raise ValueError ( \"`Sig.valid()` requires frame argument if sig has no parent.\" ) if frame is None : frame = self . parent res = Sig ( self ) # copy valid_sig = gatecoll . validate ( frame ) b_valid = valid_sig . interp ( self . tline ) . data nan = np . NaN if res . data . dtype . kind in [ \"i\" , \"u\" ]: res . data = res . data . astype ( \"float\" ) elif res . data . dtype . kind in [ \"U\" , \"S\" ]: nan = \"\" res . data [ ~ b_valid ] = nan # toc = datetime.now() - tic # _LOGGER.debug( # \"get valid sig %s in %.3f\", self.name, toc.total_seconds() # ) return res def __len__ ( self ) -> int : return self . nsamples def __repr__ ( self ) -> str : \"\"\"Return string representation.\"\"\" reprstr = f \" { self . __class__ . __qualname__ } ( { self . data . __repr__ () } )\" return reprstr def __str__ ( self ) -> str : \"\"\"Return readable string.\"\"\" return self . data . __str__ () def __add__ ( self , other ): \"\"\"add, resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , unit = self . unit , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] + %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . resample ( tline ) . data res . data = self . resample ( tline ) . data + other return res def __sub__ ( self , other ): \"\"\"subtract, resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , unit = self . unit , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] - %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . resample ( tline ) . data res . data = self . resample ( tline ) . data - other return res def __radd__ ( self , other ): \"\"\"add, resamples to parent.math_tline if exists. returns Sig.\"\"\" return self . __add__ ( other ) def __rsub__ ( self , other ): \"\"\"subtract, resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , unit = self . unit , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] - %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . resample ( tline ) . data res . data = other - self . resample ( tline ) . data return res def __mul__ ( self , other ): \"\"\"multiply(elementwise), resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): if ( self . unit and other . unit is None ) or other . unit . lower () == \"ratio\" : unit = self . unit elif ( self . unit is None or self . unit . lower () == \"ratio\" ) and other . unit : unit = other . unit elif self . unit and self . unit == other . unit : unit = self . unit + \"**2\" else : unit = f \" { self . unit } * { other . unit } \" other = other . resample ( tline ) . data else : unit = self . unit res . unit = unit res . data = self . resample ( tline ) . data * other return res def __truediv__ ( self , other ): \"\"\"divide(elementwise), resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): if ( self . unit and other . unit is None ) or other . unit . lower () == \"ratio\" : unit = self . unit elif ( self . unit is None or self . unit . lower () == \"ratio\" ) and other . unit : unit = other . unit elif self . unit and self . unit == other . unit : unit = \"ratio\" else : unit = f \" { self . unit } / { other . unit } \" other = other . resample ( tline ) . data else : unit = self . unit res . unit = unit res . data = self . resample ( tline ) . data / other return res def __pow__ ( self , other ): \"\"\"power, resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): other = other . resample ( tline ) . data unit = f \" { self . unit } **n\" elif len ( other ) == 1 : unit = f \" { self . unit } ** { other } \" if self . unit . lower () == \"ratio\" : unit = \"ratio\" res . unit = unit res . data = self . resample ( tline ) . data ** other return res def __abs__ ( self ): \"\"\"abs\"\"\" res = Sig ( self , name = f \"abs( { self . name } )\" , dtype = self . _dtype ) res . data = np . abs ( self . data ) return res def __neg__ ( self ): \"\"\"neg\"\"\" res = Sig ( self , name = f \"neg( { self . name } )\" , dtype = self . _dtype ) res . data = self . data * - 1 return res def __eq__ ( self , other ) -> bool : \"\"\"Check equality.\"\"\" if isinstance ( other , self . __class__ ): iseq = ( np . array_equal ( self . data , other . data ) and np . array_equal ( self . tline , other . tline ) and self . interp_method == other . interp_method and self . connect_gaps == other . connect_gaps and self . unit == other . unit ) if iseq : for key , val in self . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : try : iseq = iseq and val == getattr ( other , key ) except KeyError : iseq = False if iseq : # if its still true, we better check if theres an unk attr in the other for key , val in self . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : try : iseq = iseq and val == getattr ( self , key ) except KeyError : iseq = False return iseq else : return False # @profile def __getitem__ ( self , index : int | list [ int ] | slice | npt . NDArray ): \"\"\"Get item of Sig.\"\"\" if isinstance ( index , slice ) or isinstance ( index , int ): res = self . data [ index ] elif isinstance ( index , np . ndarray ) and index . dtype . kind in ( \"b\" ): # res = copy.deepcopy(self) # res.tline.unix = self.tline.unix[index] # res.data = self.data[index] # # Deepcopy is so slow. Lets try re-building signals instead unks = {} for key , val in self . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : unks . update ({ key : val }) res = Sig ( data = self . data [ index ], tline = TLine ( self . tline . unix [ index ]), name = self . name , unit = self . unit , interp_method = self . interp_method , connect_gaps = self . connect_gaps , data_enum = self . data_enum , ** unks , ) else : raise NotImplementedError ( \"unexpected index for signal\" ) return res def __setitem__ ( self , index : tuple [ slice | list | int | npt . NDArray ] | slice , value : list | npt . NDArray | str , ): \"\"\"Set item\"\"\" self . _data [ index ] = value def __iter__ ( self ): \"\"\"Iterate.\"\"\" return iter ( self . data ) def __next__ ( self ): \"\"\"Next.\"\"\" return next ( self . data ) def __deepcopy__ ( self , memo ): # pylint: disable= method-hidden \"\"\"Deepcopy of a CCGSig. Referenced frame is removed.\"\"\" deepcopy_method = self . __deepcopy__ self . __deepcopy__ = None cpy = copy . deepcopy ( self , memo ) cpy . parent = None # To avoid recursion and confusion self . __deepcopy__ = deepcopy_method # Copy the function object func = types . FunctionType ( deepcopy_method . __code__ , deepcopy_method . __globals__ , deepcopy_method . __name__ , deepcopy_method . __defaults__ , deepcopy_method . __closure__ , ) # Bind to cp and set bound_method = func . __get__ ( cpy , cpy . __class__ ) # pylint: disable=no-member cpy . __deepcopy__ = bound_method return cpy appx_bytes property Estimated size of data [bytes]. Excludes tline. data : npt . NDArray property writable data getter max : npt . NBitBase | None property Max value. min : npt . NBitBase | None property Min value. name : str property writable Return signal name. period property apprx period. tend property End of tline. tend_iso property End of tline. tstart property Start if tline. tstart_iso property Start if tline. __abs__ () abs Source code in ccg\\data\\tsdata.py 1705 1706 1707 1708 1709 def __abs__ ( self ): \"\"\"abs\"\"\" res = Sig ( self , name = f \"abs( { self . name } )\" , dtype = self . _dtype ) res . data = np . abs ( self . data ) return res __add__ ( other ) add, resamples to parent.math_tline if exists. returns Sig. Source code in ccg\\data\\tsdata.py 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 def __add__ ( self , other ): \"\"\"add, resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , unit = self . unit , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] + %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . resample ( tline ) . data res . data = self . resample ( tline ) . data + other return res __deepcopy__ ( memo ) Deepcopy of a CCGSig. Referenced frame is removed. Source code in ccg\\data\\tsdata.py 1792 1793 1794 1795 1796 1797 1798 1799 1800 1801 1802 1803 1804 1805 1806 1807 1808 1809 1810 1811 1812 1813 def __deepcopy__ ( self , memo ): # pylint: disable= method-hidden \"\"\"Deepcopy of a CCGSig. Referenced frame is removed.\"\"\" deepcopy_method = self . __deepcopy__ self . __deepcopy__ = None cpy = copy . deepcopy ( self , memo ) cpy . parent = None # To avoid recursion and confusion self . __deepcopy__ = deepcopy_method # Copy the function object func = types . FunctionType ( deepcopy_method . __code__ , deepcopy_method . __globals__ , deepcopy_method . __name__ , deepcopy_method . __defaults__ , deepcopy_method . __closure__ , ) # Bind to cp and set bound_method = func . __get__ ( cpy , cpy . __class__ ) # pylint: disable=no-member cpy . __deepcopy__ = bound_method return cpy __eq__ ( other ) Check equality. Source code in ccg\\data\\tsdata.py 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741 1742 1743 1744 1745 def __eq__ ( self , other ) -> bool : \"\"\"Check equality.\"\"\" if isinstance ( other , self . __class__ ): iseq = ( np . array_equal ( self . data , other . data ) and np . array_equal ( self . tline , other . tline ) and self . interp_method == other . interp_method and self . connect_gaps == other . connect_gaps and self . unit == other . unit ) if iseq : for key , val in self . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : try : iseq = iseq and val == getattr ( other , key ) except KeyError : iseq = False if iseq : # if its still true, we better check if theres an unk attr in the other for key , val in self . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : try : iseq = iseq and val == getattr ( self , key ) except KeyError : iseq = False return iseq else : return False __getitem__ ( index ) Get item of Sig. Source code in ccg\\data\\tsdata.py 1748 1749 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 1767 1768 1769 1770 1771 1772 1773 1774 def __getitem__ ( self , index : int | list [ int ] | slice | npt . NDArray ): \"\"\"Get item of Sig.\"\"\" if isinstance ( index , slice ) or isinstance ( index , int ): res = self . data [ index ] elif isinstance ( index , np . ndarray ) and index . dtype . kind in ( \"b\" ): # res = copy.deepcopy(self) # res.tline.unix = self.tline.unix[index] # res.data = self.data[index] # # Deepcopy is so slow. Lets try re-building signals instead unks = {} for key , val in self . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : unks . update ({ key : val }) res = Sig ( data = self . data [ index ], tline = TLine ( self . tline . unix [ index ]), name = self . name , unit = self . unit , interp_method = self . interp_method , connect_gaps = self . connect_gaps , data_enum = self . data_enum , ** unks , ) else : raise NotImplementedError ( \"unexpected index for signal\" ) return res __iter__ () Iterate. Source code in ccg\\data\\tsdata.py 1784 1785 1786 def __iter__ ( self ): \"\"\"Iterate.\"\"\" return iter ( self . data ) __mul__ ( other ) multiply(elementwise), resamples to parent.math_tline if exists. returns Sig. Source code in ccg\\data\\tsdata.py 1648 1649 1650 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664 1665 1666 def __mul__ ( self , other ): \"\"\"multiply(elementwise), resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): if ( self . unit and other . unit is None ) or other . unit . lower () == \"ratio\" : unit = self . unit elif ( self . unit is None or self . unit . lower () == \"ratio\" ) and other . unit : unit = other . unit elif self . unit and self . unit == other . unit : unit = self . unit + \"**2\" else : unit = f \" { self . unit } * { other . unit } \" other = other . resample ( tline ) . data else : unit = self . unit res . unit = unit res . data = self . resample ( tline ) . data * other return res __neg__ () neg Source code in ccg\\data\\tsdata.py 1711 1712 1713 1714 1715 def __neg__ ( self ): \"\"\"neg\"\"\" res = Sig ( self , name = f \"neg( { self . name } )\" , dtype = self . _dtype ) res . data = self . data * - 1 return res __next__ () Next. Source code in ccg\\data\\tsdata.py 1788 1789 1790 def __next__ ( self ): \"\"\"Next.\"\"\" return next ( self . data ) __pow__ ( other ) power, resamples to parent.math_tline if exists. returns Sig. Source code in ccg\\data\\tsdata.py 1688 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699 1700 1701 1702 1703 def __pow__ ( self , other ): \"\"\"power, resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): other = other . resample ( tline ) . data unit = f \" { self . unit } **n\" elif len ( other ) == 1 : unit = f \" { self . unit } ** { other } \" if self . unit . lower () == \"ratio\" : unit = \"ratio\" res . unit = unit res . data = self . resample ( tline ) . data ** other return res __radd__ ( other ) add, resamples to parent.math_tline if exists. returns Sig. Source code in ccg\\data\\tsdata.py 1626 1627 1628 def __radd__ ( self , other ): \"\"\"add, resamples to parent.math_tline if exists. returns Sig.\"\"\" return self . __add__ ( other ) __repr__ () Return string representation. Source code in ccg\\data\\tsdata.py 1581 1582 1583 1584 def __repr__ ( self ) -> str : \"\"\"Return string representation.\"\"\" reprstr = f \" { self . __class__ . __qualname__ } ( { self . data . __repr__ () } )\" return reprstr __rsub__ ( other ) subtract, resamples to parent.math_tline if exists. returns Sig. Source code in ccg\\data\\tsdata.py 1630 1631 1632 1633 1634 1635 1636 1637 1638 1639 1640 1641 1642 1643 1644 1645 1646 def __rsub__ ( self , other ): \"\"\"subtract, resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , unit = self . unit , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] - %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . resample ( tline ) . data res . data = other - self . resample ( tline ) . data return res __setitem__ ( index , value ) Set item Source code in ccg\\data\\tsdata.py 1776 1777 1778 1779 1780 1781 1782 def __setitem__ ( self , index : tuple [ slice | list | int | npt . NDArray ] | slice , value : list | npt . NDArray | str , ): \"\"\"Set item\"\"\" self . _data [ index ] = value __str__ () Return readable string. Source code in ccg\\data\\tsdata.py 1586 1587 1588 def __str__ ( self ) -> str : \"\"\"Return readable string.\"\"\" return self . data . __str__ () __sub__ ( other ) subtract, resamples to parent.math_tline if exists. returns Sig. Source code in ccg\\data\\tsdata.py 1608 1609 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622 1623 1624 def __sub__ ( self , other ): \"\"\"subtract, resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , unit = self . unit , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] - %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . resample ( tline ) . data res . data = self . resample ( tline ) . data - other return res __truediv__ ( other ) divide(elementwise), resamples to parent.math_tline if exists. returns Sig. Source code in ccg\\data\\tsdata.py 1668 1669 1670 1671 1672 1673 1674 1675 1676 1677 1678 1679 1680 1681 1682 1683 1684 1685 1686 def __truediv__ ( self , other ): \"\"\"divide(elementwise), resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): if ( self . unit and other . unit is None ) or other . unit . lower () == \"ratio\" : unit = self . unit elif ( self . unit is None or self . unit . lower () == \"ratio\" ) and other . unit : unit = other . unit elif self . unit and self . unit == other . unit : unit = \"ratio\" else : unit = f \" { self . unit } / { other . unit } \" other = other . resample ( tline ) . data else : unit = self . unit res . unit = unit res . data = self . resample ( tline ) . data / other return res append ( sig , interweave_tlines = False , remove_duplicates = False ) Append sig to signal. Source code in ccg\\data\\tsdata.py 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 @profile def append ( self , sig : Sig , interweave_tlines = False , remove_duplicates = False ): \"\"\"Append sig to signal.\"\"\" # Check if timelimes overlap check_overlap ( self , sig , interweave_tlines ) if self . parent is None : self . tline . append_inplace ( sig ) else : nshared = len ( self . parent . tlines . sigs [ self . tline . idn ]) if nshared == 1 : self . tline . append_inplace ( sig ) else : self . tline = self . tline . append_to_new ( sig ) self . _data . append ( sig . _data ) # pylint: disable=access-member-before-definition if not self . tline . is_monotonic_increasing : self . sort_tline ( inplace = True , remove_safe_duplicates = remove_duplicates ) if self . parent is not None : self . parent . tlines . remove ( self . name ) self . parent . tlines . append ( self ) # self.tline = tlref # 2/10/24 now in tlines.append() # get the rest of the attributes if sig . connect_gaps is not None : self . connect_gaps = sig . connect_gaps if sig . data_enum is not None : self . data_enum = sig . data_enum if sig . interp_method is not None : self . interp_method = sig . interp_method if sig . unit is not None : self . unit = sig . unit # Check for unknown attributes. the new signal value will overide the original. for key , val in sig . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : setattr ( self , key , val ) as_unit ( unit ) return new sig converted to unit Source code in ccg\\data\\tsdata.py 1240 1241 1242 1243 1244 def as_unit ( self , unit : str ) -> Sig : \"\"\"return new sig converted to unit\"\"\" sig = Sig ( self ) sig . convert_units ( unit ) return sig calc_idn () Calculate hash for IDN. Source code in ccg\\data\\tsdata.py 1180 1181 1182 1183 1184 1185 1186 1187 1188 def calc_idn ( self ): \"\"\"Calculate hash for IDN.\"\"\" # tic = datetime.now() idn = xxhash . xxh3_64_intdigest ( self . _data . tobytes ()) # toc = datetime.now() - tic # _LOGGER.debug(\"IDN calc'd for %s in %.3f\", self.name, toc.total_seconds()) return idn + self . tline . idn convert_units ( unit ) Convert units in place Source code in ccg\\data\\tsdata.py 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 def convert_units ( self , unit : str ) -> Sig : \"\"\"Convert units in place\"\"\" if unit != self . unit : self . data = ccg . util . convert_units ( value = self . data , from_unit = self . unit , to_unit = unit ) if self . data_range : self . data_range = ccg . util . convert_units ( value = self . data_range , from_unit = self . unit , to_unit = unit ) self . unit = unit return self dot ( n_dot = 1 , n_win = 5 , n_ord = 3 ) Calculate Derivative of signal. Returns new sig. Source code in ccg\\data\\tsdata.py 1512 1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 def dot ( self , n_dot : int = 1 , n_win : int = 5 , n_ord : int = 3 , ): \"\"\"Calculate Derivative of signal. Returns new sig.\"\"\" tic = datetime . now () inds , convs = self . tline . savgol_coef ( self . tline , n_ord , n_win , n_dot , ) ys0 = np . empty (( self . nsamples , n_win )) ys0 [:, :] = np . reshape ( self . data [ inds . ravel ()], ( self . nsamples , n_win ), ) # Calc diaganol only of dot product result = np . einsum ( \"ij,ji->i\" , ys0 [:, :], convs ) res = Sig ( self ) # To get all attr of inital # then update to new values res . name = f ' { res . name } _ { \"\" . join ([ \"dot\" ] * n_dot ) } ' res . unit = ( f ' { res . unit if res . unit else \"\" } /s { \"\" if n_dot == 1 else \"^\" + n_dot } ' ) res . data = result toc = datetime . now () - tic _LOGGER . debug ( \"Deriv of %s in %.3f [s]\" , self . name , toc . total_seconds (), ) return res interp ( points , extrapolate = False ) Interpolate signal to points. Source code in ccg\\data\\tsdata.py 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 def interp ( self , points : npt . NDArray | TLine , extrapolate : bool = False ) -> Sig : \"\"\"Interpolate signal to points.\"\"\" if isinstance ( points , TLine ): points = points . unix if self . interp_method is None or self . interp_method == InterpMethod . LINEAR : new = ccg . util . linearinterp ( self . tline . unix , self . data , points , extrapolate ) elif self . interp_method == InterpMethod . ZOH : new = self . data [ np . maximum ( np . minimum ( np . searchsorted ( self . tline . unix , points , side = \"right\" ) - 1 , self . nsamples - 1 , ), 0 , ) ] else : # TODO: Implement other interp methods. raise NotImplementedError ( f \" { self . interp_method } not implemented.\" ) res = Sig ( self ) # To create a copy first res . data = new res . tline = TLine ( points ) return res plot_prep () Prepare for plotting. Sorts tline and removes duplicates. Inserts NaNs in gaps if connect_gaps=False | None . Applies enum if it exists. Source code in ccg\\data\\tsdata.py 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 @profile def plot_prep ( self ) -> Sig : \"\"\"Prepare for plotting. Sorts tline and removes duplicates. Inserts NaNs in gaps if `connect_gaps=False | None`. Applies enum if it exists. \"\"\" res = self if not self . tline . is_monotonic_increasing : self . sort_tline ( remove_safe_duplicates = True ) if self . connect_gaps is None or not self . connect_gaps : gaps = np . greater ( self . tline . dt , self . _FGAP * self . tline . period , ) if np . sum ( gaps ) > 0 : res = Sig ( self ) # Make a copy before resampling. tline = TLine ( self . tline . unix [ np . append ( gaps , False )] + ( self . tline . dt [ gaps ] / 2 ) ) if self . _data . data . dtype . kind in ( \"i\" , \"u\" , \"b\" , \"M\" ): # Since numpy is r-worded and cant use a nan in an int, we need to convert to float self . _data . replace ( self . data . astype ( \"float\" , copy = False )) self . _dtype = self . _data . dtype nans = np . empty ( np . sum ( gaps ), dtype = self . _dtype ) nans [:] = np . nan res . append ( Sig ( data = nans , tline = tline ), interweave_tlines = True ) if res . data_enum is not None : res . base_data = res . data res . data = res . data_enum . data_to_enum ( res . data ) return res resample ( sample_to , n_win = None , n_ord = None , gap_fraction = None , interp_gaps = False ) Resample with Savitzky Golay filter. Parameters: sample_to ( TLine ) \u2013 TLine to resample to n_win ( int , default: None ) \u2013 window size, should be odd. Is relative to the sample_to index n_ord ( int , default: None ) \u2013 order of the fit gap_fraction ( float , default: None ) \u2013 size of a gap relative to the window size to interpolate between Returns: New resampled Sig \u2013 Source code in ccg\\data\\tsdata.py 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 @profile def resample ( self : Sig , sample_to : TLine , n_win : int = None , n_ord : int = None , gap_fraction : float = None , interp_gaps = False , ) -> Sig : \"\"\"Resample with Savitzky Golay filter. Parameters ---------- sample_to TLine to resample to n_win window size, should be odd. Is relative to the sample_to index n_ord order of the fit gap_fraction size of a gap relative to the window size to interpolate between Returns ------- New resampled Sig \"\"\" # Skip if the same and default window/order if ( sample_to != self . tline or n_win is not None or n_ord is not None or gap_fraction is not None ): tic = datetime . now () if n_win is None : n_win = 5 if n_ord is None : n_ord = 3 if gap_fraction is None : gap_fraction = 0.5 if self . data . dtype . kind in { \"U\" , \"S\" }: # This is a string type raise NotImplementedError ( \"Cant resample string type.\" ) if not sample_to . is_monotonic_increasing : sample_to = sample_to . sort () if not self . tline . is_monotonic_increasing : self . sort_tline () nsamplesnew = len ( sample_to ) # dt_new = sample_to.dt dtm_new = np . maximum ( sample_to . period , 0.001 ) dt_orig = self . tline . dt dtm_orig = np . maximum ( self . tline . period , 0.001 ) n_win_orig = int ( np . ceil ( max ( n_win , round ( n_win * dtm_new / dtm_orig ))) // 2 * 2 + 1 ) # Detect gaps larger than gap_fraction windows gaps = np . flatnonzero ( dt_orig > n_win_orig * dtm_orig * gap_fraction ) # interpolate between gaps ind_in_gap = [] for gap in gaps : origx = self . tline . unix [ gap : gap + 2 ] ind_in_gap . extend ( * np . where (( sample_to . unix > origx [ 0 ]) & ( sample_to . unix < origx [ 1 ])) ) if interp_gaps and len ( gaps ) > 0 : newx = np . concatenate ( ( self . tline . unix , sample_to . unix [ ind_in_gap ], ), ) newx . sort () orig = self . interp ( newx ) invalid = [] else : orig = self invalid = ind_in_gap inds , convs = orig . tline . savgol_coef ( sample_to , n_ord , n_win_orig , ) ys0 = np . empty (( nsamplesnew , n_win_orig )) ys0 [:, :] = np . reshape ( orig . data [ inds . ravel ()], ( nsamplesnew , n_win_orig ), ) # Calc diaganol only of dot product result = np . einsum ( \"ij,ji->i\" , ys0 [:, :], convs ) if np . any ( invalid ): result [ invalid ] = np . NaN res = Sig ( self ) # To get all attr of inital # then update to new values res . data = result res . tline = sample_to toc = datetime . now () - tic _LOGGER . debug ( \"Resampled %s from %s to %s samples in %.3f [s]\" , self . name , format ( self . nsamples , \",\" ), format ( res . nsamples , \",\" ), toc . total_seconds (), ) else : res = Sig ( self ) return res sort_tline ( inplace = True , remove_safe_duplicates = False , remove_all_duplicates = False ) Sort signal by timeline. Parameters: inplace \u2013 Sorts signal in place, returns None. remove_duplicates \u2013 Will remove duplicate timestamps if signal is also duplicated. Returns: Sig \u2013 self if inplace=True . Source code in ccg\\data\\tsdata.py 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 def sort_tline ( self , inplace = True , remove_safe_duplicates = False , remove_all_duplicates = False , ): \"\"\"Sort signal by timeline. Parameters ---------- inplace Sorts signal in place, returns None. remove_duplicates Will remove duplicate timestamps if signal is also duplicated. Returns ------- Sig self if `inplace=True`. \"\"\" inds = np . argsort ( self . tline . unix , kind = \"stable\" ) if inplace : self . tline = TLine ( self . tline . unix [ inds ]) if self . nsamples > 0 : self . data = self . data [ inds ] if remove_safe_duplicates : self . _remove_duplicates ( remove_all_duplicates ) if self . parent is not None : self . parent . tlines . remove ( self . name ) self . parent . tlines . append ( self ) # self.tline = tlref # 2/10/24 now in tlines.append() return self sig = Sig ( self ) # TODO: clean this up to not define, then edit. sig . name = sig . name + \"_sorted\" sig . tline = TLine ( self . tline . unix [ inds ]) if self . nsamples > 0 : sig . data = sig . data [ inds ] if remove_safe_duplicates : sig . _remove_duplicates ( remove_all_duplicates ) # pylint: disable=access-member-before-definition return sig valid ( gatecoll , frame = None ) Return new signal with invalid data replaced with nan's Source code in ccg\\data\\tsdata.py 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 1573 1574 1575 1576 def valid ( self , gatecoll : GateColl , frame : Frame = None ): \"\"\"Return new signal with invalid data replaced with nan's\"\"\" # tic = datetime.now() if frame is None and self . parent is None : raise ValueError ( \"`Sig.valid()` requires frame argument if sig has no parent.\" ) if frame is None : frame = self . parent res = Sig ( self ) # copy valid_sig = gatecoll . validate ( frame ) b_valid = valid_sig . interp ( self . tline ) . data nan = np . NaN if res . data . dtype . kind in [ \"i\" , \"u\" ]: res . data = res . data . astype ( \"float\" ) elif res . data . dtype . kind in [ \"U\" , \"S\" ]: nan = \"\" res . data [ ~ b_valid ] = nan # toc = datetime.now() - tic # _LOGGER.debug( # \"get valid sig %s in %.3f\", self.name, toc.total_seconds() # ) return res SigEnum Enumeration definition for CCGSig. Parameters: definition ( dict ) \u2013 Dictionary of conversion values. \"\" is a special key, default for unmatched values if missing, np.nan will be used. Example enumdef = {'v1':1,'v2':2,'':0,} data = np.array(['v1','v2','v3']) testenum = SigEnum(definition=enumdef) testenum.data_to_enum(data) Source code in ccg\\data\\tsdata.py 2554 2555 2556 2557 2558 2559 2560 2561 2562 2563 2564 2565 2566 2567 2568 2569 2570 2571 2572 2573 2574 2575 2576 2577 2578 2579 2580 2581 2582 2583 2584 2585 2586 2587 2588 2589 2590 2591 2592 2593 2594 2595 2596 2597 2598 class SigEnum : \"\"\"Enumeration definition for CCGSig. Parameters ---------- definition Dictionary of conversion values. \"\" is a special key, default for unmatched values if missing, np.nan will be used. Example ------- >>> enumdef = {'v1':1,'v2':2,'':0,} >>> data = np.array(['v1','v2','v3']) >>> testenum = SigEnum(definition=enumdef) >>> testenum.data_to_enum(data) >>> \"\"\" def __init__ ( self , definition : dict ): self . definition = definition def data_to_enum ( self , data : npt . NDArray ): \"\"\"Convert base data to enumerated type.\"\"\" rtn = np . empty ( data . shape ) unmatched = np . empty ( data . shape , dtype = np . bool_ ) unmatched [:] = True for key , val in self . definition . items (): if not key == \"\" : inds = data == key unmatched [ inds ] = False rtn [ inds ] = val if np . any ( unmatched ): try : rtn [ unmatched ] = self . definition [ \"\" ] except KeyError : rtn [ unmatched ] = np . nan return rtn def enum_to_data ( self , enum : npt . NDArray ): \"\"\"Convert enumerated data back to base data.\"\"\" rtn = np . empty ( enum . shape ) for key , val in self . definition . items (): inds = enum == val rtn [ inds ] = key return rtn data_to_enum ( data ) Convert base data to enumerated type. Source code in ccg\\data\\tsdata.py 2574 2575 2576 2577 2578 2579 2580 2581 2582 2583 2584 2585 2586 2587 2588 2589 2590 def data_to_enum ( self , data : npt . NDArray ): \"\"\"Convert base data to enumerated type.\"\"\" rtn = np . empty ( data . shape ) unmatched = np . empty ( data . shape , dtype = np . bool_ ) unmatched [:] = True for key , val in self . definition . items (): if not key == \"\" : inds = data == key unmatched [ inds ] = False rtn [ inds ] = val if np . any ( unmatched ): try : rtn [ unmatched ] = self . definition [ \"\" ] except KeyError : rtn [ unmatched ] = np . nan return rtn enum_to_data ( enum ) Convert enumerated data back to base data. Source code in ccg\\data\\tsdata.py 2592 2593 2594 2595 2596 2597 2598 def enum_to_data ( self , enum : npt . NDArray ): \"\"\"Convert enumerated data back to base data.\"\"\" rtn = np . empty ( enum . shape ) for key , val in self . definition . items (): inds = enum == val rtn [ inds ] = key return rtn TLine CCG Time Line. Source code in ccg\\data\\tsdata.py 1816 1817 1818 1819 1820 1821 1822 1823 1824 1825 1826 1827 1828 1829 1830 1831 1832 1833 1834 1835 1836 1837 1838 1839 1840 1841 1842 1843 1844 1845 1846 1847 1848 1849 1850 1851 1852 1853 1854 1855 1856 1857 1858 1859 1860 1861 1862 1863 1864 1865 1866 1867 1868 1869 1870 1871 1872 1873 1874 1875 1876 1877 1878 1879 1880 1881 1882 1883 1884 1885 1886 1887 1888 1889 1890 1891 1892 1893 1894 1895 1896 1897 1898 1899 1900 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 2025 2026 2027 2028 2029 2030 2031 2032 2033 2034 2035 2036 2037 2038 2039 2040 2041 2042 2043 2044 2045 2046 2047 2048 2049 2050 2051 2052 2053 2054 2055 2056 2057 2058 2059 2060 2061 2062 2063 2064 2065 2066 2067 2068 2069 2070 2071 2072 2073 2074 2075 2076 2077 2078 2079 2080 2081 2082 2083 2084 2085 2086 2087 2088 2089 2090 2091 2092 2093 2094 2095 2096 2097 2098 2099 2100 2101 2102 2103 2104 2105 2106 2107 2108 2109 2110 2111 2112 2113 2114 2115 2116 2117 2118 2119 2120 2121 2122 2123 2124 2125 2126 2127 2128 2129 2130 2131 2132 2133 2134 2135 2136 2137 2138 2139 2140 2141 2142 2143 2144 2145 2146 2147 2148 2149 2150 2151 2152 2153 2154 2155 2156 2157 2158 2159 2160 2161 2162 2163 2164 2165 2166 2167 2168 2169 2170 2171 2172 2173 2174 2175 2176 2177 2178 2179 2180 2181 2182 2183 2184 2185 2186 2187 2188 2189 2190 2191 2192 2193 2194 2195 2196 2197 2198 2199 2200 2201 2202 2203 2204 2205 2206 2207 2208 2209 2210 2211 2212 2213 2214 2215 2216 2217 2218 2219 2220 2221 2222 2223 2224 2225 2226 2227 2228 2229 2230 2231 2232 2233 2234 2235 2236 2237 2238 2239 2240 2241 2242 2243 2244 2245 class TLine : \"\"\"CCG Time Line.\"\"\" __slots__ = ( \"_iso\" , \"_sg\" , \"_datetime\" , \"_unix\" , \"_idn\" , \"_dt\" , \"_period\" , \"_is_monoton\" , \"parent\" , \"_shape\" , \"_unix\" , \"_period\" , ) @profile def __init__ ( self , data : ( TLine | npt . NDArray [ np . object_ ] | npt . NDArray [ np . number ] | npt . NDArray [ np . datetime64 ] | datetime | list ) = None , tstart : float | datetime = None , tend : float | datetime = None , nsamples : int | tuple [ int ] = None , period : float = None , sg_coef : SgCoef = None , parent : TLineCollection = None , ): if sg_coef is None : self . _sg = SgCoef () self . _iso : npt . NDArray [ np . datetime64 ] = None self . _datetime : npt . NDArray [ np . object_ ] = None self . _unix : AllocData = None self . _idn = None self . _dt = None self . _period : float | None = None self . _is_monoton : bool = None self . parent = parent # TODO: Clean up cases here. better fault detection. if nsamples is None : self . _shape = None elif isinstance ( nsamples , tuple ): self . _shape = nsamples elif isinstance ( nsamples , int ): self . _shape = ( nsamples ,) else : raise NotImplementedError ( f \"tline with nsamples of type { type ( nsamples ) } is not implemented.\" ) if data is not None : # if isinstance(data, (pd.DataFrame, pd.Series)): # if data.index is None: # raise ValueError(\"Data frame has no index.\") # if data.index.asi8 is None: # index = data.index.to_numpy() # else: # index = data.index.asi8 / 1e9 # self.unix = index # elif isinstance(data, pd.Index): # self.unix = data.asi8 / 1e9 if isinstance ( data , np . ndarray ) and data . dtype . kind == \"M\" : self . unix = ccg . util . datetime_to_unix ( data ) elif isinstance ( data , np . ndarray ) and isinstance ( data [ 0 ], datetime ): self . unix = np . array ([ t . timestamp () for t in data ]) elif isinstance ( data , np . ndarray ): self . unix = data . astype ( \"float\" ) elif isinstance ( data , datetime ): self . unix = np . array ([ data . timestamp ()]) elif isinstance ( data , TLine ): self . _shape = data . _shape self . unix = data . _unix self . _sg = data . _sg self . _idn = data . idn elif isinstance ( data , AllocData ): self . _shape = data . _shape self . unix = data elif isinstance ( data , list ): self . unix = np . array ( data ) else : raise NotImplementedError ( f \" { type ( data ) } is not supported.\" ) elif None not in { tstart , tend , nsamples } or None not in { tstart , tend , period }: if isinstance ( tstart , datetime ): tstart = tstart . timestamp () if isinstance ( tend , datetime ): tend = tend . timestamp () if nsamples is not None : self . unix = np . linspace ( start = tstart , stop = tend , num = nsamples ) elif period is not None : self . unix = np . arange ( start = tstart , stop = tend , step = period ) self . _period = period else : raise ValueError ( \"Missing nsamples or period.\" ) elif None not in { tstart , nsamples , period } or None not in { tend , nsamples , period , }: if isinstance ( tstart , datetime ): tstart = tstart . timestamp () if isinstance ( tend , datetime ): tend = tend . timestamp () if tend is None : tend = tstart + nsamples * period if tstart is None : tstart = tend - nsamples * period self . unix = np . linspace ( start = tstart , stop = tend , num = nsamples ) self . _period = period elif nsamples : # To pre-allocate self . unix = None else : raise ValueError @property def unix ( self ) -> npt . NDArray [ np . float_ ]: \"\"\"tline in unix\"\"\" return self . _unix [:] @unix . setter @profile def unix ( self , value : npt . NDArray [ np . float_ ] | AllocData ): if self . _unix is None : self . _unix = AllocData ( value , shape = self . _shape , dtype = np . dtype ( \"float64\" )) else : self . _unix . replace ( value ) # Need to clear lots of stuff if changing the timeline self . clear_cache () # @profile def calc_idn ( self ): \"\"\"Calculate hash for IDN.\"\"\" self . _idn = xxhash . xxh3_64_intdigest ( self . _unix . tobytes ()) return self . _idn @property # @profile def idn ( self ): \"\"\"return id number.\"\"\" if self . _idn is None : return self . calc_idn () return self . _idn @property def tstart ( self ) -> float : \"\"\"Start time.\"\"\" # TODO Check for monoton increasing first. return self . _unix [ 0 ] @property def tend ( self ) -> float : \"\"\"End time.\"\"\" return self . _unix [ - 1 ] @property def tstart_iso ( self ) -> np . datetime64 : \"\"\"Start time.\"\"\" # TODO Check for monoton increasing first. return self . iso [ 0 ] @property def tend_iso ( self ) -> np . datetime64 : \"\"\"End time.\"\"\" return self . iso [ - 1 ] @property def iso ( self ) -> npt . NDArray [ np . datetime64 ]: \"\"\"Array of iso formatted strings. Naive, but in local tz.\"\"\" if self . _iso is None : self . _iso = ccg . util . unix_to_iso ( self . unix ) return self . _iso @property def datetime ( self ) -> npt . NDArray [ np . object_ ]: \"\"\"Array of datetime.datetime.\"\"\" tic = datetime . now () if self . _datetime is None : if self . unix [ 0 ] > 32000000 : tmp = np . array ( [ datetime . fromtimestamp ( t ) . astimezone () for t in self . unix ] ) # SO SLOW else : tmp = np . array ([ datetime . fromtimestamp ( t ) for t in self . unix ]) self . _datetime = tmp toc = datetime . now () - tic if toc > timedelta ( seconds = 0.1 ): _LOGGER . debug ( \"datetime prop calc for %s took %.3f s\" , self . _idn , toc . total_seconds () ) return self . _datetime @property def appx_bytes ( self ): \"\"\"Estimated size of data [bytes]. Excludes tline.\"\"\" return self . _unix . appx_bytes @overload def __getitem__ ( self , ind : int | npt . NDArray [ np . int_ | np . bool_ ]) -> npt . NDArray : pass @overload def __getitem__ ( self , ind : slice ) -> TLine : pass def __getitem__ ( self , ind : int | npt . NDArray [ np . int_ | np . bool_ ] | slice ): \"\"\"Index tline.\"\"\" if isinstance ( ind , slice ): # A slice should return a new CCGTline. Vals should be unix or datetime. if isinstance ( ind . start , datetime ): ind_start = ind . start . timestamp () else : ind_start = ind . start if isinstance ( ind . stop , datetime ): ind_stop = ind . stop . timestamp () else : ind_stop = ind . stop if isinstance ( ind . step , timedelta ): step = ind . step . total_seconds () else : step = ind . step if ind . step is None : if ind . start is None : start = self . tstart else : start = ind_start if ind . stop is None : # Since python is r-worded, this is a special case. # Need to make sure the last sample is included. stop = self . tend + 0.000001 else : stop = ind_stop inds = np . logical_and ( self . unix >= start , self . unix < stop ) return TLine ( self . unix [ inds ]) else : # Step was defined so define a fresh tline i guess? _LOGGER . warning ( \"tline sliced with step defined. This is equiv to `CCGTline(tstart=slice.start,tenc=slice.stop,period=slice.step)`\" ) return TLine ( tstart = ind_start , tend = ind_stop , period = step ) return self . unix [ ind ] def __len__ ( self ) -> int : \"\"\"Length of timeline.\"\"\" return self . _unix . nsamples def __repr__ ( self ) -> str : \"\"\"Return string representation.\"\"\" # reprstr = f\"{self.__class__.__module__}.{self.__class__.__qualname__}({self.iso.__repr__()})\" reprstr = f \" { self . __class__ . __qualname__ } ( { self . iso . __repr__ () } )\" return reprstr def __str__ ( self ) -> str : \"\"\"Return readable string.\"\"\" return self . iso . __str__ () def __eq__ ( self , other ) -> bool : \"\"\"Check equality.\"\"\" if isinstance ( other , self . __class__ ): return np . array_equal ( self . unix , other . unix ) else : return False @property # profile def dt ( self ): \"\"\"delta t\"\"\" if self . _dt is None : if len ( self ) > 1 : self . _dt = np . diff ( self . unix ) else : self . _dt = np . array ([ 0 ]) return self . _dt @property def period ( self ) -> float : \"\"\"apprx period.\"\"\" if self . _period : return self . _period if self . nsamples > 1 : self . _period = stats . mode ( self . dt , keepdims = True ) . mode [ 0 ] else : self . _period = np . Inf return self . _period @property def nsamples ( self ): \"\"\"nsamples\"\"\" return len ( self ) @property # profile def is_monotonic_increasing ( self ): \"\"\"Return true if monotonic increasing.\"\"\" if self . _is_monoton is None : if len ( self ) == 1 : self . _is_monoton = True else : tmp = self . unix self . _is_monoton = np . all ( tmp [ 1 :] > tmp [: - 1 ]) return self . _is_monoton @profile def append_to_new ( self , sig : Sig ): \"\"\"Append timeline from sig to tline. Returns new timeline.\"\"\" nsamples = self . nsamples + sig . nsamples new_tline = TLine ( self , nsamples = nsamples ) new_tline . parent = None new_tline . append_inplace ( sig ) # new_tline = TLine(np.concatenate((self.unix, sig.tline.unix))) return new_tline @profile def append_inplace ( self , sig : Sig ): \"\"\"Append to tline in place. Dangerous if shared in a Frame.\"\"\" self . _unix . append ( sig . tline . _unix ) self . clear_cache () return self def index_at_time ( self , time : float | datetime ) -> int : \"\"\"Get the index of the first tstamp >= time.\"\"\" raise NotImplementedError def sort ( self ): \"\"\"Sort tline.\"\"\" raise NotImplementedError ( \"tline sort is not implemented.\" ) # Dont forget to re-calc idn def clear_cache ( self ): \"\"\"Clear the cached values.\"\"\" self . _sg . clear () old_idn = self . _idn self . _iso = None self . _datetime = None self . _idn = None self . _dt = None self . _period = None self . _is_monoton = None if self . parent is not None and old_idn != self . idn : self . parent . replace ( old_idn , self ) # @profile def savgol_coef ( self : TLine , sample_to_index : TLine , n_ord : int , n_win_orig : int , n_dot : int = 0 , ): \"\"\"Calculate Savitzky Golay coeficients.\"\"\" # Check if coef's are stored nsamplesnew = len ( sample_to_index ) if ( self . idn == self . _sg . orig_index and sample_to_index . idn == self . _sg . sample_to_index and n_ord == self . _sg . n_ord and n_win_orig == self . _sg . n_win_orig ): conv = self . _sg . conv uniqinvs = self . _sg . uniqinvs n_uniq = self . _sg . n_uniq inds = self . _sg . inds else : # Missing or different, so have to calc coef's nsamples = len ( self ) # Find orig samples near new samples ind0 = np . digitize ( sample_to_index . unix , self . unix ) ind0 = np . maximum ( np . minimum ( ind0 , nsamples - 1 , out = ind0 ), 0 , out = ind0 ) # saturate inds = ind0 [:, np . newaxis ] # make n x 1 offs = np . arange ( n_win_orig ) - int (( n_win_orig - 1 ) / 2 ) inds = inds + offs # Saturate the ends inds = np . maximum ( np . minimum ( inds , nsamples - 1 , out = inds ), 0 , out = inds ) indsz : npt . NDArray = self . unix [ inds . ravel ()] # to seconds indsz = indsz . reshape ( inds . shape ) torig = self . unix [ ind0 ] indsz = indsz - torig [:, np . newaxis ] # Find unique window spacings, round to appropriate resolution indsz = np . around ( indsz , 3 , out = indsz ) uniqz , uniqinvs = np . unique ( indsz , return_inverse = True , axis = 0 ) n_uniq = len ( uniqz ) pwrs = np . arange ( n_ord + 1 ) conv = np . empty (( n_uniq , n_win_orig , n_ord + 1 )) for i , uniq in enumerate ( uniqz ): j : npt . NDArray = uniq [:, np . newaxis ] ** pwrs try : tmp = np . linalg . inv ( j . T @ j ) @ j . T except np . linalg . LinAlgError : tmp = np . linalg . pinv ( j . T @ j ) @ j . T conv [ i , :, :] = tmp . T # Store inputs for validating accuracy of stored coef's # Compress or abbrev?? self . _sg . orig_index = self . idn self . _sg . sample_to_index = sample_to_index . idn self . _sg . n_win_orig = n_win_orig self . _sg . n_ord = n_ord # Store coef's self . _sg . conv = conv self . _sg . uniqinvs = uniqinvs self . _sg . n_uniq = n_uniq self . _sg . inds = inds # Calc coef's for this derivative convs = np . empty (( n_win_orig , nsamplesnew )) for i in range ( n_uniq ): convs [:, uniqinvs == i ] = conv [ i , :, n_dot ][:, np . newaxis ] return inds , convs appx_bytes property Estimated size of data [bytes]. Excludes tline. datetime : npt . NDArray [ np . object_ ] property Array of datetime.datetime. dt property delta t idn property return id number. is_monotonic_increasing property Return true if monotonic increasing. iso : npt . NDArray [ np . datetime64 ] property Array of iso formatted strings. Naive, but in local tz. nsamples property nsamples period : float property apprx period. tend : float property End time. tend_iso : np . datetime64 property End time. tstart : float property Start time. tstart_iso : np . datetime64 property Start time. unix : npt . NDArray [ np . float_ ] property writable tline in unix __eq__ ( other ) Check equality. Source code in ccg\\data\\tsdata.py 2083 2084 2085 2086 2087 2088 def __eq__ ( self , other ) -> bool : \"\"\"Check equality.\"\"\" if isinstance ( other , self . __class__ ): return np . array_equal ( self . unix , other . unix ) else : return False __getitem__ ( ind ) Index tline. Source code in ccg\\data\\tsdata.py 2031 2032 2033 2034 2035 2036 2037 2038 2039 2040 2041 2042 2043 2044 2045 2046 2047 2048 2049 2050 2051 2052 2053 2054 2055 2056 2057 2058 2059 2060 2061 2062 2063 2064 2065 2066 2067 def __getitem__ ( self , ind : int | npt . NDArray [ np . int_ | np . bool_ ] | slice ): \"\"\"Index tline.\"\"\" if isinstance ( ind , slice ): # A slice should return a new CCGTline. Vals should be unix or datetime. if isinstance ( ind . start , datetime ): ind_start = ind . start . timestamp () else : ind_start = ind . start if isinstance ( ind . stop , datetime ): ind_stop = ind . stop . timestamp () else : ind_stop = ind . stop if isinstance ( ind . step , timedelta ): step = ind . step . total_seconds () else : step = ind . step if ind . step is None : if ind . start is None : start = self . tstart else : start = ind_start if ind . stop is None : # Since python is r-worded, this is a special case. # Need to make sure the last sample is included. stop = self . tend + 0.000001 else : stop = ind_stop inds = np . logical_and ( self . unix >= start , self . unix < stop ) return TLine ( self . unix [ inds ]) else : # Step was defined so define a fresh tline i guess? _LOGGER . warning ( \"tline sliced with step defined. This is equiv to `CCGTline(tstart=slice.start,tenc=slice.stop,period=slice.step)`\" ) return TLine ( tstart = ind_start , tend = ind_stop , period = step ) return self . unix [ ind ] __len__ () Length of timeline. Source code in ccg\\data\\tsdata.py 2069 2070 2071 def __len__ ( self ) -> int : \"\"\"Length of timeline.\"\"\" return self . _unix . nsamples __repr__ () Return string representation. Source code in ccg\\data\\tsdata.py 2073 2074 2075 2076 2077 def __repr__ ( self ) -> str : \"\"\"Return string representation.\"\"\" # reprstr = f\"{self.__class__.__module__}.{self.__class__.__qualname__}({self.iso.__repr__()})\" reprstr = f \" { self . __class__ . __qualname__ } ( { self . iso . __repr__ () } )\" return reprstr __str__ () Return readable string. Source code in ccg\\data\\tsdata.py 2079 2080 2081 def __str__ ( self ) -> str : \"\"\"Return readable string.\"\"\" return self . iso . __str__ () append_inplace ( sig ) Append to tline in place. Dangerous if shared in a Frame. Source code in ccg\\data\\tsdata.py 2140 2141 2142 2143 2144 2145 @profile def append_inplace ( self , sig : Sig ): \"\"\"Append to tline in place. Dangerous if shared in a Frame.\"\"\" self . _unix . append ( sig . tline . _unix ) self . clear_cache () return self append_to_new ( sig ) Append timeline from sig to tline. Returns new timeline. Source code in ccg\\data\\tsdata.py 2130 2131 2132 2133 2134 2135 2136 2137 2138 @profile def append_to_new ( self , sig : Sig ): \"\"\"Append timeline from sig to tline. Returns new timeline.\"\"\" nsamples = self . nsamples + sig . nsamples new_tline = TLine ( self , nsamples = nsamples ) new_tline . parent = None new_tline . append_inplace ( sig ) # new_tline = TLine(np.concatenate((self.unix, sig.tline.unix))) return new_tline calc_idn () Calculate hash for IDN. Source code in ccg\\data\\tsdata.py 1956 1957 1958 1959 def calc_idn ( self ): \"\"\"Calculate hash for IDN.\"\"\" self . _idn = xxhash . xxh3_64_intdigest ( self . _unix . tobytes ()) return self . _idn clear_cache () Clear the cached values. Source code in ccg\\data\\tsdata.py 2156 2157 2158 2159 2160 2161 2162 2163 2164 2165 2166 2167 2168 2169 2170 def clear_cache ( self ): \"\"\"Clear the cached values.\"\"\" self . _sg . clear () old_idn = self . _idn self . _iso = None self . _datetime = None self . _idn = None self . _dt = None self . _period = None self . _is_monoton = None if self . parent is not None and old_idn != self . idn : self . parent . replace ( old_idn , self ) index_at_time ( time ) Get the index of the first tstamp >= time. Source code in ccg\\data\\tsdata.py 2147 2148 2149 def index_at_time ( self , time : float | datetime ) -> int : \"\"\"Get the index of the first tstamp >= time.\"\"\" raise NotImplementedError savgol_coef ( sample_to_index , n_ord , n_win_orig , n_dot = 0 ) Calculate Savitzky Golay coeficients. Source code in ccg\\data\\tsdata.py 2173 2174 2175 2176 2177 2178 2179 2180 2181 2182 2183 2184 2185 2186 2187 2188 2189 2190 2191 2192 2193 2194 2195 2196 2197 2198 2199 2200 2201 2202 2203 2204 2205 2206 2207 2208 2209 2210 2211 2212 2213 2214 2215 2216 2217 2218 2219 2220 2221 2222 2223 2224 2225 2226 2227 2228 2229 2230 2231 2232 2233 2234 2235 2236 2237 2238 2239 2240 2241 2242 2243 2244 2245 def savgol_coef ( self : TLine , sample_to_index : TLine , n_ord : int , n_win_orig : int , n_dot : int = 0 , ): \"\"\"Calculate Savitzky Golay coeficients.\"\"\" # Check if coef's are stored nsamplesnew = len ( sample_to_index ) if ( self . idn == self . _sg . orig_index and sample_to_index . idn == self . _sg . sample_to_index and n_ord == self . _sg . n_ord and n_win_orig == self . _sg . n_win_orig ): conv = self . _sg . conv uniqinvs = self . _sg . uniqinvs n_uniq = self . _sg . n_uniq inds = self . _sg . inds else : # Missing or different, so have to calc coef's nsamples = len ( self ) # Find orig samples near new samples ind0 = np . digitize ( sample_to_index . unix , self . unix ) ind0 = np . maximum ( np . minimum ( ind0 , nsamples - 1 , out = ind0 ), 0 , out = ind0 ) # saturate inds = ind0 [:, np . newaxis ] # make n x 1 offs = np . arange ( n_win_orig ) - int (( n_win_orig - 1 ) / 2 ) inds = inds + offs # Saturate the ends inds = np . maximum ( np . minimum ( inds , nsamples - 1 , out = inds ), 0 , out = inds ) indsz : npt . NDArray = self . unix [ inds . ravel ()] # to seconds indsz = indsz . reshape ( inds . shape ) torig = self . unix [ ind0 ] indsz = indsz - torig [:, np . newaxis ] # Find unique window spacings, round to appropriate resolution indsz = np . around ( indsz , 3 , out = indsz ) uniqz , uniqinvs = np . unique ( indsz , return_inverse = True , axis = 0 ) n_uniq = len ( uniqz ) pwrs = np . arange ( n_ord + 1 ) conv = np . empty (( n_uniq , n_win_orig , n_ord + 1 )) for i , uniq in enumerate ( uniqz ): j : npt . NDArray = uniq [:, np . newaxis ] ** pwrs try : tmp = np . linalg . inv ( j . T @ j ) @ j . T except np . linalg . LinAlgError : tmp = np . linalg . pinv ( j . T @ j ) @ j . T conv [ i , :, :] = tmp . T # Store inputs for validating accuracy of stored coef's # Compress or abbrev?? self . _sg . orig_index = self . idn self . _sg . sample_to_index = sample_to_index . idn self . _sg . n_win_orig = n_win_orig self . _sg . n_ord = n_ord # Store coef's self . _sg . conv = conv self . _sg . uniqinvs = uniqinvs self . _sg . n_uniq = n_uniq self . _sg . inds = inds # Calc coef's for this derivative convs = np . empty (( n_win_orig , nsamplesnew )) for i in range ( n_uniq ): convs [:, uniqinvs == i ] = conv [ i , :, n_dot ][:, np . newaxis ] return inds , convs sort () Sort tline. Source code in ccg\\data\\tsdata.py 2151 2152 2153 def sort ( self ): \"\"\"Sort tline.\"\"\" raise NotImplementedError ( \"tline sort is not implemented.\" ) TLineCollection Collection of timelines for Frame. Parameters: frame ( Frame ) \u2013 optional Frame to get timelines from. tlines ( TLine | list [ TLine ] , default: None ) \u2013 optional CCGTline or list of CCGTline. If used, signames is required. signames ( str | list [ str ] , default: None ) \u2013 required with tlines. If tlines is a list, must be equal length. If single tlines, can be a list. Source code in ccg\\data\\tsdata.py 2248 2249 2250 2251 2252 2253 2254 2255 2256 2257 2258 2259 2260 2261 2262 2263 2264 2265 2266 2267 2268 2269 2270 2271 2272 2273 2274 2275 2276 2277 2278 2279 2280 2281 2282 2283 2284 2285 2286 2287 2288 2289 2290 2291 2292 2293 2294 2295 2296 2297 2298 2299 2300 2301 2302 2303 2304 2305 2306 2307 2308 2309 2310 2311 2312 2313 2314 2315 2316 2317 2318 2319 2320 2321 2322 2323 2324 2325 2326 2327 2328 2329 2330 2331 2332 2333 2334 2335 2336 2337 2338 2339 2340 2341 2342 2343 2344 2345 2346 2347 2348 2349 2350 2351 2352 2353 2354 2355 2356 2357 2358 2359 2360 2361 2362 2363 2364 2365 2366 2367 2368 2369 2370 2371 2372 2373 2374 2375 2376 2377 2378 2379 2380 2381 2382 2383 2384 2385 2386 2387 2388 2389 2390 2391 2392 2393 2394 2395 2396 2397 2398 2399 2400 2401 2402 2403 2404 2405 2406 2407 2408 2409 2410 2411 2412 2413 2414 2415 2416 2417 2418 2419 2420 2421 2422 2423 2424 2425 2426 2427 2428 2429 2430 2431 2432 2433 2434 2435 2436 2437 2438 2439 2440 2441 2442 2443 2444 2445 2446 2447 2448 2449 2450 2451 2452 2453 2454 2455 2456 2457 2458 2459 2460 2461 2462 2463 2464 2465 2466 2467 2468 2469 2470 2471 2472 2473 2474 2475 2476 2477 2478 2479 2480 2481 2482 2483 2484 2485 2486 2487 2488 2489 2490 2491 2492 2493 2494 2495 2496 2497 2498 2499 2500 2501 2502 2503 2504 2505 2506 2507 2508 2509 2510 2511 2512 2513 2514 2515 2516 2517 2518 2519 2520 2521 2522 2523 2524 2525 2526 2527 2528 2529 2530 2531 2532 2533 2534 2535 2536 2537 2538 2539 2540 2541 2542 2543 2544 2545 2546 2547 2548 2549 2550 2551 class TLineCollection : \"\"\" Collection of timelines for Frame. Parameters ---------- frame optional Frame to get timelines from. tlines optional CCGTline or list of CCGTline. If used, signames is required. signames required with tlines. If tlines is a list, must be equal length. If single tlines, can be a list. \"\"\" def __init__ ( self , frame : Frame , tlines : TLine | list [ TLine ] = None , signames : str | list [ str ] = None , ) -> None : self . tlines : dict [ int , TLine ] = {} self . idns : dict [ str , int ] = {} self . sigs : dict [ int , list [ str ]] = {} if frame or tlines : self . append ( frameorsig = frame , tlines = tlines , signames = signames ) self . frame = frame @profile def append ( self , frameorsig : Sig | Frame = None , tlines : TLine | list [ TLine ] = None , signames : list [ str ] | list [ list [ str ]] = None , ) -> TLine : \"\"\" Append tline to collection. Parameters ---------- frame optional Frame to get timelines from. tlines optional CCGTline or list of CCGTline. If used, signames is required. signames required with tlines. Must be equal length list of lists of signames. Returns ------- CCGTimeline \"\"\" if frameorsig is not None : # if isinstance(frameorsig, pd.DataFrame): # tline = TLine(frameorsig) # tline.parent = self # if tline.idn in self.tlines: # self.check_sg(tline) # else: # self.tlines[tline.idn] = tline # tlref = self.tlines[tline.idn] # for col in frameorsig: # self.idns[col] = tline.idn # self.add_to_sigs(tline.idn, col) if isinstance ( frameorsig , Frame ): tlref = [] if frameorsig . nsigs > 0 : for tline in frameorsig . tlines : tline . parent = self # TODO: Check for reference issue in this case if tline . idn in self . tlines : self . check_sg ( tline ) else : self . tlines [ tline . idn ] = tline sigs = frameorsig . tlines . sigs [ tline . idn ] # Check if signame already exists with different tline idns_old = self . idns [ sigs ] if idns_old and np . any ( idns_old != tline . idn ): _LOGGER . error ( \"Existing signal( %s ) with different timeline has been replaced\" , sigs [ idns_old != tline . idn ], ) self . idns [ sigs ] = tline . idn self . add_to_sigs ( tline . idn , sigs ) tlref . append ( self . tlines [ tline . idn ]) elif isinstance ( frameorsig , Sig ): tline = frameorsig . tline tline . parent = self if tline . idn in self : self . check_sg ( tline ) else : self . tlines [ tline . idn ] = tline tlref = self . tlines [ tline . idn ] sigs = frameorsig . name # Check if signame already exists with different tline try : idns_old = self . idns [ sigs ] except KeyError : idns_old = None if any ([ idns_old == tline . idn ]): _LOGGER . error ( \"Existing signal( %s ) with different timeline\" , sigs [ idns_old != tline . idn ], ) self . idns [ sigs ] = tline . idn self . add_to_sigs ( tline . idn , sigs ) # Change 2/10/24 - fix reference to tline in sig here frameorsig . tline = tlref else : raise NotImplementedError ( f \"Appending tline from { type ( frameorsig ) } is not implemented\" ) if tlines is not None : if not isinstance ( tlines , list ): tlines = [ tlines ] if len ( signames ) != len ( tlines ): raise ValueError ( \"If tlines is specified and contains more than 1, signames must be same length.\" ) if signames is None : raise ValueError ( \"signames must be specified with tlines.\" ) tlref = [] for sigs , tline in zip ( signames , tlines ): tline . parent = self if tline . idn in self . tlines : self . check_sg ( tline ) else : self . tlines [ tline . idn ] = tline if not isinstance ( sigs , list ): sigs = [ sigs ] self . add_to_sigs ( tline . idn , sigs ) for sig in sigs : self . idns [ sig ] = tline . idn tlref . append ( tline ) return tlref def check_sg ( self , tline : TLine ): \"\"\"Check for existing _sg coef.\"\"\" # If sigs timeline has conv coef, but the cached doesnt, use it instead # pylint: disable=protected-access if tline . _sg . conv is not None and self . tlines [ tline . idn ] . _sg . conv is None : self . tlines [ tline . idn ] . _sg = tline . _sg def get_fastest ( self ): \"\"\"Return the approximate fastest tline from coll.\"\"\" tmp = self [ 0 ] fast = tmp . period for _ , tline in self . tlines . items (): if tline . period < fast : tmp = tline fast = tmp . period return tmp def remove ( self , signame ): \"\"\"Remove timeline for signame from collection. If other signals still use it, it will simply remove the reference. \"\"\" tl_idn = self . idns [ signame ] nref = len ( self . sigs [ tl_idn ]) if nref == 0 : raise ValueError ( \"No matching tline.\" ) if nref == 1 : self . tlines . pop ( tl_idn ) self . idns . pop ( signame ) self . sigs . pop ( tl_idn ) else : self . idns . pop ( signame ) self . sigs [ tl_idn ] . pop ( self . sigs [ tl_idn ] . index ( signame )) def replace ( self , old_tline : int | TLine , new_tline : TLine ): \"\"\"Replace the `old_tline` with `new_tline` in place.\"\"\" if isinstance ( old_tline , TLine ): old_idn = old_tline . idn else : old_idn = old_tline old_tline = self . tlines [ old_idn ] if old_idn in self . tlines : existing_sigs = self . sigs [ old_idn ] . copy () for existing in existing_sigs : self . remove ( existing ) old_tline . parent = None # To block the replace call in unix setter old_tline . unix = new_tline . unix self . append ( tlines = old_tline , signames = [ existing_sigs ]) @property def tstart ( self ): \"\"\"Earliest tstart in collection.\"\"\" tstart = None for _ , tline in self . tlines . items (): if tstart is None or tline . tstart < tstart : tstart = tline . tstart return tstart @property def tend ( self ): \"\"\"Latest tend in collection.\"\"\" tend = None for _ , tline in self . tlines . items (): if tend is None or tline . tend > tend : tend = tline . tend return tend @property def tstart_iso ( self ): \"\"\"Earliest start time in iso.\"\"\" return ccg . util . unix_to_iso ( self . tstart ) @property def tend_iso ( self ): \"\"\"Latest end time in iso.\"\"\" return ccg . util . unix_to_iso ( self . tend ) @property def n_tlines ( self ): \"\"\"Number of tlines in collection.\"\"\" return len ( self . tlines ) @property def nsamples ( self ): \"\"\"Number of samples in collection.\"\"\" nsamples = 0 for _ , tline in self . tlines . items (): nsamples += tline . nsamples return nsamples def add_to_sigs ( self , tline_idn : int , signame : str | list [ str ]): \"\"\"Add signal name to list.\"\"\" if isinstance ( signame , str ): signame = [ signame ] try : # try to extend incase it already exists. self . sigs [ tline_idn ] . extend ( signame ) except KeyError : # else define it as a list self . sigs [ tline_idn ] = signame def get_apprx_bytes ( self , tline : TLine ): \"\"\"Gets the approximate size of the tline and its associated signals. Parameters ---------- tline tline to get size for. Returns ------- Cumulative Bytes of tline and the signals associated with it. \"\"\" size = tline . appx_bytes for sig in self . sigs [ tline . idn ]: size += self . frame . sigs [ sig ] . appx_bytes return size def __getitem__ ( self , index : str | int ) -> TLine : if isinstance ( index , str ): return self . tlines [ self . idns [ index ]] elif isinstance ( index , int ): # TODO: Is this legit?? try : return self . tlines [ index ] except KeyError : return list ( self . tlines . values ())[ index ] else : raise NotImplementedError def __repr__ ( self ) -> str : \"\"\"Return string repr.\"\"\" isos = [] for tline in self . tlines . values (): isos . append ( repr ( tline )) # reprstr = f\"{self.__class__.__module__}.{self.__class__.__qualname__}([{', '.join(isos)}])\" reprstr = f \" { self . __class__ . __qualname__ } ([ { ', ' . join ( isos ) } ])\" return reprstr def __str__ ( self ): \"\"\"String rep.\"\"\" idnlist = self . tlines . keys () return f \"tline collection idns: { idnlist } \" def __eq__ ( self , other ) -> bool : \"\"\"Check equality.\"\"\" if isinstance ( other , self . __class__ ): eq = ( self . idns == other . idns and self . sigs == other . sigs and self . tlines == other . tlines ) return eq else : return False def __contains__ ( self , other ) -> bool : return other in self . tlines n_tlines property Number of tlines in collection. nsamples property Number of samples in collection. tend property Latest tend in collection. tend_iso property Latest end time in iso. tstart property Earliest tstart in collection. tstart_iso property Earliest start time in iso. __eq__ ( other ) Check equality. Source code in ccg\\data\\tsdata.py 2538 2539 2540 2541 2542 2543 2544 2545 2546 2547 2548 def __eq__ ( self , other ) -> bool : \"\"\"Check equality.\"\"\" if isinstance ( other , self . __class__ ): eq = ( self . idns == other . idns and self . sigs == other . sigs and self . tlines == other . tlines ) return eq else : return False __repr__ () Return string repr. Source code in ccg\\data\\tsdata.py 2524 2525 2526 2527 2528 2529 2530 2531 def __repr__ ( self ) -> str : \"\"\"Return string repr.\"\"\" isos = [] for tline in self . tlines . values (): isos . append ( repr ( tline )) # reprstr = f\"{self.__class__.__module__}.{self.__class__.__qualname__}([{', '.join(isos)}])\" reprstr = f \" { self . __class__ . __qualname__ } ([ { ', ' . join ( isos ) } ])\" return reprstr __str__ () String rep. Source code in ccg\\data\\tsdata.py 2533 2534 2535 2536 def __str__ ( self ): \"\"\"String rep.\"\"\" idnlist = self . tlines . keys () return f \"tline collection idns: { idnlist } \" add_to_sigs ( tline_idn , signame ) Add signal name to list. Source code in ccg\\data\\tsdata.py 2487 2488 2489 2490 2491 2492 2493 2494 def add_to_sigs ( self , tline_idn : int , signame : str | list [ str ]): \"\"\"Add signal name to list.\"\"\" if isinstance ( signame , str ): signame = [ signame ] try : # try to extend incase it already exists. self . sigs [ tline_idn ] . extend ( signame ) except KeyError : # else define it as a list self . sigs [ tline_idn ] = signame append ( frameorsig = None , tlines = None , signames = None ) Append tline to collection. Parameters: frame \u2013 optional Frame to get timelines from. tlines ( TLine | list [ TLine ] , default: None ) \u2013 optional CCGTline or list of CCGTline. If used, signames is required. signames ( list [ str ] | list [ list [ str ]] , default: None ) \u2013 required with tlines. Must be equal length list of lists of signames. Returns: CCGTimeline \u2013 Source code in ccg\\data\\tsdata.py 2276 2277 2278 2279 2280 2281 2282 2283 2284 2285 2286 2287 2288 2289 2290 2291 2292 2293 2294 2295 2296 2297 2298 2299 2300 2301 2302 2303 2304 2305 2306 2307 2308 2309 2310 2311 2312 2313 2314 2315 2316 2317 2318 2319 2320 2321 2322 2323 2324 2325 2326 2327 2328 2329 2330 2331 2332 2333 2334 2335 2336 2337 2338 2339 2340 2341 2342 2343 2344 2345 2346 2347 2348 2349 2350 2351 2352 2353 2354 2355 2356 2357 2358 2359 2360 2361 2362 2363 2364 2365 2366 2367 2368 2369 2370 2371 2372 2373 2374 2375 2376 2377 2378 2379 2380 2381 2382 2383 2384 2385 2386 2387 2388 2389 2390 2391 2392 2393 @profile def append ( self , frameorsig : Sig | Frame = None , tlines : TLine | list [ TLine ] = None , signames : list [ str ] | list [ list [ str ]] = None , ) -> TLine : \"\"\" Append tline to collection. Parameters ---------- frame optional Frame to get timelines from. tlines optional CCGTline or list of CCGTline. If used, signames is required. signames required with tlines. Must be equal length list of lists of signames. Returns ------- CCGTimeline \"\"\" if frameorsig is not None : # if isinstance(frameorsig, pd.DataFrame): # tline = TLine(frameorsig) # tline.parent = self # if tline.idn in self.tlines: # self.check_sg(tline) # else: # self.tlines[tline.idn] = tline # tlref = self.tlines[tline.idn] # for col in frameorsig: # self.idns[col] = tline.idn # self.add_to_sigs(tline.idn, col) if isinstance ( frameorsig , Frame ): tlref = [] if frameorsig . nsigs > 0 : for tline in frameorsig . tlines : tline . parent = self # TODO: Check for reference issue in this case if tline . idn in self . tlines : self . check_sg ( tline ) else : self . tlines [ tline . idn ] = tline sigs = frameorsig . tlines . sigs [ tline . idn ] # Check if signame already exists with different tline idns_old = self . idns [ sigs ] if idns_old and np . any ( idns_old != tline . idn ): _LOGGER . error ( \"Existing signal( %s ) with different timeline has been replaced\" , sigs [ idns_old != tline . idn ], ) self . idns [ sigs ] = tline . idn self . add_to_sigs ( tline . idn , sigs ) tlref . append ( self . tlines [ tline . idn ]) elif isinstance ( frameorsig , Sig ): tline = frameorsig . tline tline . parent = self if tline . idn in self : self . check_sg ( tline ) else : self . tlines [ tline . idn ] = tline tlref = self . tlines [ tline . idn ] sigs = frameorsig . name # Check if signame already exists with different tline try : idns_old = self . idns [ sigs ] except KeyError : idns_old = None if any ([ idns_old == tline . idn ]): _LOGGER . error ( \"Existing signal( %s ) with different timeline\" , sigs [ idns_old != tline . idn ], ) self . idns [ sigs ] = tline . idn self . add_to_sigs ( tline . idn , sigs ) # Change 2/10/24 - fix reference to tline in sig here frameorsig . tline = tlref else : raise NotImplementedError ( f \"Appending tline from { type ( frameorsig ) } is not implemented\" ) if tlines is not None : if not isinstance ( tlines , list ): tlines = [ tlines ] if len ( signames ) != len ( tlines ): raise ValueError ( \"If tlines is specified and contains more than 1, signames must be same length.\" ) if signames is None : raise ValueError ( \"signames must be specified with tlines.\" ) tlref = [] for sigs , tline in zip ( signames , tlines ): tline . parent = self if tline . idn in self . tlines : self . check_sg ( tline ) else : self . tlines [ tline . idn ] = tline if not isinstance ( sigs , list ): sigs = [ sigs ] self . add_to_sigs ( tline . idn , sigs ) for sig in sigs : self . idns [ sig ] = tline . idn tlref . append ( tline ) return tlref check_sg ( tline ) Check for existing _sg coef. Source code in ccg\\data\\tsdata.py 2395 2396 2397 2398 2399 2400 def check_sg ( self , tline : TLine ): \"\"\"Check for existing _sg coef.\"\"\" # If sigs timeline has conv coef, but the cached doesnt, use it instead # pylint: disable=protected-access if tline . _sg . conv is not None and self . tlines [ tline . idn ] . _sg . conv is None : self . tlines [ tline . idn ] . _sg = tline . _sg get_apprx_bytes ( tline ) Gets the approximate size of the tline and its associated signals. Parameters: tline ( TLine ) \u2013 tline to get size for. Returns: Cumulative Bytes of tline and the signals associated with it. \u2013 Source code in ccg\\data\\tsdata.py 2496 2497 2498 2499 2500 2501 2502 2503 2504 2505 2506 2507 2508 2509 2510 def get_apprx_bytes ( self , tline : TLine ): \"\"\"Gets the approximate size of the tline and its associated signals. Parameters ---------- tline tline to get size for. Returns ------- Cumulative Bytes of tline and the signals associated with it. \"\"\" size = tline . appx_bytes for sig in self . sigs [ tline . idn ]: size += self . frame . sigs [ sig ] . appx_bytes return size get_fastest () Return the approximate fastest tline from coll. Source code in ccg\\data\\tsdata.py 2402 2403 2404 2405 2406 2407 2408 2409 2410 2411 def get_fastest ( self ): \"\"\"Return the approximate fastest tline from coll.\"\"\" tmp = self [ 0 ] fast = tmp . period for _ , tline in self . tlines . items (): if tline . period < fast : tmp = tline fast = tmp . period return tmp remove ( signame ) Remove timeline for signame from collection. If other signals still use it, it will simply remove the reference. Source code in ccg\\data\\tsdata.py 2413 2414 2415 2416 2417 2418 2419 2420 2421 2422 2423 2424 2425 2426 2427 2428 def remove ( self , signame ): \"\"\"Remove timeline for signame from collection. If other signals still use it, it will simply remove the reference. \"\"\" tl_idn = self . idns [ signame ] nref = len ( self . sigs [ tl_idn ]) if nref == 0 : raise ValueError ( \"No matching tline.\" ) if nref == 1 : self . tlines . pop ( tl_idn ) self . idns . pop ( signame ) self . sigs . pop ( tl_idn ) else : self . idns . pop ( signame ) self . sigs [ tl_idn ] . pop ( self . sigs [ tl_idn ] . index ( signame )) replace ( old_tline , new_tline ) Replace the old_tline with new_tline in place. Source code in ccg\\data\\tsdata.py 2430 2431 2432 2433 2434 2435 2436 2437 2438 2439 2440 2441 2442 2443 2444 def replace ( self , old_tline : int | TLine , new_tline : TLine ): \"\"\"Replace the `old_tline` with `new_tline` in place.\"\"\" if isinstance ( old_tline , TLine ): old_idn = old_tline . idn else : old_idn = old_tline old_tline = self . tlines [ old_idn ] if old_idn in self . tlines : existing_sigs = self . sigs [ old_idn ] . copy () for existing in existing_sigs : self . remove ( existing ) old_tline . parent = None # To block the replace call in unix setter old_tline . unix = new_tline . unix self . append ( tlines = old_tline , signames = [ existing_sigs ]) get_math_tline ( sig1 , sig2 ) returns timeline for math. sig1.parent.math_tline if it exits, or fastest. Source code in ccg\\data\\tsdata.py 2647 2648 2649 2650 2651 2652 2653 2654 2655 def get_math_tline ( sig1 : Sig , sig2 : Sig | npt . NDArray | float | int ): \"\"\"returns timeline for math. sig1.parent.math_tline if it exits, or fastest.\"\"\" if sig1 . parent and sig1 . parent . math_tline : return sig1 . parent . math_tline if isinstance ( sig2 , Sig ) and sig2 . parent and sig2 . parent . math_tline : return sig2 . parent . math_tline if isinstance ( sig2 , Sig ) and sig1 . tline . period > sig2 . tline . period : return sig2 . tline return sig1 . tline","title":"Data"},{"location":"data/#ccg.data.tsdata.Frame","text":"Collection of Time Series data. Parameters: data ( Sig | list [ Sig ] | None , default: None ) \u2013 TS Data, by default None. References to Sig will be broken. name ( str | None , default: None ) \u2013 Frame name, by default None math_tline ( TLine | None , default: None ) \u2013 TLine for Frame wide math, by default None Attributes: sigs ( dict [ str , Sig ] ) \u2013 dictionary of Sigs tlines ( TLineCollection ) \u2013 Collection of timelines, referenced by Sigs name ( str ) \u2013 Frame Name nsigs ( int ) \u2013 nsamples ( int ) \u2013 tend ( float | None ) \u2013 tstart ( float | None ) \u2013 tline ( TLine | None ) \u2013 Source code in ccg\\data\\tsdata.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 class Frame : \"\"\"Collection of Time Series data. Parameters ---------- data : Sig | list[Sig] | None, optional TS Data, by default None. References to Sig will be broken. name : str | None, optional Frame name, by default None math_tline : TLine | None, optional TLine for Frame wide math, by default None Attributes ------- sigs : dict[str, Sig] dictionary of Sigs tlines: TLineCollection Collection of timelines, referenced by Sigs name: str Frame Name nsigs nsamples tend tstart tline \"\"\" CUTOFF = 0.5 # For difflib compares def __init__ ( self , data : Sig | list [ Sig ] | None = None , name : str | None = None , math_tline : TLine | None = None , ) -> None : self . sigs : dict [ str , Sig ] = {} self . tlines = TLineCollection ( self ) self . name = name sigs = [] self . math_tline = math_tline # if isinstance(data, pd.DataFrame): # tline = TLine(data) # for col in data: # sig = Sig( # data=data[col], # tline=tline, # name=col, # frame=self, # ) # sigs.append(sig) if isinstance ( data , Sig ): sigs . append ( data ) elif isinstance ( data , list ): for sig in data : sigs . append ( sig ) elif data is None : pass else : raise NotImplementedError ( f \"Frame generation from { type ( data ) } is not implemented.\" ) self . append ( sigs ) @property def nsigs ( self ) -> int : \"\"\"Number of Sigs in collection.\"\"\" return len ( self . sigs ) @property def nsamples ( self ) -> int : \"\"\"Cumulative samples (counting unique timelines as well).\"\"\" nsamples = self . tlines . nsamples for _ , sig in self . sigs . items (): nsamples += sig . nsamples return nsamples @property def tend ( self ) -> float | None : \"\"\"Latest end time from TLine collection. Returns ------- float Time in unix. \"\"\" return self . tlines . tend @property def tstart ( self ) -> float | None : \"\"\"Earliest start time from TLine collection. Returns ------- float Time in unix. \"\"\" return self . tlines . tstart @property def tend_iso ( self ) -> npt . NDArray [ np . datetime64 ]: \"\"\"Latest end time from TLine collection. Returns ------- float Time in iso. \"\"\" return self . tlines . tend_iso @property def tstart_iso ( self ): \"\"\"Earliest start time from TLine collection. Returns ------- float Time in iso. \"\"\" return self . tlines . tstart_iso # def calc_idn(self): # \"\"\"Calculate hash for IDN.\"\"\" # tic = datetime.now() # idn = xxhash.xxh3_64(self.sigs).intdigest() # toc = datetime.now() - tic # _LOGGER.debug(\"IDN calc'd for %s in %.3f\", self.name, toc.total_seconds()) # return idn def resample ( self , sample_to : TLine , sigs : str | list [ str ] | None = None , inplace : bool | None = False , prefix : str | None = None , suffix : str | None = None , ** kwargs , ): \"\"\"Resample Frame to a `sample_to` TLine. Parameters ---------- sample_to : TLine TLine to resample to sigs : str | list[str] | None, optional list of sigs to resample, full frame if None, by default None inplace : bool | None, optional if True, will resample signals and append (id prefix or suffix is not None) or replace inplace. By default False prefix : str | None, optional prefix to signame, by default None suffix : str | None, optional suffix to signame, by default None **kwargs Additional arguments passed to `Sig.resample()` Returns ------- Frame Returns Self if inplace, else a new Frame \"\"\" if inplace : res = self else : res = Frame () if sigs is not None : if isinstance ( sigs , str ): sigs = [ sigs ] else : sigs = list ( self . sigs . keys ()) for sig in sigs : newsig = self . sigs [ sig ] . resample ( sample_to , ** kwargs ) if prefix is not None : newsig . name = prefix + newsig . name if suffix is not None : newsig . name = newsig . name + suffix if inplace and prefix is None and suffix is None : res . remove ( sig ) res . append ( newsig ) return res def append ( self , item : Sig | Frame | list [ Sig ], append_existing_signals : bool = False , interweave_tlines : bool = False , ): \"\"\"Append to CCG Frame in place.\"\"\" if isinstance ( item , Frame ): sigs_to_apnd = list ( item . sigs . keys ()) for _ , new_sigs in item . tlines . sigs . items (): for sig in new_sigs : if append_existing_signals and sig in self and sig in sigs_to_apnd : check_overlap ( self [ sig ], item [ sig ], interweave_tlines ) old_idn = self . tlines . idns [ sig ] new_tline = self . tlines [ old_idn ] . append_to_new ( item [ sig ]) if new_tline . is_monotonic_increasing : for old_sig in list ( self . tlines . sigs [ old_idn ]): if old_sig in item : self . tlines . remove ( old_sig ) self [ old_sig ] . tline = new_tline self . tlines . append ( self [ old_sig ]) # for references self [ old_sig ] . _data . append ( item [ old_sig ] . _data ) # get the rest of the attributes if item [ old_sig ] . connect_gaps is not None : self [ old_sig ] . connect_gaps = item [ old_sig ] . connect_gaps if item [ old_sig ] . data_enum is not None : self [ old_sig ] . data_enum = item [ old_sig ] . data_enum if item [ old_sig ] . interp_method is not None : self [ old_sig ] . interp_method = item [ old_sig ] . interp_method if item [ old_sig ] . unit is not None : self [ old_sig ] . unit = item [ old_sig ] . unit # Check for unknown attributes. the new signal value will overide the original. for key , val in item [ old_sig ] . __dict__ . items (): if ( not key . startswith ( \"_\" ) and key not in SIG_ATTRS ): setattr ( self [ old_sig ], key , val ) sigs_to_apnd . remove ( old_sig ) else : raise NotImplementedError ( \"batch appends not implemented for non-monoton\" ) for signame in sigs_to_apnd : sig = item [ signame ] self . _append_sig ( sig , append_existing_signals , interweave_tlines ) elif isinstance ( item , list ): for sig in item : self . _append_sig ( sig , append_existing_signals , interweave_tlines ) else : self . _append_sig ( item , append_existing_signals , interweave_tlines ) @profile def _append_sig ( self , sig : Sig , append_existing_signals : bool = False , interweave_tlines : bool = False , ): \"\"\"Append a signal to Frame.\"\"\" # create a new sig to break references to existing sig_copy = Sig ( sig ) # Check for matching name if sig_copy . name in self . sigs : if append_existing_signals : self . sigs [ sig_copy . name ] . append ( sig_copy , interweave_tlines = interweave_tlines , remove_duplicates = False , ) else : _LOGGER . warning ( \"Sig %s already exists, use append_existing_signals=True.\" , sig . name , ) else : self . tlines . append ( sig_copy ) # sig_copy.tline = tlref # replace with the tline reference # 2/10/24 now in tlines.append() sig_copy . parent = self self . sigs [ sig_copy . name ] = sig_copy def _rename_sig ( self , oldname , newname ): \"\"\" Rename signal references in frame. Use `frm['oldname'].name = newname` to rename signal and update frame references together. \"\"\" self . sigs [ newname ] = self . sigs . pop ( oldname ) self . tlines . idns [ newname ] = self . tlines . idns . pop ( oldname ) ind = self . tlines . sigs [ self . tlines . idns [ newname ]] . index ( oldname ) self . tlines . sigs [ self . tlines . idns [ newname ]][ ind ] = newname def sort ( self , remove_safe_duplicates = False , remove_all_duplicates = False ): \"\"\"Sort signals by timeline for monoton increasing.\"\"\" for _ , sig in self . sigs . items (): sig . sort_tline ( inplace = True , remove_safe_duplicates = remove_safe_duplicates , remove_all_duplicates = remove_all_duplicates , ) # def to_pandas(self) -> pd.DataFrame: # \"\"\"Convert CCGFrame to pd.DataFrame.\"\"\" # serieslist = [] # for sig in self: # serieslist.append(sig.to_pandas()) # pddf = pd.concat(serieslist, join=\"outer\", axis=1) # return pddf def clear ( self ): \"\"\"Clears frame in place.\"\"\" self . sigs : dict [ str , Sig ] = {} self . tlines = TLineCollection ( self ) def clean_names ( self ): \"\"\"Cleans signal names.\"\"\" rename_list = {} for signame , _ in self . sigs . items (): clean_name = ccg . util . clean_name ( signame ) if clean_name != signame : rename_list . update ({ signame : clean_name }) for signame , clean_name in rename_list . items (): _LOGGER . debug ( \" %s renamed to %s \" , signame , clean_name ) self [ signame ] . name = clean_name def remove ( self , signames : str | list [ str ]): \"\"\"Removes sigs from frame.\"\"\" if not isinstance ( signames , list ): signames = [ signames ] for signame in signames : if signame in self : self . tlines . remove ( signame ) self . sigs . pop ( signame , None ) def plot ( self ): \"\"\"Plot data frame.\"\"\" from ccg.ui.plot import Plot plt = Plot ( self ) plt . plot () def valid ( self , gatecoll : GateColl , tline : TLine | None = None ) -> Frame : \"\"\"Returns a new Frame, invalid data replaced with nan. calc'd on `tline` or combined TLine if None Parameters ---------- gatecoll : GateColl Collection of gating conditions tline : TLine | None, optional TLine to calculate validity on, by default None Returns ------- Frame New instance of Frame \"\"\" res = Frame ( name = self . name ) # if tline is None: # tline = self.tlines.get_fastest() valid_sig = gatecoll . validate ( self , tline ) for tmp_tline in self . tlines : if tmp_tline . nsamples > 1 : b_valid = valid_sig . interp ( tmp_tline ) . data for sig in self . tlines . sigs [ tmp_tline . idn ]: newsig = Sig ( self [ sig ]) nan = np . NaN if newsig . data . dtype . kind in [ \"i\" , \"u\" ]: newsig . data = newsig . data . astype ( \"float\" ) elif newsig . data . dtype . kind in [ \"U\" , \"S\" ]: nan = \"\" newsig . data [ ~ b_valid ] = nan res . append ( newsig ) return res @property def tline ( self ) -> TLine | None : \"\"\"If frame has only one tline, return it.\"\"\" if self . tlines . n_tlines == 1 : return list ( self . tlines . tlines . values ())[ 0 ] else : raise ValueError ( f \" { 'frame' if self . name is None else self . name } has more than one tline,\" + f \" { 'frame' if self . name is None else self . name } .tline() invalid.\" ) @profile def from_excel ( self , filename : str | Path , tline_col : int | str = None , signame_row : int = None , signame_regex : str = None , filedata : BytesIO | StringIO | bytes = None , sigunit_row : int = None , sigdata_row : int = None , ) -> Frame : \"\"\"Generate frame from excel file. Parameters ---------- filename tline_col Column to use for an index signame_row Row with names to parse with _regex signame_regex regex string to parse signal names. Use named groups for parameters to pass into Sig instatiation, for example name, units, etc. example here: https://regex101.com/r/bfBrdf/6 filedata string or bytes io. filename will only be used for ext, name, etc. \"\"\" tic = datetime . now () if isinstance ( filename , str ): filename = Path ( filename ) if signame_row is None : signame_row = 0 if tline_col is None : tline_col = 0 if signame_regex is None : signame_regex = r \"(?P<name>^.*?)(?:(?:\\s?\\((?P<unit>(?!.*\\().*)\\))|$)\" # Default regex `signal name (unit)`-> `{'name':'signal name','unit':'unit'` # https://regex101.com/r/bfBrdf/6 regex = re . compile ( signame_regex ) data = self . read_filedata ( filename , filedata ) toc = datetime . now () - tic _LOGGER . debug ( \"read %s in %.3f .\" , filename , toc . total_seconds ()) tic = datetime . now () if isinstance ( signame_row , str ): for i , row in enumerate ( data ): if row [ 0 ] == signame_row : signame_row = i break else : raise ValueError ( f \"Signal Name Row: { signame_row } not found in first column of data file.\" ) signames = data [ signame_row , :] . astype ( \"str\" ) signames = np . char . strip ( signames ) if sigunit_row is not None : sigunits = data [ sigunit_row , :] . astype ( \"str\" ) sig_args = [ { \"name\" : name , \"unit\" : unit } for name , unit in zip ( signames , sigunits ) ] else : sig_args = [ regex . match ( signame ) . groupdict () for signame in signames ] # Check for duplicate names and add _dup existing = [] for sig in sig_args : if sig [ \"name\" ] not in existing : existing . append ( sig [ \"name\" ]) else : existing . append ( sig [ \"name\" ] + \"_dup\" ) sig [ \"name\" ] = sig [ \"name\" ] + \"_dup\" if isinstance ( tline_col , str ): tline_col = np . where ( signames == tline_col ) if tline_col [ 0 ] . size == 0 : raise ValueError ( \"tline_col is not in signames.\" ) else : tline_col = [ tline_col ] if sigdata_row is None : sigdata_row = signame_row + 1 tmp : npt . NDArray = data [ sigdata_row :, tline_col ] . ravel () try : tmp = tmp . astype ( \"float\" ) except ValueError : tmp = tmp . astype ( type ( tmp [ 0 ])) tline = TLine ( tmp ) for i , kwargs in enumerate ( sig_args ): if i != tline_col [ 0 ]: sigtype = type ( data [ sigdata_row , i ]) sigdata = data [ sigdata_row :, i ] . ravel () . astype ( sigtype ) if sigtype is str : try : sigdata = sigdata . astype ( float ) except ValueError : pass new_sig = Sig ( data = sigdata , tline = tline , ** kwargs , ) self . append ( new_sig ) toc = datetime . now () - tic _LOGGER . debug ( \"built frame in %.3f .\" , toc . total_seconds ()) tic = datetime . now () return self @profile def read_filedata ( self , filename : Path , filedata : BytesIO | StringIO | bytes | None = None ): \"\"\"Reads file data for building frame from file\"\"\" ext = filename . suffix if ext in [ \".xlsx\" , \".xlsm\" , \".XLSX\" , \".XLSM\" ]: # Use openpyxl if filedata is None : wb = openpyxl . load_workbook ( filename = filename , read_only = True , data_only = True ) else : wb = openpyxl . load_workbook ( filename = filedata , read_only = True , data_only = True ) ws = wb . active data = ws . values data = np . array ( list ( data )) wb . close () elif ext in [ \".xls\" , \".XLS\" ]: # Use xlrd wb_xls : xlrd . book . Book = xlrd . open_workbook ( filename = filename , file_contents = filedata ) ws = wb_xls . sheet_by_index ( 0 ) # data = np.array(ws._cell_values) data = np . empty ( shape = ( ws . nrows , ws . ncols ), dtype = \"O\" ) for i in range ( ws . ncols ): data [:, i ] = ws . col_values ( i ) elif ext in [ \".csv\" , \".CSV\" ]: if filedata is None : with open ( filename , \"r\" , encoding = \"utf8\" ) as file : csvreader = csv . reader ( file , dialect = \"excel\" ) tmp = list ( csvreader ) max_col = max ( map ( len , tmp )) data = np . array ( [ tmp_row + [ None ] * ( max_col - len ( tmp_row )) for tmp_row in tmp ], dtype = \"O\" , ) else : if isinstance ( filedata , bytes ): csvreader = csv . reader ( io . StringIO ( filedata . decode ( \"utf-8\" ))) else : csvreader = csv . reader ( filedata ) tmp = list ( csvreader ) max_col = max ( map ( len , tmp )) data = np . array ( [ tmp_row + [ None ] * ( max_col - len ( tmp_row )) for tmp_row in tmp ], dtype = \"O\" , ) else : raise NotImplementedError ( f \"Frame from Excel not implemented for ext: { ext } \" ) return data # async def read_filedata_async( # self, filename: Path, filedata: BytesIO | StringIO | bytes = None # ): # \"\"\"Reads file data for building frame from file\"\"\" # ext = filename.suffix # if ext in [\".xlsx\", \".xlsm\", \".XLSX\", \".XLSM\"]: # # Use openpyxl # if filedata is None: # wb = openpyxl.load_workbook( # filename=filename, read_only=True, data_only=True # ) # else: # wb = openpyxl.load_workbook( # filename=filedata, read_only=True, data_only=True # ) # ws = wb.active # data = ws.values # data = np.array(list(data)) # wb.close() # elif ext in [\".xls\", \".XLS\"]: # # Use xlrd # wb_xls: xlrd.book.Book = xlrd.open_workbook( # filename=filename, file_contents=filedata # ) # ws = wb_xls.sheet_by_index(0) # # data = np.array(ws._cell_values) # data = np.empty(shape=(ws.nrows, ws.ncols), dtype=\"O\") # for i in range(ws.ncols): # data[:, i] = ws.col_values(i) # elif ext in [\".csv\", \".CSV\"]: # if filedata is None: # async with aiofiles.open(filename, \"r\", encoding=\"utf8\") as file: # csvreader = aiocsv.AsyncReader(file, dialect=\"excel\") # tmp = await list(csvreader) # max_col = max(map(len, tmp)) # data = np.array( # [ # tmp_row + [None] * (max_col - len(tmp_row)) # for tmp_row in tmp # ], # dtype=\"O\", # ) # else: # if isinstance(filedata, bytes): # csvreader = aiocsv.AsyncReader( # io.StringIO(filedata.decode(\"utf-8\")) # ) # else: # csvreader = aiocsv.AsyncReader(filedata) # tmp = await list(csvreader) # max_col = max(map(len, tmp)) # data = np.array( # [tmp_row + [None] * (max_col - len(tmp_row)) for tmp_row in tmp], # dtype=\"O\", # ) # else: # raise NotImplementedError( # f\"Frame from Excel not implemented for ext: {ext}\" # ) # return data def __getattr__ ( self , signame : str ) -> Sig : \"\"\"Provides dot notation access to Sigs if their names conform to dot notation. Parameters ---------- signame : str Must conform to dot notation (no spaces or special characters, starts with non numeric char, etc.) Returns ------- Sig Reference to Sig in Self \"\"\" if signame . startswith ( \"_\" ): raise AttributeError # Probably dont want to let it return _** return self . __getitem__ ( signame ) @overload def __getitem__ ( self , index : str ) -> Sig : pass @overload def __getitem__ ( self , index : Frame | list [ str ] | slice | set [ str ] | tuple [ str ] ) -> Frame : pass @profile def __getitem__ ( self , index : Frame | list [ str ] | set [ str ] | tuple [ str ] | str | slice ) -> Frame | Sig : \"\"\"Frame item getter. Parameters ---------- index : Frame | list[str] | slice | set[str] | str Frame, list of Sig names, slice of Returns ------- Frame | Sig New instance of Frame if index is Frame, list[str], slice. Reference to the Sig if str is a sig name. Examples -------- >>>TEST_LIST = [1.0, 2.0, 3.0] >>>TEST_ARR = np.array(TEST_LIST) >>>TEST_TIME = [0.0, 1.0, 2.0] >>>TEST_TLINE = TLine(TEST_TIME) >>>TEST_SIG = Sig(data=TEST_ARR, tline=TEST_TLINE, name=\"TestSig\") >>>assert frm[\"TestSig\"] == TEST_SIG # The reference to TEST_SIG was broken when appended to frm >>>assert frm[\"TestSig\"] is frm.sigs[\"TestSig\"] # The reference is preserved to the Sig in frm >>>assert frm[[\"TestSig\", \"TestSig2\"]] is not frm # The reference is broken to frm >>>assert frm[[\"TestSig\", \"TestSig2\"]] == frm >>>slicedfrm = frm[0:1.1] # sliced in time, with no step there is no resample >>>assert slicedfrm.tstart == 0.0 >>>assert slicedfrm.tend == 1.0 >>>assert slicedfrm.TestSig.nsamples == 2 # note 2 samples since no step was defined in slice >>>sliced_w_resample = frm[0:1.1:0.1] # Sliced in time, resamples to slice since step was defined. >>>assert sliced_w_resample.tstart == 0.0 >>>assert sliced_w_resample.tend == 1.0 >>>assert sliced_w_resample.TestSig.nsamples == 11 # note 2 samples since no step was defined in slice \"\"\" res = Frame ( name = self . name ) if isinstance ( index , Frame ): # This should be a boolean frame with indices that should be returned raise NotImplementedError ( \"Get item by boolean index is not implemented.\" ) if isinstance ( index , str ): self . _check_dot ( index ) if index not in self . sigs : index = self . check_for_alt ( index ) return self . sigs [ index ] if isinstance ( index , list | set | tuple ): if not index : # if empty return all sigs index = list ( self . sigs . keys ()) for signame in index : # Check for _dot notation, calculate derivatives if not present self . _check_dot ( signame ) if signame not in self . sigs : signame = self . check_for_alt ( signame ) res . append ( self . sigs [ signame ]) # improve to slice instead of re-build? elif isinstance ( index , slice ): # slicing is in time axis. if isinstance ( index . start , datetime ): ind_start = index . start . timestamp () else : ind_start = index . start if isinstance ( index . stop , datetime ): ind_stop = index . stop . timestamp () else : ind_stop = index . stop if isinstance ( index . step , timedelta ): step = index . step . total_seconds () else : step = index . step if index . step is None : # No step, so dont resample for tline in self . tlines : if index . start is None : start = tline . tstart else : start = ind_start if index . stop is None : # Since python is r-worded, this is a special case. # Need to make sure the last sample is included. stop = tline . tend + 0.000001 else : stop = ind_stop inds = np . logical_and ( tline . unix >= start , tline . unix < stop ) if np . any ( inds ): new_tline = TLine ( tline [ inds ]) for signame in self . tlines . sigs [ tline . idn ]: unks = {} old_sig = self . sigs [ signame ] for key , val in old_sig . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : unks . update ({ key : val }) new_sig = Sig ( data = old_sig . data [ inds ], tline = new_tline , name = old_sig . name , unit = old_sig . unit , interp_method = old_sig . interp_method , connect_gaps = old_sig . connect_gaps , data_enum = old_sig . data_enum , ** unks , ) res . append ( new_sig ) else : # Step was defined so we need to resample for tline in self . tlines : if index . start is None : start = tline . tstart else : start = ind_start if index . stop is None : stop = tline . tend else : stop = ind_stop new_tline = TLine ( tstart = start , tend = stop , period = step ) for signame in self . tlines . sigs [ tline . idn ]: res . append ( self . sigs [ signame ] . resample ( sample_to = new_tline )) else : raise NotImplementedError ( f \"Get item for index of type { type ( index ) } not implemented\" ) return res @profile def check_for_alt ( self , index ): \"\"\"Check for alternate name in case of missing dot notation\"\"\" # alt = difflib.get_close_matches( # index, self.sigs.keys(), n=1, cutoff=self.CUTOFF # ) alt = extractOne ( index , self . sigs . keys ()) if alt : if len ( alt [ 0 ]) != len ( index ): raise KeyError ( f \"' { index } ' is not in frame: { self . name } \" ) deltas_ok = [ x == \".\" or x == \" \" if x != y else True for x , y in zip ( index , alt [ 0 ]) ] if all ( deltas_ok ): index = alt [ 0 ] else : raise KeyError ( f \"' { index } ' is not in frame: { self . name } \" ) else : raise KeyError ( f \"' { index } ' is not in frame: { self . name } \" ) return index def __contains__ ( self , key ): \"\"\"Checks if key is a signame in frame\"\"\" self . _check_dot ( key ) res = key in self . sigs if res : return True else : try : _ = self . check_for_alt ( key ) return True except KeyError : return False def _check_dot ( self , signame : str ): \"\"\"Check if signame is _dot and calc deriv if needed.\"\"\" if signame not in self . sigs : if \"_dot\" in signame : n_dot = signame . count ( \"dot\" ) base_name = signame [ 0 : signame . index ( \"_dot\" )] if base_name not in self . sigs : base_name = self . check_for_alt ( base_name ) if base_name + \"_\" + \"dot\" * n_dot not in self . sigs : new_sig = self [ base_name ] . dot ( n_dot ) self . append ( new_sig ) @profile def subset ( self , index : slice , sigs : list [ str ] = None ): \"\"\"Get a subset of frame. Allows slicing by signals and in timeline.\"\"\" res = Frame ( name = self . name ) if sigs is None or not sigs : sigs = self . sigs . keys () if isinstance ( index . start , datetime ): ind_start = index . start . timestamp () else : ind_start = index . start if isinstance ( index . stop , datetime ): ind_stop = index . stop . timestamp () else : ind_stop = index . stop if isinstance ( index . step , timedelta ): step = index . step . total_seconds () else : step = index . step if index . step is None : # No step, so dont resample for tline in self . tlines : if any ( x in sigs for x in self . tlines . sigs [ tline . idn ]): if index . start is None : start = tline . tstart else : start = ind_start if index . stop is None : # Since python is r-worded, this is a special case. # Need to make sure the last sample is included. stop = tline . tend + 0.000001 else : stop = ind_stop inds = np . logical_and ( tline . unix >= start , tline . unix < stop ) if np . any ( inds ): new_tline = TLine ( tline [ inds ]) for signame in self . tlines . sigs [ tline . idn ]: if signame in sigs : old_sig = self . sigs [ signame ] new_sig = Sig ( old_sig ) new_sig . data = old_sig . data [ inds ] new_sig . tline = new_tline res . append ( new_sig ) else : # Step was defined so we need to resample for tline in self . tlines : if index . start is None : start = tline . tstart else : start = ind_start if index . stop is None : stop = tline . tend else : stop = ind_stop new_tline = TLine ( tstart = start , tend = stop , period = step ) for signame in self . tlines . sigs [ tline . idn ]: if signame in sigs : res . append ( self . sigs [ signame ] . resample ( sample_to = new_tline )) return res def __iter__ ( self ): \"\"\"Iterate.\"\"\" return iter ( self . sigs . values ()) def __repr__ ( self ) -> str : \"\"\"Return repr string.\"\"\" sigs = self . sigs . keys () reprstr = f \" { self . __class__ . __qualname__ } ([ { ', ' . join ( sigs ) } ])\" return reprstr def __eq__ ( self , other : Self ) -> bool : \"\"\"Check equality.\"\"\" if isinstance ( other , self . __class__ ): iseq = self . sigs == other . sigs and self . tlines == other . tlines return iseq return False","title":"Frame"},{"location":"data/#ccg.data.tsdata.Frame.nsamples","text":"Cumulative samples (counting unique timelines as well).","title":"nsamples"},{"location":"data/#ccg.data.tsdata.Frame.nsigs","text":"Number of Sigs in collection.","title":"nsigs"},{"location":"data/#ccg.data.tsdata.Frame.tend","text":"Latest end time from TLine collection. Returns: float \u2013 Time in unix.","title":"tend"},{"location":"data/#ccg.data.tsdata.Frame.tend_iso","text":"Latest end time from TLine collection. Returns: float \u2013 Time in iso.","title":"tend_iso"},{"location":"data/#ccg.data.tsdata.Frame.tline","text":"If frame has only one tline, return it.","title":"tline"},{"location":"data/#ccg.data.tsdata.Frame.tstart","text":"Earliest start time from TLine collection. Returns: float \u2013 Time in unix.","title":"tstart"},{"location":"data/#ccg.data.tsdata.Frame.tstart_iso","text":"Earliest start time from TLine collection. Returns: float \u2013 Time in iso.","title":"tstart_iso"},{"location":"data/#ccg.data.tsdata.Frame.__contains__","text":"Checks if key is a signame in frame Source code in ccg\\data\\tsdata.py 858 859 860 861 862 863 864 865 866 867 868 869 def __contains__ ( self , key ): \"\"\"Checks if key is a signame in frame\"\"\" self . _check_dot ( key ) res = key in self . sigs if res : return True else : try : _ = self . check_for_alt ( key ) return True except KeyError : return False","title":"__contains__"},{"location":"data/#ccg.data.tsdata.Frame.__eq__","text":"Check equality. Source code in ccg\\data\\tsdata.py 955 956 957 958 959 960 961 def __eq__ ( self , other : Self ) -> bool : \"\"\"Check equality.\"\"\" if isinstance ( other , self . __class__ ): iseq = self . sigs == other . sigs and self . tlines == other . tlines return iseq return False","title":"__eq__"},{"location":"data/#ccg.data.tsdata.Frame.__getattr__","text":"Provides dot notation access to Sigs if their names conform to dot notation. Parameters: signame ( str ) \u2013 Must conform to dot notation (no spaces or special characters, starts with non numeric char, etc.) Returns: Sig \u2013 Reference to Sig in Self Source code in ccg\\data\\tsdata.py 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 def __getattr__ ( self , signame : str ) -> Sig : \"\"\"Provides dot notation access to Sigs if their names conform to dot notation. Parameters ---------- signame : str Must conform to dot notation (no spaces or special characters, starts with non numeric char, etc.) Returns ------- Sig Reference to Sig in Self \"\"\" if signame . startswith ( \"_\" ): raise AttributeError # Probably dont want to let it return _** return self . __getitem__ ( signame )","title":"__getattr__"},{"location":"data/#ccg.data.tsdata.Frame.__getitem__","text":"Frame item getter. Parameters: index ( Frame | list [ str ] | slice | set [ str ] | str ) \u2013 Frame, list of Sig names, slice of Returns: Frame | Sig \u2013 New instance of Frame if index is Frame, list[str], slice. Reference to the Sig if str is a sig name. Examples: >>>TEST_LIST = [1.0, 2.0, 3.0] >>>TEST_ARR = np.array(TEST_LIST) >>>TEST_TIME = [0.0, 1.0, 2.0] >>>TEST_TLINE = TLine(TEST_TIME) >>>TEST_SIG = Sig(data=TEST_ARR, tline=TEST_TLINE, name=\"TestSig\") >>>assert frm[\"TestSig\"] == TEST_SIG # The reference to TEST_SIG was broken when appended to frm >>>assert frm[\"TestSig\"] is frm.sigs[\"TestSig\"] # The reference is preserved to the Sig in frm >>>assert frm[[\"TestSig\", \"TestSig2\"]] is not frm # The reference is broken to frm >>>assert frm[[\"TestSig\", \"TestSig2\"]] == frm >>>slicedfrm = frm[0:1.1] # sliced in time, with no step there is no resample >>>assert slicedfrm.tstart == 0.0 >>>assert slicedfrm.tend == 1.0 >>>assert slicedfrm.TestSig.nsamples == 2 # note 2 samples since no step was defined in slice >>>sliced_w_resample = frm[0:1.1:0.1] # Sliced in time, resamples to slice since step was defined. >>>assert sliced_w_resample.tstart == 0.0 >>>assert sliced_w_resample.tend == 1.0 >>>assert sliced_w_resample.TestSig.nsamples == 11 # note 2 samples since no step was defined in slice Source code in ccg\\data\\tsdata.py 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 @profile def __getitem__ ( self , index : Frame | list [ str ] | set [ str ] | tuple [ str ] | str | slice ) -> Frame | Sig : \"\"\"Frame item getter. Parameters ---------- index : Frame | list[str] | slice | set[str] | str Frame, list of Sig names, slice of Returns ------- Frame | Sig New instance of Frame if index is Frame, list[str], slice. Reference to the Sig if str is a sig name. Examples -------- >>>TEST_LIST = [1.0, 2.0, 3.0] >>>TEST_ARR = np.array(TEST_LIST) >>>TEST_TIME = [0.0, 1.0, 2.0] >>>TEST_TLINE = TLine(TEST_TIME) >>>TEST_SIG = Sig(data=TEST_ARR, tline=TEST_TLINE, name=\"TestSig\") >>>assert frm[\"TestSig\"] == TEST_SIG # The reference to TEST_SIG was broken when appended to frm >>>assert frm[\"TestSig\"] is frm.sigs[\"TestSig\"] # The reference is preserved to the Sig in frm >>>assert frm[[\"TestSig\", \"TestSig2\"]] is not frm # The reference is broken to frm >>>assert frm[[\"TestSig\", \"TestSig2\"]] == frm >>>slicedfrm = frm[0:1.1] # sliced in time, with no step there is no resample >>>assert slicedfrm.tstart == 0.0 >>>assert slicedfrm.tend == 1.0 >>>assert slicedfrm.TestSig.nsamples == 2 # note 2 samples since no step was defined in slice >>>sliced_w_resample = frm[0:1.1:0.1] # Sliced in time, resamples to slice since step was defined. >>>assert sliced_w_resample.tstart == 0.0 >>>assert sliced_w_resample.tend == 1.0 >>>assert sliced_w_resample.TestSig.nsamples == 11 # note 2 samples since no step was defined in slice \"\"\" res = Frame ( name = self . name ) if isinstance ( index , Frame ): # This should be a boolean frame with indices that should be returned raise NotImplementedError ( \"Get item by boolean index is not implemented.\" ) if isinstance ( index , str ): self . _check_dot ( index ) if index not in self . sigs : index = self . check_for_alt ( index ) return self . sigs [ index ] if isinstance ( index , list | set | tuple ): if not index : # if empty return all sigs index = list ( self . sigs . keys ()) for signame in index : # Check for _dot notation, calculate derivatives if not present self . _check_dot ( signame ) if signame not in self . sigs : signame = self . check_for_alt ( signame ) res . append ( self . sigs [ signame ]) # improve to slice instead of re-build? elif isinstance ( index , slice ): # slicing is in time axis. if isinstance ( index . start , datetime ): ind_start = index . start . timestamp () else : ind_start = index . start if isinstance ( index . stop , datetime ): ind_stop = index . stop . timestamp () else : ind_stop = index . stop if isinstance ( index . step , timedelta ): step = index . step . total_seconds () else : step = index . step if index . step is None : # No step, so dont resample for tline in self . tlines : if index . start is None : start = tline . tstart else : start = ind_start if index . stop is None : # Since python is r-worded, this is a special case. # Need to make sure the last sample is included. stop = tline . tend + 0.000001 else : stop = ind_stop inds = np . logical_and ( tline . unix >= start , tline . unix < stop ) if np . any ( inds ): new_tline = TLine ( tline [ inds ]) for signame in self . tlines . sigs [ tline . idn ]: unks = {} old_sig = self . sigs [ signame ] for key , val in old_sig . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : unks . update ({ key : val }) new_sig = Sig ( data = old_sig . data [ inds ], tline = new_tline , name = old_sig . name , unit = old_sig . unit , interp_method = old_sig . interp_method , connect_gaps = old_sig . connect_gaps , data_enum = old_sig . data_enum , ** unks , ) res . append ( new_sig ) else : # Step was defined so we need to resample for tline in self . tlines : if index . start is None : start = tline . tstart else : start = ind_start if index . stop is None : stop = tline . tend else : stop = ind_stop new_tline = TLine ( tstart = start , tend = stop , period = step ) for signame in self . tlines . sigs [ tline . idn ]: res . append ( self . sigs [ signame ] . resample ( sample_to = new_tline )) else : raise NotImplementedError ( f \"Get item for index of type { type ( index ) } not implemented\" ) return res","title":"__getitem__"},{"location":"data/#ccg.data.tsdata.Frame.__iter__","text":"Iterate. Source code in ccg\\data\\tsdata.py 945 946 947 def __iter__ ( self ): \"\"\"Iterate.\"\"\" return iter ( self . sigs . values ())","title":"__iter__"},{"location":"data/#ccg.data.tsdata.Frame.__repr__","text":"Return repr string. Source code in ccg\\data\\tsdata.py 949 950 951 952 953 def __repr__ ( self ) -> str : \"\"\"Return repr string.\"\"\" sigs = self . sigs . keys () reprstr = f \" { self . __class__ . __qualname__ } ([ { ', ' . join ( sigs ) } ])\" return reprstr","title":"__repr__"},{"location":"data/#ccg.data.tsdata.Frame.append","text":"Append to CCG Frame in place. Source code in ccg\\data\\tsdata.py 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 def append ( self , item : Sig | Frame | list [ Sig ], append_existing_signals : bool = False , interweave_tlines : bool = False , ): \"\"\"Append to CCG Frame in place.\"\"\" if isinstance ( item , Frame ): sigs_to_apnd = list ( item . sigs . keys ()) for _ , new_sigs in item . tlines . sigs . items (): for sig in new_sigs : if append_existing_signals and sig in self and sig in sigs_to_apnd : check_overlap ( self [ sig ], item [ sig ], interweave_tlines ) old_idn = self . tlines . idns [ sig ] new_tline = self . tlines [ old_idn ] . append_to_new ( item [ sig ]) if new_tline . is_monotonic_increasing : for old_sig in list ( self . tlines . sigs [ old_idn ]): if old_sig in item : self . tlines . remove ( old_sig ) self [ old_sig ] . tline = new_tline self . tlines . append ( self [ old_sig ]) # for references self [ old_sig ] . _data . append ( item [ old_sig ] . _data ) # get the rest of the attributes if item [ old_sig ] . connect_gaps is not None : self [ old_sig ] . connect_gaps = item [ old_sig ] . connect_gaps if item [ old_sig ] . data_enum is not None : self [ old_sig ] . data_enum = item [ old_sig ] . data_enum if item [ old_sig ] . interp_method is not None : self [ old_sig ] . interp_method = item [ old_sig ] . interp_method if item [ old_sig ] . unit is not None : self [ old_sig ] . unit = item [ old_sig ] . unit # Check for unknown attributes. the new signal value will overide the original. for key , val in item [ old_sig ] . __dict__ . items (): if ( not key . startswith ( \"_\" ) and key not in SIG_ATTRS ): setattr ( self [ old_sig ], key , val ) sigs_to_apnd . remove ( old_sig ) else : raise NotImplementedError ( \"batch appends not implemented for non-monoton\" ) for signame in sigs_to_apnd : sig = item [ signame ] self . _append_sig ( sig , append_existing_signals , interweave_tlines ) elif isinstance ( item , list ): for sig in item : self . _append_sig ( sig , append_existing_signals , interweave_tlines ) else : self . _append_sig ( item , append_existing_signals , interweave_tlines )","title":"append"},{"location":"data/#ccg.data.tsdata.Frame.check_for_alt","text":"Check for alternate name in case of missing dot notation Source code in ccg\\data\\tsdata.py 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 @profile def check_for_alt ( self , index ): \"\"\"Check for alternate name in case of missing dot notation\"\"\" # alt = difflib.get_close_matches( # index, self.sigs.keys(), n=1, cutoff=self.CUTOFF # ) alt = extractOne ( index , self . sigs . keys ()) if alt : if len ( alt [ 0 ]) != len ( index ): raise KeyError ( f \"' { index } ' is not in frame: { self . name } \" ) deltas_ok = [ x == \".\" or x == \" \" if x != y else True for x , y in zip ( index , alt [ 0 ]) ] if all ( deltas_ok ): index = alt [ 0 ] else : raise KeyError ( f \"' { index } ' is not in frame: { self . name } \" ) else : raise KeyError ( f \"' { index } ' is not in frame: { self . name } \" ) return index","title":"check_for_alt"},{"location":"data/#ccg.data.tsdata.Frame.clean_names","text":"Cleans signal names. Source code in ccg\\data\\tsdata.py 363 364 365 366 367 368 369 370 371 372 373 def clean_names ( self ): \"\"\"Cleans signal names.\"\"\" rename_list = {} for signame , _ in self . sigs . items (): clean_name = ccg . util . clean_name ( signame ) if clean_name != signame : rename_list . update ({ signame : clean_name }) for signame , clean_name in rename_list . items (): _LOGGER . debug ( \" %s renamed to %s \" , signame , clean_name ) self [ signame ] . name = clean_name","title":"clean_names"},{"location":"data/#ccg.data.tsdata.Frame.clear","text":"Clears frame in place. Source code in ccg\\data\\tsdata.py 358 359 360 361 def clear ( self ): \"\"\"Clears frame in place.\"\"\" self . sigs : dict [ str , Sig ] = {} self . tlines = TLineCollection ( self )","title":"clear"},{"location":"data/#ccg.data.tsdata.Frame.from_excel","text":"Generate frame from excel file. Parameters: filename ( str | Path ) \u2013 tline_col ( int | str , default: None ) \u2013 Column to use for an index signame_row ( int , default: None ) \u2013 Row with names to parse with _regex signame_regex ( str , default: None ) \u2013 regex string to parse signal names. Use named groups for parameters to pass into Sig instatiation, for example name, units, etc. example here: https://regex101.com/r/bfBrdf/6 filedata ( BytesIO | StringIO | bytes , default: None ) \u2013 string or bytes io. filename will only be used for ext, name, etc. Source code in ccg\\data\\tsdata.py 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 @profile def from_excel ( self , filename : str | Path , tline_col : int | str = None , signame_row : int = None , signame_regex : str = None , filedata : BytesIO | StringIO | bytes = None , sigunit_row : int = None , sigdata_row : int = None , ) -> Frame : \"\"\"Generate frame from excel file. Parameters ---------- filename tline_col Column to use for an index signame_row Row with names to parse with _regex signame_regex regex string to parse signal names. Use named groups for parameters to pass into Sig instatiation, for example name, units, etc. example here: https://regex101.com/r/bfBrdf/6 filedata string or bytes io. filename will only be used for ext, name, etc. \"\"\" tic = datetime . now () if isinstance ( filename , str ): filename = Path ( filename ) if signame_row is None : signame_row = 0 if tline_col is None : tline_col = 0 if signame_regex is None : signame_regex = r \"(?P<name>^.*?)(?:(?:\\s?\\((?P<unit>(?!.*\\().*)\\))|$)\" # Default regex `signal name (unit)`-> `{'name':'signal name','unit':'unit'` # https://regex101.com/r/bfBrdf/6 regex = re . compile ( signame_regex ) data = self . read_filedata ( filename , filedata ) toc = datetime . now () - tic _LOGGER . debug ( \"read %s in %.3f .\" , filename , toc . total_seconds ()) tic = datetime . now () if isinstance ( signame_row , str ): for i , row in enumerate ( data ): if row [ 0 ] == signame_row : signame_row = i break else : raise ValueError ( f \"Signal Name Row: { signame_row } not found in first column of data file.\" ) signames = data [ signame_row , :] . astype ( \"str\" ) signames = np . char . strip ( signames ) if sigunit_row is not None : sigunits = data [ sigunit_row , :] . astype ( \"str\" ) sig_args = [ { \"name\" : name , \"unit\" : unit } for name , unit in zip ( signames , sigunits ) ] else : sig_args = [ regex . match ( signame ) . groupdict () for signame in signames ] # Check for duplicate names and add _dup existing = [] for sig in sig_args : if sig [ \"name\" ] not in existing : existing . append ( sig [ \"name\" ]) else : existing . append ( sig [ \"name\" ] + \"_dup\" ) sig [ \"name\" ] = sig [ \"name\" ] + \"_dup\" if isinstance ( tline_col , str ): tline_col = np . where ( signames == tline_col ) if tline_col [ 0 ] . size == 0 : raise ValueError ( \"tline_col is not in signames.\" ) else : tline_col = [ tline_col ] if sigdata_row is None : sigdata_row = signame_row + 1 tmp : npt . NDArray = data [ sigdata_row :, tline_col ] . ravel () try : tmp = tmp . astype ( \"float\" ) except ValueError : tmp = tmp . astype ( type ( tmp [ 0 ])) tline = TLine ( tmp ) for i , kwargs in enumerate ( sig_args ): if i != tline_col [ 0 ]: sigtype = type ( data [ sigdata_row , i ]) sigdata = data [ sigdata_row :, i ] . ravel () . astype ( sigtype ) if sigtype is str : try : sigdata = sigdata . astype ( float ) except ValueError : pass new_sig = Sig ( data = sigdata , tline = tline , ** kwargs , ) self . append ( new_sig ) toc = datetime . now () - tic _LOGGER . debug ( \"built frame in %.3f .\" , toc . total_seconds ()) tic = datetime . now () return self","title":"from_excel"},{"location":"data/#ccg.data.tsdata.Frame.plot","text":"Plot data frame. Source code in ccg\\data\\tsdata.py 384 385 386 387 388 389 def plot ( self ): \"\"\"Plot data frame.\"\"\" from ccg.ui.plot import Plot plt = Plot ( self ) plt . plot ()","title":"plot"},{"location":"data/#ccg.data.tsdata.Frame.read_filedata","text":"Reads file data for building frame from file Source code in ccg\\data\\tsdata.py 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 @profile def read_filedata ( self , filename : Path , filedata : BytesIO | StringIO | bytes | None = None ): \"\"\"Reads file data for building frame from file\"\"\" ext = filename . suffix if ext in [ \".xlsx\" , \".xlsm\" , \".XLSX\" , \".XLSM\" ]: # Use openpyxl if filedata is None : wb = openpyxl . load_workbook ( filename = filename , read_only = True , data_only = True ) else : wb = openpyxl . load_workbook ( filename = filedata , read_only = True , data_only = True ) ws = wb . active data = ws . values data = np . array ( list ( data )) wb . close () elif ext in [ \".xls\" , \".XLS\" ]: # Use xlrd wb_xls : xlrd . book . Book = xlrd . open_workbook ( filename = filename , file_contents = filedata ) ws = wb_xls . sheet_by_index ( 0 ) # data = np.array(ws._cell_values) data = np . empty ( shape = ( ws . nrows , ws . ncols ), dtype = \"O\" ) for i in range ( ws . ncols ): data [:, i ] = ws . col_values ( i ) elif ext in [ \".csv\" , \".CSV\" ]: if filedata is None : with open ( filename , \"r\" , encoding = \"utf8\" ) as file : csvreader = csv . reader ( file , dialect = \"excel\" ) tmp = list ( csvreader ) max_col = max ( map ( len , tmp )) data = np . array ( [ tmp_row + [ None ] * ( max_col - len ( tmp_row )) for tmp_row in tmp ], dtype = \"O\" , ) else : if isinstance ( filedata , bytes ): csvreader = csv . reader ( io . StringIO ( filedata . decode ( \"utf-8\" ))) else : csvreader = csv . reader ( filedata ) tmp = list ( csvreader ) max_col = max ( map ( len , tmp )) data = np . array ( [ tmp_row + [ None ] * ( max_col - len ( tmp_row )) for tmp_row in tmp ], dtype = \"O\" , ) else : raise NotImplementedError ( f \"Frame from Excel not implemented for ext: { ext } \" ) return data","title":"read_filedata"},{"location":"data/#ccg.data.tsdata.Frame.remove","text":"Removes sigs from frame. Source code in ccg\\data\\tsdata.py 375 376 377 378 379 380 381 382 def remove ( self , signames : str | list [ str ]): \"\"\"Removes sigs from frame.\"\"\" if not isinstance ( signames , list ): signames = [ signames ] for signame in signames : if signame in self : self . tlines . remove ( signame ) self . sigs . pop ( signame , None )","title":"remove"},{"location":"data/#ccg.data.tsdata.Frame.resample","text":"Resample Frame to a sample_to TLine. Parameters: sample_to ( TLine ) \u2013 TLine to resample to sigs ( str | list [ str ] | None , default: None ) \u2013 list of sigs to resample, full frame if None, by default None inplace ( bool | None , default: False ) \u2013 if True, will resample signals and append (id prefix or suffix is not None) or replace inplace. By default False prefix ( str | None , default: None ) \u2013 prefix to signame, by default None suffix ( str | None , default: None ) \u2013 suffix to signame, by default None **kwargs \u2013 Additional arguments passed to Sig.resample() Returns: Frame \u2013 Returns Self if inplace, else a new Frame Source code in ccg\\data\\tsdata.py 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 def resample ( self , sample_to : TLine , sigs : str | list [ str ] | None = None , inplace : bool | None = False , prefix : str | None = None , suffix : str | None = None , ** kwargs , ): \"\"\"Resample Frame to a `sample_to` TLine. Parameters ---------- sample_to : TLine TLine to resample to sigs : str | list[str] | None, optional list of sigs to resample, full frame if None, by default None inplace : bool | None, optional if True, will resample signals and append (id prefix or suffix is not None) or replace inplace. By default False prefix : str | None, optional prefix to signame, by default None suffix : str | None, optional suffix to signame, by default None **kwargs Additional arguments passed to `Sig.resample()` Returns ------- Frame Returns Self if inplace, else a new Frame \"\"\" if inplace : res = self else : res = Frame () if sigs is not None : if isinstance ( sigs , str ): sigs = [ sigs ] else : sigs = list ( self . sigs . keys ()) for sig in sigs : newsig = self . sigs [ sig ] . resample ( sample_to , ** kwargs ) if prefix is not None : newsig . name = prefix + newsig . name if suffix is not None : newsig . name = newsig . name + suffix if inplace and prefix is None and suffix is None : res . remove ( sig ) res . append ( newsig ) return res","title":"resample"},{"location":"data/#ccg.data.tsdata.Frame.sort","text":"Sort signals by timeline for monoton increasing. Source code in ccg\\data\\tsdata.py 339 340 341 342 343 344 345 346 def sort ( self , remove_safe_duplicates = False , remove_all_duplicates = False ): \"\"\"Sort signals by timeline for monoton increasing.\"\"\" for _ , sig in self . sigs . items (): sig . sort_tline ( inplace = True , remove_safe_duplicates = remove_safe_duplicates , remove_all_duplicates = remove_all_duplicates , )","title":"sort"},{"location":"data/#ccg.data.tsdata.Frame.subset","text":"Get a subset of frame. Allows slicing by signals and in timeline. Source code in ccg\\data\\tsdata.py 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 @profile def subset ( self , index : slice , sigs : list [ str ] = None ): \"\"\"Get a subset of frame. Allows slicing by signals and in timeline.\"\"\" res = Frame ( name = self . name ) if sigs is None or not sigs : sigs = self . sigs . keys () if isinstance ( index . start , datetime ): ind_start = index . start . timestamp () else : ind_start = index . start if isinstance ( index . stop , datetime ): ind_stop = index . stop . timestamp () else : ind_stop = index . stop if isinstance ( index . step , timedelta ): step = index . step . total_seconds () else : step = index . step if index . step is None : # No step, so dont resample for tline in self . tlines : if any ( x in sigs for x in self . tlines . sigs [ tline . idn ]): if index . start is None : start = tline . tstart else : start = ind_start if index . stop is None : # Since python is r-worded, this is a special case. # Need to make sure the last sample is included. stop = tline . tend + 0.000001 else : stop = ind_stop inds = np . logical_and ( tline . unix >= start , tline . unix < stop ) if np . any ( inds ): new_tline = TLine ( tline [ inds ]) for signame in self . tlines . sigs [ tline . idn ]: if signame in sigs : old_sig = self . sigs [ signame ] new_sig = Sig ( old_sig ) new_sig . data = old_sig . data [ inds ] new_sig . tline = new_tline res . append ( new_sig ) else : # Step was defined so we need to resample for tline in self . tlines : if index . start is None : start = tline . tstart else : start = ind_start if index . stop is None : stop = tline . tend else : stop = ind_stop new_tline = TLine ( tstart = start , tend = stop , period = step ) for signame in self . tlines . sigs [ tline . idn ]: if signame in sigs : res . append ( self . sigs [ signame ] . resample ( sample_to = new_tline )) return res","title":"subset"},{"location":"data/#ccg.data.tsdata.Frame.valid","text":"Returns a new Frame, invalid data replaced with nan. calc'd on tline or combined TLine if None Parameters: gatecoll ( GateColl ) \u2013 Collection of gating conditions tline ( TLine | None , default: None ) \u2013 TLine to calculate validity on, by default None Returns: Frame \u2013 New instance of Frame Source code in ccg\\data\\tsdata.py 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 def valid ( self , gatecoll : GateColl , tline : TLine | None = None ) -> Frame : \"\"\"Returns a new Frame, invalid data replaced with nan. calc'd on `tline` or combined TLine if None Parameters ---------- gatecoll : GateColl Collection of gating conditions tline : TLine | None, optional TLine to calculate validity on, by default None Returns ------- Frame New instance of Frame \"\"\" res = Frame ( name = self . name ) # if tline is None: # tline = self.tlines.get_fastest() valid_sig = gatecoll . validate ( self , tline ) for tmp_tline in self . tlines : if tmp_tline . nsamples > 1 : b_valid = valid_sig . interp ( tmp_tline ) . data for sig in self . tlines . sigs [ tmp_tline . idn ]: newsig = Sig ( self [ sig ]) nan = np . NaN if newsig . data . dtype . kind in [ \"i\" , \"u\" ]: newsig . data = newsig . data . astype ( \"float\" ) elif newsig . data . dtype . kind in [ \"U\" , \"S\" ]: nan = \"\" newsig . data [ ~ b_valid ] = nan res . append ( newsig ) return res","title":"valid"},{"location":"data/#ccg.data.tsdata.SgCoef","text":"Store Savitzky Golay coeficients. Source code in ccg\\data\\tsdata.py 2601 2602 2603 2604 2605 2606 2607 2608 2609 2610 2611 2612 2613 2614 2615 2616 2617 2618 2619 2620 2621 2622 2623 2624 2625 2626 2627 2628 2629 2630 2631 2632 2633 2634 2635 2636 2637 2638 2639 2640 2641 2642 2643 2644 class SgCoef : \"\"\"Store Savitzky Golay coeficients.\"\"\" __slots__ = ( \"orig_index\" , \"sample_to_index\" , \"n_win_orig\" , \"n_ord\" , \"conv\" , \"uniqinvs\" , \"n_uniq\" , \"inds\" , ) def __init__ ( self , orig_index : int = None , sample_to_index : int = None , n_win_orig : int = None , n_ord : int = None , conv : npt . NDArray = None , uniqinvs : npt . NDArray = None , n_uniq : int = None , inds : npt . NDArray = None , ): self . orig_index = orig_index self . sample_to_index = sample_to_index self . n_win_orig = n_win_orig self . n_ord = n_ord self . conv = conv self . uniqinvs = uniqinvs self . n_uniq = n_uniq self . inds = inds def clear ( self ): \"\"\"Clear SgCoef.\"\"\" self . orig_index = None self . sample_to_index = None self . n_win_orig = None self . n_ord = None self . conv = None self . uniqinvs = None self . n_uniq = None self . inds : npt . NDArray = None","title":"SgCoef"},{"location":"data/#ccg.data.tsdata.SgCoef.clear","text":"Clear SgCoef. Source code in ccg\\data\\tsdata.py 2635 2636 2637 2638 2639 2640 2641 2642 2643 2644 def clear ( self ): \"\"\"Clear SgCoef.\"\"\" self . orig_index = None self . sample_to_index = None self . n_win_orig = None self . n_ord = None self . conv = None self . uniqinvs = None self . n_uniq = None self . inds : npt . NDArray = None","title":"clear"},{"location":"data/#ccg.data.tsdata.Sig","text":"CCG Sig class. Contains signal data and timeline. Parameters: data ( Sig | NDArray | list | None , default: None ) \u2013 Data source for the signal. tline ( TLine | None , default: None ) \u2013 Timeline instance for signal. Must be same length as data. name ( str | None , default: None ) \u2013 Signal name, must be unique in a Frame . unit ( str | None , default: None ) \u2013 Optional unit. interp_method ( InterpMethod | None , default: None ) \u2013 interpolation method for signal. parent ( Frame | None , default: None ) \u2013 Reference to the 'Frame' if this is in a frame. connect_gaps ( bool | None , default: None ) \u2013 Option for plotting using Plot data_enum ( SigEnum | None , default: None ) \u2013 Enumeration definition to alias values, used for plotting string data. data_range ( list [ float ] | None , default: None ) \u2013 Used for plot scaling. **kwargs \u2013 Argument for inserting unknown attributes. Source code in ccg\\data\\tsdata.py 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622 1623 1624 1625 1626 1627 1628 1629 1630 1631 1632 1633 1634 1635 1636 1637 1638 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 1649 1650 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664 1665 1666 1667 1668 1669 1670 1671 1672 1673 1674 1675 1676 1677 1678 1679 1680 1681 1682 1683 1684 1685 1686 1687 1688 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699 1700 1701 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711 1712 1713 1714 1715 1716 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741 1742 1743 1744 1745 1746 1747 1748 1749 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 1767 1768 1769 1770 1771 1772 1773 1774 1775 1776 1777 1778 1779 1780 1781 1782 1783 1784 1785 1786 1787 1788 1789 1790 1791 1792 1793 1794 1795 1796 1797 1798 1799 1800 1801 1802 1803 1804 1805 1806 1807 1808 1809 1810 1811 1812 1813 class Sig : \"\"\" CCG Sig class. Contains signal data and timeline. Parameters ---------- data Data source for the signal. tline Timeline instance for signal. Must be same length as data. name Signal name, must be unique in a `Frame`. unit Optional unit. interp_method interpolation method for signal. parent Reference to the 'Frame' if this is in a frame. connect_gaps Option for plotting using `Plot` data_enum Enumeration definition to alias values, used for plotting string data. data_range Used for plot scaling. **kwargs Argument for inserting unknown attributes. \"\"\" _FGAP = 5 @profile def __init__ ( self , data : Sig | npt . NDArray | list | None = None , tline : TLine | None = None , name : str | None = None , unit : str | None = None , interp_method : InterpMethod | None = None , parent : Frame | None = None , connect_gaps : bool | None = None , data_enum : SigEnum | None = None , nsamples : int | None = None , dtype : npt . DTypeLike = None , data_range : list [ float ] | None = None , ** kwargs , ) -> None : self . parent = parent self . connect_gaps = connect_gaps self . data_enum = data_enum self . base_data = None self . _name = None self . _dtype = dtype self . _data : AllocData = None self . interp_method = None if nsamples is None : self . _shape = None else : self . _shape = ( nsamples ,) if tline is not None : self . tline = tline self . unit = unit self . data_range = data_range for key , value in kwargs . items (): setattr ( self , key , value ) if isinstance ( data , Sig ): # This is here to break references safely self . _dtype = data . _dtype self . _shape = data . _shape self . tline = TLine ( data . tline , nsamples = self . _shape ) self . data = data . _data self . data_range = data . data_range self . interp_method = data . interp_method if unit is None : self . unit = data . unit self . _name = data . name if data_enum is None : self . data_enum = data . data_enum if connect_gaps is None : self . connect_gaps = data . connect_gaps if data_range is not None : self . data_range = data_range for key , val in data . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : setattr ( self , key , val ) elif isinstance ( data , list ): self . data = np . array ( data ) elif isinstance ( data , np . ndarray ): self . data = data elif isinstance ( data , ( float , int , np . number )): if tline is not None : self . data = np . ones ( shape = tline . _unix . shape , dtype = type ( data )) * data # self.data = np.array([data] * tline.unix.size, dtype=type(data)) else : self . data = data elif isinstance ( data , str ): if tline is not None : self . data = np . array ([ data ] * tline . nsamples , dtype = type ( data )) else : self . data = data elif data is None : self . data = None # for pre-allocation else : raise NotImplementedError ( f \"Sig gen from { type ( data ) } is not implemented.\" ) if name is not None : self . _name = name if self . _data is None or self . _dtype . type is np . str_ : # This is a string type so make sure interp is nearest self . interp_method = InterpMethod . NEAREST else : if interp_method is not None : self . interp_method = interp_method if self . nsamples and self . nsamples != self . tline . nsamples : _LOGGER . warning ( \"Length of %s 's TLine: %i doesnt match length of it's data: %i \" , self . name , self . tline . nsamples , self . nsamples , ) @property def name ( self ) -> str : \"\"\"Return signal name.\"\"\" return self . _name @name . setter def name ( self , new_name ): if self . parent is not None : self . parent . _rename_sig ( # pylint: disable=access-member-before-definition self . _name , new_name ) self . _name = new_name @property def data ( self ) -> npt . NDArray : \"\"\"data getter\"\"\" return self . _data [:] @data . setter @profile def data ( self , value : npt . NDArray | AllocData | None ): if self . _data is None : # pre-allocate self . _data = AllocData ( data = value , shape = self . _shape , dtype = self . _dtype ) if self . _shape is None : self . _shape = self . _data . shape if self . _dtype is None : self . _dtype = self . _data . data . dtype if not hasattr ( self , \"tline\" ): self . tline = TLine ( nsamples = self . _shape ) else : self . _data . replace ( value ) @property def max ( self ) -> npt . NBitBase | None : \"\"\"Max value.\"\"\" if np . issubdtype ( self . data . dtype , np . number ): try : return np . nanmax ( self . data ) except ValueError : pass return None @property def min ( self ) -> npt . NBitBase | None : \"\"\"Min value.\"\"\" if np . issubdtype ( self . data . dtype , np . number ): try : return np . nanmin ( self . data ) except ValueError : pass return None @property def nsamples ( self ): return self . _data . nsamples @property def appx_bytes ( self ): \"\"\"Estimated size of data [bytes]. Excludes tline.\"\"\" return self . _data . appx_bytes @property def tstart ( self ): \"\"\"Start if tline.\"\"\" return self . tline . tstart @property def tend ( self ): \"\"\"End of tline.\"\"\" return self . tline . tend @property def tstart_iso ( self ): \"\"\"Start if tline.\"\"\" return self . tline . tstart_iso @property def tend_iso ( self ): \"\"\"End of tline.\"\"\" return self . tline . tend_iso @property def period ( self ): \"\"\"apprx period.\"\"\" return self . tline . period def calc_idn ( self ): \"\"\"Calculate hash for IDN.\"\"\" # tic = datetime.now() idn = xxhash . xxh3_64_intdigest ( self . _data . tobytes ()) # toc = datetime.now() - tic # _LOGGER.debug(\"IDN calc'd for %s in %.3f\", self.name, toc.total_seconds()) return idn + self . tline . idn @profile def append ( self , sig : Sig , interweave_tlines = False , remove_duplicates = False ): \"\"\"Append sig to signal.\"\"\" # Check if timelimes overlap check_overlap ( self , sig , interweave_tlines ) if self . parent is None : self . tline . append_inplace ( sig ) else : nshared = len ( self . parent . tlines . sigs [ self . tline . idn ]) if nshared == 1 : self . tline . append_inplace ( sig ) else : self . tline = self . tline . append_to_new ( sig ) self . _data . append ( sig . _data ) # pylint: disable=access-member-before-definition if not self . tline . is_monotonic_increasing : self . sort_tline ( inplace = True , remove_safe_duplicates = remove_duplicates ) if self . parent is not None : self . parent . tlines . remove ( self . name ) self . parent . tlines . append ( self ) # self.tline = tlref # 2/10/24 now in tlines.append() # get the rest of the attributes if sig . connect_gaps is not None : self . connect_gaps = sig . connect_gaps if sig . data_enum is not None : self . data_enum = sig . data_enum if sig . interp_method is not None : self . interp_method = sig . interp_method if sig . unit is not None : self . unit = sig . unit # Check for unknown attributes. the new signal value will overide the original. for key , val in sig . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : setattr ( self , key , val ) def convert_units ( self , unit : str ) -> Sig : \"\"\"Convert units in place\"\"\" if unit != self . unit : self . data = ccg . util . convert_units ( value = self . data , from_unit = self . unit , to_unit = unit ) if self . data_range : self . data_range = ccg . util . convert_units ( value = self . data_range , from_unit = self . unit , to_unit = unit ) self . unit = unit return self def as_unit ( self , unit : str ) -> Sig : \"\"\"return new sig converted to unit\"\"\" sig = Sig ( self ) sig . convert_units ( unit ) return sig def sort_tline ( self , inplace = True , remove_safe_duplicates = False , remove_all_duplicates = False , ): \"\"\"Sort signal by timeline. Parameters ---------- inplace Sorts signal in place, returns None. remove_duplicates Will remove duplicate timestamps if signal is also duplicated. Returns ------- Sig self if `inplace=True`. \"\"\" inds = np . argsort ( self . tline . unix , kind = \"stable\" ) if inplace : self . tline = TLine ( self . tline . unix [ inds ]) if self . nsamples > 0 : self . data = self . data [ inds ] if remove_safe_duplicates : self . _remove_duplicates ( remove_all_duplicates ) if self . parent is not None : self . parent . tlines . remove ( self . name ) self . parent . tlines . append ( self ) # self.tline = tlref # 2/10/24 now in tlines.append() return self sig = Sig ( self ) # TODO: clean this up to not define, then edit. sig . name = sig . name + \"_sorted\" sig . tline = TLine ( self . tline . unix [ inds ]) if self . nsamples > 0 : sig . data = sig . data [ inds ] if remove_safe_duplicates : sig . _remove_duplicates ( remove_all_duplicates ) # pylint: disable=access-member-before-definition return sig def _remove_duplicates ( self , remove_all_duplicates = False ): \"\"\"Removes duplicate samples if both time and data match. If `remove_all_duplicates=True`, will remove duplicates even if values dont match. **Must be sorted first** Use `self.sort_tline(remove_safe_duplicates=True, remove_all_duplicates=True)` \"\"\" # Check if its monoton increasing now. if not self . tline . is_monotonic_increasing : # find duplicate timestamps inds = self . tline . dt == 0 if self . data . dtype . kind in [ \"i\" , \"u\" , \"f\" ]: data_dt = np . diff ( self . data ) data_dt = data_dt == 0 else : data_dt = self . data [ 1 :] == self . data [ 0 : - 1 ] dups = inds & data_dt dups = np . append ( False , dups ) if np . any ( dups ): _LOGGER . debug ( \"Removed %i duplicates from %s .\" , np . sum ( dups ), self . name ) self . tline = TLine ( self . tline . unix [ ~ dups ]) self . data = self . data [ ~ dups ] # If there are still duplicates, there are different values at the same timestep. if remove_all_duplicates and not self . tline . is_monotonic_increasing : inds = self . tline . dt == 0 dups = inds dups = np . append ( False , dups ) if np . any ( dups ): _LOGGER . warning ( \"Removed %i duplicate timestamps with different values from %s .\" , np . sum ( dups ), self . name , ) self . tline = TLine ( self . tline . unix [ ~ dups ]) self . data = self . data [ ~ dups ] @profile def plot_prep ( self ) -> Sig : \"\"\"Prepare for plotting. Sorts tline and removes duplicates. Inserts NaNs in gaps if `connect_gaps=False | None`. Applies enum if it exists. \"\"\" res = self if not self . tline . is_monotonic_increasing : self . sort_tline ( remove_safe_duplicates = True ) if self . connect_gaps is None or not self . connect_gaps : gaps = np . greater ( self . tline . dt , self . _FGAP * self . tline . period , ) if np . sum ( gaps ) > 0 : res = Sig ( self ) # Make a copy before resampling. tline = TLine ( self . tline . unix [ np . append ( gaps , False )] + ( self . tline . dt [ gaps ] / 2 ) ) if self . _data . data . dtype . kind in ( \"i\" , \"u\" , \"b\" , \"M\" ): # Since numpy is r-worded and cant use a nan in an int, we need to convert to float self . _data . replace ( self . data . astype ( \"float\" , copy = False )) self . _dtype = self . _data . dtype nans = np . empty ( np . sum ( gaps ), dtype = self . _dtype ) nans [:] = np . nan res . append ( Sig ( data = nans , tline = tline ), interweave_tlines = True ) if res . data_enum is not None : res . base_data = res . data res . data = res . data_enum . data_to_enum ( res . data ) return res def interp ( self , points : npt . NDArray | TLine , extrapolate : bool = False ) -> Sig : \"\"\"Interpolate signal to points.\"\"\" if isinstance ( points , TLine ): points = points . unix if self . interp_method is None or self . interp_method == InterpMethod . LINEAR : new = ccg . util . linearinterp ( self . tline . unix , self . data , points , extrapolate ) elif self . interp_method == InterpMethod . ZOH : new = self . data [ np . maximum ( np . minimum ( np . searchsorted ( self . tline . unix , points , side = \"right\" ) - 1 , self . nsamples - 1 , ), 0 , ) ] else : # TODO: Implement other interp methods. raise NotImplementedError ( f \" { self . interp_method } not implemented.\" ) res = Sig ( self ) # To create a copy first res . data = new res . tline = TLine ( points ) return res @profile def resample ( self : Sig , sample_to : TLine , n_win : int = None , n_ord : int = None , gap_fraction : float = None , interp_gaps = False , ) -> Sig : \"\"\"Resample with Savitzky Golay filter. Parameters ---------- sample_to TLine to resample to n_win window size, should be odd. Is relative to the sample_to index n_ord order of the fit gap_fraction size of a gap relative to the window size to interpolate between Returns ------- New resampled Sig \"\"\" # Skip if the same and default window/order if ( sample_to != self . tline or n_win is not None or n_ord is not None or gap_fraction is not None ): tic = datetime . now () if n_win is None : n_win = 5 if n_ord is None : n_ord = 3 if gap_fraction is None : gap_fraction = 0.5 if self . data . dtype . kind in { \"U\" , \"S\" }: # This is a string type raise NotImplementedError ( \"Cant resample string type.\" ) if not sample_to . is_monotonic_increasing : sample_to = sample_to . sort () if not self . tline . is_monotonic_increasing : self . sort_tline () nsamplesnew = len ( sample_to ) # dt_new = sample_to.dt dtm_new = np . maximum ( sample_to . period , 0.001 ) dt_orig = self . tline . dt dtm_orig = np . maximum ( self . tline . period , 0.001 ) n_win_orig = int ( np . ceil ( max ( n_win , round ( n_win * dtm_new / dtm_orig ))) // 2 * 2 + 1 ) # Detect gaps larger than gap_fraction windows gaps = np . flatnonzero ( dt_orig > n_win_orig * dtm_orig * gap_fraction ) # interpolate between gaps ind_in_gap = [] for gap in gaps : origx = self . tline . unix [ gap : gap + 2 ] ind_in_gap . extend ( * np . where (( sample_to . unix > origx [ 0 ]) & ( sample_to . unix < origx [ 1 ])) ) if interp_gaps and len ( gaps ) > 0 : newx = np . concatenate ( ( self . tline . unix , sample_to . unix [ ind_in_gap ], ), ) newx . sort () orig = self . interp ( newx ) invalid = [] else : orig = self invalid = ind_in_gap inds , convs = orig . tline . savgol_coef ( sample_to , n_ord , n_win_orig , ) ys0 = np . empty (( nsamplesnew , n_win_orig )) ys0 [:, :] = np . reshape ( orig . data [ inds . ravel ()], ( nsamplesnew , n_win_orig ), ) # Calc diaganol only of dot product result = np . einsum ( \"ij,ji->i\" , ys0 [:, :], convs ) if np . any ( invalid ): result [ invalid ] = np . NaN res = Sig ( self ) # To get all attr of inital # then update to new values res . data = result res . tline = sample_to toc = datetime . now () - tic _LOGGER . debug ( \"Resampled %s from %s to %s samples in %.3f [s]\" , self . name , format ( self . nsamples , \",\" ), format ( res . nsamples , \",\" ), toc . total_seconds (), ) else : res = Sig ( self ) return res def dot ( self , n_dot : int = 1 , n_win : int = 5 , n_ord : int = 3 , ): \"\"\"Calculate Derivative of signal. Returns new sig.\"\"\" tic = datetime . now () inds , convs = self . tline . savgol_coef ( self . tline , n_ord , n_win , n_dot , ) ys0 = np . empty (( self . nsamples , n_win )) ys0 [:, :] = np . reshape ( self . data [ inds . ravel ()], ( self . nsamples , n_win ), ) # Calc diaganol only of dot product result = np . einsum ( \"ij,ji->i\" , ys0 [:, :], convs ) res = Sig ( self ) # To get all attr of inital # then update to new values res . name = f ' { res . name } _ { \"\" . join ([ \"dot\" ] * n_dot ) } ' res . unit = ( f ' { res . unit if res . unit else \"\" } /s { \"\" if n_dot == 1 else \"^\" + n_dot } ' ) res . data = result toc = datetime . now () - tic _LOGGER . debug ( \"Deriv of %s in %.3f [s]\" , self . name , toc . total_seconds (), ) return res def valid ( self , gatecoll : GateColl , frame : Frame = None ): \"\"\"Return new signal with invalid data replaced with nan's\"\"\" # tic = datetime.now() if frame is None and self . parent is None : raise ValueError ( \"`Sig.valid()` requires frame argument if sig has no parent.\" ) if frame is None : frame = self . parent res = Sig ( self ) # copy valid_sig = gatecoll . validate ( frame ) b_valid = valid_sig . interp ( self . tline ) . data nan = np . NaN if res . data . dtype . kind in [ \"i\" , \"u\" ]: res . data = res . data . astype ( \"float\" ) elif res . data . dtype . kind in [ \"U\" , \"S\" ]: nan = \"\" res . data [ ~ b_valid ] = nan # toc = datetime.now() - tic # _LOGGER.debug( # \"get valid sig %s in %.3f\", self.name, toc.total_seconds() # ) return res def __len__ ( self ) -> int : return self . nsamples def __repr__ ( self ) -> str : \"\"\"Return string representation.\"\"\" reprstr = f \" { self . __class__ . __qualname__ } ( { self . data . __repr__ () } )\" return reprstr def __str__ ( self ) -> str : \"\"\"Return readable string.\"\"\" return self . data . __str__ () def __add__ ( self , other ): \"\"\"add, resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , unit = self . unit , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] + %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . resample ( tline ) . data res . data = self . resample ( tline ) . data + other return res def __sub__ ( self , other ): \"\"\"subtract, resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , unit = self . unit , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] - %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . resample ( tline ) . data res . data = self . resample ( tline ) . data - other return res def __radd__ ( self , other ): \"\"\"add, resamples to parent.math_tline if exists. returns Sig.\"\"\" return self . __add__ ( other ) def __rsub__ ( self , other ): \"\"\"subtract, resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , unit = self . unit , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] - %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . resample ( tline ) . data res . data = other - self . resample ( tline ) . data return res def __mul__ ( self , other ): \"\"\"multiply(elementwise), resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): if ( self . unit and other . unit is None ) or other . unit . lower () == \"ratio\" : unit = self . unit elif ( self . unit is None or self . unit . lower () == \"ratio\" ) and other . unit : unit = other . unit elif self . unit and self . unit == other . unit : unit = self . unit + \"**2\" else : unit = f \" { self . unit } * { other . unit } \" other = other . resample ( tline ) . data else : unit = self . unit res . unit = unit res . data = self . resample ( tline ) . data * other return res def __truediv__ ( self , other ): \"\"\"divide(elementwise), resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): if ( self . unit and other . unit is None ) or other . unit . lower () == \"ratio\" : unit = self . unit elif ( self . unit is None or self . unit . lower () == \"ratio\" ) and other . unit : unit = other . unit elif self . unit and self . unit == other . unit : unit = \"ratio\" else : unit = f \" { self . unit } / { other . unit } \" other = other . resample ( tline ) . data else : unit = self . unit res . unit = unit res . data = self . resample ( tline ) . data / other return res def __pow__ ( self , other ): \"\"\"power, resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): other = other . resample ( tline ) . data unit = f \" { self . unit } **n\" elif len ( other ) == 1 : unit = f \" { self . unit } ** { other } \" if self . unit . lower () == \"ratio\" : unit = \"ratio\" res . unit = unit res . data = self . resample ( tline ) . data ** other return res def __abs__ ( self ): \"\"\"abs\"\"\" res = Sig ( self , name = f \"abs( { self . name } )\" , dtype = self . _dtype ) res . data = np . abs ( self . data ) return res def __neg__ ( self ): \"\"\"neg\"\"\" res = Sig ( self , name = f \"neg( { self . name } )\" , dtype = self . _dtype ) res . data = self . data * - 1 return res def __eq__ ( self , other ) -> bool : \"\"\"Check equality.\"\"\" if isinstance ( other , self . __class__ ): iseq = ( np . array_equal ( self . data , other . data ) and np . array_equal ( self . tline , other . tline ) and self . interp_method == other . interp_method and self . connect_gaps == other . connect_gaps and self . unit == other . unit ) if iseq : for key , val in self . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : try : iseq = iseq and val == getattr ( other , key ) except KeyError : iseq = False if iseq : # if its still true, we better check if theres an unk attr in the other for key , val in self . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : try : iseq = iseq and val == getattr ( self , key ) except KeyError : iseq = False return iseq else : return False # @profile def __getitem__ ( self , index : int | list [ int ] | slice | npt . NDArray ): \"\"\"Get item of Sig.\"\"\" if isinstance ( index , slice ) or isinstance ( index , int ): res = self . data [ index ] elif isinstance ( index , np . ndarray ) and index . dtype . kind in ( \"b\" ): # res = copy.deepcopy(self) # res.tline.unix = self.tline.unix[index] # res.data = self.data[index] # # Deepcopy is so slow. Lets try re-building signals instead unks = {} for key , val in self . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : unks . update ({ key : val }) res = Sig ( data = self . data [ index ], tline = TLine ( self . tline . unix [ index ]), name = self . name , unit = self . unit , interp_method = self . interp_method , connect_gaps = self . connect_gaps , data_enum = self . data_enum , ** unks , ) else : raise NotImplementedError ( \"unexpected index for signal\" ) return res def __setitem__ ( self , index : tuple [ slice | list | int | npt . NDArray ] | slice , value : list | npt . NDArray | str , ): \"\"\"Set item\"\"\" self . _data [ index ] = value def __iter__ ( self ): \"\"\"Iterate.\"\"\" return iter ( self . data ) def __next__ ( self ): \"\"\"Next.\"\"\" return next ( self . data ) def __deepcopy__ ( self , memo ): # pylint: disable= method-hidden \"\"\"Deepcopy of a CCGSig. Referenced frame is removed.\"\"\" deepcopy_method = self . __deepcopy__ self . __deepcopy__ = None cpy = copy . deepcopy ( self , memo ) cpy . parent = None # To avoid recursion and confusion self . __deepcopy__ = deepcopy_method # Copy the function object func = types . FunctionType ( deepcopy_method . __code__ , deepcopy_method . __globals__ , deepcopy_method . __name__ , deepcopy_method . __defaults__ , deepcopy_method . __closure__ , ) # Bind to cp and set bound_method = func . __get__ ( cpy , cpy . __class__ ) # pylint: disable=no-member cpy . __deepcopy__ = bound_method return cpy","title":"Sig"},{"location":"data/#ccg.data.tsdata.Sig.appx_bytes","text":"Estimated size of data [bytes]. Excludes tline.","title":"appx_bytes"},{"location":"data/#ccg.data.tsdata.Sig.data","text":"data getter","title":"data"},{"location":"data/#ccg.data.tsdata.Sig.max","text":"Max value.","title":"max"},{"location":"data/#ccg.data.tsdata.Sig.min","text":"Min value.","title":"min"},{"location":"data/#ccg.data.tsdata.Sig.name","text":"Return signal name.","title":"name"},{"location":"data/#ccg.data.tsdata.Sig.period","text":"apprx period.","title":"period"},{"location":"data/#ccg.data.tsdata.Sig.tend","text":"End of tline.","title":"tend"},{"location":"data/#ccg.data.tsdata.Sig.tend_iso","text":"End of tline.","title":"tend_iso"},{"location":"data/#ccg.data.tsdata.Sig.tstart","text":"Start if tline.","title":"tstart"},{"location":"data/#ccg.data.tsdata.Sig.tstart_iso","text":"Start if tline.","title":"tstart_iso"},{"location":"data/#ccg.data.tsdata.Sig.__abs__","text":"abs Source code in ccg\\data\\tsdata.py 1705 1706 1707 1708 1709 def __abs__ ( self ): \"\"\"abs\"\"\" res = Sig ( self , name = f \"abs( { self . name } )\" , dtype = self . _dtype ) res . data = np . abs ( self . data ) return res","title":"__abs__"},{"location":"data/#ccg.data.tsdata.Sig.__add__","text":"add, resamples to parent.math_tline if exists. returns Sig. Source code in ccg\\data\\tsdata.py 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 def __add__ ( self , other ): \"\"\"add, resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , unit = self . unit , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] + %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . resample ( tline ) . data res . data = self . resample ( tline ) . data + other return res","title":"__add__"},{"location":"data/#ccg.data.tsdata.Sig.__deepcopy__","text":"Deepcopy of a CCGSig. Referenced frame is removed. Source code in ccg\\data\\tsdata.py 1792 1793 1794 1795 1796 1797 1798 1799 1800 1801 1802 1803 1804 1805 1806 1807 1808 1809 1810 1811 1812 1813 def __deepcopy__ ( self , memo ): # pylint: disable= method-hidden \"\"\"Deepcopy of a CCGSig. Referenced frame is removed.\"\"\" deepcopy_method = self . __deepcopy__ self . __deepcopy__ = None cpy = copy . deepcopy ( self , memo ) cpy . parent = None # To avoid recursion and confusion self . __deepcopy__ = deepcopy_method # Copy the function object func = types . FunctionType ( deepcopy_method . __code__ , deepcopy_method . __globals__ , deepcopy_method . __name__ , deepcopy_method . __defaults__ , deepcopy_method . __closure__ , ) # Bind to cp and set bound_method = func . __get__ ( cpy , cpy . __class__ ) # pylint: disable=no-member cpy . __deepcopy__ = bound_method return cpy","title":"__deepcopy__"},{"location":"data/#ccg.data.tsdata.Sig.__eq__","text":"Check equality. Source code in ccg\\data\\tsdata.py 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741 1742 1743 1744 1745 def __eq__ ( self , other ) -> bool : \"\"\"Check equality.\"\"\" if isinstance ( other , self . __class__ ): iseq = ( np . array_equal ( self . data , other . data ) and np . array_equal ( self . tline , other . tline ) and self . interp_method == other . interp_method and self . connect_gaps == other . connect_gaps and self . unit == other . unit ) if iseq : for key , val in self . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : try : iseq = iseq and val == getattr ( other , key ) except KeyError : iseq = False if iseq : # if its still true, we better check if theres an unk attr in the other for key , val in self . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : try : iseq = iseq and val == getattr ( self , key ) except KeyError : iseq = False return iseq else : return False","title":"__eq__"},{"location":"data/#ccg.data.tsdata.Sig.__getitem__","text":"Get item of Sig. Source code in ccg\\data\\tsdata.py 1748 1749 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 1767 1768 1769 1770 1771 1772 1773 1774 def __getitem__ ( self , index : int | list [ int ] | slice | npt . NDArray ): \"\"\"Get item of Sig.\"\"\" if isinstance ( index , slice ) or isinstance ( index , int ): res = self . data [ index ] elif isinstance ( index , np . ndarray ) and index . dtype . kind in ( \"b\" ): # res = copy.deepcopy(self) # res.tline.unix = self.tline.unix[index] # res.data = self.data[index] # # Deepcopy is so slow. Lets try re-building signals instead unks = {} for key , val in self . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : unks . update ({ key : val }) res = Sig ( data = self . data [ index ], tline = TLine ( self . tline . unix [ index ]), name = self . name , unit = self . unit , interp_method = self . interp_method , connect_gaps = self . connect_gaps , data_enum = self . data_enum , ** unks , ) else : raise NotImplementedError ( \"unexpected index for signal\" ) return res","title":"__getitem__"},{"location":"data/#ccg.data.tsdata.Sig.__iter__","text":"Iterate. Source code in ccg\\data\\tsdata.py 1784 1785 1786 def __iter__ ( self ): \"\"\"Iterate.\"\"\" return iter ( self . data )","title":"__iter__"},{"location":"data/#ccg.data.tsdata.Sig.__mul__","text":"multiply(elementwise), resamples to parent.math_tline if exists. returns Sig. Source code in ccg\\data\\tsdata.py 1648 1649 1650 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664 1665 1666 def __mul__ ( self , other ): \"\"\"multiply(elementwise), resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): if ( self . unit and other . unit is None ) or other . unit . lower () == \"ratio\" : unit = self . unit elif ( self . unit is None or self . unit . lower () == \"ratio\" ) and other . unit : unit = other . unit elif self . unit and self . unit == other . unit : unit = self . unit + \"**2\" else : unit = f \" { self . unit } * { other . unit } \" other = other . resample ( tline ) . data else : unit = self . unit res . unit = unit res . data = self . resample ( tline ) . data * other return res","title":"__mul__"},{"location":"data/#ccg.data.tsdata.Sig.__neg__","text":"neg Source code in ccg\\data\\tsdata.py 1711 1712 1713 1714 1715 def __neg__ ( self ): \"\"\"neg\"\"\" res = Sig ( self , name = f \"neg( { self . name } )\" , dtype = self . _dtype ) res . data = self . data * - 1 return res","title":"__neg__"},{"location":"data/#ccg.data.tsdata.Sig.__next__","text":"Next. Source code in ccg\\data\\tsdata.py 1788 1789 1790 def __next__ ( self ): \"\"\"Next.\"\"\" return next ( self . data )","title":"__next__"},{"location":"data/#ccg.data.tsdata.Sig.__pow__","text":"power, resamples to parent.math_tline if exists. returns Sig. Source code in ccg\\data\\tsdata.py 1688 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699 1700 1701 1702 1703 def __pow__ ( self , other ): \"\"\"power, resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): other = other . resample ( tline ) . data unit = f \" { self . unit } **n\" elif len ( other ) == 1 : unit = f \" { self . unit } ** { other } \" if self . unit . lower () == \"ratio\" : unit = \"ratio\" res . unit = unit res . data = self . resample ( tline ) . data ** other return res","title":"__pow__"},{"location":"data/#ccg.data.tsdata.Sig.__radd__","text":"add, resamples to parent.math_tline if exists. returns Sig. Source code in ccg\\data\\tsdata.py 1626 1627 1628 def __radd__ ( self , other ): \"\"\"add, resamples to parent.math_tline if exists. returns Sig.\"\"\" return self . __add__ ( other )","title":"__radd__"},{"location":"data/#ccg.data.tsdata.Sig.__repr__","text":"Return string representation. Source code in ccg\\data\\tsdata.py 1581 1582 1583 1584 def __repr__ ( self ) -> str : \"\"\"Return string representation.\"\"\" reprstr = f \" { self . __class__ . __qualname__ } ( { self . data . __repr__ () } )\" return reprstr","title":"__repr__"},{"location":"data/#ccg.data.tsdata.Sig.__rsub__","text":"subtract, resamples to parent.math_tline if exists. returns Sig. Source code in ccg\\data\\tsdata.py 1630 1631 1632 1633 1634 1635 1636 1637 1638 1639 1640 1641 1642 1643 1644 1645 1646 def __rsub__ ( self , other ): \"\"\"subtract, resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , unit = self . unit , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] - %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . resample ( tline ) . data res . data = other - self . resample ( tline ) . data return res","title":"__rsub__"},{"location":"data/#ccg.data.tsdata.Sig.__setitem__","text":"Set item Source code in ccg\\data\\tsdata.py 1776 1777 1778 1779 1780 1781 1782 def __setitem__ ( self , index : tuple [ slice | list | int | npt . NDArray ] | slice , value : list | npt . NDArray | str , ): \"\"\"Set item\"\"\" self . _data [ index ] = value","title":"__setitem__"},{"location":"data/#ccg.data.tsdata.Sig.__str__","text":"Return readable string. Source code in ccg\\data\\tsdata.py 1586 1587 1588 def __str__ ( self ) -> str : \"\"\"Return readable string.\"\"\" return self . data . __str__ ()","title":"__str__"},{"location":"data/#ccg.data.tsdata.Sig.__sub__","text":"subtract, resamples to parent.math_tline if exists. returns Sig. Source code in ccg\\data\\tsdata.py 1608 1609 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622 1623 1624 def __sub__ ( self , other ): \"\"\"subtract, resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , unit = self . unit , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] - %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . resample ( tline ) . data res . data = self . resample ( tline ) . data - other return res","title":"__sub__"},{"location":"data/#ccg.data.tsdata.Sig.__truediv__","text":"divide(elementwise), resamples to parent.math_tline if exists. returns Sig. Source code in ccg\\data\\tsdata.py 1668 1669 1670 1671 1672 1673 1674 1675 1676 1677 1678 1679 1680 1681 1682 1683 1684 1685 1686 def __truediv__ ( self , other ): \"\"\"divide(elementwise), resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): if ( self . unit and other . unit is None ) or other . unit . lower () == \"ratio\" : unit = self . unit elif ( self . unit is None or self . unit . lower () == \"ratio\" ) and other . unit : unit = other . unit elif self . unit and self . unit == other . unit : unit = \"ratio\" else : unit = f \" { self . unit } / { other . unit } \" other = other . resample ( tline ) . data else : unit = self . unit res . unit = unit res . data = self . resample ( tline ) . data / other return res","title":"__truediv__"},{"location":"data/#ccg.data.tsdata.Sig.append","text":"Append sig to signal. Source code in ccg\\data\\tsdata.py 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 @profile def append ( self , sig : Sig , interweave_tlines = False , remove_duplicates = False ): \"\"\"Append sig to signal.\"\"\" # Check if timelimes overlap check_overlap ( self , sig , interweave_tlines ) if self . parent is None : self . tline . append_inplace ( sig ) else : nshared = len ( self . parent . tlines . sigs [ self . tline . idn ]) if nshared == 1 : self . tline . append_inplace ( sig ) else : self . tline = self . tline . append_to_new ( sig ) self . _data . append ( sig . _data ) # pylint: disable=access-member-before-definition if not self . tline . is_monotonic_increasing : self . sort_tline ( inplace = True , remove_safe_duplicates = remove_duplicates ) if self . parent is not None : self . parent . tlines . remove ( self . name ) self . parent . tlines . append ( self ) # self.tline = tlref # 2/10/24 now in tlines.append() # get the rest of the attributes if sig . connect_gaps is not None : self . connect_gaps = sig . connect_gaps if sig . data_enum is not None : self . data_enum = sig . data_enum if sig . interp_method is not None : self . interp_method = sig . interp_method if sig . unit is not None : self . unit = sig . unit # Check for unknown attributes. the new signal value will overide the original. for key , val in sig . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : setattr ( self , key , val )","title":"append"},{"location":"data/#ccg.data.tsdata.Sig.as_unit","text":"return new sig converted to unit Source code in ccg\\data\\tsdata.py 1240 1241 1242 1243 1244 def as_unit ( self , unit : str ) -> Sig : \"\"\"return new sig converted to unit\"\"\" sig = Sig ( self ) sig . convert_units ( unit ) return sig","title":"as_unit"},{"location":"data/#ccg.data.tsdata.Sig.calc_idn","text":"Calculate hash for IDN. Source code in ccg\\data\\tsdata.py 1180 1181 1182 1183 1184 1185 1186 1187 1188 def calc_idn ( self ): \"\"\"Calculate hash for IDN.\"\"\" # tic = datetime.now() idn = xxhash . xxh3_64_intdigest ( self . _data . tobytes ()) # toc = datetime.now() - tic # _LOGGER.debug(\"IDN calc'd for %s in %.3f\", self.name, toc.total_seconds()) return idn + self . tline . idn","title":"calc_idn"},{"location":"data/#ccg.data.tsdata.Sig.convert_units","text":"Convert units in place Source code in ccg\\data\\tsdata.py 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 def convert_units ( self , unit : str ) -> Sig : \"\"\"Convert units in place\"\"\" if unit != self . unit : self . data = ccg . util . convert_units ( value = self . data , from_unit = self . unit , to_unit = unit ) if self . data_range : self . data_range = ccg . util . convert_units ( value = self . data_range , from_unit = self . unit , to_unit = unit ) self . unit = unit return self","title":"convert_units"},{"location":"data/#ccg.data.tsdata.Sig.dot","text":"Calculate Derivative of signal. Returns new sig. Source code in ccg\\data\\tsdata.py 1512 1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 def dot ( self , n_dot : int = 1 , n_win : int = 5 , n_ord : int = 3 , ): \"\"\"Calculate Derivative of signal. Returns new sig.\"\"\" tic = datetime . now () inds , convs = self . tline . savgol_coef ( self . tline , n_ord , n_win , n_dot , ) ys0 = np . empty (( self . nsamples , n_win )) ys0 [:, :] = np . reshape ( self . data [ inds . ravel ()], ( self . nsamples , n_win ), ) # Calc diaganol only of dot product result = np . einsum ( \"ij,ji->i\" , ys0 [:, :], convs ) res = Sig ( self ) # To get all attr of inital # then update to new values res . name = f ' { res . name } _ { \"\" . join ([ \"dot\" ] * n_dot ) } ' res . unit = ( f ' { res . unit if res . unit else \"\" } /s { \"\" if n_dot == 1 else \"^\" + n_dot } ' ) res . data = result toc = datetime . now () - tic _LOGGER . debug ( \"Deriv of %s in %.3f [s]\" , self . name , toc . total_seconds (), ) return res","title":"dot"},{"location":"data/#ccg.data.tsdata.Sig.interp","text":"Interpolate signal to points. Source code in ccg\\data\\tsdata.py 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 def interp ( self , points : npt . NDArray | TLine , extrapolate : bool = False ) -> Sig : \"\"\"Interpolate signal to points.\"\"\" if isinstance ( points , TLine ): points = points . unix if self . interp_method is None or self . interp_method == InterpMethod . LINEAR : new = ccg . util . linearinterp ( self . tline . unix , self . data , points , extrapolate ) elif self . interp_method == InterpMethod . ZOH : new = self . data [ np . maximum ( np . minimum ( np . searchsorted ( self . tline . unix , points , side = \"right\" ) - 1 , self . nsamples - 1 , ), 0 , ) ] else : # TODO: Implement other interp methods. raise NotImplementedError ( f \" { self . interp_method } not implemented.\" ) res = Sig ( self ) # To create a copy first res . data = new res . tline = TLine ( points ) return res","title":"interp"},{"location":"data/#ccg.data.tsdata.Sig.plot_prep","text":"Prepare for plotting. Sorts tline and removes duplicates. Inserts NaNs in gaps if connect_gaps=False | None . Applies enum if it exists. Source code in ccg\\data\\tsdata.py 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 @profile def plot_prep ( self ) -> Sig : \"\"\"Prepare for plotting. Sorts tline and removes duplicates. Inserts NaNs in gaps if `connect_gaps=False | None`. Applies enum if it exists. \"\"\" res = self if not self . tline . is_monotonic_increasing : self . sort_tline ( remove_safe_duplicates = True ) if self . connect_gaps is None or not self . connect_gaps : gaps = np . greater ( self . tline . dt , self . _FGAP * self . tline . period , ) if np . sum ( gaps ) > 0 : res = Sig ( self ) # Make a copy before resampling. tline = TLine ( self . tline . unix [ np . append ( gaps , False )] + ( self . tline . dt [ gaps ] / 2 ) ) if self . _data . data . dtype . kind in ( \"i\" , \"u\" , \"b\" , \"M\" ): # Since numpy is r-worded and cant use a nan in an int, we need to convert to float self . _data . replace ( self . data . astype ( \"float\" , copy = False )) self . _dtype = self . _data . dtype nans = np . empty ( np . sum ( gaps ), dtype = self . _dtype ) nans [:] = np . nan res . append ( Sig ( data = nans , tline = tline ), interweave_tlines = True ) if res . data_enum is not None : res . base_data = res . data res . data = res . data_enum . data_to_enum ( res . data ) return res","title":"plot_prep"},{"location":"data/#ccg.data.tsdata.Sig.resample","text":"Resample with Savitzky Golay filter. Parameters: sample_to ( TLine ) \u2013 TLine to resample to n_win ( int , default: None ) \u2013 window size, should be odd. Is relative to the sample_to index n_ord ( int , default: None ) \u2013 order of the fit gap_fraction ( float , default: None ) \u2013 size of a gap relative to the window size to interpolate between Returns: New resampled Sig \u2013 Source code in ccg\\data\\tsdata.py 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 @profile def resample ( self : Sig , sample_to : TLine , n_win : int = None , n_ord : int = None , gap_fraction : float = None , interp_gaps = False , ) -> Sig : \"\"\"Resample with Savitzky Golay filter. Parameters ---------- sample_to TLine to resample to n_win window size, should be odd. Is relative to the sample_to index n_ord order of the fit gap_fraction size of a gap relative to the window size to interpolate between Returns ------- New resampled Sig \"\"\" # Skip if the same and default window/order if ( sample_to != self . tline or n_win is not None or n_ord is not None or gap_fraction is not None ): tic = datetime . now () if n_win is None : n_win = 5 if n_ord is None : n_ord = 3 if gap_fraction is None : gap_fraction = 0.5 if self . data . dtype . kind in { \"U\" , \"S\" }: # This is a string type raise NotImplementedError ( \"Cant resample string type.\" ) if not sample_to . is_monotonic_increasing : sample_to = sample_to . sort () if not self . tline . is_monotonic_increasing : self . sort_tline () nsamplesnew = len ( sample_to ) # dt_new = sample_to.dt dtm_new = np . maximum ( sample_to . period , 0.001 ) dt_orig = self . tline . dt dtm_orig = np . maximum ( self . tline . period , 0.001 ) n_win_orig = int ( np . ceil ( max ( n_win , round ( n_win * dtm_new / dtm_orig ))) // 2 * 2 + 1 ) # Detect gaps larger than gap_fraction windows gaps = np . flatnonzero ( dt_orig > n_win_orig * dtm_orig * gap_fraction ) # interpolate between gaps ind_in_gap = [] for gap in gaps : origx = self . tline . unix [ gap : gap + 2 ] ind_in_gap . extend ( * np . where (( sample_to . unix > origx [ 0 ]) & ( sample_to . unix < origx [ 1 ])) ) if interp_gaps and len ( gaps ) > 0 : newx = np . concatenate ( ( self . tline . unix , sample_to . unix [ ind_in_gap ], ), ) newx . sort () orig = self . interp ( newx ) invalid = [] else : orig = self invalid = ind_in_gap inds , convs = orig . tline . savgol_coef ( sample_to , n_ord , n_win_orig , ) ys0 = np . empty (( nsamplesnew , n_win_orig )) ys0 [:, :] = np . reshape ( orig . data [ inds . ravel ()], ( nsamplesnew , n_win_orig ), ) # Calc diaganol only of dot product result = np . einsum ( \"ij,ji->i\" , ys0 [:, :], convs ) if np . any ( invalid ): result [ invalid ] = np . NaN res = Sig ( self ) # To get all attr of inital # then update to new values res . data = result res . tline = sample_to toc = datetime . now () - tic _LOGGER . debug ( \"Resampled %s from %s to %s samples in %.3f [s]\" , self . name , format ( self . nsamples , \",\" ), format ( res . nsamples , \",\" ), toc . total_seconds (), ) else : res = Sig ( self ) return res","title":"resample"},{"location":"data/#ccg.data.tsdata.Sig.sort_tline","text":"Sort signal by timeline. Parameters: inplace \u2013 Sorts signal in place, returns None. remove_duplicates \u2013 Will remove duplicate timestamps if signal is also duplicated. Returns: Sig \u2013 self if inplace=True . Source code in ccg\\data\\tsdata.py 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 def sort_tline ( self , inplace = True , remove_safe_duplicates = False , remove_all_duplicates = False , ): \"\"\"Sort signal by timeline. Parameters ---------- inplace Sorts signal in place, returns None. remove_duplicates Will remove duplicate timestamps if signal is also duplicated. Returns ------- Sig self if `inplace=True`. \"\"\" inds = np . argsort ( self . tline . unix , kind = \"stable\" ) if inplace : self . tline = TLine ( self . tline . unix [ inds ]) if self . nsamples > 0 : self . data = self . data [ inds ] if remove_safe_duplicates : self . _remove_duplicates ( remove_all_duplicates ) if self . parent is not None : self . parent . tlines . remove ( self . name ) self . parent . tlines . append ( self ) # self.tline = tlref # 2/10/24 now in tlines.append() return self sig = Sig ( self ) # TODO: clean this up to not define, then edit. sig . name = sig . name + \"_sorted\" sig . tline = TLine ( self . tline . unix [ inds ]) if self . nsamples > 0 : sig . data = sig . data [ inds ] if remove_safe_duplicates : sig . _remove_duplicates ( remove_all_duplicates ) # pylint: disable=access-member-before-definition return sig","title":"sort_tline"},{"location":"data/#ccg.data.tsdata.Sig.valid","text":"Return new signal with invalid data replaced with nan's Source code in ccg\\data\\tsdata.py 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 1573 1574 1575 1576 def valid ( self , gatecoll : GateColl , frame : Frame = None ): \"\"\"Return new signal with invalid data replaced with nan's\"\"\" # tic = datetime.now() if frame is None and self . parent is None : raise ValueError ( \"`Sig.valid()` requires frame argument if sig has no parent.\" ) if frame is None : frame = self . parent res = Sig ( self ) # copy valid_sig = gatecoll . validate ( frame ) b_valid = valid_sig . interp ( self . tline ) . data nan = np . NaN if res . data . dtype . kind in [ \"i\" , \"u\" ]: res . data = res . data . astype ( \"float\" ) elif res . data . dtype . kind in [ \"U\" , \"S\" ]: nan = \"\" res . data [ ~ b_valid ] = nan # toc = datetime.now() - tic # _LOGGER.debug( # \"get valid sig %s in %.3f\", self.name, toc.total_seconds() # ) return res","title":"valid"},{"location":"data/#ccg.data.tsdata.SigEnum","text":"Enumeration definition for CCGSig. Parameters: definition ( dict ) \u2013 Dictionary of conversion values. \"\" is a special key, default for unmatched values if missing, np.nan will be used. Example enumdef = {'v1':1,'v2':2,'':0,} data = np.array(['v1','v2','v3']) testenum = SigEnum(definition=enumdef) testenum.data_to_enum(data) Source code in ccg\\data\\tsdata.py 2554 2555 2556 2557 2558 2559 2560 2561 2562 2563 2564 2565 2566 2567 2568 2569 2570 2571 2572 2573 2574 2575 2576 2577 2578 2579 2580 2581 2582 2583 2584 2585 2586 2587 2588 2589 2590 2591 2592 2593 2594 2595 2596 2597 2598 class SigEnum : \"\"\"Enumeration definition for CCGSig. Parameters ---------- definition Dictionary of conversion values. \"\" is a special key, default for unmatched values if missing, np.nan will be used. Example ------- >>> enumdef = {'v1':1,'v2':2,'':0,} >>> data = np.array(['v1','v2','v3']) >>> testenum = SigEnum(definition=enumdef) >>> testenum.data_to_enum(data) >>> \"\"\" def __init__ ( self , definition : dict ): self . definition = definition def data_to_enum ( self , data : npt . NDArray ): \"\"\"Convert base data to enumerated type.\"\"\" rtn = np . empty ( data . shape ) unmatched = np . empty ( data . shape , dtype = np . bool_ ) unmatched [:] = True for key , val in self . definition . items (): if not key == \"\" : inds = data == key unmatched [ inds ] = False rtn [ inds ] = val if np . any ( unmatched ): try : rtn [ unmatched ] = self . definition [ \"\" ] except KeyError : rtn [ unmatched ] = np . nan return rtn def enum_to_data ( self , enum : npt . NDArray ): \"\"\"Convert enumerated data back to base data.\"\"\" rtn = np . empty ( enum . shape ) for key , val in self . definition . items (): inds = enum == val rtn [ inds ] = key return rtn","title":"SigEnum"},{"location":"data/#ccg.data.tsdata.SigEnum.data_to_enum","text":"Convert base data to enumerated type. Source code in ccg\\data\\tsdata.py 2574 2575 2576 2577 2578 2579 2580 2581 2582 2583 2584 2585 2586 2587 2588 2589 2590 def data_to_enum ( self , data : npt . NDArray ): \"\"\"Convert base data to enumerated type.\"\"\" rtn = np . empty ( data . shape ) unmatched = np . empty ( data . shape , dtype = np . bool_ ) unmatched [:] = True for key , val in self . definition . items (): if not key == \"\" : inds = data == key unmatched [ inds ] = False rtn [ inds ] = val if np . any ( unmatched ): try : rtn [ unmatched ] = self . definition [ \"\" ] except KeyError : rtn [ unmatched ] = np . nan return rtn","title":"data_to_enum"},{"location":"data/#ccg.data.tsdata.SigEnum.enum_to_data","text":"Convert enumerated data back to base data. Source code in ccg\\data\\tsdata.py 2592 2593 2594 2595 2596 2597 2598 def enum_to_data ( self , enum : npt . NDArray ): \"\"\"Convert enumerated data back to base data.\"\"\" rtn = np . empty ( enum . shape ) for key , val in self . definition . items (): inds = enum == val rtn [ inds ] = key return rtn","title":"enum_to_data"},{"location":"data/#ccg.data.tsdata.TLine","text":"CCG Time Line. Source code in ccg\\data\\tsdata.py 1816 1817 1818 1819 1820 1821 1822 1823 1824 1825 1826 1827 1828 1829 1830 1831 1832 1833 1834 1835 1836 1837 1838 1839 1840 1841 1842 1843 1844 1845 1846 1847 1848 1849 1850 1851 1852 1853 1854 1855 1856 1857 1858 1859 1860 1861 1862 1863 1864 1865 1866 1867 1868 1869 1870 1871 1872 1873 1874 1875 1876 1877 1878 1879 1880 1881 1882 1883 1884 1885 1886 1887 1888 1889 1890 1891 1892 1893 1894 1895 1896 1897 1898 1899 1900 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 2025 2026 2027 2028 2029 2030 2031 2032 2033 2034 2035 2036 2037 2038 2039 2040 2041 2042 2043 2044 2045 2046 2047 2048 2049 2050 2051 2052 2053 2054 2055 2056 2057 2058 2059 2060 2061 2062 2063 2064 2065 2066 2067 2068 2069 2070 2071 2072 2073 2074 2075 2076 2077 2078 2079 2080 2081 2082 2083 2084 2085 2086 2087 2088 2089 2090 2091 2092 2093 2094 2095 2096 2097 2098 2099 2100 2101 2102 2103 2104 2105 2106 2107 2108 2109 2110 2111 2112 2113 2114 2115 2116 2117 2118 2119 2120 2121 2122 2123 2124 2125 2126 2127 2128 2129 2130 2131 2132 2133 2134 2135 2136 2137 2138 2139 2140 2141 2142 2143 2144 2145 2146 2147 2148 2149 2150 2151 2152 2153 2154 2155 2156 2157 2158 2159 2160 2161 2162 2163 2164 2165 2166 2167 2168 2169 2170 2171 2172 2173 2174 2175 2176 2177 2178 2179 2180 2181 2182 2183 2184 2185 2186 2187 2188 2189 2190 2191 2192 2193 2194 2195 2196 2197 2198 2199 2200 2201 2202 2203 2204 2205 2206 2207 2208 2209 2210 2211 2212 2213 2214 2215 2216 2217 2218 2219 2220 2221 2222 2223 2224 2225 2226 2227 2228 2229 2230 2231 2232 2233 2234 2235 2236 2237 2238 2239 2240 2241 2242 2243 2244 2245 class TLine : \"\"\"CCG Time Line.\"\"\" __slots__ = ( \"_iso\" , \"_sg\" , \"_datetime\" , \"_unix\" , \"_idn\" , \"_dt\" , \"_period\" , \"_is_monoton\" , \"parent\" , \"_shape\" , \"_unix\" , \"_period\" , ) @profile def __init__ ( self , data : ( TLine | npt . NDArray [ np . object_ ] | npt . NDArray [ np . number ] | npt . NDArray [ np . datetime64 ] | datetime | list ) = None , tstart : float | datetime = None , tend : float | datetime = None , nsamples : int | tuple [ int ] = None , period : float = None , sg_coef : SgCoef = None , parent : TLineCollection = None , ): if sg_coef is None : self . _sg = SgCoef () self . _iso : npt . NDArray [ np . datetime64 ] = None self . _datetime : npt . NDArray [ np . object_ ] = None self . _unix : AllocData = None self . _idn = None self . _dt = None self . _period : float | None = None self . _is_monoton : bool = None self . parent = parent # TODO: Clean up cases here. better fault detection. if nsamples is None : self . _shape = None elif isinstance ( nsamples , tuple ): self . _shape = nsamples elif isinstance ( nsamples , int ): self . _shape = ( nsamples ,) else : raise NotImplementedError ( f \"tline with nsamples of type { type ( nsamples ) } is not implemented.\" ) if data is not None : # if isinstance(data, (pd.DataFrame, pd.Series)): # if data.index is None: # raise ValueError(\"Data frame has no index.\") # if data.index.asi8 is None: # index = data.index.to_numpy() # else: # index = data.index.asi8 / 1e9 # self.unix = index # elif isinstance(data, pd.Index): # self.unix = data.asi8 / 1e9 if isinstance ( data , np . ndarray ) and data . dtype . kind == \"M\" : self . unix = ccg . util . datetime_to_unix ( data ) elif isinstance ( data , np . ndarray ) and isinstance ( data [ 0 ], datetime ): self . unix = np . array ([ t . timestamp () for t in data ]) elif isinstance ( data , np . ndarray ): self . unix = data . astype ( \"float\" ) elif isinstance ( data , datetime ): self . unix = np . array ([ data . timestamp ()]) elif isinstance ( data , TLine ): self . _shape = data . _shape self . unix = data . _unix self . _sg = data . _sg self . _idn = data . idn elif isinstance ( data , AllocData ): self . _shape = data . _shape self . unix = data elif isinstance ( data , list ): self . unix = np . array ( data ) else : raise NotImplementedError ( f \" { type ( data ) } is not supported.\" ) elif None not in { tstart , tend , nsamples } or None not in { tstart , tend , period }: if isinstance ( tstart , datetime ): tstart = tstart . timestamp () if isinstance ( tend , datetime ): tend = tend . timestamp () if nsamples is not None : self . unix = np . linspace ( start = tstart , stop = tend , num = nsamples ) elif period is not None : self . unix = np . arange ( start = tstart , stop = tend , step = period ) self . _period = period else : raise ValueError ( \"Missing nsamples or period.\" ) elif None not in { tstart , nsamples , period } or None not in { tend , nsamples , period , }: if isinstance ( tstart , datetime ): tstart = tstart . timestamp () if isinstance ( tend , datetime ): tend = tend . timestamp () if tend is None : tend = tstart + nsamples * period if tstart is None : tstart = tend - nsamples * period self . unix = np . linspace ( start = tstart , stop = tend , num = nsamples ) self . _period = period elif nsamples : # To pre-allocate self . unix = None else : raise ValueError @property def unix ( self ) -> npt . NDArray [ np . float_ ]: \"\"\"tline in unix\"\"\" return self . _unix [:] @unix . setter @profile def unix ( self , value : npt . NDArray [ np . float_ ] | AllocData ): if self . _unix is None : self . _unix = AllocData ( value , shape = self . _shape , dtype = np . dtype ( \"float64\" )) else : self . _unix . replace ( value ) # Need to clear lots of stuff if changing the timeline self . clear_cache () # @profile def calc_idn ( self ): \"\"\"Calculate hash for IDN.\"\"\" self . _idn = xxhash . xxh3_64_intdigest ( self . _unix . tobytes ()) return self . _idn @property # @profile def idn ( self ): \"\"\"return id number.\"\"\" if self . _idn is None : return self . calc_idn () return self . _idn @property def tstart ( self ) -> float : \"\"\"Start time.\"\"\" # TODO Check for monoton increasing first. return self . _unix [ 0 ] @property def tend ( self ) -> float : \"\"\"End time.\"\"\" return self . _unix [ - 1 ] @property def tstart_iso ( self ) -> np . datetime64 : \"\"\"Start time.\"\"\" # TODO Check for monoton increasing first. return self . iso [ 0 ] @property def tend_iso ( self ) -> np . datetime64 : \"\"\"End time.\"\"\" return self . iso [ - 1 ] @property def iso ( self ) -> npt . NDArray [ np . datetime64 ]: \"\"\"Array of iso formatted strings. Naive, but in local tz.\"\"\" if self . _iso is None : self . _iso = ccg . util . unix_to_iso ( self . unix ) return self . _iso @property def datetime ( self ) -> npt . NDArray [ np . object_ ]: \"\"\"Array of datetime.datetime.\"\"\" tic = datetime . now () if self . _datetime is None : if self . unix [ 0 ] > 32000000 : tmp = np . array ( [ datetime . fromtimestamp ( t ) . astimezone () for t in self . unix ] ) # SO SLOW else : tmp = np . array ([ datetime . fromtimestamp ( t ) for t in self . unix ]) self . _datetime = tmp toc = datetime . now () - tic if toc > timedelta ( seconds = 0.1 ): _LOGGER . debug ( \"datetime prop calc for %s took %.3f s\" , self . _idn , toc . total_seconds () ) return self . _datetime @property def appx_bytes ( self ): \"\"\"Estimated size of data [bytes]. Excludes tline.\"\"\" return self . _unix . appx_bytes @overload def __getitem__ ( self , ind : int | npt . NDArray [ np . int_ | np . bool_ ]) -> npt . NDArray : pass @overload def __getitem__ ( self , ind : slice ) -> TLine : pass def __getitem__ ( self , ind : int | npt . NDArray [ np . int_ | np . bool_ ] | slice ): \"\"\"Index tline.\"\"\" if isinstance ( ind , slice ): # A slice should return a new CCGTline. Vals should be unix or datetime. if isinstance ( ind . start , datetime ): ind_start = ind . start . timestamp () else : ind_start = ind . start if isinstance ( ind . stop , datetime ): ind_stop = ind . stop . timestamp () else : ind_stop = ind . stop if isinstance ( ind . step , timedelta ): step = ind . step . total_seconds () else : step = ind . step if ind . step is None : if ind . start is None : start = self . tstart else : start = ind_start if ind . stop is None : # Since python is r-worded, this is a special case. # Need to make sure the last sample is included. stop = self . tend + 0.000001 else : stop = ind_stop inds = np . logical_and ( self . unix >= start , self . unix < stop ) return TLine ( self . unix [ inds ]) else : # Step was defined so define a fresh tline i guess? _LOGGER . warning ( \"tline sliced with step defined. This is equiv to `CCGTline(tstart=slice.start,tenc=slice.stop,period=slice.step)`\" ) return TLine ( tstart = ind_start , tend = ind_stop , period = step ) return self . unix [ ind ] def __len__ ( self ) -> int : \"\"\"Length of timeline.\"\"\" return self . _unix . nsamples def __repr__ ( self ) -> str : \"\"\"Return string representation.\"\"\" # reprstr = f\"{self.__class__.__module__}.{self.__class__.__qualname__}({self.iso.__repr__()})\" reprstr = f \" { self . __class__ . __qualname__ } ( { self . iso . __repr__ () } )\" return reprstr def __str__ ( self ) -> str : \"\"\"Return readable string.\"\"\" return self . iso . __str__ () def __eq__ ( self , other ) -> bool : \"\"\"Check equality.\"\"\" if isinstance ( other , self . __class__ ): return np . array_equal ( self . unix , other . unix ) else : return False @property # profile def dt ( self ): \"\"\"delta t\"\"\" if self . _dt is None : if len ( self ) > 1 : self . _dt = np . diff ( self . unix ) else : self . _dt = np . array ([ 0 ]) return self . _dt @property def period ( self ) -> float : \"\"\"apprx period.\"\"\" if self . _period : return self . _period if self . nsamples > 1 : self . _period = stats . mode ( self . dt , keepdims = True ) . mode [ 0 ] else : self . _period = np . Inf return self . _period @property def nsamples ( self ): \"\"\"nsamples\"\"\" return len ( self ) @property # profile def is_monotonic_increasing ( self ): \"\"\"Return true if monotonic increasing.\"\"\" if self . _is_monoton is None : if len ( self ) == 1 : self . _is_monoton = True else : tmp = self . unix self . _is_monoton = np . all ( tmp [ 1 :] > tmp [: - 1 ]) return self . _is_monoton @profile def append_to_new ( self , sig : Sig ): \"\"\"Append timeline from sig to tline. Returns new timeline.\"\"\" nsamples = self . nsamples + sig . nsamples new_tline = TLine ( self , nsamples = nsamples ) new_tline . parent = None new_tline . append_inplace ( sig ) # new_tline = TLine(np.concatenate((self.unix, sig.tline.unix))) return new_tline @profile def append_inplace ( self , sig : Sig ): \"\"\"Append to tline in place. Dangerous if shared in a Frame.\"\"\" self . _unix . append ( sig . tline . _unix ) self . clear_cache () return self def index_at_time ( self , time : float | datetime ) -> int : \"\"\"Get the index of the first tstamp >= time.\"\"\" raise NotImplementedError def sort ( self ): \"\"\"Sort tline.\"\"\" raise NotImplementedError ( \"tline sort is not implemented.\" ) # Dont forget to re-calc idn def clear_cache ( self ): \"\"\"Clear the cached values.\"\"\" self . _sg . clear () old_idn = self . _idn self . _iso = None self . _datetime = None self . _idn = None self . _dt = None self . _period = None self . _is_monoton = None if self . parent is not None and old_idn != self . idn : self . parent . replace ( old_idn , self ) # @profile def savgol_coef ( self : TLine , sample_to_index : TLine , n_ord : int , n_win_orig : int , n_dot : int = 0 , ): \"\"\"Calculate Savitzky Golay coeficients.\"\"\" # Check if coef's are stored nsamplesnew = len ( sample_to_index ) if ( self . idn == self . _sg . orig_index and sample_to_index . idn == self . _sg . sample_to_index and n_ord == self . _sg . n_ord and n_win_orig == self . _sg . n_win_orig ): conv = self . _sg . conv uniqinvs = self . _sg . uniqinvs n_uniq = self . _sg . n_uniq inds = self . _sg . inds else : # Missing or different, so have to calc coef's nsamples = len ( self ) # Find orig samples near new samples ind0 = np . digitize ( sample_to_index . unix , self . unix ) ind0 = np . maximum ( np . minimum ( ind0 , nsamples - 1 , out = ind0 ), 0 , out = ind0 ) # saturate inds = ind0 [:, np . newaxis ] # make n x 1 offs = np . arange ( n_win_orig ) - int (( n_win_orig - 1 ) / 2 ) inds = inds + offs # Saturate the ends inds = np . maximum ( np . minimum ( inds , nsamples - 1 , out = inds ), 0 , out = inds ) indsz : npt . NDArray = self . unix [ inds . ravel ()] # to seconds indsz = indsz . reshape ( inds . shape ) torig = self . unix [ ind0 ] indsz = indsz - torig [:, np . newaxis ] # Find unique window spacings, round to appropriate resolution indsz = np . around ( indsz , 3 , out = indsz ) uniqz , uniqinvs = np . unique ( indsz , return_inverse = True , axis = 0 ) n_uniq = len ( uniqz ) pwrs = np . arange ( n_ord + 1 ) conv = np . empty (( n_uniq , n_win_orig , n_ord + 1 )) for i , uniq in enumerate ( uniqz ): j : npt . NDArray = uniq [:, np . newaxis ] ** pwrs try : tmp = np . linalg . inv ( j . T @ j ) @ j . T except np . linalg . LinAlgError : tmp = np . linalg . pinv ( j . T @ j ) @ j . T conv [ i , :, :] = tmp . T # Store inputs for validating accuracy of stored coef's # Compress or abbrev?? self . _sg . orig_index = self . idn self . _sg . sample_to_index = sample_to_index . idn self . _sg . n_win_orig = n_win_orig self . _sg . n_ord = n_ord # Store coef's self . _sg . conv = conv self . _sg . uniqinvs = uniqinvs self . _sg . n_uniq = n_uniq self . _sg . inds = inds # Calc coef's for this derivative convs = np . empty (( n_win_orig , nsamplesnew )) for i in range ( n_uniq ): convs [:, uniqinvs == i ] = conv [ i , :, n_dot ][:, np . newaxis ] return inds , convs","title":"TLine"},{"location":"data/#ccg.data.tsdata.TLine.appx_bytes","text":"Estimated size of data [bytes]. Excludes tline.","title":"appx_bytes"},{"location":"data/#ccg.data.tsdata.TLine.datetime","text":"Array of datetime.datetime.","title":"datetime"},{"location":"data/#ccg.data.tsdata.TLine.dt","text":"delta t","title":"dt"},{"location":"data/#ccg.data.tsdata.TLine.idn","text":"return id number.","title":"idn"},{"location":"data/#ccg.data.tsdata.TLine.is_monotonic_increasing","text":"Return true if monotonic increasing.","title":"is_monotonic_increasing"},{"location":"data/#ccg.data.tsdata.TLine.iso","text":"Array of iso formatted strings. Naive, but in local tz.","title":"iso"},{"location":"data/#ccg.data.tsdata.TLine.nsamples","text":"nsamples","title":"nsamples"},{"location":"data/#ccg.data.tsdata.TLine.period","text":"apprx period.","title":"period"},{"location":"data/#ccg.data.tsdata.TLine.tend","text":"End time.","title":"tend"},{"location":"data/#ccg.data.tsdata.TLine.tend_iso","text":"End time.","title":"tend_iso"},{"location":"data/#ccg.data.tsdata.TLine.tstart","text":"Start time.","title":"tstart"},{"location":"data/#ccg.data.tsdata.TLine.tstart_iso","text":"Start time.","title":"tstart_iso"},{"location":"data/#ccg.data.tsdata.TLine.unix","text":"tline in unix","title":"unix"},{"location":"data/#ccg.data.tsdata.TLine.__eq__","text":"Check equality. Source code in ccg\\data\\tsdata.py 2083 2084 2085 2086 2087 2088 def __eq__ ( self , other ) -> bool : \"\"\"Check equality.\"\"\" if isinstance ( other , self . __class__ ): return np . array_equal ( self . unix , other . unix ) else : return False","title":"__eq__"},{"location":"data/#ccg.data.tsdata.TLine.__getitem__","text":"Index tline. Source code in ccg\\data\\tsdata.py 2031 2032 2033 2034 2035 2036 2037 2038 2039 2040 2041 2042 2043 2044 2045 2046 2047 2048 2049 2050 2051 2052 2053 2054 2055 2056 2057 2058 2059 2060 2061 2062 2063 2064 2065 2066 2067 def __getitem__ ( self , ind : int | npt . NDArray [ np . int_ | np . bool_ ] | slice ): \"\"\"Index tline.\"\"\" if isinstance ( ind , slice ): # A slice should return a new CCGTline. Vals should be unix or datetime. if isinstance ( ind . start , datetime ): ind_start = ind . start . timestamp () else : ind_start = ind . start if isinstance ( ind . stop , datetime ): ind_stop = ind . stop . timestamp () else : ind_stop = ind . stop if isinstance ( ind . step , timedelta ): step = ind . step . total_seconds () else : step = ind . step if ind . step is None : if ind . start is None : start = self . tstart else : start = ind_start if ind . stop is None : # Since python is r-worded, this is a special case. # Need to make sure the last sample is included. stop = self . tend + 0.000001 else : stop = ind_stop inds = np . logical_and ( self . unix >= start , self . unix < stop ) return TLine ( self . unix [ inds ]) else : # Step was defined so define a fresh tline i guess? _LOGGER . warning ( \"tline sliced with step defined. This is equiv to `CCGTline(tstart=slice.start,tenc=slice.stop,period=slice.step)`\" ) return TLine ( tstart = ind_start , tend = ind_stop , period = step ) return self . unix [ ind ]","title":"__getitem__"},{"location":"data/#ccg.data.tsdata.TLine.__len__","text":"Length of timeline. Source code in ccg\\data\\tsdata.py 2069 2070 2071 def __len__ ( self ) -> int : \"\"\"Length of timeline.\"\"\" return self . _unix . nsamples","title":"__len__"},{"location":"data/#ccg.data.tsdata.TLine.__repr__","text":"Return string representation. Source code in ccg\\data\\tsdata.py 2073 2074 2075 2076 2077 def __repr__ ( self ) -> str : \"\"\"Return string representation.\"\"\" # reprstr = f\"{self.__class__.__module__}.{self.__class__.__qualname__}({self.iso.__repr__()})\" reprstr = f \" { self . __class__ . __qualname__ } ( { self . iso . __repr__ () } )\" return reprstr","title":"__repr__"},{"location":"data/#ccg.data.tsdata.TLine.__str__","text":"Return readable string. Source code in ccg\\data\\tsdata.py 2079 2080 2081 def __str__ ( self ) -> str : \"\"\"Return readable string.\"\"\" return self . iso . __str__ ()","title":"__str__"},{"location":"data/#ccg.data.tsdata.TLine.append_inplace","text":"Append to tline in place. Dangerous if shared in a Frame. Source code in ccg\\data\\tsdata.py 2140 2141 2142 2143 2144 2145 @profile def append_inplace ( self , sig : Sig ): \"\"\"Append to tline in place. Dangerous if shared in a Frame.\"\"\" self . _unix . append ( sig . tline . _unix ) self . clear_cache () return self","title":"append_inplace"},{"location":"data/#ccg.data.tsdata.TLine.append_to_new","text":"Append timeline from sig to tline. Returns new timeline. Source code in ccg\\data\\tsdata.py 2130 2131 2132 2133 2134 2135 2136 2137 2138 @profile def append_to_new ( self , sig : Sig ): \"\"\"Append timeline from sig to tline. Returns new timeline.\"\"\" nsamples = self . nsamples + sig . nsamples new_tline = TLine ( self , nsamples = nsamples ) new_tline . parent = None new_tline . append_inplace ( sig ) # new_tline = TLine(np.concatenate((self.unix, sig.tline.unix))) return new_tline","title":"append_to_new"},{"location":"data/#ccg.data.tsdata.TLine.calc_idn","text":"Calculate hash for IDN. Source code in ccg\\data\\tsdata.py 1956 1957 1958 1959 def calc_idn ( self ): \"\"\"Calculate hash for IDN.\"\"\" self . _idn = xxhash . xxh3_64_intdigest ( self . _unix . tobytes ()) return self . _idn","title":"calc_idn"},{"location":"data/#ccg.data.tsdata.TLine.clear_cache","text":"Clear the cached values. Source code in ccg\\data\\tsdata.py 2156 2157 2158 2159 2160 2161 2162 2163 2164 2165 2166 2167 2168 2169 2170 def clear_cache ( self ): \"\"\"Clear the cached values.\"\"\" self . _sg . clear () old_idn = self . _idn self . _iso = None self . _datetime = None self . _idn = None self . _dt = None self . _period = None self . _is_monoton = None if self . parent is not None and old_idn != self . idn : self . parent . replace ( old_idn , self )","title":"clear_cache"},{"location":"data/#ccg.data.tsdata.TLine.index_at_time","text":"Get the index of the first tstamp >= time. Source code in ccg\\data\\tsdata.py 2147 2148 2149 def index_at_time ( self , time : float | datetime ) -> int : \"\"\"Get the index of the first tstamp >= time.\"\"\" raise NotImplementedError","title":"index_at_time"},{"location":"data/#ccg.data.tsdata.TLine.savgol_coef","text":"Calculate Savitzky Golay coeficients. Source code in ccg\\data\\tsdata.py 2173 2174 2175 2176 2177 2178 2179 2180 2181 2182 2183 2184 2185 2186 2187 2188 2189 2190 2191 2192 2193 2194 2195 2196 2197 2198 2199 2200 2201 2202 2203 2204 2205 2206 2207 2208 2209 2210 2211 2212 2213 2214 2215 2216 2217 2218 2219 2220 2221 2222 2223 2224 2225 2226 2227 2228 2229 2230 2231 2232 2233 2234 2235 2236 2237 2238 2239 2240 2241 2242 2243 2244 2245 def savgol_coef ( self : TLine , sample_to_index : TLine , n_ord : int , n_win_orig : int , n_dot : int = 0 , ): \"\"\"Calculate Savitzky Golay coeficients.\"\"\" # Check if coef's are stored nsamplesnew = len ( sample_to_index ) if ( self . idn == self . _sg . orig_index and sample_to_index . idn == self . _sg . sample_to_index and n_ord == self . _sg . n_ord and n_win_orig == self . _sg . n_win_orig ): conv = self . _sg . conv uniqinvs = self . _sg . uniqinvs n_uniq = self . _sg . n_uniq inds = self . _sg . inds else : # Missing or different, so have to calc coef's nsamples = len ( self ) # Find orig samples near new samples ind0 = np . digitize ( sample_to_index . unix , self . unix ) ind0 = np . maximum ( np . minimum ( ind0 , nsamples - 1 , out = ind0 ), 0 , out = ind0 ) # saturate inds = ind0 [:, np . newaxis ] # make n x 1 offs = np . arange ( n_win_orig ) - int (( n_win_orig - 1 ) / 2 ) inds = inds + offs # Saturate the ends inds = np . maximum ( np . minimum ( inds , nsamples - 1 , out = inds ), 0 , out = inds ) indsz : npt . NDArray = self . unix [ inds . ravel ()] # to seconds indsz = indsz . reshape ( inds . shape ) torig = self . unix [ ind0 ] indsz = indsz - torig [:, np . newaxis ] # Find unique window spacings, round to appropriate resolution indsz = np . around ( indsz , 3 , out = indsz ) uniqz , uniqinvs = np . unique ( indsz , return_inverse = True , axis = 0 ) n_uniq = len ( uniqz ) pwrs = np . arange ( n_ord + 1 ) conv = np . empty (( n_uniq , n_win_orig , n_ord + 1 )) for i , uniq in enumerate ( uniqz ): j : npt . NDArray = uniq [:, np . newaxis ] ** pwrs try : tmp = np . linalg . inv ( j . T @ j ) @ j . T except np . linalg . LinAlgError : tmp = np . linalg . pinv ( j . T @ j ) @ j . T conv [ i , :, :] = tmp . T # Store inputs for validating accuracy of stored coef's # Compress or abbrev?? self . _sg . orig_index = self . idn self . _sg . sample_to_index = sample_to_index . idn self . _sg . n_win_orig = n_win_orig self . _sg . n_ord = n_ord # Store coef's self . _sg . conv = conv self . _sg . uniqinvs = uniqinvs self . _sg . n_uniq = n_uniq self . _sg . inds = inds # Calc coef's for this derivative convs = np . empty (( n_win_orig , nsamplesnew )) for i in range ( n_uniq ): convs [:, uniqinvs == i ] = conv [ i , :, n_dot ][:, np . newaxis ] return inds , convs","title":"savgol_coef"},{"location":"data/#ccg.data.tsdata.TLine.sort","text":"Sort tline. Source code in ccg\\data\\tsdata.py 2151 2152 2153 def sort ( self ): \"\"\"Sort tline.\"\"\" raise NotImplementedError ( \"tline sort is not implemented.\" )","title":"sort"},{"location":"data/#ccg.data.tsdata.TLineCollection","text":"Collection of timelines for Frame. Parameters: frame ( Frame ) \u2013 optional Frame to get timelines from. tlines ( TLine | list [ TLine ] , default: None ) \u2013 optional CCGTline or list of CCGTline. If used, signames is required. signames ( str | list [ str ] , default: None ) \u2013 required with tlines. If tlines is a list, must be equal length. If single tlines, can be a list. Source code in ccg\\data\\tsdata.py 2248 2249 2250 2251 2252 2253 2254 2255 2256 2257 2258 2259 2260 2261 2262 2263 2264 2265 2266 2267 2268 2269 2270 2271 2272 2273 2274 2275 2276 2277 2278 2279 2280 2281 2282 2283 2284 2285 2286 2287 2288 2289 2290 2291 2292 2293 2294 2295 2296 2297 2298 2299 2300 2301 2302 2303 2304 2305 2306 2307 2308 2309 2310 2311 2312 2313 2314 2315 2316 2317 2318 2319 2320 2321 2322 2323 2324 2325 2326 2327 2328 2329 2330 2331 2332 2333 2334 2335 2336 2337 2338 2339 2340 2341 2342 2343 2344 2345 2346 2347 2348 2349 2350 2351 2352 2353 2354 2355 2356 2357 2358 2359 2360 2361 2362 2363 2364 2365 2366 2367 2368 2369 2370 2371 2372 2373 2374 2375 2376 2377 2378 2379 2380 2381 2382 2383 2384 2385 2386 2387 2388 2389 2390 2391 2392 2393 2394 2395 2396 2397 2398 2399 2400 2401 2402 2403 2404 2405 2406 2407 2408 2409 2410 2411 2412 2413 2414 2415 2416 2417 2418 2419 2420 2421 2422 2423 2424 2425 2426 2427 2428 2429 2430 2431 2432 2433 2434 2435 2436 2437 2438 2439 2440 2441 2442 2443 2444 2445 2446 2447 2448 2449 2450 2451 2452 2453 2454 2455 2456 2457 2458 2459 2460 2461 2462 2463 2464 2465 2466 2467 2468 2469 2470 2471 2472 2473 2474 2475 2476 2477 2478 2479 2480 2481 2482 2483 2484 2485 2486 2487 2488 2489 2490 2491 2492 2493 2494 2495 2496 2497 2498 2499 2500 2501 2502 2503 2504 2505 2506 2507 2508 2509 2510 2511 2512 2513 2514 2515 2516 2517 2518 2519 2520 2521 2522 2523 2524 2525 2526 2527 2528 2529 2530 2531 2532 2533 2534 2535 2536 2537 2538 2539 2540 2541 2542 2543 2544 2545 2546 2547 2548 2549 2550 2551 class TLineCollection : \"\"\" Collection of timelines for Frame. Parameters ---------- frame optional Frame to get timelines from. tlines optional CCGTline or list of CCGTline. If used, signames is required. signames required with tlines. If tlines is a list, must be equal length. If single tlines, can be a list. \"\"\" def __init__ ( self , frame : Frame , tlines : TLine | list [ TLine ] = None , signames : str | list [ str ] = None , ) -> None : self . tlines : dict [ int , TLine ] = {} self . idns : dict [ str , int ] = {} self . sigs : dict [ int , list [ str ]] = {} if frame or tlines : self . append ( frameorsig = frame , tlines = tlines , signames = signames ) self . frame = frame @profile def append ( self , frameorsig : Sig | Frame = None , tlines : TLine | list [ TLine ] = None , signames : list [ str ] | list [ list [ str ]] = None , ) -> TLine : \"\"\" Append tline to collection. Parameters ---------- frame optional Frame to get timelines from. tlines optional CCGTline or list of CCGTline. If used, signames is required. signames required with tlines. Must be equal length list of lists of signames. Returns ------- CCGTimeline \"\"\" if frameorsig is not None : # if isinstance(frameorsig, pd.DataFrame): # tline = TLine(frameorsig) # tline.parent = self # if tline.idn in self.tlines: # self.check_sg(tline) # else: # self.tlines[tline.idn] = tline # tlref = self.tlines[tline.idn] # for col in frameorsig: # self.idns[col] = tline.idn # self.add_to_sigs(tline.idn, col) if isinstance ( frameorsig , Frame ): tlref = [] if frameorsig . nsigs > 0 : for tline in frameorsig . tlines : tline . parent = self # TODO: Check for reference issue in this case if tline . idn in self . tlines : self . check_sg ( tline ) else : self . tlines [ tline . idn ] = tline sigs = frameorsig . tlines . sigs [ tline . idn ] # Check if signame already exists with different tline idns_old = self . idns [ sigs ] if idns_old and np . any ( idns_old != tline . idn ): _LOGGER . error ( \"Existing signal( %s ) with different timeline has been replaced\" , sigs [ idns_old != tline . idn ], ) self . idns [ sigs ] = tline . idn self . add_to_sigs ( tline . idn , sigs ) tlref . append ( self . tlines [ tline . idn ]) elif isinstance ( frameorsig , Sig ): tline = frameorsig . tline tline . parent = self if tline . idn in self : self . check_sg ( tline ) else : self . tlines [ tline . idn ] = tline tlref = self . tlines [ tline . idn ] sigs = frameorsig . name # Check if signame already exists with different tline try : idns_old = self . idns [ sigs ] except KeyError : idns_old = None if any ([ idns_old == tline . idn ]): _LOGGER . error ( \"Existing signal( %s ) with different timeline\" , sigs [ idns_old != tline . idn ], ) self . idns [ sigs ] = tline . idn self . add_to_sigs ( tline . idn , sigs ) # Change 2/10/24 - fix reference to tline in sig here frameorsig . tline = tlref else : raise NotImplementedError ( f \"Appending tline from { type ( frameorsig ) } is not implemented\" ) if tlines is not None : if not isinstance ( tlines , list ): tlines = [ tlines ] if len ( signames ) != len ( tlines ): raise ValueError ( \"If tlines is specified and contains more than 1, signames must be same length.\" ) if signames is None : raise ValueError ( \"signames must be specified with tlines.\" ) tlref = [] for sigs , tline in zip ( signames , tlines ): tline . parent = self if tline . idn in self . tlines : self . check_sg ( tline ) else : self . tlines [ tline . idn ] = tline if not isinstance ( sigs , list ): sigs = [ sigs ] self . add_to_sigs ( tline . idn , sigs ) for sig in sigs : self . idns [ sig ] = tline . idn tlref . append ( tline ) return tlref def check_sg ( self , tline : TLine ): \"\"\"Check for existing _sg coef.\"\"\" # If sigs timeline has conv coef, but the cached doesnt, use it instead # pylint: disable=protected-access if tline . _sg . conv is not None and self . tlines [ tline . idn ] . _sg . conv is None : self . tlines [ tline . idn ] . _sg = tline . _sg def get_fastest ( self ): \"\"\"Return the approximate fastest tline from coll.\"\"\" tmp = self [ 0 ] fast = tmp . period for _ , tline in self . tlines . items (): if tline . period < fast : tmp = tline fast = tmp . period return tmp def remove ( self , signame ): \"\"\"Remove timeline for signame from collection. If other signals still use it, it will simply remove the reference. \"\"\" tl_idn = self . idns [ signame ] nref = len ( self . sigs [ tl_idn ]) if nref == 0 : raise ValueError ( \"No matching tline.\" ) if nref == 1 : self . tlines . pop ( tl_idn ) self . idns . pop ( signame ) self . sigs . pop ( tl_idn ) else : self . idns . pop ( signame ) self . sigs [ tl_idn ] . pop ( self . sigs [ tl_idn ] . index ( signame )) def replace ( self , old_tline : int | TLine , new_tline : TLine ): \"\"\"Replace the `old_tline` with `new_tline` in place.\"\"\" if isinstance ( old_tline , TLine ): old_idn = old_tline . idn else : old_idn = old_tline old_tline = self . tlines [ old_idn ] if old_idn in self . tlines : existing_sigs = self . sigs [ old_idn ] . copy () for existing in existing_sigs : self . remove ( existing ) old_tline . parent = None # To block the replace call in unix setter old_tline . unix = new_tline . unix self . append ( tlines = old_tline , signames = [ existing_sigs ]) @property def tstart ( self ): \"\"\"Earliest tstart in collection.\"\"\" tstart = None for _ , tline in self . tlines . items (): if tstart is None or tline . tstart < tstart : tstart = tline . tstart return tstart @property def tend ( self ): \"\"\"Latest tend in collection.\"\"\" tend = None for _ , tline in self . tlines . items (): if tend is None or tline . tend > tend : tend = tline . tend return tend @property def tstart_iso ( self ): \"\"\"Earliest start time in iso.\"\"\" return ccg . util . unix_to_iso ( self . tstart ) @property def tend_iso ( self ): \"\"\"Latest end time in iso.\"\"\" return ccg . util . unix_to_iso ( self . tend ) @property def n_tlines ( self ): \"\"\"Number of tlines in collection.\"\"\" return len ( self . tlines ) @property def nsamples ( self ): \"\"\"Number of samples in collection.\"\"\" nsamples = 0 for _ , tline in self . tlines . items (): nsamples += tline . nsamples return nsamples def add_to_sigs ( self , tline_idn : int , signame : str | list [ str ]): \"\"\"Add signal name to list.\"\"\" if isinstance ( signame , str ): signame = [ signame ] try : # try to extend incase it already exists. self . sigs [ tline_idn ] . extend ( signame ) except KeyError : # else define it as a list self . sigs [ tline_idn ] = signame def get_apprx_bytes ( self , tline : TLine ): \"\"\"Gets the approximate size of the tline and its associated signals. Parameters ---------- tline tline to get size for. Returns ------- Cumulative Bytes of tline and the signals associated with it. \"\"\" size = tline . appx_bytes for sig in self . sigs [ tline . idn ]: size += self . frame . sigs [ sig ] . appx_bytes return size def __getitem__ ( self , index : str | int ) -> TLine : if isinstance ( index , str ): return self . tlines [ self . idns [ index ]] elif isinstance ( index , int ): # TODO: Is this legit?? try : return self . tlines [ index ] except KeyError : return list ( self . tlines . values ())[ index ] else : raise NotImplementedError def __repr__ ( self ) -> str : \"\"\"Return string repr.\"\"\" isos = [] for tline in self . tlines . values (): isos . append ( repr ( tline )) # reprstr = f\"{self.__class__.__module__}.{self.__class__.__qualname__}([{', '.join(isos)}])\" reprstr = f \" { self . __class__ . __qualname__ } ([ { ', ' . join ( isos ) } ])\" return reprstr def __str__ ( self ): \"\"\"String rep.\"\"\" idnlist = self . tlines . keys () return f \"tline collection idns: { idnlist } \" def __eq__ ( self , other ) -> bool : \"\"\"Check equality.\"\"\" if isinstance ( other , self . __class__ ): eq = ( self . idns == other . idns and self . sigs == other . sigs and self . tlines == other . tlines ) return eq else : return False def __contains__ ( self , other ) -> bool : return other in self . tlines","title":"TLineCollection"},{"location":"data/#ccg.data.tsdata.TLineCollection.n_tlines","text":"Number of tlines in collection.","title":"n_tlines"},{"location":"data/#ccg.data.tsdata.TLineCollection.nsamples","text":"Number of samples in collection.","title":"nsamples"},{"location":"data/#ccg.data.tsdata.TLineCollection.tend","text":"Latest tend in collection.","title":"tend"},{"location":"data/#ccg.data.tsdata.TLineCollection.tend_iso","text":"Latest end time in iso.","title":"tend_iso"},{"location":"data/#ccg.data.tsdata.TLineCollection.tstart","text":"Earliest tstart in collection.","title":"tstart"},{"location":"data/#ccg.data.tsdata.TLineCollection.tstart_iso","text":"Earliest start time in iso.","title":"tstart_iso"},{"location":"data/#ccg.data.tsdata.TLineCollection.__eq__","text":"Check equality. Source code in ccg\\data\\tsdata.py 2538 2539 2540 2541 2542 2543 2544 2545 2546 2547 2548 def __eq__ ( self , other ) -> bool : \"\"\"Check equality.\"\"\" if isinstance ( other , self . __class__ ): eq = ( self . idns == other . idns and self . sigs == other . sigs and self . tlines == other . tlines ) return eq else : return False","title":"__eq__"},{"location":"data/#ccg.data.tsdata.TLineCollection.__repr__","text":"Return string repr. Source code in ccg\\data\\tsdata.py 2524 2525 2526 2527 2528 2529 2530 2531 def __repr__ ( self ) -> str : \"\"\"Return string repr.\"\"\" isos = [] for tline in self . tlines . values (): isos . append ( repr ( tline )) # reprstr = f\"{self.__class__.__module__}.{self.__class__.__qualname__}([{', '.join(isos)}])\" reprstr = f \" { self . __class__ . __qualname__ } ([ { ', ' . join ( isos ) } ])\" return reprstr","title":"__repr__"},{"location":"data/#ccg.data.tsdata.TLineCollection.__str__","text":"String rep. Source code in ccg\\data\\tsdata.py 2533 2534 2535 2536 def __str__ ( self ): \"\"\"String rep.\"\"\" idnlist = self . tlines . keys () return f \"tline collection idns: { idnlist } \"","title":"__str__"},{"location":"data/#ccg.data.tsdata.TLineCollection.add_to_sigs","text":"Add signal name to list. Source code in ccg\\data\\tsdata.py 2487 2488 2489 2490 2491 2492 2493 2494 def add_to_sigs ( self , tline_idn : int , signame : str | list [ str ]): \"\"\"Add signal name to list.\"\"\" if isinstance ( signame , str ): signame = [ signame ] try : # try to extend incase it already exists. self . sigs [ tline_idn ] . extend ( signame ) except KeyError : # else define it as a list self . sigs [ tline_idn ] = signame","title":"add_to_sigs"},{"location":"data/#ccg.data.tsdata.TLineCollection.append","text":"Append tline to collection. Parameters: frame \u2013 optional Frame to get timelines from. tlines ( TLine | list [ TLine ] , default: None ) \u2013 optional CCGTline or list of CCGTline. If used, signames is required. signames ( list [ str ] | list [ list [ str ]] , default: None ) \u2013 required with tlines. Must be equal length list of lists of signames. Returns: CCGTimeline \u2013 Source code in ccg\\data\\tsdata.py 2276 2277 2278 2279 2280 2281 2282 2283 2284 2285 2286 2287 2288 2289 2290 2291 2292 2293 2294 2295 2296 2297 2298 2299 2300 2301 2302 2303 2304 2305 2306 2307 2308 2309 2310 2311 2312 2313 2314 2315 2316 2317 2318 2319 2320 2321 2322 2323 2324 2325 2326 2327 2328 2329 2330 2331 2332 2333 2334 2335 2336 2337 2338 2339 2340 2341 2342 2343 2344 2345 2346 2347 2348 2349 2350 2351 2352 2353 2354 2355 2356 2357 2358 2359 2360 2361 2362 2363 2364 2365 2366 2367 2368 2369 2370 2371 2372 2373 2374 2375 2376 2377 2378 2379 2380 2381 2382 2383 2384 2385 2386 2387 2388 2389 2390 2391 2392 2393 @profile def append ( self , frameorsig : Sig | Frame = None , tlines : TLine | list [ TLine ] = None , signames : list [ str ] | list [ list [ str ]] = None , ) -> TLine : \"\"\" Append tline to collection. Parameters ---------- frame optional Frame to get timelines from. tlines optional CCGTline or list of CCGTline. If used, signames is required. signames required with tlines. Must be equal length list of lists of signames. Returns ------- CCGTimeline \"\"\" if frameorsig is not None : # if isinstance(frameorsig, pd.DataFrame): # tline = TLine(frameorsig) # tline.parent = self # if tline.idn in self.tlines: # self.check_sg(tline) # else: # self.tlines[tline.idn] = tline # tlref = self.tlines[tline.idn] # for col in frameorsig: # self.idns[col] = tline.idn # self.add_to_sigs(tline.idn, col) if isinstance ( frameorsig , Frame ): tlref = [] if frameorsig . nsigs > 0 : for tline in frameorsig . tlines : tline . parent = self # TODO: Check for reference issue in this case if tline . idn in self . tlines : self . check_sg ( tline ) else : self . tlines [ tline . idn ] = tline sigs = frameorsig . tlines . sigs [ tline . idn ] # Check if signame already exists with different tline idns_old = self . idns [ sigs ] if idns_old and np . any ( idns_old != tline . idn ): _LOGGER . error ( \"Existing signal( %s ) with different timeline has been replaced\" , sigs [ idns_old != tline . idn ], ) self . idns [ sigs ] = tline . idn self . add_to_sigs ( tline . idn , sigs ) tlref . append ( self . tlines [ tline . idn ]) elif isinstance ( frameorsig , Sig ): tline = frameorsig . tline tline . parent = self if tline . idn in self : self . check_sg ( tline ) else : self . tlines [ tline . idn ] = tline tlref = self . tlines [ tline . idn ] sigs = frameorsig . name # Check if signame already exists with different tline try : idns_old = self . idns [ sigs ] except KeyError : idns_old = None if any ([ idns_old == tline . idn ]): _LOGGER . error ( \"Existing signal( %s ) with different timeline\" , sigs [ idns_old != tline . idn ], ) self . idns [ sigs ] = tline . idn self . add_to_sigs ( tline . idn , sigs ) # Change 2/10/24 - fix reference to tline in sig here frameorsig . tline = tlref else : raise NotImplementedError ( f \"Appending tline from { type ( frameorsig ) } is not implemented\" ) if tlines is not None : if not isinstance ( tlines , list ): tlines = [ tlines ] if len ( signames ) != len ( tlines ): raise ValueError ( \"If tlines is specified and contains more than 1, signames must be same length.\" ) if signames is None : raise ValueError ( \"signames must be specified with tlines.\" ) tlref = [] for sigs , tline in zip ( signames , tlines ): tline . parent = self if tline . idn in self . tlines : self . check_sg ( tline ) else : self . tlines [ tline . idn ] = tline if not isinstance ( sigs , list ): sigs = [ sigs ] self . add_to_sigs ( tline . idn , sigs ) for sig in sigs : self . idns [ sig ] = tline . idn tlref . append ( tline ) return tlref","title":"append"},{"location":"data/#ccg.data.tsdata.TLineCollection.check_sg","text":"Check for existing _sg coef. Source code in ccg\\data\\tsdata.py 2395 2396 2397 2398 2399 2400 def check_sg ( self , tline : TLine ): \"\"\"Check for existing _sg coef.\"\"\" # If sigs timeline has conv coef, but the cached doesnt, use it instead # pylint: disable=protected-access if tline . _sg . conv is not None and self . tlines [ tline . idn ] . _sg . conv is None : self . tlines [ tline . idn ] . _sg = tline . _sg","title":"check_sg"},{"location":"data/#ccg.data.tsdata.TLineCollection.get_apprx_bytes","text":"Gets the approximate size of the tline and its associated signals. Parameters: tline ( TLine ) \u2013 tline to get size for. Returns: Cumulative Bytes of tline and the signals associated with it. \u2013 Source code in ccg\\data\\tsdata.py 2496 2497 2498 2499 2500 2501 2502 2503 2504 2505 2506 2507 2508 2509 2510 def get_apprx_bytes ( self , tline : TLine ): \"\"\"Gets the approximate size of the tline and its associated signals. Parameters ---------- tline tline to get size for. Returns ------- Cumulative Bytes of tline and the signals associated with it. \"\"\" size = tline . appx_bytes for sig in self . sigs [ tline . idn ]: size += self . frame . sigs [ sig ] . appx_bytes return size","title":"get_apprx_bytes"},{"location":"data/#ccg.data.tsdata.TLineCollection.get_fastest","text":"Return the approximate fastest tline from coll. Source code in ccg\\data\\tsdata.py 2402 2403 2404 2405 2406 2407 2408 2409 2410 2411 def get_fastest ( self ): \"\"\"Return the approximate fastest tline from coll.\"\"\" tmp = self [ 0 ] fast = tmp . period for _ , tline in self . tlines . items (): if tline . period < fast : tmp = tline fast = tmp . period return tmp","title":"get_fastest"},{"location":"data/#ccg.data.tsdata.TLineCollection.remove","text":"Remove timeline for signame from collection. If other signals still use it, it will simply remove the reference. Source code in ccg\\data\\tsdata.py 2413 2414 2415 2416 2417 2418 2419 2420 2421 2422 2423 2424 2425 2426 2427 2428 def remove ( self , signame ): \"\"\"Remove timeline for signame from collection. If other signals still use it, it will simply remove the reference. \"\"\" tl_idn = self . idns [ signame ] nref = len ( self . sigs [ tl_idn ]) if nref == 0 : raise ValueError ( \"No matching tline.\" ) if nref == 1 : self . tlines . pop ( tl_idn ) self . idns . pop ( signame ) self . sigs . pop ( tl_idn ) else : self . idns . pop ( signame ) self . sigs [ tl_idn ] . pop ( self . sigs [ tl_idn ] . index ( signame ))","title":"remove"},{"location":"data/#ccg.data.tsdata.TLineCollection.replace","text":"Replace the old_tline with new_tline in place. Source code in ccg\\data\\tsdata.py 2430 2431 2432 2433 2434 2435 2436 2437 2438 2439 2440 2441 2442 2443 2444 def replace ( self , old_tline : int | TLine , new_tline : TLine ): \"\"\"Replace the `old_tline` with `new_tline` in place.\"\"\" if isinstance ( old_tline , TLine ): old_idn = old_tline . idn else : old_idn = old_tline old_tline = self . tlines [ old_idn ] if old_idn in self . tlines : existing_sigs = self . sigs [ old_idn ] . copy () for existing in existing_sigs : self . remove ( existing ) old_tline . parent = None # To block the replace call in unix setter old_tline . unix = new_tline . unix self . append ( tlines = old_tline , signames = [ existing_sigs ])","title":"replace"},{"location":"data/#ccg.data.tsdata.get_math_tline","text":"returns timeline for math. sig1.parent.math_tline if it exits, or fastest. Source code in ccg\\data\\tsdata.py 2647 2648 2649 2650 2651 2652 2653 2654 2655 def get_math_tline ( sig1 : Sig , sig2 : Sig | npt . NDArray | float | int ): \"\"\"returns timeline for math. sig1.parent.math_tline if it exits, or fastest.\"\"\" if sig1 . parent and sig1 . parent . math_tline : return sig1 . parent . math_tline if isinstance ( sig2 , Sig ) and sig2 . parent and sig2 . parent . math_tline : return sig2 . parent . math_tline if isinstance ( sig2 , Sig ) and sig1 . tline . period > sig2 . tline . period : return sig2 . tline return sig1 . tline","title":"get_math_tline"},{"location":"reference/SUMMARY/","text":"ccg controllers aem link motec data alloc_data gating tbldata tsdata db mongo ui panel plot plot_themes plotgo web util","title":"SUMMARY"},{"location":"reference/ccg/","text":"CCG Package Imports: util, ScatterData, Tbl, Tbls, Frame, Sig, TLine, Plot, PlotConfig, GateCollAND, GateCollOR, GateCond, gatecoll_from_dict, gatecoll_from_file, gatecoll_to_dict,","title":"ccg"},{"location":"reference/ccg/util/","text":"CCG Utility functions. InterpMethod Bases: str , Enum Interp methods enum. Source code in ccg\\util.py 55 56 57 58 59 60 61 62 63 64 65 class InterpMethod ( str , Enum ): \"\"\"Interp methods enum.\"\"\" LINEAR = \"lin\" ZOH = \"zoh\" NEAREST = \"near\" @classmethod def _missing_ ( cls , value ): \"\"\"return default\"\"\" return cls . LINEAR array_to_list ( data ) Recursively converts arrays in dict to lists. Source code in ccg\\util.py 585 586 587 588 589 590 591 592 593 594 595 596 def array_to_list ( data : Iterable ): \"\"\"Recursively converts arrays in dict to lists.\"\"\" if isinstance ( data , dict ): for key , val in data . items (): if isinstance ( val , dict ) or isinstance ( val , list ): data [ key ] = array_to_list ( val ) elif isinstance ( val , np . ndarray ): data [ key ] = val . tolist () elif isinstance ( data , list ): for item in data : item = array_to_list ( item ) return data byte2str ( bytes_data ) Converts bytes to string and drops trailing zeros Source code in ccg\\util.py 576 577 578 579 580 581 582 def byte2str ( bytes_data : bytes ) -> str | bytes : \"\"\"Converts bytes to string and drops trailing zeros\"\"\" try : return bytes_data . decode ( \"ascii\" ) . strip () . rstrip ( \" \\0 \" ) . strip () except UnicodeDecodeError as err : _LOGGER . warning ( \"Exception decoding %s . Error: %s \" , bytes_data , err ) return bytes_data calculate_colors ( data , colorscale = 'Turbo' , colorscale_center = None ) Calculate colors for data table. Source code in ccg\\util.py 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 def calculate_colors ( data : npt . NDArray , colorscale = \"Turbo\" , colorscale_center = None ) -> list : \"\"\"Calculate colors for data table.\"\"\" tic = datetime . now () scale = pc . get_colorscale ( colorscale ) if not isinstance ( data , np . ndarray ): data = np . atleast_1d ( np . array ( data )) if colorscale_center is not None : data_range = centered_range ( data , colorscale_center ) else : data_range = np . nanpercentile ( data , [ 2 , 98 ]) . tolist () # If the range is zero, adjust it slightly to avoid division by zero if data_range [ 1 ] - data_range [ 0 ] == 0 : data_range [ 0 ] -= 0.5 data_range [ 1 ] += 0.5 pts = ( data - data_range [ 0 ]) / ( data_range [ 1 ] - data_range [ 0 ]) pts = np . clip ( pts , 0 , 1 ) if np . any ( np . isnan ( pts )): print ( pts ) colors = pc . sample_colorscale ( scale , pts . flatten () . tolist ()) # colors = np.array(colors).reshape(data.shape) toc = datetime . now () - tic _LOGGER . debug ( \"Color calc: %.3f \" , toc . total_seconds ()) return np . array ( colors ) . reshape ( data . shape ) . tolist () calculate_font_colors ( colors , light_font = '#e5e5e5' , dark_font = '#434343' ) Calculate font colors for data table. Source code in ccg\\util.py 366 367 368 369 370 371 372 373 374 375 def calculate_font_colors ( colors : list , light_font = \"#e5e5e5\" , dark_font = \"#434343\" ) -> npt . NDArray : \"\"\"Calculate font colors for data table.\"\"\" tic = datetime . now () font_colors = max_contrast ( colors , light_font , dark_font ) # font_colors = np.array(font_colors).reshape(colors.shape) toc = datetime . now () - tic _LOGGER . debug ( \"Font color calc: %.3f \" , toc . total_seconds ()) return font_colors centered_range ( data , centerpoint ) Return centered range from 2 to 98th percentile Source code in ccg\\util.py 378 379 380 381 382 383 384 385 386 387 def centered_range ( data : list | npt . NDArray , centerpoint : float ): \"\"\"Return centered range from 2 to 98th percentile\"\"\" delta = np . array ( data ) - centerpoint data_range = np . max ( np . abs ( np . nanpercentile ( delta , [ 2 , 98 ]))) data_range = 0.5 if data_range == 0 else data_range data_range = [ centerpoint - data_range , centerpoint + data_range , ] return data_range clean_name ( name ) Clean name for frame or sig name. Source code in ccg\\util.py 559 560 561 562 563 564 565 566 567 def clean_name ( name : str ): \"\"\"Clean name for frame or sig name.\"\"\" return ( name . replace ( \" - \" , \"_\" ) . replace ( \" \" , \"_\" ) . replace ( \"-\" , \"_\" ) . replace ( \".\" , \"_\" ) . lower () ) clean_time_str ( in_str , date = datetime . now () . date () . isoformat ()) Clean strings for datetime.strptime Source code in ccg\\util.py 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 @profile def clean_time_str ( in_str : str | list [ str ] | npt . NDArray , date = datetime . now () . date () . isoformat () ): \"\"\"Clean strings for datetime.strptime\"\"\" regex = re . compile ( r \"^(?P<hr>\\d{1,2})*?:?(?P<min>\\d{1,2})*?:?(?P<sec>\\d{1,2})*?(?P<ms>\\.\\d{1,6})?$\" ) if isinstance ( in_str , str ): res = regex . match ( in_str ) if res is None : raise ValueError ( f \"Unable to parse { in_str } to ISO time\" ) out_str = f ' { date } T { ( res [ \"hr\" ] or \"\" ) . zfill ( 2 ) } : { ( res [ \"min\" ] or \"\" ) . zfill ( 2 ) } : { ( res [ \"sec\" ] or \"\" ) . zfill ( 2 ) }{ res [ \"ms\" ] or \"\" } ' else : out_str = in_str . copy () for i , tmp_str in enumerate ( in_str ): res = regex . match ( tmp_str ) if res is None : raise ValueError ( f \"Unable to parse { tmp_str } to ISO time\" ) out_str [ i ] = ( f ' { date } T { ( res [ \"hr\" ] or \"\" ) . zfill ( 2 ) } : { ( res [ \"min\" ] or \"\" ) . zfill ( 2 ) } : { ( res [ \"sec\" ] or \"\" ) . zfill ( 2 ) }{ res [ \"ms\" ] or \"\" } ' ) return out_str convert_units ( value , from_unit , to_unit ) Unit converter Source code in ccg\\util.py 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 def convert_units ( value : npt . NDArray | list , from_unit : str , to_unit : str ): \"\"\"Unit converter\"\"\" if ( from_unit == to_unit or from_unit == \"\" or to_unit == \"\" or from_unit is None or to_unit is None ): res = value else : from_gain , from_offset , from_quant = find_unit ( from_unit ) to_gain , to_offset , to_quant = find_unit ( to_unit ) if from_quant != to_quant : raise ValueError ( f \" { to_quant } not compatible with { from_quant } in unit conversion.\" ) islist = False if isinstance ( value , list ): value = np . array ( value ) islist = True res = (( value + from_offset ) * from_gain ) / to_gain - to_offset if isinstance ( res , np . ndarray ): res = res . astype ( value . dtype ) if islist : res = res . tolist () return res datetime_to_unix ( array ) convert datetime64 to unix timestamp. In local TZ but naive. Source code in ccg\\util.py 413 414 415 416 417 418 419 def datetime_to_unix ( array : npt . NDArray [ np . datetime64 ]) -> npt . NDArray [ np . floating ]: \"\"\"convert datetime64 to unix timestamp. In local TZ but naive.\"\"\" rtn = array . astype ( \"datetime64[us]\" ) . astype ( \"float\" ) / 1e6 # UTC tz = datetime . now () . astimezone () . tzinfo # Local TZ off = tz . utcoffset ( datetime . now ()) . total_seconds () rtn -= off return rtn find_unit ( unit ) Find unit conversion coef's Parameters: unit ( str | None ) \u2013 Returns: tuple [ float , float , str ] \u2013 Returns Gain, Offset, and Quantity Raises: NotImplementedError \u2013 If unit not in conversion definitions Source code in ccg\\util.py 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 def find_unit ( unit : str | None ) -> tuple [ float , float , str ]: \"\"\"Find unit conversion coef's Parameters ---------- unit : str | None Returns ------- tuple[float, float, str] Returns Gain, Offset, and Quantity Raises ------ NotImplementedError If unit not in conversion definitions \"\"\" for quant , values in UNIT_CONV . items (): if str ( unit ) . lower () in values : return ( * values [ str ( unit ) . lower ()], quant ) assert unit is not None if \"/s\" in unit : # Check for derivative sig, for quant , values in UNIT_CONV . items (): test_unit = str ( unit ) . lower () . replace ( \"/s\" , \"\" ) if test_unit in values : return ( * values [ test_unit ], quant + \"_rate\" ) raise NotImplementedError ( f \" { unit } not found in UNIT_CONV\" ) getsize ( obj_0 ) Recursively iterate to sum size of object & members. Source code in ccg\\util.py 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 def getsize ( obj_0 ): \"\"\"Recursively iterate to sum size of object & members.\"\"\" # From https://stackoverflow.com/users/541136/aaron-hall 's answer here: # https://stackoverflow.com/questions/449560/how-do-i-determine-the-size-of-an-object-in-python _seen_ids = set () def inner ( obj ): obj_id = id ( obj ) if obj_id in _seen_ids : return 0 _seen_ids . add ( obj_id ) size = sys . getsizeof ( obj ) if isinstance ( obj , ZERO_DEPTH_BASES ): pass # bypass remaining control flow and return elif isinstance ( obj , ( tuple , list , Set , deque )): size += sum ( inner ( i ) for i in obj ) elif isinstance ( obj , Mapping ): size += sum ( inner ( k ) + inner ( v ) for k , v in obj . items ()) # Check for custom object instances - may subclass above too if hasattr ( obj , \"__dict__\" ): size += inner ( vars ( obj )) if hasattr ( obj , \"__slots__\" ): # can have __slots__ with __dict__ size += sum ( inner ( getattr ( obj , s )) for s in obj . __slots__ if hasattr ( obj , s ) ) return size return inner ( obj_0 ) hex_to_rgb ( hexstr ) Return rgb. Source code in ccg\\util.py 213 214 215 216 217 218 219 220 def hex_to_rgb ( hexstr : str ): \"\"\"Return rgb.\"\"\" match = re . search ( r \"#\\w {6} \" , hexstr ) if match : hexstr = match . group () return int ( hexstr [ 1 : 3 ], 16 ), int ( hexstr [ 3 : 5 ], 16 ), int ( hexstr [ 5 : 7 ], 16 ) else : return None is_pandas ( value ) Check if pandas dataframe, avoiding importing the module. Source code in ccg\\util.py 730 731 732 733 734 def is_pandas ( value ): \"\"\"Check if pandas dataframe, avoiding importing the module.\"\"\" df_cls = getattr ( sys . modules . get ( \"pandas\" ), \"DataFrame\" , None ) return df_cls is not None and isinstance ( value , df_cls ) iscompat ( dtype1 , dtype2 ) Return True if data types are compatible Parameters: dtype1 ( DTypeLike ) \u2013 dtype2 ( DTypeLike ) \u2013 Returns: bool \u2013 Source code in ccg\\util.py 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 def iscompat ( dtype1 : npt . DTypeLike , dtype2 : npt . DTypeLike ) -> bool : \"\"\"Return True if data types are compatible Parameters ---------- dtype1 : npt.DTypeLike dtype2 : npt.DTypeLike Returns ------- bool \"\"\" for types in COMPAT_TYPES : if dtype1 . kind in types : if dtype2 . kind in types : return True return False lin2s ( col ) Linear to sRGB. Source code in ccg\\util.py 233 234 235 236 237 238 239 def lin2s ( col ): \"Linear to sRGB.\" col1 = col ** ( 1 / 2.4 ) * 1.055 - 0.055 col2 = col * 12.92 if col2 <= 0.03928 : return int ( col2 * 255 ) return int ( col1 * 255 ) linearinterp ( bps , data , points , extrapolate = False ) Nd Linear interpolation Parameters: bps ( list [ NDArray ] ) \u2013 List of arrays of breakpoints data ( NDArray ) \u2013 Data points ( NDArray ) \u2013 New breakpoints to interpolate to extrapolate ( bool , default: False ) \u2013 by default False Returns: NDArray [ floating ] \u2013 Source code in ccg\\util.py 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 @profile def linearinterp ( bps : list [ npt . NDArray ], data : npt . NDArray , points : npt . NDArray , extrapolate : bool = False , ) -> npt . NDArray [ np . floating ]: \"\"\"Nd Linear interpolation Parameters ---------- bps : list[npt.NDArray] List of arrays of breakpoints data : npt.NDArray Data points : npt.NDArray New breakpoints to interpolate to extrapolate : bool, optional by default False Returns ------- npt.NDArray[np.floating] \"\"\" # Make sure BPs is a list if not isinstance ( bps , list ): bps = [ bps ] # Make sure data and points are useful # if data.ndim == 1: # data = data[:, None] if points . ndim == 1 : points = points [:, None ] # Check that data matches bps shape nd = len ( bps ) nint : int = 2 ** nd npts = points . shape [ 0 ] bmatch = True for i , bp in enumerate ( bps ): bmatch = bmatch and len ( bp ) == data . shape [ i ] if not bmatch : raise TypeError ( \"Shape of data doesnt match bps.\" ) # check that pts is right size if nd > 1 : tst = points . shape [ 1 ] == nd if not tst : raise TypeError ( \"Points should be npts x nd\" ) ind0 : list [ npt . NDArray ] = [] intf = np . zeros (( npts , nd )) adders = np . zeros (( nint , nd ), dtype = np . int_ ) for i in range ( nd ): ind0 . append ( np . digitize ( points [:, i ], bps [ i ], right = False ) - 1 ) # So annoying # Saturate ind0 [ i ] = np . clip ( ind0 [ i ], 0 , len ( bps [ i ]) - 2 ) diff = bps [ i ][ ind0 [ i ] + 1 ] - bps [ i ][ ind0 [ i ]] intf [:, i ] = ( points [:, i ] - bps [ i ][ ind0 [ i ]]) / diff # adder adder = np . tile ( np . concatenate ( ( np . tile ( 0 , int ( 2 ** i )), np . tile ( 1 , int ( 2 ** i )), ) ), int ( nint / ( 2 ** ( i + 1 ))), ) adders [:, i ] = adder if not extrapolate : intf : npt . NDArray [ np . float64 ] = np . clip ( intf , 0.0 , 1.0 ) new = np . zeros (( npts ,)) for i in range ( nint ): adder = adders [ i ] fint = np . prod (( intf * adder ) + (( 1 - intf ) * ( 1 - adder )), 1 ) ind = tuple ( x + y for x , y in zip ( ind0 , adder )) new += data [ ind ] * fint return new lum ( color ) Luminance. Source code in ccg\\util.py 253 254 255 256 257 258 259 260 def lum ( color : str ): \"\"\"Luminance.\"\"\" if color . startswith ( \"#\" ): red , grn , blu = hex_to_rgb ( color ) elif color . startswith ( \"rgb\" ): red , grn , blu = rgb2val ( color ) return 0.2126 * s2lin ( red ) + 0.7152 * s2lin ( grn ) + 0.0722 * s2lin ( blu ) max_contrast ( testcolors , col1 , col2 ) Choose col1 or col2 to maximize contrast with testcolor. Source code in ccg\\util.py 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 def max_contrast ( testcolors : list [ str ] | str , col1 : str , col2 : str ): \"\"\"Choose col1 or col2 to maximize contrast with testcolor.\"\"\" lu1 = lum ( col1 ) lu2 = lum ( col2 ) if isinstance ( testcolors , str ): tmp = [ testcolors ] else : tmp = testcolors res = [] for testcolor in tmp : test = lum ( testcolor ) if test > (( lu1 + 0.05 ) * ( lu2 + 0.05 )) ** 0.5 - 0.05 : if lu1 > lu2 : res . append ( col2 ) else : res . append ( col1 ) else : if lu1 > lu2 : res . append ( col1 ) else : res . append ( col2 ) if isinstance ( testcolors , str ): return res [ 0 ] return res merge_dict ( orig , new ) Recursively merge new dict into orig. Source code in ccg\\util.py 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 def merge_dict ( orig : dict | list , new : dict | list ) -> None : \"\"\"Recursively merge new dict into orig.\"\"\" if isinstance ( orig , dict ): for key in new . keys (): if ( key in orig and isinstance ( orig [ key ], ( dict , list )) and isinstance ( new [ key ], ( dict , list )) ): merge_dict ( orig [ key ], new [ key ]) elif key in orig and isinstance ( orig [ key ], np . ndarray ): if orig [ key ] . dtype is np . floating : if not np . array_equal ( orig [ key ], new [ key ], equal_nan = True ): orig [ key ] = new [ key ] else : if not np . array_equal ( orig [ key ], new [ key ]): orig [ key ] = new [ key ] # elif key in orig and type(orig[key]) != type( # new[key] # ): # 11-14-23 - for array replacing single val elif key in orig and not isinstance ( orig [ key ], type ( new [ key ])): orig [ key ] = new [ key ] elif key in orig and orig [ key ] == new [ key ]: pass else : orig [ key ] = new [ key ] elif isinstance ( orig , list ): # Here to better merge plot dicts. List should end up len of new list. # Safest to simply replace any lists with the new list, # but to try to maintain links, shorten to new len, then check equality if len ( new ) < len ( orig ): del orig [ len ( new ) :] if len ( new ) > len ( orig ): orig . extend ( new [ len ( orig ) :]) if orig and isinstance ( orig [ 0 ], dict ): for i , _ in enumerate ( orig ): merge_dict ( orig [ i ], new [ i ]) elif orig == new : pass else : orig [:] = new [:] monotonic_increasing ( value ) check if value is monotonic increasing Source code in ccg\\util.py 206 207 208 209 210 def monotonic_increasing ( value : np . ndarray ): \"\"\"check if value is monotonic increasing\"\"\" if len ( value ) == 0 : return True return np . all (( value [ 1 :] - value [: - 1 ]) > 0 ) np_time_2_seconds ( time ) Convert np.datetime64 or np.timedelta64 to floating seconds. Source code in ccg\\util.py 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 def np_time_2_seconds ( time : npt . NDArray ): \"\"\"Convert np.datetime64 or np.timedelta64 to floating seconds.\"\"\" if time . dtype . kind != \"m\" : raise ValueError ( f \"Convert to time not supported for { time . dtype } \" ) regex = re . compile ( r \"(?<=\\[).{1,2}(?=\\])\" ) unit = regex . findall ( str ( time . dtype ))[ - 1 ] if unit == \"us\" : return time . astype ( \"float\" ) / 1e6 if unit == \"ms\" : return time . astype ( \"float\" ) / 1e3 if unit == \"s\" : return time . astype ( \"float\" ) if unit == \"m\" : return time . astype ( \"float\" ) * 60 if unit == \"h\" : return time . astype ( \"float\" ) * 60 * 60 raise NotImplementedError ( f \"Conv not implemented for { time . dtype } \" ) profile ( func ) Dummy for profile decorators. Source code in ccg\\util.py 50 51 52 def profile ( func ): \"\"\"Dummy for profile decorators.\"\"\" return func recursive_get ( data , fields ) Gets fields from dictionary from multiple depths. Source code in ccg\\util.py 570 571 572 573 def recursive_get ( data : dict , fields : tuple ): \"\"\"Gets fields from dictionary from multiple depths.\"\"\" field , * subfields = fields return recursive_get ( data [ field ], subfields ) if subfields else data [ field ] rel_path ( filename , rel_to = None ) Return string of relative path if possible, else return absolute path. Source code in ccg\\util.py 390 391 392 393 394 395 396 397 398 399 def rel_path ( filename : Path | str , rel_to : Path | str = None ) -> str : \"\"\"Return string of relative path if possible, else return absolute path.\"\"\" if rel_to is None : rel_to = Path . cwd () elif isinstance ( rel_to , str ): rel_to = Path ( rel_to ) . absolute () . resolve () path = Path ( filename ) . absolute () . resolve () if path . is_relative_to ( rel_to ): return str ( path . relative_to ( rel_to )) return str ( path ) rgb2val ( color ) Return r, g, b values. Source code in ccg\\util.py 263 264 265 266 267 def rgb2val ( color : str ): \"\"\"Return r, g, b values.\"\"\" regex = r \"\\d{1,3}\" matches = re . findall ( regex , color ) return tuple ( int ( x ) for x in matches ) run_at ( tstart , coro , loop , coro_args = None , repeat_every = None ) async Run coroutine at tstart. Source code in ccg\\util.py 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 async def run_at ( tstart : datetime , coro : Coroutine , loop : asyncio . AbstractEventLoop , coro_args : dict | None = None , repeat_every : timedelta | None = None , ): \"\"\"Run coroutine at tstart.\"\"\" if tstart . tzinfo is None : # assume its local tstart = tstart . astimezone () if repeat_every : # If there is a repeat, ensure that the tstart is after now. while datetime . now () . astimezone () > tstart : tstart = tstart + repeat_every else : if tstart <= datetime . now () . astimezone (): raise ValueError ( f \" { coro . __name__ } scheduled in the past.\" ) await wait_until ( tstart ) # TODO: fix the error of calling a coroutine, need to check usage of this function if coro_args is None : tmp = await coro () else : tmp = await coro ( ** coro_args ) if repeat_every : loop . create_task ( run_at ( tstart = tstart + repeat_every , coro = coro , loop = loop , repeat_every = repeat_every , coro_args = coro_args , ) ) _LOGGER . debug ( \" %s sched for: %s \" , coro . __name__ , tstart + repeat_every ) return tmp s2lin ( col ) Linear from sRGB. Source code in ccg\\util.py 223 224 225 226 227 228 229 230 def s2lin ( col ): \"\"\"Linear from sRGB.\"\"\" col = col / 255.0 if col <= 0.03928 : col = col / 12.92 else : col = (( col + 0.055 ) / 1.055 ) ** 2.4 return col shift_lightness ( hexstr , factor ) Shift lightness of color. Source code in ccg\\util.py 242 243 244 245 246 247 248 249 def shift_lightness ( hexstr : str , factor ): \"\"\"Shift lightness of color.\"\"\" red , grn , blu = hex_to_rgb ( hexstr ) hue , lig , sat = colorsys . rgb_to_hls ( s2lin ( red ), s2lin ( grn ), s2lin ( blu )) lnew = min ( max ( lig * factor , 0 ), 1 ) red , grn , blu = colorsys . hls_to_rgb ( hue , lnew , sat ) hexstr = f \"# { lin2s ( red ) : 02x }{ lin2s ( grn ) : 02x }{ lin2s ( blu ) : 02x } \" return hexstr table_colors ( data , colorscale = 'Turbo' , colorscale_center = None , light_font = '#e5e5e5' , dark_font = '#434343' ) Calculate colors for data table. Returns (colors, font_colors). Source code in ccg\\util.py 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 def table_colors ( data : npt . NDArray , colorscale = \"Turbo\" , colorscale_center = None , light_font = \"#e5e5e5\" , dark_font = \"#434343\" , ): \"\"\"Calculate colors for data table. Returns (colors, font_colors).\"\"\" scale = pc . get_colorscale ( colorscale ) if not isinstance ( data , np . ndarray ): data = np . atleast_1d ( np . array ( data )) if colorscale_center is not None : data_range = centered_range ( data , colorscale_center ) else : data_range = np . nanpercentile ( data , [ 2 , 98 ]) . tolist () # If the range is zero, adjust it slightly to avoid division by zero if data_range [ 1 ] - data_range [ 0 ] == 0 : data_range [ 0 ] -= 0.5 data_range [ 1 ] += 0.5 pts = ( data - data_range [ 0 ]) / ( data_range [ 1 ] - data_range [ 0 ]) pts = np . clip ( pts , 0 , 1 ) if np . any ( np . isnan ( pts )): print ( pts ) colors = pc . sample_colorscale ( scale , pts . flatten () . tolist ()) font_colors = max_contrast ( colors , light_font , dark_font ) colors = np . array ( colors ) . reshape ( data . shape ) font_colors = np . array ( font_colors ) . reshape ( data . shape ) return colors , font_colors unix_to_iso ( unix ) convert unix timestamp to iso formatted string. In local TZ but naive. Source code in ccg\\util.py 402 403 404 405 406 407 408 409 410 def unix_to_iso ( unix : npt . NDArray [ np . floating ] | float ) -> npt . NDArray [ np . datetime64 ]: \"\"\"convert unix timestamp to iso formatted string. In local TZ but naive.\"\"\" if isinstance ( unix , float ): unix = np . array ( unix ) rtn : npt . NDArray [ np . datetime64 ] = ( unix * 1e3 ) . astype ( \"datetime64[ms]\" ) # UTC tz = datetime . now () . astimezone () . tzinfo # Local TZ off = tz . utcoffset ( datetime . now ()) . total_seconds () rtn += np . timedelta64 ( int ( off * 1e3 ), \"ms\" ) return rtn wait_until ( tstart ) async Wait until tstart. Source code in ccg\\util.py 554 555 556 async def wait_until ( tstart : datetime ): \"\"\"Wait until tstart.\"\"\" await asyncio . sleep (( tstart - datetime . now () . astimezone ()) . total_seconds ())","title":"util"},{"location":"reference/ccg/util/#ccg.util.InterpMethod","text":"Bases: str , Enum Interp methods enum. Source code in ccg\\util.py 55 56 57 58 59 60 61 62 63 64 65 class InterpMethod ( str , Enum ): \"\"\"Interp methods enum.\"\"\" LINEAR = \"lin\" ZOH = \"zoh\" NEAREST = \"near\" @classmethod def _missing_ ( cls , value ): \"\"\"return default\"\"\" return cls . LINEAR","title":"InterpMethod"},{"location":"reference/ccg/util/#ccg.util.array_to_list","text":"Recursively converts arrays in dict to lists. Source code in ccg\\util.py 585 586 587 588 589 590 591 592 593 594 595 596 def array_to_list ( data : Iterable ): \"\"\"Recursively converts arrays in dict to lists.\"\"\" if isinstance ( data , dict ): for key , val in data . items (): if isinstance ( val , dict ) or isinstance ( val , list ): data [ key ] = array_to_list ( val ) elif isinstance ( val , np . ndarray ): data [ key ] = val . tolist () elif isinstance ( data , list ): for item in data : item = array_to_list ( item ) return data","title":"array_to_list"},{"location":"reference/ccg/util/#ccg.util.byte2str","text":"Converts bytes to string and drops trailing zeros Source code in ccg\\util.py 576 577 578 579 580 581 582 def byte2str ( bytes_data : bytes ) -> str | bytes : \"\"\"Converts bytes to string and drops trailing zeros\"\"\" try : return bytes_data . decode ( \"ascii\" ) . strip () . rstrip ( \" \\0 \" ) . strip () except UnicodeDecodeError as err : _LOGGER . warning ( \"Exception decoding %s . Error: %s \" , bytes_data , err ) return bytes_data","title":"byte2str"},{"location":"reference/ccg/util/#ccg.util.calculate_colors","text":"Calculate colors for data table. Source code in ccg\\util.py 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 def calculate_colors ( data : npt . NDArray , colorscale = \"Turbo\" , colorscale_center = None ) -> list : \"\"\"Calculate colors for data table.\"\"\" tic = datetime . now () scale = pc . get_colorscale ( colorscale ) if not isinstance ( data , np . ndarray ): data = np . atleast_1d ( np . array ( data )) if colorscale_center is not None : data_range = centered_range ( data , colorscale_center ) else : data_range = np . nanpercentile ( data , [ 2 , 98 ]) . tolist () # If the range is zero, adjust it slightly to avoid division by zero if data_range [ 1 ] - data_range [ 0 ] == 0 : data_range [ 0 ] -= 0.5 data_range [ 1 ] += 0.5 pts = ( data - data_range [ 0 ]) / ( data_range [ 1 ] - data_range [ 0 ]) pts = np . clip ( pts , 0 , 1 ) if np . any ( np . isnan ( pts )): print ( pts ) colors = pc . sample_colorscale ( scale , pts . flatten () . tolist ()) # colors = np.array(colors).reshape(data.shape) toc = datetime . now () - tic _LOGGER . debug ( \"Color calc: %.3f \" , toc . total_seconds ()) return np . array ( colors ) . reshape ( data . shape ) . tolist ()","title":"calculate_colors"},{"location":"reference/ccg/util/#ccg.util.calculate_font_colors","text":"Calculate font colors for data table. Source code in ccg\\util.py 366 367 368 369 370 371 372 373 374 375 def calculate_font_colors ( colors : list , light_font = \"#e5e5e5\" , dark_font = \"#434343\" ) -> npt . NDArray : \"\"\"Calculate font colors for data table.\"\"\" tic = datetime . now () font_colors = max_contrast ( colors , light_font , dark_font ) # font_colors = np.array(font_colors).reshape(colors.shape) toc = datetime . now () - tic _LOGGER . debug ( \"Font color calc: %.3f \" , toc . total_seconds ()) return font_colors","title":"calculate_font_colors"},{"location":"reference/ccg/util/#ccg.util.centered_range","text":"Return centered range from 2 to 98th percentile Source code in ccg\\util.py 378 379 380 381 382 383 384 385 386 387 def centered_range ( data : list | npt . NDArray , centerpoint : float ): \"\"\"Return centered range from 2 to 98th percentile\"\"\" delta = np . array ( data ) - centerpoint data_range = np . max ( np . abs ( np . nanpercentile ( delta , [ 2 , 98 ]))) data_range = 0.5 if data_range == 0 else data_range data_range = [ centerpoint - data_range , centerpoint + data_range , ] return data_range","title":"centered_range"},{"location":"reference/ccg/util/#ccg.util.clean_name","text":"Clean name for frame or sig name. Source code in ccg\\util.py 559 560 561 562 563 564 565 566 567 def clean_name ( name : str ): \"\"\"Clean name for frame or sig name.\"\"\" return ( name . replace ( \" - \" , \"_\" ) . replace ( \" \" , \"_\" ) . replace ( \"-\" , \"_\" ) . replace ( \".\" , \"_\" ) . lower () )","title":"clean_name"},{"location":"reference/ccg/util/#ccg.util.clean_time_str","text":"Clean strings for datetime.strptime Source code in ccg\\util.py 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 @profile def clean_time_str ( in_str : str | list [ str ] | npt . NDArray , date = datetime . now () . date () . isoformat () ): \"\"\"Clean strings for datetime.strptime\"\"\" regex = re . compile ( r \"^(?P<hr>\\d{1,2})*?:?(?P<min>\\d{1,2})*?:?(?P<sec>\\d{1,2})*?(?P<ms>\\.\\d{1,6})?$\" ) if isinstance ( in_str , str ): res = regex . match ( in_str ) if res is None : raise ValueError ( f \"Unable to parse { in_str } to ISO time\" ) out_str = f ' { date } T { ( res [ \"hr\" ] or \"\" ) . zfill ( 2 ) } : { ( res [ \"min\" ] or \"\" ) . zfill ( 2 ) } : { ( res [ \"sec\" ] or \"\" ) . zfill ( 2 ) }{ res [ \"ms\" ] or \"\" } ' else : out_str = in_str . copy () for i , tmp_str in enumerate ( in_str ): res = regex . match ( tmp_str ) if res is None : raise ValueError ( f \"Unable to parse { tmp_str } to ISO time\" ) out_str [ i ] = ( f ' { date } T { ( res [ \"hr\" ] or \"\" ) . zfill ( 2 ) } : { ( res [ \"min\" ] or \"\" ) . zfill ( 2 ) } : { ( res [ \"sec\" ] or \"\" ) . zfill ( 2 ) }{ res [ \"ms\" ] or \"\" } ' ) return out_str","title":"clean_time_str"},{"location":"reference/ccg/util/#ccg.util.convert_units","text":"Unit converter Source code in ccg\\util.py 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 def convert_units ( value : npt . NDArray | list , from_unit : str , to_unit : str ): \"\"\"Unit converter\"\"\" if ( from_unit == to_unit or from_unit == \"\" or to_unit == \"\" or from_unit is None or to_unit is None ): res = value else : from_gain , from_offset , from_quant = find_unit ( from_unit ) to_gain , to_offset , to_quant = find_unit ( to_unit ) if from_quant != to_quant : raise ValueError ( f \" { to_quant } not compatible with { from_quant } in unit conversion.\" ) islist = False if isinstance ( value , list ): value = np . array ( value ) islist = True res = (( value + from_offset ) * from_gain ) / to_gain - to_offset if isinstance ( res , np . ndarray ): res = res . astype ( value . dtype ) if islist : res = res . tolist () return res","title":"convert_units"},{"location":"reference/ccg/util/#ccg.util.datetime_to_unix","text":"convert datetime64 to unix timestamp. In local TZ but naive. Source code in ccg\\util.py 413 414 415 416 417 418 419 def datetime_to_unix ( array : npt . NDArray [ np . datetime64 ]) -> npt . NDArray [ np . floating ]: \"\"\"convert datetime64 to unix timestamp. In local TZ but naive.\"\"\" rtn = array . astype ( \"datetime64[us]\" ) . astype ( \"float\" ) / 1e6 # UTC tz = datetime . now () . astimezone () . tzinfo # Local TZ off = tz . utcoffset ( datetime . now ()) . total_seconds () rtn -= off return rtn","title":"datetime_to_unix"},{"location":"reference/ccg/util/#ccg.util.find_unit","text":"Find unit conversion coef's Parameters: unit ( str | None ) \u2013 Returns: tuple [ float , float , str ] \u2013 Returns Gain, Offset, and Quantity Raises: NotImplementedError \u2013 If unit not in conversion definitions Source code in ccg\\util.py 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 def find_unit ( unit : str | None ) -> tuple [ float , float , str ]: \"\"\"Find unit conversion coef's Parameters ---------- unit : str | None Returns ------- tuple[float, float, str] Returns Gain, Offset, and Quantity Raises ------ NotImplementedError If unit not in conversion definitions \"\"\" for quant , values in UNIT_CONV . items (): if str ( unit ) . lower () in values : return ( * values [ str ( unit ) . lower ()], quant ) assert unit is not None if \"/s\" in unit : # Check for derivative sig, for quant , values in UNIT_CONV . items (): test_unit = str ( unit ) . lower () . replace ( \"/s\" , \"\" ) if test_unit in values : return ( * values [ test_unit ], quant + \"_rate\" ) raise NotImplementedError ( f \" { unit } not found in UNIT_CONV\" )","title":"find_unit"},{"location":"reference/ccg/util/#ccg.util.getsize","text":"Recursively iterate to sum size of object & members. Source code in ccg\\util.py 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 def getsize ( obj_0 ): \"\"\"Recursively iterate to sum size of object & members.\"\"\" # From https://stackoverflow.com/users/541136/aaron-hall 's answer here: # https://stackoverflow.com/questions/449560/how-do-i-determine-the-size-of-an-object-in-python _seen_ids = set () def inner ( obj ): obj_id = id ( obj ) if obj_id in _seen_ids : return 0 _seen_ids . add ( obj_id ) size = sys . getsizeof ( obj ) if isinstance ( obj , ZERO_DEPTH_BASES ): pass # bypass remaining control flow and return elif isinstance ( obj , ( tuple , list , Set , deque )): size += sum ( inner ( i ) for i in obj ) elif isinstance ( obj , Mapping ): size += sum ( inner ( k ) + inner ( v ) for k , v in obj . items ()) # Check for custom object instances - may subclass above too if hasattr ( obj , \"__dict__\" ): size += inner ( vars ( obj )) if hasattr ( obj , \"__slots__\" ): # can have __slots__ with __dict__ size += sum ( inner ( getattr ( obj , s )) for s in obj . __slots__ if hasattr ( obj , s ) ) return size return inner ( obj_0 )","title":"getsize"},{"location":"reference/ccg/util/#ccg.util.hex_to_rgb","text":"Return rgb. Source code in ccg\\util.py 213 214 215 216 217 218 219 220 def hex_to_rgb ( hexstr : str ): \"\"\"Return rgb.\"\"\" match = re . search ( r \"#\\w {6} \" , hexstr ) if match : hexstr = match . group () return int ( hexstr [ 1 : 3 ], 16 ), int ( hexstr [ 3 : 5 ], 16 ), int ( hexstr [ 5 : 7 ], 16 ) else : return None","title":"hex_to_rgb"},{"location":"reference/ccg/util/#ccg.util.is_pandas","text":"Check if pandas dataframe, avoiding importing the module. Source code in ccg\\util.py 730 731 732 733 734 def is_pandas ( value ): \"\"\"Check if pandas dataframe, avoiding importing the module.\"\"\" df_cls = getattr ( sys . modules . get ( \"pandas\" ), \"DataFrame\" , None ) return df_cls is not None and isinstance ( value , df_cls )","title":"is_pandas"},{"location":"reference/ccg/util/#ccg.util.iscompat","text":"Return True if data types are compatible Parameters: dtype1 ( DTypeLike ) \u2013 dtype2 ( DTypeLike ) \u2013 Returns: bool \u2013 Source code in ccg\\util.py 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 def iscompat ( dtype1 : npt . DTypeLike , dtype2 : npt . DTypeLike ) -> bool : \"\"\"Return True if data types are compatible Parameters ---------- dtype1 : npt.DTypeLike dtype2 : npt.DTypeLike Returns ------- bool \"\"\" for types in COMPAT_TYPES : if dtype1 . kind in types : if dtype2 . kind in types : return True return False","title":"iscompat"},{"location":"reference/ccg/util/#ccg.util.lin2s","text":"Linear to sRGB. Source code in ccg\\util.py 233 234 235 236 237 238 239 def lin2s ( col ): \"Linear to sRGB.\" col1 = col ** ( 1 / 2.4 ) * 1.055 - 0.055 col2 = col * 12.92 if col2 <= 0.03928 : return int ( col2 * 255 ) return int ( col1 * 255 )","title":"lin2s"},{"location":"reference/ccg/util/#ccg.util.linearinterp","text":"Nd Linear interpolation Parameters: bps ( list [ NDArray ] ) \u2013 List of arrays of breakpoints data ( NDArray ) \u2013 Data points ( NDArray ) \u2013 New breakpoints to interpolate to extrapolate ( bool , default: False ) \u2013 by default False Returns: NDArray [ floating ] \u2013 Source code in ccg\\util.py 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 @profile def linearinterp ( bps : list [ npt . NDArray ], data : npt . NDArray , points : npt . NDArray , extrapolate : bool = False , ) -> npt . NDArray [ np . floating ]: \"\"\"Nd Linear interpolation Parameters ---------- bps : list[npt.NDArray] List of arrays of breakpoints data : npt.NDArray Data points : npt.NDArray New breakpoints to interpolate to extrapolate : bool, optional by default False Returns ------- npt.NDArray[np.floating] \"\"\" # Make sure BPs is a list if not isinstance ( bps , list ): bps = [ bps ] # Make sure data and points are useful # if data.ndim == 1: # data = data[:, None] if points . ndim == 1 : points = points [:, None ] # Check that data matches bps shape nd = len ( bps ) nint : int = 2 ** nd npts = points . shape [ 0 ] bmatch = True for i , bp in enumerate ( bps ): bmatch = bmatch and len ( bp ) == data . shape [ i ] if not bmatch : raise TypeError ( \"Shape of data doesnt match bps.\" ) # check that pts is right size if nd > 1 : tst = points . shape [ 1 ] == nd if not tst : raise TypeError ( \"Points should be npts x nd\" ) ind0 : list [ npt . NDArray ] = [] intf = np . zeros (( npts , nd )) adders = np . zeros (( nint , nd ), dtype = np . int_ ) for i in range ( nd ): ind0 . append ( np . digitize ( points [:, i ], bps [ i ], right = False ) - 1 ) # So annoying # Saturate ind0 [ i ] = np . clip ( ind0 [ i ], 0 , len ( bps [ i ]) - 2 ) diff = bps [ i ][ ind0 [ i ] + 1 ] - bps [ i ][ ind0 [ i ]] intf [:, i ] = ( points [:, i ] - bps [ i ][ ind0 [ i ]]) / diff # adder adder = np . tile ( np . concatenate ( ( np . tile ( 0 , int ( 2 ** i )), np . tile ( 1 , int ( 2 ** i )), ) ), int ( nint / ( 2 ** ( i + 1 ))), ) adders [:, i ] = adder if not extrapolate : intf : npt . NDArray [ np . float64 ] = np . clip ( intf , 0.0 , 1.0 ) new = np . zeros (( npts ,)) for i in range ( nint ): adder = adders [ i ] fint = np . prod (( intf * adder ) + (( 1 - intf ) * ( 1 - adder )), 1 ) ind = tuple ( x + y for x , y in zip ( ind0 , adder )) new += data [ ind ] * fint return new","title":"linearinterp"},{"location":"reference/ccg/util/#ccg.util.lum","text":"Luminance. Source code in ccg\\util.py 253 254 255 256 257 258 259 260 def lum ( color : str ): \"\"\"Luminance.\"\"\" if color . startswith ( \"#\" ): red , grn , blu = hex_to_rgb ( color ) elif color . startswith ( \"rgb\" ): red , grn , blu = rgb2val ( color ) return 0.2126 * s2lin ( red ) + 0.7152 * s2lin ( grn ) + 0.0722 * s2lin ( blu )","title":"lum"},{"location":"reference/ccg/util/#ccg.util.max_contrast","text":"Choose col1 or col2 to maximize contrast with testcolor. Source code in ccg\\util.py 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 def max_contrast ( testcolors : list [ str ] | str , col1 : str , col2 : str ): \"\"\"Choose col1 or col2 to maximize contrast with testcolor.\"\"\" lu1 = lum ( col1 ) lu2 = lum ( col2 ) if isinstance ( testcolors , str ): tmp = [ testcolors ] else : tmp = testcolors res = [] for testcolor in tmp : test = lum ( testcolor ) if test > (( lu1 + 0.05 ) * ( lu2 + 0.05 )) ** 0.5 - 0.05 : if lu1 > lu2 : res . append ( col2 ) else : res . append ( col1 ) else : if lu1 > lu2 : res . append ( col1 ) else : res . append ( col2 ) if isinstance ( testcolors , str ): return res [ 0 ] return res","title":"max_contrast"},{"location":"reference/ccg/util/#ccg.util.merge_dict","text":"Recursively merge new dict into orig. Source code in ccg\\util.py 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 def merge_dict ( orig : dict | list , new : dict | list ) -> None : \"\"\"Recursively merge new dict into orig.\"\"\" if isinstance ( orig , dict ): for key in new . keys (): if ( key in orig and isinstance ( orig [ key ], ( dict , list )) and isinstance ( new [ key ], ( dict , list )) ): merge_dict ( orig [ key ], new [ key ]) elif key in orig and isinstance ( orig [ key ], np . ndarray ): if orig [ key ] . dtype is np . floating : if not np . array_equal ( orig [ key ], new [ key ], equal_nan = True ): orig [ key ] = new [ key ] else : if not np . array_equal ( orig [ key ], new [ key ]): orig [ key ] = new [ key ] # elif key in orig and type(orig[key]) != type( # new[key] # ): # 11-14-23 - for array replacing single val elif key in orig and not isinstance ( orig [ key ], type ( new [ key ])): orig [ key ] = new [ key ] elif key in orig and orig [ key ] == new [ key ]: pass else : orig [ key ] = new [ key ] elif isinstance ( orig , list ): # Here to better merge plot dicts. List should end up len of new list. # Safest to simply replace any lists with the new list, # but to try to maintain links, shorten to new len, then check equality if len ( new ) < len ( orig ): del orig [ len ( new ) :] if len ( new ) > len ( orig ): orig . extend ( new [ len ( orig ) :]) if orig and isinstance ( orig [ 0 ], dict ): for i , _ in enumerate ( orig ): merge_dict ( orig [ i ], new [ i ]) elif orig == new : pass else : orig [:] = new [:]","title":"merge_dict"},{"location":"reference/ccg/util/#ccg.util.monotonic_increasing","text":"check if value is monotonic increasing Source code in ccg\\util.py 206 207 208 209 210 def monotonic_increasing ( value : np . ndarray ): \"\"\"check if value is monotonic increasing\"\"\" if len ( value ) == 0 : return True return np . all (( value [ 1 :] - value [: - 1 ]) > 0 )","title":"monotonic_increasing"},{"location":"reference/ccg/util/#ccg.util.np_time_2_seconds","text":"Convert np.datetime64 or np.timedelta64 to floating seconds. Source code in ccg\\util.py 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 def np_time_2_seconds ( time : npt . NDArray ): \"\"\"Convert np.datetime64 or np.timedelta64 to floating seconds.\"\"\" if time . dtype . kind != \"m\" : raise ValueError ( f \"Convert to time not supported for { time . dtype } \" ) regex = re . compile ( r \"(?<=\\[).{1,2}(?=\\])\" ) unit = regex . findall ( str ( time . dtype ))[ - 1 ] if unit == \"us\" : return time . astype ( \"float\" ) / 1e6 if unit == \"ms\" : return time . astype ( \"float\" ) / 1e3 if unit == \"s\" : return time . astype ( \"float\" ) if unit == \"m\" : return time . astype ( \"float\" ) * 60 if unit == \"h\" : return time . astype ( \"float\" ) * 60 * 60 raise NotImplementedError ( f \"Conv not implemented for { time . dtype } \" )","title":"np_time_2_seconds"},{"location":"reference/ccg/util/#ccg.util.profile","text":"Dummy for profile decorators. Source code in ccg\\util.py 50 51 52 def profile ( func ): \"\"\"Dummy for profile decorators.\"\"\" return func","title":"profile"},{"location":"reference/ccg/util/#ccg.util.recursive_get","text":"Gets fields from dictionary from multiple depths. Source code in ccg\\util.py 570 571 572 573 def recursive_get ( data : dict , fields : tuple ): \"\"\"Gets fields from dictionary from multiple depths.\"\"\" field , * subfields = fields return recursive_get ( data [ field ], subfields ) if subfields else data [ field ]","title":"recursive_get"},{"location":"reference/ccg/util/#ccg.util.rel_path","text":"Return string of relative path if possible, else return absolute path. Source code in ccg\\util.py 390 391 392 393 394 395 396 397 398 399 def rel_path ( filename : Path | str , rel_to : Path | str = None ) -> str : \"\"\"Return string of relative path if possible, else return absolute path.\"\"\" if rel_to is None : rel_to = Path . cwd () elif isinstance ( rel_to , str ): rel_to = Path ( rel_to ) . absolute () . resolve () path = Path ( filename ) . absolute () . resolve () if path . is_relative_to ( rel_to ): return str ( path . relative_to ( rel_to )) return str ( path )","title":"rel_path"},{"location":"reference/ccg/util/#ccg.util.rgb2val","text":"Return r, g, b values. Source code in ccg\\util.py 263 264 265 266 267 def rgb2val ( color : str ): \"\"\"Return r, g, b values.\"\"\" regex = r \"\\d{1,3}\" matches = re . findall ( regex , color ) return tuple ( int ( x ) for x in matches )","title":"rgb2val"},{"location":"reference/ccg/util/#ccg.util.run_at","text":"Run coroutine at tstart. Source code in ccg\\util.py 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 async def run_at ( tstart : datetime , coro : Coroutine , loop : asyncio . AbstractEventLoop , coro_args : dict | None = None , repeat_every : timedelta | None = None , ): \"\"\"Run coroutine at tstart.\"\"\" if tstart . tzinfo is None : # assume its local tstart = tstart . astimezone () if repeat_every : # If there is a repeat, ensure that the tstart is after now. while datetime . now () . astimezone () > tstart : tstart = tstart + repeat_every else : if tstart <= datetime . now () . astimezone (): raise ValueError ( f \" { coro . __name__ } scheduled in the past.\" ) await wait_until ( tstart ) # TODO: fix the error of calling a coroutine, need to check usage of this function if coro_args is None : tmp = await coro () else : tmp = await coro ( ** coro_args ) if repeat_every : loop . create_task ( run_at ( tstart = tstart + repeat_every , coro = coro , loop = loop , repeat_every = repeat_every , coro_args = coro_args , ) ) _LOGGER . debug ( \" %s sched for: %s \" , coro . __name__ , tstart + repeat_every ) return tmp","title":"run_at"},{"location":"reference/ccg/util/#ccg.util.s2lin","text":"Linear from sRGB. Source code in ccg\\util.py 223 224 225 226 227 228 229 230 def s2lin ( col ): \"\"\"Linear from sRGB.\"\"\" col = col / 255.0 if col <= 0.03928 : col = col / 12.92 else : col = (( col + 0.055 ) / 1.055 ) ** 2.4 return col","title":"s2lin"},{"location":"reference/ccg/util/#ccg.util.shift_lightness","text":"Shift lightness of color. Source code in ccg\\util.py 242 243 244 245 246 247 248 249 def shift_lightness ( hexstr : str , factor ): \"\"\"Shift lightness of color.\"\"\" red , grn , blu = hex_to_rgb ( hexstr ) hue , lig , sat = colorsys . rgb_to_hls ( s2lin ( red ), s2lin ( grn ), s2lin ( blu )) lnew = min ( max ( lig * factor , 0 ), 1 ) red , grn , blu = colorsys . hls_to_rgb ( hue , lnew , sat ) hexstr = f \"# { lin2s ( red ) : 02x }{ lin2s ( grn ) : 02x }{ lin2s ( blu ) : 02x } \" return hexstr","title":"shift_lightness"},{"location":"reference/ccg/util/#ccg.util.table_colors","text":"Calculate colors for data table. Returns (colors, font_colors). Source code in ccg\\util.py 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 def table_colors ( data : npt . NDArray , colorscale = \"Turbo\" , colorscale_center = None , light_font = \"#e5e5e5\" , dark_font = \"#434343\" , ): \"\"\"Calculate colors for data table. Returns (colors, font_colors).\"\"\" scale = pc . get_colorscale ( colorscale ) if not isinstance ( data , np . ndarray ): data = np . atleast_1d ( np . array ( data )) if colorscale_center is not None : data_range = centered_range ( data , colorscale_center ) else : data_range = np . nanpercentile ( data , [ 2 , 98 ]) . tolist () # If the range is zero, adjust it slightly to avoid division by zero if data_range [ 1 ] - data_range [ 0 ] == 0 : data_range [ 0 ] -= 0.5 data_range [ 1 ] += 0.5 pts = ( data - data_range [ 0 ]) / ( data_range [ 1 ] - data_range [ 0 ]) pts = np . clip ( pts , 0 , 1 ) if np . any ( np . isnan ( pts )): print ( pts ) colors = pc . sample_colorscale ( scale , pts . flatten () . tolist ()) font_colors = max_contrast ( colors , light_font , dark_font ) colors = np . array ( colors ) . reshape ( data . shape ) font_colors = np . array ( font_colors ) . reshape ( data . shape ) return colors , font_colors","title":"table_colors"},{"location":"reference/ccg/util/#ccg.util.unix_to_iso","text":"convert unix timestamp to iso formatted string. In local TZ but naive. Source code in ccg\\util.py 402 403 404 405 406 407 408 409 410 def unix_to_iso ( unix : npt . NDArray [ np . floating ] | float ) -> npt . NDArray [ np . datetime64 ]: \"\"\"convert unix timestamp to iso formatted string. In local TZ but naive.\"\"\" if isinstance ( unix , float ): unix = np . array ( unix ) rtn : npt . NDArray [ np . datetime64 ] = ( unix * 1e3 ) . astype ( \"datetime64[ms]\" ) # UTC tz = datetime . now () . astimezone () . tzinfo # Local TZ off = tz . utcoffset ( datetime . now ()) . total_seconds () rtn += np . timedelta64 ( int ( off * 1e3 ), \"ms\" ) return rtn","title":"unix_to_iso"},{"location":"reference/ccg/util/#ccg.util.wait_until","text":"Wait until tstart. Source code in ccg\\util.py 554 555 556 async def wait_until ( tstart : datetime ): \"\"\"Wait until tstart.\"\"\" await asyncio . sleep (( tstart - datetime . now () . astimezone ()) . total_seconds ())","title":"wait_until"},{"location":"reference/ccg/controllers/","text":"","title":"controllers"},{"location":"reference/ccg/controllers/aem/","text":"AEM Data Parsing chan_names ( file , strt_loc ) Read chan names section Source code in ccg\\controllers\\aem.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 def chan_names ( file : BufferedReader , strt_loc : int , ): \"\"\"Read chan names section\"\"\" # initial seems to be L-LE sig_names = [] frmt = \"<4sIIB\" names = [ \"header\" , \"Num1\" , \"Num2\" , \"next_len\" ] data_dict = seg_reader ( file , strt_loc = strt_loc , unpk_format = frmt , format_names = names , ) strt_loc += struct . calcsize ( frmt ) while data_dict [ \"next_len\" ]: frmt = f \"< { data_dict [ 'next_len' ] } sB\" strt_next = strt_loc + data_dict [ \"next_len\" ] + 1 data_dict = seg_reader ( file , strt_loc = strt_loc , unpk_format = frmt , format_names = [ \"signame\" , \"next_len\" ], data = data_dict , ) sig_names . append ( data_dict [ \"signame\" ]) strt_loc = strt_next return ( sig_names , strt_loc ) read_cal ( filename ) Read .itssn file Source code in ccg\\controllers\\aem.py 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 @profile def read_cal ( filename : str ) -> Tbls : \"\"\"Read .itssn file\"\"\" fname = Path ( filename ) frmt = \"<4sI16sI\" names = [ \"head\" , \"headnum\" , \"term\" , \"next_len\" , ] with open ( fname , \"rb\" ) as file : data = seg_reader ( file , frmt , names ) while data [ \"term\" ] != \"NRTX\" : names = [ \"data\" , \"term\" , \"next_len\" , ] frmt = f '< { data [ \"next_len\" ] } s4sI' data = seg_reader ( file , frmt , names ) frmt = \"BBBBIffIffHHHHIHHIHHIHHI\" names = [ \"num1\" , \"num2\" , \"num3\" , \"num4\" , \"cur_len\" , \"cur_val\" , \"cur_val2\" , \"n5\" , \"min\" , \"max\" , \"par_type\" , \"par_id\" , \"n10\" , \"str_len\" , \"addr1\" , \"n11\" , \"n12\" , \"addr2\" , \"n13\" , \"n14\" , \"addr3\" , \"n15\" , \"n16\" , \"addr4\" , ] flds = struct . unpack ( frmt , data [ \"data\" ][: struct . calcsize ( frmt )]) for name , fld in zip ( names , flds ): data [ name ] = fld assert data [ \"n10\" ] == 1 assert data [ \"num4\" ] in { 3 , 23 , 24 , 41 } assert data [ \"n11\" ] == 2 assert data [ \"n13\" ] == 4 assert data [ \"n12\" ] == data [ \"n14\" ] addr1 = data [ \"addr1\" ] - 1160000 + 12 name = ccg . util . byte2str ( data [ \"data\" ][ addr1 : addr1 + data [ \"str_len\" ]]) addr2 = data [ \"addr2\" ] - 1160000 + 12 addr3 = data [ \"addr3\" ] - 1160000 + 12 if addr2 : frmt = f '< { data [ \"n12\" ] } H' if addr3 : frmt = frmt + f ' { data [ \"n14\" ] } I' tmp = struct . unpack ( frmt , data [ \"data\" ][ addr2 : addr2 + struct . calcsize ( frmt )] ) else : tmp = None t = 1 print ( tmp ) print ( t ) return data read_data ( filenames ) Read and parse .ld file. Source code in ccg\\controllers\\aem.py 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 @profile def read_data ( filenames : str | tuple [ str ] | list [ str ]) -> Frame : \"\"\"Read and parse .ld file.\"\"\" if not isinstance ( filenames , list ) and not isinstance ( filenames , tuple ): filenames = ( filenames ,) tstart = 0 name = \"\" for i , filename in enumerate ( filenames ): if i > 0 : name = name + \", \" + Path ( filename ) . name else : name = Path ( filename ) . name data = Frame ( name = name ) regex = re . compile ( r \"(?P<name>^.*)( \\[(?P<unit>.*)\\])( (?P<name2>.*))?|(?P<name1>^.*)\" ) for filename in filenames : fname = Path ( filename ) with open ( fname , \"rb\" ) as file : chans , next_loc = chan_names ( file , 0 ) chans . pop ( - 1 ) # waste the last one that was '' signames = [] units = [] for signame in chans : match = regex . match ( signame ) if match [ \"unit\" ]: unit = match [ \"unit\" ] if match [ \"name2\" ]: name = match [ \"name\" ] + \"_\" + match [ \"name2\" ] else : name = match [ \"name\" ] else : unit = None name = match [ \"name1\" ] if name in signames : name = name + \"_\" + ( unit or \"dup\" ) signames . append ( name ) units . append ( unit ) sig_reader ( file , sig_names = signames , units = units , start_loc = next_loc - 1 , tstart = tstart , data = data , ) tstart = round ( data . tend / 10 + 1 ) * 10 return data seg_reader ( file , unpk_format , format_names , strt_loc = None , data = None ) Read segment from binary file. Source code in ccg\\controllers\\aem.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 @profile def seg_reader ( file : BufferedReader , unpk_format : str , format_names : list [ str ], strt_loc : int = None , data : dict [ str , list ] = None , ) -> Sig : \"\"\"Read segment from binary file.\"\"\" if data is None : data = dict () if strt_loc is not None : file . seek ( strt_loc ) for name , field in zip ( format_names , struct . unpack ( unpk_format , file . read ( struct . calcsize ( unpk_format ))), ): if not name . startswith ( \"__\" ): if isinstance ( field , bytes ): field = ccg . util . byte2str ( field ) data [ name ] = field return data sig_reader ( file , start_loc , sig_names , units = None , data = None , tstart = 0 ) read signal data Source code in ccg\\controllers\\aem.py 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 @profile def sig_reader ( file : BufferedReader , start_loc : int , sig_names : list [ str ], units : list [ str ] = None , data : Frame = None , tstart : float = 0 , ): \"\"\"read signal data\"\"\" nchan = len ( sig_names ) if data is None : data = Frame () if start_loc is not None : file . seek ( start_loc ) else : start_loc = file . tell () float_data = np . fromfile ( file , dtype = np . dtype ( \"<f\" ), count =- 1 ) file . seek ( start_loc ) u32_data = np . fromfile ( file , dtype = np . dtype ( \"<u4\" ), count =- 1 ) time_unit = units [ 0 ] or \"us/10\" # assumes tlow first time_conv = { \"us/10\" : 1e7 , \"us\" : 1e6 , \"ms\" : 1e3 }[ time_unit ] tlow = u32_data [ 0 :: nchan ] thi = u32_data [ 1 :: nchan ] time = (( thi << 32 ) + tlow ) / time_conv + tstart tline = TLine ( time ) for i , ( signame , unit ) in enumerate ( zip ( sig_names , units )): sig = Sig ( data = float_data [ i :: nchan ], name = signame , unit = unit , tline = tline ) data . append ( sig , append_existing_signals = True ) return data","title":"aem"},{"location":"reference/ccg/controllers/aem/#ccg.controllers.aem.chan_names","text":"Read chan names section Source code in ccg\\controllers\\aem.py 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 def chan_names ( file : BufferedReader , strt_loc : int , ): \"\"\"Read chan names section\"\"\" # initial seems to be L-LE sig_names = [] frmt = \"<4sIIB\" names = [ \"header\" , \"Num1\" , \"Num2\" , \"next_len\" ] data_dict = seg_reader ( file , strt_loc = strt_loc , unpk_format = frmt , format_names = names , ) strt_loc += struct . calcsize ( frmt ) while data_dict [ \"next_len\" ]: frmt = f \"< { data_dict [ 'next_len' ] } sB\" strt_next = strt_loc + data_dict [ \"next_len\" ] + 1 data_dict = seg_reader ( file , strt_loc = strt_loc , unpk_format = frmt , format_names = [ \"signame\" , \"next_len\" ], data = data_dict , ) sig_names . append ( data_dict [ \"signame\" ]) strt_loc = strt_next return ( sig_names , strt_loc )","title":"chan_names"},{"location":"reference/ccg/controllers/aem/#ccg.controllers.aem.read_cal","text":"Read .itssn file Source code in ccg\\controllers\\aem.py 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 @profile def read_cal ( filename : str ) -> Tbls : \"\"\"Read .itssn file\"\"\" fname = Path ( filename ) frmt = \"<4sI16sI\" names = [ \"head\" , \"headnum\" , \"term\" , \"next_len\" , ] with open ( fname , \"rb\" ) as file : data = seg_reader ( file , frmt , names ) while data [ \"term\" ] != \"NRTX\" : names = [ \"data\" , \"term\" , \"next_len\" , ] frmt = f '< { data [ \"next_len\" ] } s4sI' data = seg_reader ( file , frmt , names ) frmt = \"BBBBIffIffHHHHIHHIHHIHHI\" names = [ \"num1\" , \"num2\" , \"num3\" , \"num4\" , \"cur_len\" , \"cur_val\" , \"cur_val2\" , \"n5\" , \"min\" , \"max\" , \"par_type\" , \"par_id\" , \"n10\" , \"str_len\" , \"addr1\" , \"n11\" , \"n12\" , \"addr2\" , \"n13\" , \"n14\" , \"addr3\" , \"n15\" , \"n16\" , \"addr4\" , ] flds = struct . unpack ( frmt , data [ \"data\" ][: struct . calcsize ( frmt )]) for name , fld in zip ( names , flds ): data [ name ] = fld assert data [ \"n10\" ] == 1 assert data [ \"num4\" ] in { 3 , 23 , 24 , 41 } assert data [ \"n11\" ] == 2 assert data [ \"n13\" ] == 4 assert data [ \"n12\" ] == data [ \"n14\" ] addr1 = data [ \"addr1\" ] - 1160000 + 12 name = ccg . util . byte2str ( data [ \"data\" ][ addr1 : addr1 + data [ \"str_len\" ]]) addr2 = data [ \"addr2\" ] - 1160000 + 12 addr3 = data [ \"addr3\" ] - 1160000 + 12 if addr2 : frmt = f '< { data [ \"n12\" ] } H' if addr3 : frmt = frmt + f ' { data [ \"n14\" ] } I' tmp = struct . unpack ( frmt , data [ \"data\" ][ addr2 : addr2 + struct . calcsize ( frmt )] ) else : tmp = None t = 1 print ( tmp ) print ( t ) return data","title":"read_cal"},{"location":"reference/ccg/controllers/aem/#ccg.controllers.aem.read_data","text":"Read and parse .ld file. Source code in ccg\\controllers\\aem.py 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 @profile def read_data ( filenames : str | tuple [ str ] | list [ str ]) -> Frame : \"\"\"Read and parse .ld file.\"\"\" if not isinstance ( filenames , list ) and not isinstance ( filenames , tuple ): filenames = ( filenames ,) tstart = 0 name = \"\" for i , filename in enumerate ( filenames ): if i > 0 : name = name + \", \" + Path ( filename ) . name else : name = Path ( filename ) . name data = Frame ( name = name ) regex = re . compile ( r \"(?P<name>^.*)( \\[(?P<unit>.*)\\])( (?P<name2>.*))?|(?P<name1>^.*)\" ) for filename in filenames : fname = Path ( filename ) with open ( fname , \"rb\" ) as file : chans , next_loc = chan_names ( file , 0 ) chans . pop ( - 1 ) # waste the last one that was '' signames = [] units = [] for signame in chans : match = regex . match ( signame ) if match [ \"unit\" ]: unit = match [ \"unit\" ] if match [ \"name2\" ]: name = match [ \"name\" ] + \"_\" + match [ \"name2\" ] else : name = match [ \"name\" ] else : unit = None name = match [ \"name1\" ] if name in signames : name = name + \"_\" + ( unit or \"dup\" ) signames . append ( name ) units . append ( unit ) sig_reader ( file , sig_names = signames , units = units , start_loc = next_loc - 1 , tstart = tstart , data = data , ) tstart = round ( data . tend / 10 + 1 ) * 10 return data","title":"read_data"},{"location":"reference/ccg/controllers/aem/#ccg.controllers.aem.seg_reader","text":"Read segment from binary file. Source code in ccg\\controllers\\aem.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 @profile def seg_reader ( file : BufferedReader , unpk_format : str , format_names : list [ str ], strt_loc : int = None , data : dict [ str , list ] = None , ) -> Sig : \"\"\"Read segment from binary file.\"\"\" if data is None : data = dict () if strt_loc is not None : file . seek ( strt_loc ) for name , field in zip ( format_names , struct . unpack ( unpk_format , file . read ( struct . calcsize ( unpk_format ))), ): if not name . startswith ( \"__\" ): if isinstance ( field , bytes ): field = ccg . util . byte2str ( field ) data [ name ] = field return data","title":"seg_reader"},{"location":"reference/ccg/controllers/aem/#ccg.controllers.aem.sig_reader","text":"read signal data Source code in ccg\\controllers\\aem.py 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 @profile def sig_reader ( file : BufferedReader , start_loc : int , sig_names : list [ str ], units : list [ str ] = None , data : Frame = None , tstart : float = 0 , ): \"\"\"read signal data\"\"\" nchan = len ( sig_names ) if data is None : data = Frame () if start_loc is not None : file . seek ( start_loc ) else : start_loc = file . tell () float_data = np . fromfile ( file , dtype = np . dtype ( \"<f\" ), count =- 1 ) file . seek ( start_loc ) u32_data = np . fromfile ( file , dtype = np . dtype ( \"<u4\" ), count =- 1 ) time_unit = units [ 0 ] or \"us/10\" # assumes tlow first time_conv = { \"us/10\" : 1e7 , \"us\" : 1e6 , \"ms\" : 1e3 }[ time_unit ] tlow = u32_data [ 0 :: nchan ] thi = u32_data [ 1 :: nchan ] time = (( thi << 32 ) + tlow ) / time_conv + tstart tline = TLine ( time ) for i , ( signame , unit ) in enumerate ( zip ( sig_names , units )): sig = Sig ( data = float_data [ i :: nchan ], name = signame , unit = unit , tline = tline ) data . append ( sig , append_existing_signals = True ) return data","title":"sig_reader"},{"location":"reference/ccg/controllers/link/","text":"Functions and classes for working with Link ECU's. FirmwareModel Bases: ABC Base class for M1 firmware model. Source code in ccg\\controllers\\link.py 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 class FirmwareModel ( ABC ): \"\"\"Base class for M1 firmware model.\"\"\" reference_tables = {} fueling_tables = { \"Engine.Efficiency.Value\" : { \"unit\" : \"%\" , \"prec\" : 1 , \"range\" : [ 10 , 200 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine.Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 1 , }, \"Y\" : { \"sig\" : \"Throttle.Position\" , \"unit\" : \"%\" , \"range\" : [ 0 , 100 ], \"prec\" : 1 , }, \"Z\" : { \"sig\" : \"Inlet.Manifold.Pressure\" , \"unit\" : \"kPa\" , \"range\" : [ 0 , np . inf ], \"prec\" : 1 , }, }, } } fueling_params = { \"Engine.Cylinders\" : 8 } def __init__ ( self , caldir : str | Path | None = None , data : str | Path | Frame | None = None , gate : GateColl | str | Path | None = None , warning_dialog : Callable | None = None , ): self . table_data = None self . read_cal ( caldir ) self . tabs = ccg . ui . panel . CalDataTabs ( self . table_data ) self . _needs_calcs = True self . _needs_scatter_update = True self . _data = None self . warning_dialog = warning_dialog if data is None : self . data = None elif isinstance ( data , Frame ): self . data = data else : self . read_data ( data ) if gate is None : self . gate = None elif isinstance ( gate , GateColl ): self . gate = gate else : self . read_gate ( gate ) self . bank_gates = [] self . resampled = None self . slow_sig : str @property def slow_freq ( self ): \"\"\"return freq of slow signal.\"\"\" return round ( 1 / self . data [ self . slow_sig ] . period ) @property @abstractmethod def n_cyl ( self ) -> int : \"\"\"Returns num of cyls\"\"\" @property @abstractmethod def n_banks ( self ) -> int : \"\"\"Returns n_banks\"\"\" @property def data ( self ): \"\"\"data\"\"\" return self . _data @data . setter def data ( self , value : Frame ): \"\"\"data setter\"\"\" self . _needs_calcs = True self . _needs_scatter_update = True self . _needs_bank_warning = True self . _data = value def read_gate ( self , filename : str | Path ): \"\"\"Read Gate File\"\"\" self . gate = GateCollAND () . from_file ( filename ) self . _needs_calcs = True self . _needs_scatter_update = True self . _needs_bank_warning = True async def read_gate_async ( self , filename : str | Path ): return await asyncio . to_thread ( self . read_gate , filename ) def read_data ( self , filename : str | Path ): \"\"\"Read data file\"\"\" self . data = read_data ( filename ) # self._needs_calcs set in data.setter def read_cal ( self , dirname : str | Path | None ): \"\"\"Read the calibration data into table_data.\"\"\" if dirname is not None : self . table_data = read_cals ( dirname ) self . convert_tables () self . _needs_calcs = True self . _needs_scatter_update = True self . _needs_bank_warning = True async def read_cal_async ( self , dirname : str | Path ): \"\"\"Async cal read Parameters ---------- dirname : str | Path Dir of cal files \"\"\" if dirname is not None : self . table_data = await read_cals_async ( dirname ) self . convert_tables () self . _needs_calcs = True self . _needs_scatter_update = True self . _needs_bank_warning = True self . tabs . update_tabs ( self . table_data ) # TODO: warning for no dirname? @property def fueling_names ( self ): \"\"\"return names of fueling tables\"\"\" param_names = [] for param in self . fueling_tables : if \"#\" in param : param_names . extend ( param . replace ( \"#\" , str ( i + 1 )) for i in range ( self . n_cyl ) ) else : param_names . append ( param ) return param_names @property def param_names ( self ): \"\"\"Return the names of the parameters\"\"\" param_names = self . fueling_names for param in self . fueling_params : if \"#\" in param : param_names . extend ( param . replace ( \"#\" , str ( i + 1 )) for i in range ( self . n_cyl ) ) else : param_names . append ( param ) for param in self . reference_tables : if \"#\" in param : param_names . extend ( param . replace ( \"#\" , str ( i + 1 )) for i in range ( self . n_cyl ) ) else : param_names . append ( param ) return param_names def convert_tables ( self ): \"\"\"Convert tables using configurations in self.fueling_tables.\"\"\" if self . table_data : for name , config in dict ( self . fueling_tables , ** self . reference_tables ) . items (): if \"#\" in name : names = [ name . replace ( \"#\" , str ( i )) for i in range ( 1 , self . n_cyl + 1 ) ] else : names = [ name ] for name in names : self . table_data [ name ] . convert_units ( config [ \"unit\" ]) self . table_data [ name ] . precision = config [ \"prec\" ] self . table_data [ name ] . data_range = config [ \"range\" ] if \"axes\" in config : for axes , ax_cfg in config [ \"axes\" ] . items (): if axes in self . table_data [ name ] . axes : self . table_data [ name ] . axes [ axes ] . convert_units ( ax_cfg [ \"unit\" ] ) self . table_data [ name ] . axes [ axes ] . precision = ax_cfg [ \"prec\" ] self . table_data [ name ] . axes [ axes ] . data_range = ax_cfg [ \"range\" ] self . table_data [ name ] . axes [ axes ] . name = ax_cfg [ \"sig\" ] # to avoid ctrl-z back to old units self . table_data [ name ] . _archive [ \"prev\" ] = [] self . table_data [ name ] . snapshot ( \"orig\" ) def write_cal ( self , dirname : Path , pars_to_write : list [ str ]): write_cals ( dirname , self . table_data , pars_to_write ) @abstractmethod def update_calcd_data ( self ): \"\"\"Update calcs for fitting/plotting.\"\"\" @abstractmethod def update_scatter_data ( self ): \"\"\"Update scatter data for fitting/plotting.\"\"\" data property writable data fueling_names property return names of fueling tables n_banks : int abstractmethod property Returns n_banks n_cyl : int abstractmethod property Returns num of cyls param_names property Return the names of the parameters slow_freq property return freq of slow signal. convert_tables () Convert tables using configurations in self.fueling_tables. Source code in ccg\\controllers\\link.py 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 def convert_tables ( self ): \"\"\"Convert tables using configurations in self.fueling_tables.\"\"\" if self . table_data : for name , config in dict ( self . fueling_tables , ** self . reference_tables ) . items (): if \"#\" in name : names = [ name . replace ( \"#\" , str ( i )) for i in range ( 1 , self . n_cyl + 1 ) ] else : names = [ name ] for name in names : self . table_data [ name ] . convert_units ( config [ \"unit\" ]) self . table_data [ name ] . precision = config [ \"prec\" ] self . table_data [ name ] . data_range = config [ \"range\" ] if \"axes\" in config : for axes , ax_cfg in config [ \"axes\" ] . items (): if axes in self . table_data [ name ] . axes : self . table_data [ name ] . axes [ axes ] . convert_units ( ax_cfg [ \"unit\" ] ) self . table_data [ name ] . axes [ axes ] . precision = ax_cfg [ \"prec\" ] self . table_data [ name ] . axes [ axes ] . data_range = ax_cfg [ \"range\" ] self . table_data [ name ] . axes [ axes ] . name = ax_cfg [ \"sig\" ] # to avoid ctrl-z back to old units self . table_data [ name ] . _archive [ \"prev\" ] = [] self . table_data [ name ] . snapshot ( \"orig\" ) read_cal ( dirname ) Read the calibration data into table_data. Source code in ccg\\controllers\\link.py 412 413 414 415 416 417 418 419 def read_cal ( self , dirname : str | Path | None ): \"\"\"Read the calibration data into table_data.\"\"\" if dirname is not None : self . table_data = read_cals ( dirname ) self . convert_tables () self . _needs_calcs = True self . _needs_scatter_update = True self . _needs_bank_warning = True read_cal_async ( dirname ) async Async cal read Parameters: dirname ( str | Path ) \u2013 Dir of cal files Source code in ccg\\controllers\\link.py 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 async def read_cal_async ( self , dirname : str | Path ): \"\"\"Async cal read Parameters ---------- dirname : str | Path Dir of cal files \"\"\" if dirname is not None : self . table_data = await read_cals_async ( dirname ) self . convert_tables () self . _needs_calcs = True self . _needs_scatter_update = True self . _needs_bank_warning = True self . tabs . update_tabs ( self . table_data ) read_data ( filename ) Read data file Source code in ccg\\controllers\\link.py 407 408 409 def read_data ( self , filename : str | Path ): \"\"\"Read data file\"\"\" self . data = read_data ( filename ) read_gate ( filename ) Read Gate File Source code in ccg\\controllers\\link.py 397 398 399 400 401 402 def read_gate ( self , filename : str | Path ): \"\"\"Read Gate File\"\"\" self . gate = GateCollAND () . from_file ( filename ) self . _needs_calcs = True self . _needs_scatter_update = True self . _needs_bank_warning = True update_calcd_data () abstractmethod Update calcs for fitting/plotting. Source code in ccg\\controllers\\link.py 509 510 511 @abstractmethod def update_calcd_data ( self ): \"\"\"Update calcs for fitting/plotting.\"\"\" update_scatter_data () abstractmethod Update scatter data for fitting/plotting. Source code in ccg\\controllers\\link.py 513 514 515 @abstractmethod def update_scatter_data ( self ): \"\"\"Update scatter data for fitting/plotting.\"\"\" G4xXtreme Bases: FirmwareModel Firmware model for LINK G4X Source code in ccg\\controllers\\link.py 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 class G4xXtreme ( FirmwareModel ): \"\"\"Firmware model for LINK G4X\"\"\" reference_tables = { # \"Fuel.Mixture Aim.Main\": { # \"unit\": \"LA\", # \"prec\": 2, # \"range\": [0.01, 5], # \"axes\": { # \"X\": { # \"sig\": \"Engine.Speed\", # \"unit\": \"rpm\", # \"range\": [0, 30000], # \"prec\": 1, # }, # \"Y\": { # \"sig\": \"Inlet.Manifold.Pressure\", # \"unit\": \"mbar\", # \"range\": [np.NINF, np.inf], # \"prec\": 1, # }, # \"Z\": { # \"sig\": \"Driver.Fuel.Mixture Aim Main Switch\", # \"unit\": \"\", # \"range\": [\"A\", \"B\"], # \"prec\": 0, # }, # }, # }, # \"Fuel.Timing.Secondary.Main\": { # \"unit\": \"dBTDC\", # \"prec\": 1, # \"range\": [0, 1440], # \"axes\": { # \"X\": { # \"sig\": \"Engine.Speed\", # \"unit\": \"rpm\", # \"range\": [0, 30000], # \"prec\": 1, # }, # \"Y\": { # \"sig\": \"Inlet.Manifold.Pressure\", # \"unit\": \"mbar\", # \"range\": [0, np.inf], # \"prec\": 1, # }, # }, # }, } fueling_tables = { \"Fuel Table 1\" : { \"unit\" : \"%\" , \"prec\" : 1 , \"range\" : [ 10 , 200 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"MAP\" , \"unit\" : \"kPa\" , \"range\" : [ 0 , np . inf ], \"prec\" : 0 , }, }, }, \"Wastegate %DC 1\" : { \"unit\" : \"%\" , \"prec\" : 1 , \"range\" : [ 0 , 100 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"GP Pressure 2 - Pboost\" , \"unit\" : \"kPa\" , \"range\" : [ 0 , np . inf ], \"prec\" : 0 , }, }, }, \"Wastegate %DC 2\" : { \"unit\" : \"%\" , \"prec\" : 1 , \"range\" : [ 0 , 100 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"GP Pressure 2 - Pboost\" , \"unit\" : \"kPa\" , \"range\" : [ 0 , np . inf ], \"prec\" : 0 , }, }, }, \"Wastegate %DC 3\" : { \"unit\" : \"%\" , \"prec\" : 1 , \"range\" : [ 0 , 100 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"GP Pressure 2 - Pboost\" , \"unit\" : \"kPa\" , \"range\" : [ 0 , np . inf ], \"prec\" : 0 , }, }, }, \"Boost Target 1\" : { \"unit\" : \"kPa\" , \"prec\" : 1 , \"range\" : [ 100 , 160 ], # Cheat for green shirt \"axes\" : { \"X\" : { \"sig\" : \"Engine Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"APS (Main)\" , \"unit\" : \"%\" , \"range\" : [ 0 , np . inf ], \"prec\" : 0 , }, }, }, \"Boost Target 2\" : { \"unit\" : \"kPa\" , \"prec\" : 1 , \"range\" : [ 100 , 300 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"APS (Main)\" , \"unit\" : \"%\" , \"range\" : [ 0 , np . inf ], \"prec\" : 0 , }, }, }, \"Boost Target 3\" : { \"unit\" : \"kPa\" , \"prec\" : 1 , \"range\" : [ 100 , 300 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"APS (Main)\" , \"unit\" : \"%\" , \"range\" : [ 0 , np . inf ], \"prec\" : 0 , }, }, }, \"AFR_Lambda Target\" : { \"unit\" : \"\" , \"prec\" : 3 , \"range\" : [ 0.6 , 2 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"MAP\" , \"unit\" : \"kPa\" , \"range\" : [ 0 , np . inf ], \"prec\" : 0 , }, }, }, \"E-Throttle 1 Target\" : { \"unit\" : \"%\" , \"prec\" : 1 , \"range\" : [ 0 , 100 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"APS (Main)\" , \"unit\" : \"%\" , \"range\" : [ 0 , 100 ], \"prec\" : 0 , }, }, }, \"IAT Fuel Trim\" : { \"unit\" : \"%trim\" , \"prec\" : 2 , \"range\" : [ - 30.0 , 30.0 ], \"axes\" : { \"X\" : { \"sig\" : \"IAT\" , \"unit\" : \"\u00b0C\" , \"range\" : [ 0 , 150 ], \"prec\" : 1 , }, }, }, \"Warm Up Enrichment\" : { \"unit\" : \"%trim\" , \"prec\" : 2 , \"range\" : [ - 30.0 , 30.0 ], \"axes\" : { \"X\" : { \"sig\" : \"ECT\" , \"unit\" : \"\u00b0C\" , \"range\" : [ - 50 , 200 ], \"prec\" : 1 , }, }, }, \"Turbo Speed\" : { \"unit\" : \"krpm\" , \"prec\" : 0 , \"range\" : [ 0 , 200 ], \"axes\" : { \"X\" : { \"sig\" : \"maf_cor\" , \"unit\" : \"g/s\" , \"range\" : [ 0 , 500 ], \"prec\" : 1 , }, \"Y\" : { \"sig\" : \"pr_comp\" , \"unit\" : \"ratio\" , \"range\" : [ 0 , 3 ], \"prec\" : 2 , }, }, }, \"pr_comp\" : { \"unit\" : \"\" , \"prec\" : 3 , \"range\" : [ 0.0 , 4.0 ], \"axes\" : { \"X\" : { \"sig\" : \"maf_cor\" , \"unit\" : \"g/s\" , \"range\" : [ 0 , 500.0 ], \"prec\" : 1 , }, \"Y\" : { \"sig\" : \"Turbo Speed\" , \"unit\" : \"krpm\" , \"range\" : [ 0 , 300.0 ], \"prec\" : 1 , }, }, }, \"Throttle PR\" : { \"unit\" : \"%\" , \"prec\" : 1 , \"range\" : [ 0 , 100 ], \"axes\" : { \"X\" : { \"sig\" : \"maf_cor\" , \"unit\" : \"g/s\" , \"range\" : [ 0 , 500 ], \"prec\" : 1 , }, \"Y\" : { \"sig\" : \"pr_throttle\" , \"unit\" : \"ratio\" , \"range\" : [ 0 , 1 ], \"prec\" : 2 , }, }, }, \"maf_nom\" : { \"unit\" : \"g/s\" , \"prec\" : 1 , \"range\" : [ 0 , 500 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 10000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"APS (Main)\" , \"unit\" : \"%\" , \"range\" : [ 0 , 100 ], \"prec\" : 1 , }, }, }, \"map_nom\" : { \"unit\" : \"kPa\" , \"prec\" : 1 , \"range\" : [ 0 , 300 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 10000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"maf_nom\" , \"unit\" : \"g/s\" , \"range\" : [ 0 , 500 ], \"prec\" : 1 , }, }, }, \"map_target_1\" : { \"unit\" : \"kPa\" , \"prec\" : 1 , \"range\" : [ 0 , 300 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 10000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"APS (Main)\" , \"unit\" : \"%\" , \"range\" : [ 0 , 100 ], \"prec\" : 1 , }, }, }, \"map_target_2\" : { \"unit\" : \"kPa\" , \"prec\" : 1 , \"range\" : [ 0 , 300 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 10000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"APS (Main)\" , \"unit\" : \"%\" , \"range\" : [ 0 , 100 ], \"prec\" : 1 , }, }, }, \"map_target_3\" : { \"unit\" : \"kPa\" , \"prec\" : 1 , \"range\" : [ 0 , 300 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 10000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"APS (Main)\" , \"unit\" : \"%\" , \"range\" : [ 0 , 100 ], \"prec\" : 1 , }, }, }, \"map_target_scaler\" : { \"unit\" : \"ratio\" , \"prec\" : 2 , \"range\" : [ 0 , 3 ], \"axes\" : { \"X\" : { \"sig\" : \"Active Boost Table\" , \"unit\" : \"\" , \"range\" : [ 1 , 3 ], \"prec\" : 0 , }, }, }, \"nturbo_target_scaler\" : { \"unit\" : \"ratio\" , \"prec\" : 2 , \"range\" : [ 0 , 3 ], \"axes\" : { \"X\" : { \"sig\" : \"APS (Main)\" , \"unit\" : \"%\" , \"range\" : [ 0 , 100 ], \"prec\" : 1 , }, }, }, \"pamb_ref\" : { \"unit\" : \"kPa\" , \"prec\" : 1 , \"range\" : [ 50 , 150 ], \"axes\" : {}, }, \"nturbo_max\" : { \"unit\" : \"krpm\" , \"prec\" : 1 , \"range\" : [ 0 , 300 ], \"axes\" : {}, }, } fueling_params = { # \"Fuel.Efficiency.Mode\": { # 0: \"Manifold Air Density\", # 1: \"Ambient Air Density\", # 2: \"Airbox Air Density\", # }, # \"Inlet.Manifold.Pressure.Mode\": { # 0: \"Automatic\", # 1: \"Estimate\", # 2: \"Sensor\", # }, # \"Engine.Rotors\": 2, # \"Engine.Rotor #.Bank\": 1, # \"Engine.Load.Normalised.Mode\": { # 0: \"Normal\", # 1: \"Inlet Manifold Pressure\", # 2: \"Throttle Position\", # }, # \"Inlet.Manifold.Pressure.Estimate.Mode\": { # 0: \"Ambient Pressure Relative\", # 1: \"100kPa Relative\", # }, } # TODO: complete calcd_sigs = [ \"Fueling.Error.Total\" , \"Fuel Table 1.Corrected\" , \"Wastegate %DC 1.Corrected\" , \"Wastegate %DC 2.Corrected\" , \"Wastegate %DC 3.Corrected\" , \"Boost Target 2.Corrected\" , \"Boost Target 2.Corrected\" , \"Boost Target 3.Corrected\" , \"Throttle PR.Corrected\" , \"Turbo Speed.Corrected\" , \"IAT Fuel Trim.Corrected\" , \"maf\" , \"rho_air\" , \"pr_comp\" , \"pr_throttle\" , \"maf_cor\" , \"fmaf_cor\" , \"maf\" , \"maf_est_cor\" , ] def __init__ ( self , caldir : str | Path = None , data : str | Path | Frame = None , gate : GateColl | str | Path = None , warning_dialog : Callable = None , ): super () . __init__ ( caldir = caldir , data = data , gate = gate , warning_dialog = warning_dialog , ) self . slow_sig = \"Engine Speed\" @property def n_cyl ( self ): return 4 @property def n_banks ( self ): return 1 @property def displacement ( self ): return 2.457 # @profile def check_substitute_sigs ( self ): \"\"\"Try to substitute for some common missing sigs.\"\"\" # Set units for pamb self . data [ \"CAN An 2\" ] . unit = \"mbar\" tmp = self . data [ \"CAN An 2\" ] . as_unit ( \"kPa\" ) tmp . name = \"pamb\" self . data . append ( tmp ) # Fix units that are mislabeled if self . data [ \"IAT Fuel Corr.\" ] . unit == \"%\" : self . data [ \"IAT Fuel Corr.\" ] . unit = \"%trim\" if self . data [ \"Post Start Enrich\" ] . unit == \"%\" : self . data [ \"Post Start Enrich\" ] . unit = \"%trim\" if self . data [ \"Warm Up Enrichment\" ] . unit == \"%\" : self . data [ \"Warm Up Enrichment\" ] . unit = \"%trim\" self . data [ \"IAT Fuel Corr.\" ] . convert_units ( \"ratio\" ) self . data [ \"Post Start Enrich\" ] . convert_units ( \"ratio\" ) self . data [ \"Warm Up Enrichment\" ] . convert_units ( \"ratio\" ) # @profile def check_sigs ( self ): \"\"\"Check that required input sigs are present.\"\"\" if self . table_data and self . data : self . check_substitute_sigs () required_sigs = set ( [ \"Lambda 1\" , \"Fuel Table 1\" , \"AFR/Lambda Target\" , \"CL Lambda Fuel Corr.\" , \"CL Lambda LT corr.\" , \"TPS (Main)\" , \"MAP\" , \"Engine Speed\" , \"IAT\" , \"Boost Target\" , \"GP Pressure 2 - Pboost\" , \"Boost Base DC\" , \"WGate DC\" , \"pamb\" , \"Turbo Speed\" , \"TPS (Main)\" , \"CAN An 2\" , \"GP Temperature 1 - Ambient Temp\" , \"Mass Air Flow Estimated\" , \"Load (Abs)\" , \"IAT Fuel Corr.\" , \"Post Start Enrich\" , \"Warm Up Enrichment\" , ] ) for table in self . fueling_tables : for axis in self . table_data [ table . replace ( \"#\" , \"1\" )] . axes : if axis . name not in self . calcd_sigs : required_sigs . add ( axis . name ) for table in self . reference_tables : for axis in self . table_data [ table . replace ( \"#\" , \"1\" )] . axes : if axis . name not in self . calcd_sigs : required_sigs . add ( axis . name ) for sig in self . gate . sigs : if sig not in self . calcd_sigs : required_sigs . add ( sig ) ok_slow = [] required_sigs = list ( required_sigs ) for sig in required_sigs : if sig not in ok_slow : self . slow_sig = sig break for sig in required_sigs : if ( sig not in ok_slow and self . data [ sig ] . period > self . data [ self . slow_sig ] . period ): self . slow_sig = sig missing = [] for sig in required_sigs : if sig not in self . data : missing . append ( sig ) if missing : raise ValueError ( f \"Missing required signals: { missing } \" ) # Build slower timeline for r-worded Link data slow_tline = TLine ( tstart = self . data . tstart , tend = self . data . tend , period = 0.04 ) self . resampled = self . data [ required_sigs ] . resample ( slow_tline ) self . data . math_tline = self . data [ self . slow_sig ] . tline self . resampled . math_tline = slow_tline self . resampled . name = \"resampled\" return True else : return False # @profile def update_calcd_data ( self , _ = None ): \"\"\"Update calculations for fitting/plotting.\"\"\" if self . _needs_calcs : tic = datetime . now () if self . check_sigs (): tmp = ( self . resampled [ \"IAT Fuel Corr.\" ] * self . resampled [ \"Post Start Enrich\" ] * self . resampled [ \"Warm Up Enrichment\" ] ) tmp . name = \"Fueling.Corr.logged\" self . resampled . append ( tmp ) tmp = self . table_data [ \"IAT Fuel Trim\" ] . interp ( self . resampled ) tmp . name = \"IAT Fuel Corr new\" self . resampled . append ( tmp . convert_units ( \"ratio\" )) tmp = self . table_data [ \"Warm Up Enrichment\" ] . interp ( self . resampled ) tmp . name = \"ECT Fuel Corr new\" self . resampled . append ( tmp . convert_units ( \"ratio\" )) tmp = self . table_data [ \"Fuel Table 1\" ] . interp ( self . resampled ) tmp . name = \"Fuel Table 1.new\" self . resampled . append ( tmp ) tmp = ( self . resampled [ \"IAT Fuel Corr new\" ] * self . resampled [ \"Post Start Enrich\" ] # Shortcut assumes const * self . resampled [ \"ECT Fuel Corr new\" ] ) tmp . name = \"Fueling.Corr.new\" self . resampled . append ( tmp ) tmp = ( ( self . resampled [ \"CL Lambda Fuel Corr.\" ] . convert_units ( \"ratio\" ) + 1 ) * ( self . resampled [ \"CL Lambda LT corr.\" ] . convert_units ( \"ratio\" ) + 1 ) * self . resampled [ \"Lambda 1\" ] / self . resampled [ \"AFR/Lambda Target\" ] ) tmp . name = \"Fueling.Error.Total\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ \"Fueling.Error.Total\" ] * self . resampled [ \"Fuel Table 1\" ] / self . resampled [ \"Fueling.Corr.new\" ] * self . resampled [ \"Fueling.Corr.logged\" ] ) tmp . name = \"Fuel Table 1.Corrected\" tmp . unit = \"%\" self . resampled . append ( tmp ) tmp = ( self . resampled [ \"Fueling.Error.Total\" ] * self . resampled [ \"Fuel Table 1\" ] / self . resampled [ \"Fuel Table 1.new\" ] * self . resampled [ \"Warm Up Enrichment\" ] / self . resampled [ \"ECT Fuel Corr.new\" ] * self . resampled [ \"IAT Fuel Corr.\" ] ) tmp . name = \"IAT Fuel Trim.Corrected\" self . resampled . append ( tmp . convert_units ( \"%trim\" )) tmp = ( self . resampled [ \"Fueling.Error.Total\" ] * self . resampled [ \"Fuel Table 1\" ] / self . resampled [ \"Fuel Table 1.new\" ] * self . resampled [ \"IAT Fuel Corr.\" ] / self . resampled [ \"IAT Fuel Corr.new\" ] * self . resampled [ \"Warm Up Enrichment\" ] ) tmp . name = \"Warm Up Enrichment.Corrected\" self . resampled . append ( tmp . convert_units ( \"%trim\" )) # WGC pboost_d = ( self . resampled [ \"GP Pressure 2 - Pboost\" ] - self . resampled [ \"Boost Target\" ] ) inds = abs ( pboost_d . data ) < 10 tmp = self . resampled [ \"Boost Base DC\" ] . data tmp [ inds ] = self . resampled [ \"WGate DC\" ][ inds ] tmpsig = Sig ( self . resampled [ \"Boost Base DC\" ]) tmpsig . name = \"Wastegate %DC 1.Corrected\" self . resampled . append ( tmpsig ) tmpsig = Sig ( self . resampled [ \"Boost Base DC\" ]) tmpsig . name = \"Wastegate %DC 2.Corrected\" self . resampled . append ( tmpsig ) tmpsig = Sig ( self . resampled [ \"Boost Base DC\" ]) tmpsig . name = \"Wastegate %DC 3.Corrected\" self . resampled . append ( tmpsig ) if self . table_data : self . resampled . append ( self . resampled [ \"Engine Speed\" ] . dot ( n_win = 9 )) self . resampled . remove ( \"MAP_dot\" ) self . resampled . append ( self . resampled [ \"MAP\" ] . dot ( n_win = 13 )) # Calcs for boost target tmpsig = Sig ( data = self . resampled [ \"Lambda 1\" ], name = \"AFR_Lambda Target.Corrected\" , ) self . resampled . append ( tmpsig ) tmpsig = ( self . resampled [ \"GP Pressure 2 - Pboost\" ] / self . resampled [ \"pamb\" ] ) tmpsig . name = \"pr_comp.Corrected\" self . resampled . append ( tmpsig ) tmpsig = Sig ( tmpsig , name = \"pr_comp\" ) self . resampled . append ( tmpsig ) tmpsig = Sig ( data = np . sqrt ( self . resampled [ \"GP Temperature 1 - Ambient Temp\" ] . as_unit ( \"k\" ) / 288 ) * self . resampled [ \"pamb\" ] / 101.3 , unit = \"ratio\" , name = \"fmaf_cor\" , tline = self . resampled [ \"pamb\" ] . tline , ) self . resampled . append ( tmpsig ) tmpsig = ( self . resampled [ \"Load (Abs)\" ] . as_unit ( \"ratio\" ) * ( self . resampled [ \"CL Lambda Fuel Corr.\" ] . as_unit ( \"ratio\" ) + 1 ) * ( self . resampled [ \"CL Lambda LT corr.\" ] . as_unit ( \"ratio\" ) + 1 ) * self . resampled [ \"Engine Speed\" ] / ( 60 * 2 ) * 1.188 # Density of dry air * self . displacement # Displacememt * 1.0 # Fudge factor ) tmpsig . name = \"maf\" tmpsig . unit = \"g/s\" self . resampled . append ( tmpsig ) tmpsig = self . resampled [ \"maf\" ] * self . resampled [ \"fmaf_cor\" ] tmpsig . name = \"maf_cor\" self . resampled . append ( tmpsig ) tmpsig = ( self . resampled [ \"Mass Air Flow Estimated\" ] * self . resampled [ \"fmaf_cor\" ] ) tmpsig . name = \"maf_est_cor\" self . resampled . append ( tmpsig ) tmpsig = Sig ( data = self . resampled [ \"Turbo Speed\" ], name = \"Turbo Speed.Corrected\" , ) self . resampled . append ( tmpsig ) tmpsig = Sig ( data = self . resampled [ \"MAP\" ] / self . resampled [ \"GP Pressure 2 - Pboost\" ], name = \"pr_throttle\" , unit = \"ratio\" , ) self . resampled . append ( tmpsig ) tmpsig = Sig ( data = self . resampled [ \"TPS (Main)\" ], name = \"Throttle PR.Corrected\" , unit = \"%\" , ) self . resampled . append ( tmpsig ) self . resampled . append ( self . table_data [ \"maf_nom\" ] . interp ( self . resampled )) [ nmots , maps ] = np . meshgrid ( np . arange ( min ( self . table_data [ \"Fuel Table 1\" ] . axes [ 0 ]), max ( self . table_data [ \"Fuel Table 1\" ] . axes [ 0 ]), 100 , ), np . arange ( min ( self . table_data [ \"Fuel Table 1\" ] . axes [ 1 ]), max ( self . table_data [ \"Fuel Table 1\" ] . axes [ 1 ]), 4 , ), ) nvmaps = np . append ( nmots . reshape (( - 1 , 1 )), maps . reshape (( - 1 , 1 )), axis = 1 , ) ves = self . table_data [ \"Fuel Table 1\" ] . interp ( nvmaps ) rls = ves * maps . ravel () / 101.3 # TODO: Add tint comp to this calc mafs = rls / 100 * self . displacement * nmots . ravel () / 60 / 2 * 1.188 mapscatter = ScatterData ( [ nmots . ravel (), mafs . ravel (), maps . ravel (), ], name = \"Calculated\" , color = ves , color_name = \"Vol Eff\" , ) self . table_data [ \"map_nom\" ] . scatter_data = mapscatter [ nmots , apss ] = np . meshgrid ( np . arange ( min ( self . table_data [ \"Fuel Table 1\" ] . axes [ 0 ]), max ( self . table_data [ \"Fuel Table 1\" ] . axes [ 0 ]), 100 , ), np . arange ( 0 , 100 , 2 ), ) nvapss = np . append ( nmots . reshape (( - 1 , 1 )), apss . reshape (( - 1 , 1 )), axis = 1 , ) for i , scaler in enumerate ( self . table_data [ \"map_target_scaler\" ] . data ): mafsnom : np . ndarray = ( self . table_data [ \"maf_nom\" ] . interp ( nvapss ) * scaler ) nvmafs = np . append ( nmots . reshape (( - 1 , 1 )), mafsnom . reshape (( - 1 , 1 )), axis = 1 , ) mapstarget = self . table_data [ \"map_nom\" ] . interp ( nvmafs ) maptgtscatter = ScatterData ( [ nmots . ravel (), apss . ravel (), mapstarget . ravel (), ], name = \"Calculated\" , color = mafsnom , color_name = \"Maf Target\" , color_unit = \"g/s\" , ) self . table_data [ f \"map_target_ { i + 1 } \" ] . scatter_data = maptgtscatter pr_wot_nom = ( mapstarget / self . table_data [ \"pamb_ref\" ] . data [ 0 ] ) # Target pr1 for wot prmafs = np . append ( mafsnom . reshape (( - 1 , 1 )), pr_wot_nom . reshape (( - 1 , 1 )), axis = 1 , ) nturbo_est = self . table_data [ \"Turbo Speed\" ] . interp ( prmafs ) nturbo_max = min ( [ max ( nturbo_est ), self . table_data [ \"nturbo_max\" ] . data [ 0 ]] ) fturbo = self . table_data [ \"nturbo_target_scaler\" ] . interp ( apss . reshape (( - 1 , 1 )) ) nturbo_nom = nturbo_max * fturbo mafvnts = np . append ( mafsnom . reshape (( - 1 , 1 )), nturbo_nom . reshape (( - 1 , 1 )), axis = 1 , ) pr_comp_nom = self . table_data [ \"pr_comp\" ] . interp ( mafvnts ) # ath_map = self.table_data['E-Throttle 1 Target'].interp(nvapss) # pr_map = self.table_data['Throttle PR'].interp() boosttgtsct = ScatterData ( [ nmots . ravel (), apss . ravel (), np . maximum ( pr_comp_nom . ravel () * self . table_data [ \"pamb_ref\" ] . data [ 0 ], mapstarget , ), ], name = \"Calculated\" , color = nturbo_nom , color_name = \"Nturbo Target\" , color_unit = \"krpm\" , ) self . table_data [ f \"Boost Target { i + 1 } \" ] . scatter_data = boosttgtsct pr_throttle_nom = pr_wot_nom / pr_comp_nom mafvprs = np . append ( mafsnom . reshape (( - 1 , 1 )), pr_throttle_nom . reshape (( - 1 , 1 )), axis = 1 , ) if i == 2 : # Calc throttle target for boost3 etcnom = self . table_data [ \"Throttle PR\" ] . interp ( mafvprs ) etctgt = ScatterData ( [ nmots . ravel (), apss . ravel (), etcnom . ravel ()], name = \"Calculated\" , color = nturbo_nom , color_name = \"Nturbo Target\" , color_unit = \"krpm\" , ) self . table_data [ \"E-Throttle 1 Target\" ] . scatter_data = etctgt # TODO: Fix here for boost 1 and 2 toc = datetime . now () - tic _LOGGER . debug ( \"Firmware calcs in %.3f \" , toc . total_seconds ()) # Set some ranges self . resampled [ \"Engine Speed\" ] . data_range = [ 0 , 9000 ] self . resampled [ \"AFR/Lambda Target\" ] . data_range = [ 0.6 , 1.4 , ] self . _needs_calcs = False self . update_scatter_data () def update_scatter_data ( self ): \"\"\"Update scatter data for fitting.\"\"\" # Build signal list if self . _needs_calcs : self . update_calcd_data () for table in self . table_data : if f \" { table . name } .Corrected\" in self . resampled : if self . tabs [ table . name ] . additional_gate : gate = GateCollAND ( [ self . gate , self . tabs [ table . name ] . additional_gate , ] ) else : gate = self . gate tmp = [] for axis in table . axes : tmp . append ( self . resampled [ f \" { axis . name } \" ] . valid ( gate ) . resample ( self . resampled . math_tline ) ) tmp . append ( self . resampled [ f \" { table . name } .Corrected\" ] . valid ( gate ) . resample ( self . resampled . math_tline ) ) if table . name == \"Fuel Table 1\" and False : color = self . resampled [ \"IAT\" ] color_unit = \"\u00b0C\" color_name = \"IAT\" color_range = [ 10 , 60 ] else : color = None color_name = None color_unit = None color_range = None table . scatter_data = ScatterData ( data = tmp , name = \"Measured\" , color = color , color_unit = color_unit , color_name = color_name , color_range = color_range , ) . clean () table . scatter_data [ - 1 ] . color_from_density () # else: # table.scatter_data = None # Removed 2/6/24 to allowe defining scatter data elsewhere def normalize_cyl_trims ( self ): pass check_sigs () Check that required input sigs are present. Source code in ccg\\controllers\\link.py 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 def check_sigs ( self ): \"\"\"Check that required input sigs are present.\"\"\" if self . table_data and self . data : self . check_substitute_sigs () required_sigs = set ( [ \"Lambda 1\" , \"Fuel Table 1\" , \"AFR/Lambda Target\" , \"CL Lambda Fuel Corr.\" , \"CL Lambda LT corr.\" , \"TPS (Main)\" , \"MAP\" , \"Engine Speed\" , \"IAT\" , \"Boost Target\" , \"GP Pressure 2 - Pboost\" , \"Boost Base DC\" , \"WGate DC\" , \"pamb\" , \"Turbo Speed\" , \"TPS (Main)\" , \"CAN An 2\" , \"GP Temperature 1 - Ambient Temp\" , \"Mass Air Flow Estimated\" , \"Load (Abs)\" , \"IAT Fuel Corr.\" , \"Post Start Enrich\" , \"Warm Up Enrichment\" , ] ) for table in self . fueling_tables : for axis in self . table_data [ table . replace ( \"#\" , \"1\" )] . axes : if axis . name not in self . calcd_sigs : required_sigs . add ( axis . name ) for table in self . reference_tables : for axis in self . table_data [ table . replace ( \"#\" , \"1\" )] . axes : if axis . name not in self . calcd_sigs : required_sigs . add ( axis . name ) for sig in self . gate . sigs : if sig not in self . calcd_sigs : required_sigs . add ( sig ) ok_slow = [] required_sigs = list ( required_sigs ) for sig in required_sigs : if sig not in ok_slow : self . slow_sig = sig break for sig in required_sigs : if ( sig not in ok_slow and self . data [ sig ] . period > self . data [ self . slow_sig ] . period ): self . slow_sig = sig missing = [] for sig in required_sigs : if sig not in self . data : missing . append ( sig ) if missing : raise ValueError ( f \"Missing required signals: { missing } \" ) # Build slower timeline for r-worded Link data slow_tline = TLine ( tstart = self . data . tstart , tend = self . data . tend , period = 0.04 ) self . resampled = self . data [ required_sigs ] . resample ( slow_tline ) self . data . math_tline = self . data [ self . slow_sig ] . tline self . resampled . math_tline = slow_tline self . resampled . name = \"resampled\" return True else : return False check_substitute_sigs () Try to substitute for some common missing sigs. Source code in ccg\\controllers\\link.py 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 def check_substitute_sigs ( self ): \"\"\"Try to substitute for some common missing sigs.\"\"\" # Set units for pamb self . data [ \"CAN An 2\" ] . unit = \"mbar\" tmp = self . data [ \"CAN An 2\" ] . as_unit ( \"kPa\" ) tmp . name = \"pamb\" self . data . append ( tmp ) # Fix units that are mislabeled if self . data [ \"IAT Fuel Corr.\" ] . unit == \"%\" : self . data [ \"IAT Fuel Corr.\" ] . unit = \"%trim\" if self . data [ \"Post Start Enrich\" ] . unit == \"%\" : self . data [ \"Post Start Enrich\" ] . unit = \"%trim\" if self . data [ \"Warm Up Enrichment\" ] . unit == \"%\" : self . data [ \"Warm Up Enrichment\" ] . unit = \"%trim\" self . data [ \"IAT Fuel Corr.\" ] . convert_units ( \"ratio\" ) self . data [ \"Post Start Enrich\" ] . convert_units ( \"ratio\" ) self . data [ \"Warm Up Enrichment\" ] . convert_units ( \"ratio\" ) update_calcd_data ( _ = None ) Update calculations for fitting/plotting. Source code in ccg\\controllers\\link.py 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 def update_calcd_data ( self , _ = None ): \"\"\"Update calculations for fitting/plotting.\"\"\" if self . _needs_calcs : tic = datetime . now () if self . check_sigs (): tmp = ( self . resampled [ \"IAT Fuel Corr.\" ] * self . resampled [ \"Post Start Enrich\" ] * self . resampled [ \"Warm Up Enrichment\" ] ) tmp . name = \"Fueling.Corr.logged\" self . resampled . append ( tmp ) tmp = self . table_data [ \"IAT Fuel Trim\" ] . interp ( self . resampled ) tmp . name = \"IAT Fuel Corr new\" self . resampled . append ( tmp . convert_units ( \"ratio\" )) tmp = self . table_data [ \"Warm Up Enrichment\" ] . interp ( self . resampled ) tmp . name = \"ECT Fuel Corr new\" self . resampled . append ( tmp . convert_units ( \"ratio\" )) tmp = self . table_data [ \"Fuel Table 1\" ] . interp ( self . resampled ) tmp . name = \"Fuel Table 1.new\" self . resampled . append ( tmp ) tmp = ( self . resampled [ \"IAT Fuel Corr new\" ] * self . resampled [ \"Post Start Enrich\" ] # Shortcut assumes const * self . resampled [ \"ECT Fuel Corr new\" ] ) tmp . name = \"Fueling.Corr.new\" self . resampled . append ( tmp ) tmp = ( ( self . resampled [ \"CL Lambda Fuel Corr.\" ] . convert_units ( \"ratio\" ) + 1 ) * ( self . resampled [ \"CL Lambda LT corr.\" ] . convert_units ( \"ratio\" ) + 1 ) * self . resampled [ \"Lambda 1\" ] / self . resampled [ \"AFR/Lambda Target\" ] ) tmp . name = \"Fueling.Error.Total\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ \"Fueling.Error.Total\" ] * self . resampled [ \"Fuel Table 1\" ] / self . resampled [ \"Fueling.Corr.new\" ] * self . resampled [ \"Fueling.Corr.logged\" ] ) tmp . name = \"Fuel Table 1.Corrected\" tmp . unit = \"%\" self . resampled . append ( tmp ) tmp = ( self . resampled [ \"Fueling.Error.Total\" ] * self . resampled [ \"Fuel Table 1\" ] / self . resampled [ \"Fuel Table 1.new\" ] * self . resampled [ \"Warm Up Enrichment\" ] / self . resampled [ \"ECT Fuel Corr.new\" ] * self . resampled [ \"IAT Fuel Corr.\" ] ) tmp . name = \"IAT Fuel Trim.Corrected\" self . resampled . append ( tmp . convert_units ( \"%trim\" )) tmp = ( self . resampled [ \"Fueling.Error.Total\" ] * self . resampled [ \"Fuel Table 1\" ] / self . resampled [ \"Fuel Table 1.new\" ] * self . resampled [ \"IAT Fuel Corr.\" ] / self . resampled [ \"IAT Fuel Corr.new\" ] * self . resampled [ \"Warm Up Enrichment\" ] ) tmp . name = \"Warm Up Enrichment.Corrected\" self . resampled . append ( tmp . convert_units ( \"%trim\" )) # WGC pboost_d = ( self . resampled [ \"GP Pressure 2 - Pboost\" ] - self . resampled [ \"Boost Target\" ] ) inds = abs ( pboost_d . data ) < 10 tmp = self . resampled [ \"Boost Base DC\" ] . data tmp [ inds ] = self . resampled [ \"WGate DC\" ][ inds ] tmpsig = Sig ( self . resampled [ \"Boost Base DC\" ]) tmpsig . name = \"Wastegate %DC 1.Corrected\" self . resampled . append ( tmpsig ) tmpsig = Sig ( self . resampled [ \"Boost Base DC\" ]) tmpsig . name = \"Wastegate %DC 2.Corrected\" self . resampled . append ( tmpsig ) tmpsig = Sig ( self . resampled [ \"Boost Base DC\" ]) tmpsig . name = \"Wastegate %DC 3.Corrected\" self . resampled . append ( tmpsig ) if self . table_data : self . resampled . append ( self . resampled [ \"Engine Speed\" ] . dot ( n_win = 9 )) self . resampled . remove ( \"MAP_dot\" ) self . resampled . append ( self . resampled [ \"MAP\" ] . dot ( n_win = 13 )) # Calcs for boost target tmpsig = Sig ( data = self . resampled [ \"Lambda 1\" ], name = \"AFR_Lambda Target.Corrected\" , ) self . resampled . append ( tmpsig ) tmpsig = ( self . resampled [ \"GP Pressure 2 - Pboost\" ] / self . resampled [ \"pamb\" ] ) tmpsig . name = \"pr_comp.Corrected\" self . resampled . append ( tmpsig ) tmpsig = Sig ( tmpsig , name = \"pr_comp\" ) self . resampled . append ( tmpsig ) tmpsig = Sig ( data = np . sqrt ( self . resampled [ \"GP Temperature 1 - Ambient Temp\" ] . as_unit ( \"k\" ) / 288 ) * self . resampled [ \"pamb\" ] / 101.3 , unit = \"ratio\" , name = \"fmaf_cor\" , tline = self . resampled [ \"pamb\" ] . tline , ) self . resampled . append ( tmpsig ) tmpsig = ( self . resampled [ \"Load (Abs)\" ] . as_unit ( \"ratio\" ) * ( self . resampled [ \"CL Lambda Fuel Corr.\" ] . as_unit ( \"ratio\" ) + 1 ) * ( self . resampled [ \"CL Lambda LT corr.\" ] . as_unit ( \"ratio\" ) + 1 ) * self . resampled [ \"Engine Speed\" ] / ( 60 * 2 ) * 1.188 # Density of dry air * self . displacement # Displacememt * 1.0 # Fudge factor ) tmpsig . name = \"maf\" tmpsig . unit = \"g/s\" self . resampled . append ( tmpsig ) tmpsig = self . resampled [ \"maf\" ] * self . resampled [ \"fmaf_cor\" ] tmpsig . name = \"maf_cor\" self . resampled . append ( tmpsig ) tmpsig = ( self . resampled [ \"Mass Air Flow Estimated\" ] * self . resampled [ \"fmaf_cor\" ] ) tmpsig . name = \"maf_est_cor\" self . resampled . append ( tmpsig ) tmpsig = Sig ( data = self . resampled [ \"Turbo Speed\" ], name = \"Turbo Speed.Corrected\" , ) self . resampled . append ( tmpsig ) tmpsig = Sig ( data = self . resampled [ \"MAP\" ] / self . resampled [ \"GP Pressure 2 - Pboost\" ], name = \"pr_throttle\" , unit = \"ratio\" , ) self . resampled . append ( tmpsig ) tmpsig = Sig ( data = self . resampled [ \"TPS (Main)\" ], name = \"Throttle PR.Corrected\" , unit = \"%\" , ) self . resampled . append ( tmpsig ) self . resampled . append ( self . table_data [ \"maf_nom\" ] . interp ( self . resampled )) [ nmots , maps ] = np . meshgrid ( np . arange ( min ( self . table_data [ \"Fuel Table 1\" ] . axes [ 0 ]), max ( self . table_data [ \"Fuel Table 1\" ] . axes [ 0 ]), 100 , ), np . arange ( min ( self . table_data [ \"Fuel Table 1\" ] . axes [ 1 ]), max ( self . table_data [ \"Fuel Table 1\" ] . axes [ 1 ]), 4 , ), ) nvmaps = np . append ( nmots . reshape (( - 1 , 1 )), maps . reshape (( - 1 , 1 )), axis = 1 , ) ves = self . table_data [ \"Fuel Table 1\" ] . interp ( nvmaps ) rls = ves * maps . ravel () / 101.3 # TODO: Add tint comp to this calc mafs = rls / 100 * self . displacement * nmots . ravel () / 60 / 2 * 1.188 mapscatter = ScatterData ( [ nmots . ravel (), mafs . ravel (), maps . ravel (), ], name = \"Calculated\" , color = ves , color_name = \"Vol Eff\" , ) self . table_data [ \"map_nom\" ] . scatter_data = mapscatter [ nmots , apss ] = np . meshgrid ( np . arange ( min ( self . table_data [ \"Fuel Table 1\" ] . axes [ 0 ]), max ( self . table_data [ \"Fuel Table 1\" ] . axes [ 0 ]), 100 , ), np . arange ( 0 , 100 , 2 ), ) nvapss = np . append ( nmots . reshape (( - 1 , 1 )), apss . reshape (( - 1 , 1 )), axis = 1 , ) for i , scaler in enumerate ( self . table_data [ \"map_target_scaler\" ] . data ): mafsnom : np . ndarray = ( self . table_data [ \"maf_nom\" ] . interp ( nvapss ) * scaler ) nvmafs = np . append ( nmots . reshape (( - 1 , 1 )), mafsnom . reshape (( - 1 , 1 )), axis = 1 , ) mapstarget = self . table_data [ \"map_nom\" ] . interp ( nvmafs ) maptgtscatter = ScatterData ( [ nmots . ravel (), apss . ravel (), mapstarget . ravel (), ], name = \"Calculated\" , color = mafsnom , color_name = \"Maf Target\" , color_unit = \"g/s\" , ) self . table_data [ f \"map_target_ { i + 1 } \" ] . scatter_data = maptgtscatter pr_wot_nom = ( mapstarget / self . table_data [ \"pamb_ref\" ] . data [ 0 ] ) # Target pr1 for wot prmafs = np . append ( mafsnom . reshape (( - 1 , 1 )), pr_wot_nom . reshape (( - 1 , 1 )), axis = 1 , ) nturbo_est = self . table_data [ \"Turbo Speed\" ] . interp ( prmafs ) nturbo_max = min ( [ max ( nturbo_est ), self . table_data [ \"nturbo_max\" ] . data [ 0 ]] ) fturbo = self . table_data [ \"nturbo_target_scaler\" ] . interp ( apss . reshape (( - 1 , 1 )) ) nturbo_nom = nturbo_max * fturbo mafvnts = np . append ( mafsnom . reshape (( - 1 , 1 )), nturbo_nom . reshape (( - 1 , 1 )), axis = 1 , ) pr_comp_nom = self . table_data [ \"pr_comp\" ] . interp ( mafvnts ) # ath_map = self.table_data['E-Throttle 1 Target'].interp(nvapss) # pr_map = self.table_data['Throttle PR'].interp() boosttgtsct = ScatterData ( [ nmots . ravel (), apss . ravel (), np . maximum ( pr_comp_nom . ravel () * self . table_data [ \"pamb_ref\" ] . data [ 0 ], mapstarget , ), ], name = \"Calculated\" , color = nturbo_nom , color_name = \"Nturbo Target\" , color_unit = \"krpm\" , ) self . table_data [ f \"Boost Target { i + 1 } \" ] . scatter_data = boosttgtsct pr_throttle_nom = pr_wot_nom / pr_comp_nom mafvprs = np . append ( mafsnom . reshape (( - 1 , 1 )), pr_throttle_nom . reshape (( - 1 , 1 )), axis = 1 , ) if i == 2 : # Calc throttle target for boost3 etcnom = self . table_data [ \"Throttle PR\" ] . interp ( mafvprs ) etctgt = ScatterData ( [ nmots . ravel (), apss . ravel (), etcnom . ravel ()], name = \"Calculated\" , color = nturbo_nom , color_name = \"Nturbo Target\" , color_unit = \"krpm\" , ) self . table_data [ \"E-Throttle 1 Target\" ] . scatter_data = etctgt # TODO: Fix here for boost 1 and 2 toc = datetime . now () - tic _LOGGER . debug ( \"Firmware calcs in %.3f \" , toc . total_seconds ()) # Set some ranges self . resampled [ \"Engine Speed\" ] . data_range = [ 0 , 9000 ] self . resampled [ \"AFR/Lambda Target\" ] . data_range = [ 0.6 , 1.4 , ] self . _needs_calcs = False self . update_scatter_data () update_scatter_data () Update scatter data for fitting. Source code in ccg\\controllers\\link.py 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 def update_scatter_data ( self ): \"\"\"Update scatter data for fitting.\"\"\" # Build signal list if self . _needs_calcs : self . update_calcd_data () for table in self . table_data : if f \" { table . name } .Corrected\" in self . resampled : if self . tabs [ table . name ] . additional_gate : gate = GateCollAND ( [ self . gate , self . tabs [ table . name ] . additional_gate , ] ) else : gate = self . gate tmp = [] for axis in table . axes : tmp . append ( self . resampled [ f \" { axis . name } \" ] . valid ( gate ) . resample ( self . resampled . math_tline ) ) tmp . append ( self . resampled [ f \" { table . name } .Corrected\" ] . valid ( gate ) . resample ( self . resampled . math_tline ) ) if table . name == \"Fuel Table 1\" and False : color = self . resampled [ \"IAT\" ] color_unit = \"\u00b0C\" color_name = \"IAT\" color_range = [ 10 , 60 ] else : color = None color_name = None color_unit = None color_range = None table . scatter_data = ScatterData ( data = tmp , name = \"Measured\" , color = color , color_unit = color_unit , color_name = color_name , color_range = color_range , ) . clean () table . scatter_data [ - 1 ] . color_from_density () read_cal_xml_async ( caltbl ) async Read and parse a single cal XML file Parameters: caltbl ( str | Path ) \u2013 path to file Returns: Tbl \u2013 parsed Tbl Source code in ccg\\controllers\\link.py 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 async def read_cal_xml_async ( caltbl : Path ) -> Tbl : \"\"\"Read and parse a single cal XML file Parameters ---------- caltbl : str | Path path to file Returns ------- Tbl parsed Tbl \"\"\" tree = await asyncio . to_thread ( ET . parse , caltbl ) root = await asyncio . to_thread ( tree . getroot ) tmp = await asyncio . to_thread ( root . find , \"LinkTableImportExportInfoV2\" ) tmp = tmp . attrib # ncol = tmp['ColumnCount'] xs = np . array ( tmp [ \"XAxisValues\" ] . split ( \",\" ), dtype = np . float32 ) xs = xs [ np . append ( True , np . diff ( xs ) > 0 )] xs = Axis ( xs , name = \"X\" ) axes = [ xs ] size = len ( xs ) if ( \"YAxisValues\" in tmp and tmp [ \"YAxisFunction\" ] != \"0\" and len ( tmp [ \"YAxisValues\" ]) > 0 ): ys = np . array ( tmp [ \"YAxisValues\" ] . split ( \",\" ), dtype = np . float32 ) ys = ys [ np . append ( True , np . diff ( ys ) > 0 )] ys = Axis ( ys , name = \"Y\" ) axes . append ( ys ) size = ( len ( xs ), len ( ys )) data = np . array ( tmp [ \"CellValues\" ] . split ( \",\" ), dtype = np . float32 ) data = data . reshape ( size , order = \"F\" ) par = Tbl ( data = data , name = caltbl . stem , axes = axes ) return par read_cals ( dirname ) This function is deprecated. Use read_cals_async() instead. Parameters: dirname ( Path ) \u2013 The directory name where the calibration tables are located. Returns: Tbls \u2013 The calibration tables. Notes .. deprecated:: 1.0.0 Use read_cals_async() instead. Source code in ccg\\controllers\\link.py 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 def read_cals ( dirname : Path | str ) -> Tbls : \"\"\" This function is deprecated. Use `read_cals_async()` instead. Parameters ---------- dirname : Path The directory name where the calibration tables are located. Returns ------- Tbls The calibration tables. Notes ----- .. deprecated:: 1.0.0 Use `read_cals_async()` instead. \"\"\" tbls = Tbls () for caltbl in Path ( dirname ) . glob ( \"*.lte\" ): tree = ET . parse ( caltbl ) root = tree . getroot () tmp = root . find ( \"LinkTableImportExportInfoV2\" ) . attrib # ncol = tmp['ColumnCount'] xs = np . array ( tmp [ \"XAxisValues\" ] . split ( \",\" ), dtype = np . float32 ) xs = xs [ np . append ( True , np . diff ( xs ) > 0 )] xs = Axis ( xs , name = \"X\" ) axes = [ xs ] size = len ( xs ) if ( \"YAxisValues\" in tmp and tmp [ \"YAxisFunction\" ] != \"0\" and len ( tmp [ \"YAxisValues\" ]) > 0 ): ys = np . array ( tmp [ \"YAxisValues\" ] . split ( \",\" ), dtype = np . float32 ) ys = ys [ np . append ( True , np . diff ( ys ) > 0 )] ys = Axis ( ys , name = \"Y\" ) axes . append ( ys ) size = ( len ( xs ), len ( ys )) data = np . array ( tmp [ \"CellValues\" ] . split ( \",\" ), dtype = np . float32 ) data = data . reshape ( size , order = \"F\" ) par = Tbl ( data = data , name = caltbl . stem , axes = axes ) tbls . append ( par ) for partbl in Path ( dirname ) . glob ( \"*tbl.json\" ): pars = Tbl () . from_file ( partbl ) tbls . append ( pars ) return tbls read_cals_async ( dirname ) async Read cal's async Parameters: dirname ( str | Path ) \u2013 Directory of cal files Returns: Tbls \u2013 Table data Source code in ccg\\controllers\\link.py 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 async def read_cals_async ( dirname : str | Path ) -> Tbls : \"\"\"Read cal's async Parameters ---------- dirname : str | Path Directory of cal files Returns ------- Tbls Table data \"\"\" tbldata = Tbls () tasks = [ read_cal_xml_async ( caltbl ) for caltbl in Path ( dirname ) . glob ( \"*.lte\" )] tasks . extend ( [ Tbl () . from_file_async ( partbl ) for partbl in Path ( dirname ) . glob ( \"*.tbl.json\" )] ) pars = await asyncio . gather ( * tasks ) tbldata . append ( pars ) return tbldata read_link_datafile ( filename ) Reads a link formatted data file Source code in ccg\\controllers\\link.py 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 @profile def read_link_datafile ( filename : str | Path ) -> Frame : \"\"\"Reads a link formatted data file\"\"\" tic = datetime . now () tline_col = 0 data_row = 4 if isinstance ( filename , str ): filename = Path ( filename ) res = Frame ( name = filename . stem ) try : with open ( filename , \"r\" , encoding = \"utf8\" ) as file : csvreader = csv . reader ( file , dialect = \"excel\" ) header = [ next ( csvreader ) for _ in range ( data_row )] # 4 rows of header info data = np . loadtxt ( file , skiprows = 0 , delimiter = \",\" ) # Can use loadtxt since uniform except ValueError as err : err . add_note ( \"Likely due to quoted numerics in Link file. Open and resave in Excel to correct\" ) raise # TODO: FIX HERE to automagically fix link's r-worded files toc = datetime . now () - tic _LOGGER . debug ( \"read %s in %.3f .\" , filename . stem , toc . total_seconds ()) tic = datetime . now () sig_args = [ { \"name\" : name , \"unit\" : unit } for name , unit in zip ( header [ 1 ], header [ 2 ]) ] # Check for duplicate names and add _dup existing = [] for sig in sig_args : if sig [ \"name\" ] not in existing : existing . append ( sig [ \"name\" ]) else : existing . append ( sig [ \"name\" ] + \"_dup\" ) sig [ \"name\" ] = sig [ \"name\" ] + \"_dup\" tmp = data [:, tline_col ] . ravel () tline = TLine ( tmp ) for i , kwargs in enumerate ( sig_args ): if i != tline_col : sigtype = type ( data [ 0 , i ]) sigdata = data [:, i ] . ravel () . astype ( sigtype ) if sigtype is str : try : sigdata = sigdata . astype ( float ) except ValueError : pass new_sig = Sig ( data = sigdata , tline = tline , ** kwargs , ) res . append ( new_sig ) toc = datetime . now () - tic _LOGGER . debug ( \"built frame in %.3f .\" , toc . total_seconds ()) tic = datetime . now () return res","title":"link"},{"location":"reference/ccg/controllers/link/#ccg.controllers.link.FirmwareModel","text":"Bases: ABC Base class for M1 firmware model. Source code in ccg\\controllers\\link.py 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 class FirmwareModel ( ABC ): \"\"\"Base class for M1 firmware model.\"\"\" reference_tables = {} fueling_tables = { \"Engine.Efficiency.Value\" : { \"unit\" : \"%\" , \"prec\" : 1 , \"range\" : [ 10 , 200 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine.Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 1 , }, \"Y\" : { \"sig\" : \"Throttle.Position\" , \"unit\" : \"%\" , \"range\" : [ 0 , 100 ], \"prec\" : 1 , }, \"Z\" : { \"sig\" : \"Inlet.Manifold.Pressure\" , \"unit\" : \"kPa\" , \"range\" : [ 0 , np . inf ], \"prec\" : 1 , }, }, } } fueling_params = { \"Engine.Cylinders\" : 8 } def __init__ ( self , caldir : str | Path | None = None , data : str | Path | Frame | None = None , gate : GateColl | str | Path | None = None , warning_dialog : Callable | None = None , ): self . table_data = None self . read_cal ( caldir ) self . tabs = ccg . ui . panel . CalDataTabs ( self . table_data ) self . _needs_calcs = True self . _needs_scatter_update = True self . _data = None self . warning_dialog = warning_dialog if data is None : self . data = None elif isinstance ( data , Frame ): self . data = data else : self . read_data ( data ) if gate is None : self . gate = None elif isinstance ( gate , GateColl ): self . gate = gate else : self . read_gate ( gate ) self . bank_gates = [] self . resampled = None self . slow_sig : str @property def slow_freq ( self ): \"\"\"return freq of slow signal.\"\"\" return round ( 1 / self . data [ self . slow_sig ] . period ) @property @abstractmethod def n_cyl ( self ) -> int : \"\"\"Returns num of cyls\"\"\" @property @abstractmethod def n_banks ( self ) -> int : \"\"\"Returns n_banks\"\"\" @property def data ( self ): \"\"\"data\"\"\" return self . _data @data . setter def data ( self , value : Frame ): \"\"\"data setter\"\"\" self . _needs_calcs = True self . _needs_scatter_update = True self . _needs_bank_warning = True self . _data = value def read_gate ( self , filename : str | Path ): \"\"\"Read Gate File\"\"\" self . gate = GateCollAND () . from_file ( filename ) self . _needs_calcs = True self . _needs_scatter_update = True self . _needs_bank_warning = True async def read_gate_async ( self , filename : str | Path ): return await asyncio . to_thread ( self . read_gate , filename ) def read_data ( self , filename : str | Path ): \"\"\"Read data file\"\"\" self . data = read_data ( filename ) # self._needs_calcs set in data.setter def read_cal ( self , dirname : str | Path | None ): \"\"\"Read the calibration data into table_data.\"\"\" if dirname is not None : self . table_data = read_cals ( dirname ) self . convert_tables () self . _needs_calcs = True self . _needs_scatter_update = True self . _needs_bank_warning = True async def read_cal_async ( self , dirname : str | Path ): \"\"\"Async cal read Parameters ---------- dirname : str | Path Dir of cal files \"\"\" if dirname is not None : self . table_data = await read_cals_async ( dirname ) self . convert_tables () self . _needs_calcs = True self . _needs_scatter_update = True self . _needs_bank_warning = True self . tabs . update_tabs ( self . table_data ) # TODO: warning for no dirname? @property def fueling_names ( self ): \"\"\"return names of fueling tables\"\"\" param_names = [] for param in self . fueling_tables : if \"#\" in param : param_names . extend ( param . replace ( \"#\" , str ( i + 1 )) for i in range ( self . n_cyl ) ) else : param_names . append ( param ) return param_names @property def param_names ( self ): \"\"\"Return the names of the parameters\"\"\" param_names = self . fueling_names for param in self . fueling_params : if \"#\" in param : param_names . extend ( param . replace ( \"#\" , str ( i + 1 )) for i in range ( self . n_cyl ) ) else : param_names . append ( param ) for param in self . reference_tables : if \"#\" in param : param_names . extend ( param . replace ( \"#\" , str ( i + 1 )) for i in range ( self . n_cyl ) ) else : param_names . append ( param ) return param_names def convert_tables ( self ): \"\"\"Convert tables using configurations in self.fueling_tables.\"\"\" if self . table_data : for name , config in dict ( self . fueling_tables , ** self . reference_tables ) . items (): if \"#\" in name : names = [ name . replace ( \"#\" , str ( i )) for i in range ( 1 , self . n_cyl + 1 ) ] else : names = [ name ] for name in names : self . table_data [ name ] . convert_units ( config [ \"unit\" ]) self . table_data [ name ] . precision = config [ \"prec\" ] self . table_data [ name ] . data_range = config [ \"range\" ] if \"axes\" in config : for axes , ax_cfg in config [ \"axes\" ] . items (): if axes in self . table_data [ name ] . axes : self . table_data [ name ] . axes [ axes ] . convert_units ( ax_cfg [ \"unit\" ] ) self . table_data [ name ] . axes [ axes ] . precision = ax_cfg [ \"prec\" ] self . table_data [ name ] . axes [ axes ] . data_range = ax_cfg [ \"range\" ] self . table_data [ name ] . axes [ axes ] . name = ax_cfg [ \"sig\" ] # to avoid ctrl-z back to old units self . table_data [ name ] . _archive [ \"prev\" ] = [] self . table_data [ name ] . snapshot ( \"orig\" ) def write_cal ( self , dirname : Path , pars_to_write : list [ str ]): write_cals ( dirname , self . table_data , pars_to_write ) @abstractmethod def update_calcd_data ( self ): \"\"\"Update calcs for fitting/plotting.\"\"\" @abstractmethod def update_scatter_data ( self ): \"\"\"Update scatter data for fitting/plotting.\"\"\"","title":"FirmwareModel"},{"location":"reference/ccg/controllers/link/#ccg.controllers.link.FirmwareModel.data","text":"data","title":"data"},{"location":"reference/ccg/controllers/link/#ccg.controllers.link.FirmwareModel.fueling_names","text":"return names of fueling tables","title":"fueling_names"},{"location":"reference/ccg/controllers/link/#ccg.controllers.link.FirmwareModel.n_banks","text":"Returns n_banks","title":"n_banks"},{"location":"reference/ccg/controllers/link/#ccg.controllers.link.FirmwareModel.n_cyl","text":"Returns num of cyls","title":"n_cyl"},{"location":"reference/ccg/controllers/link/#ccg.controllers.link.FirmwareModel.param_names","text":"Return the names of the parameters","title":"param_names"},{"location":"reference/ccg/controllers/link/#ccg.controllers.link.FirmwareModel.slow_freq","text":"return freq of slow signal.","title":"slow_freq"},{"location":"reference/ccg/controllers/link/#ccg.controllers.link.FirmwareModel.convert_tables","text":"Convert tables using configurations in self.fueling_tables. Source code in ccg\\controllers\\link.py 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 def convert_tables ( self ): \"\"\"Convert tables using configurations in self.fueling_tables.\"\"\" if self . table_data : for name , config in dict ( self . fueling_tables , ** self . reference_tables ) . items (): if \"#\" in name : names = [ name . replace ( \"#\" , str ( i )) for i in range ( 1 , self . n_cyl + 1 ) ] else : names = [ name ] for name in names : self . table_data [ name ] . convert_units ( config [ \"unit\" ]) self . table_data [ name ] . precision = config [ \"prec\" ] self . table_data [ name ] . data_range = config [ \"range\" ] if \"axes\" in config : for axes , ax_cfg in config [ \"axes\" ] . items (): if axes in self . table_data [ name ] . axes : self . table_data [ name ] . axes [ axes ] . convert_units ( ax_cfg [ \"unit\" ] ) self . table_data [ name ] . axes [ axes ] . precision = ax_cfg [ \"prec\" ] self . table_data [ name ] . axes [ axes ] . data_range = ax_cfg [ \"range\" ] self . table_data [ name ] . axes [ axes ] . name = ax_cfg [ \"sig\" ] # to avoid ctrl-z back to old units self . table_data [ name ] . _archive [ \"prev\" ] = [] self . table_data [ name ] . snapshot ( \"orig\" )","title":"convert_tables"},{"location":"reference/ccg/controllers/link/#ccg.controllers.link.FirmwareModel.read_cal","text":"Read the calibration data into table_data. Source code in ccg\\controllers\\link.py 412 413 414 415 416 417 418 419 def read_cal ( self , dirname : str | Path | None ): \"\"\"Read the calibration data into table_data.\"\"\" if dirname is not None : self . table_data = read_cals ( dirname ) self . convert_tables () self . _needs_calcs = True self . _needs_scatter_update = True self . _needs_bank_warning = True","title":"read_cal"},{"location":"reference/ccg/controllers/link/#ccg.controllers.link.FirmwareModel.read_cal_async","text":"Async cal read Parameters: dirname ( str | Path ) \u2013 Dir of cal files Source code in ccg\\controllers\\link.py 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 async def read_cal_async ( self , dirname : str | Path ): \"\"\"Async cal read Parameters ---------- dirname : str | Path Dir of cal files \"\"\" if dirname is not None : self . table_data = await read_cals_async ( dirname ) self . convert_tables () self . _needs_calcs = True self . _needs_scatter_update = True self . _needs_bank_warning = True self . tabs . update_tabs ( self . table_data )","title":"read_cal_async"},{"location":"reference/ccg/controllers/link/#ccg.controllers.link.FirmwareModel.read_data","text":"Read data file Source code in ccg\\controllers\\link.py 407 408 409 def read_data ( self , filename : str | Path ): \"\"\"Read data file\"\"\" self . data = read_data ( filename )","title":"read_data"},{"location":"reference/ccg/controllers/link/#ccg.controllers.link.FirmwareModel.read_gate","text":"Read Gate File Source code in ccg\\controllers\\link.py 397 398 399 400 401 402 def read_gate ( self , filename : str | Path ): \"\"\"Read Gate File\"\"\" self . gate = GateCollAND () . from_file ( filename ) self . _needs_calcs = True self . _needs_scatter_update = True self . _needs_bank_warning = True","title":"read_gate"},{"location":"reference/ccg/controllers/link/#ccg.controllers.link.FirmwareModel.update_calcd_data","text":"Update calcs for fitting/plotting. Source code in ccg\\controllers\\link.py 509 510 511 @abstractmethod def update_calcd_data ( self ): \"\"\"Update calcs for fitting/plotting.\"\"\"","title":"update_calcd_data"},{"location":"reference/ccg/controllers/link/#ccg.controllers.link.FirmwareModel.update_scatter_data","text":"Update scatter data for fitting/plotting. Source code in ccg\\controllers\\link.py 513 514 515 @abstractmethod def update_scatter_data ( self ): \"\"\"Update scatter data for fitting/plotting.\"\"\"","title":"update_scatter_data"},{"location":"reference/ccg/controllers/link/#ccg.controllers.link.G4xXtreme","text":"Bases: FirmwareModel Firmware model for LINK G4X Source code in ccg\\controllers\\link.py 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 class G4xXtreme ( FirmwareModel ): \"\"\"Firmware model for LINK G4X\"\"\" reference_tables = { # \"Fuel.Mixture Aim.Main\": { # \"unit\": \"LA\", # \"prec\": 2, # \"range\": [0.01, 5], # \"axes\": { # \"X\": { # \"sig\": \"Engine.Speed\", # \"unit\": \"rpm\", # \"range\": [0, 30000], # \"prec\": 1, # }, # \"Y\": { # \"sig\": \"Inlet.Manifold.Pressure\", # \"unit\": \"mbar\", # \"range\": [np.NINF, np.inf], # \"prec\": 1, # }, # \"Z\": { # \"sig\": \"Driver.Fuel.Mixture Aim Main Switch\", # \"unit\": \"\", # \"range\": [\"A\", \"B\"], # \"prec\": 0, # }, # }, # }, # \"Fuel.Timing.Secondary.Main\": { # \"unit\": \"dBTDC\", # \"prec\": 1, # \"range\": [0, 1440], # \"axes\": { # \"X\": { # \"sig\": \"Engine.Speed\", # \"unit\": \"rpm\", # \"range\": [0, 30000], # \"prec\": 1, # }, # \"Y\": { # \"sig\": \"Inlet.Manifold.Pressure\", # \"unit\": \"mbar\", # \"range\": [0, np.inf], # \"prec\": 1, # }, # }, # }, } fueling_tables = { \"Fuel Table 1\" : { \"unit\" : \"%\" , \"prec\" : 1 , \"range\" : [ 10 , 200 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"MAP\" , \"unit\" : \"kPa\" , \"range\" : [ 0 , np . inf ], \"prec\" : 0 , }, }, }, \"Wastegate %DC 1\" : { \"unit\" : \"%\" , \"prec\" : 1 , \"range\" : [ 0 , 100 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"GP Pressure 2 - Pboost\" , \"unit\" : \"kPa\" , \"range\" : [ 0 , np . inf ], \"prec\" : 0 , }, }, }, \"Wastegate %DC 2\" : { \"unit\" : \"%\" , \"prec\" : 1 , \"range\" : [ 0 , 100 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"GP Pressure 2 - Pboost\" , \"unit\" : \"kPa\" , \"range\" : [ 0 , np . inf ], \"prec\" : 0 , }, }, }, \"Wastegate %DC 3\" : { \"unit\" : \"%\" , \"prec\" : 1 , \"range\" : [ 0 , 100 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"GP Pressure 2 - Pboost\" , \"unit\" : \"kPa\" , \"range\" : [ 0 , np . inf ], \"prec\" : 0 , }, }, }, \"Boost Target 1\" : { \"unit\" : \"kPa\" , \"prec\" : 1 , \"range\" : [ 100 , 160 ], # Cheat for green shirt \"axes\" : { \"X\" : { \"sig\" : \"Engine Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"APS (Main)\" , \"unit\" : \"%\" , \"range\" : [ 0 , np . inf ], \"prec\" : 0 , }, }, }, \"Boost Target 2\" : { \"unit\" : \"kPa\" , \"prec\" : 1 , \"range\" : [ 100 , 300 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"APS (Main)\" , \"unit\" : \"%\" , \"range\" : [ 0 , np . inf ], \"prec\" : 0 , }, }, }, \"Boost Target 3\" : { \"unit\" : \"kPa\" , \"prec\" : 1 , \"range\" : [ 100 , 300 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"APS (Main)\" , \"unit\" : \"%\" , \"range\" : [ 0 , np . inf ], \"prec\" : 0 , }, }, }, \"AFR_Lambda Target\" : { \"unit\" : \"\" , \"prec\" : 3 , \"range\" : [ 0.6 , 2 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"MAP\" , \"unit\" : \"kPa\" , \"range\" : [ 0 , np . inf ], \"prec\" : 0 , }, }, }, \"E-Throttle 1 Target\" : { \"unit\" : \"%\" , \"prec\" : 1 , \"range\" : [ 0 , 100 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"APS (Main)\" , \"unit\" : \"%\" , \"range\" : [ 0 , 100 ], \"prec\" : 0 , }, }, }, \"IAT Fuel Trim\" : { \"unit\" : \"%trim\" , \"prec\" : 2 , \"range\" : [ - 30.0 , 30.0 ], \"axes\" : { \"X\" : { \"sig\" : \"IAT\" , \"unit\" : \"\u00b0C\" , \"range\" : [ 0 , 150 ], \"prec\" : 1 , }, }, }, \"Warm Up Enrichment\" : { \"unit\" : \"%trim\" , \"prec\" : 2 , \"range\" : [ - 30.0 , 30.0 ], \"axes\" : { \"X\" : { \"sig\" : \"ECT\" , \"unit\" : \"\u00b0C\" , \"range\" : [ - 50 , 200 ], \"prec\" : 1 , }, }, }, \"Turbo Speed\" : { \"unit\" : \"krpm\" , \"prec\" : 0 , \"range\" : [ 0 , 200 ], \"axes\" : { \"X\" : { \"sig\" : \"maf_cor\" , \"unit\" : \"g/s\" , \"range\" : [ 0 , 500 ], \"prec\" : 1 , }, \"Y\" : { \"sig\" : \"pr_comp\" , \"unit\" : \"ratio\" , \"range\" : [ 0 , 3 ], \"prec\" : 2 , }, }, }, \"pr_comp\" : { \"unit\" : \"\" , \"prec\" : 3 , \"range\" : [ 0.0 , 4.0 ], \"axes\" : { \"X\" : { \"sig\" : \"maf_cor\" , \"unit\" : \"g/s\" , \"range\" : [ 0 , 500.0 ], \"prec\" : 1 , }, \"Y\" : { \"sig\" : \"Turbo Speed\" , \"unit\" : \"krpm\" , \"range\" : [ 0 , 300.0 ], \"prec\" : 1 , }, }, }, \"Throttle PR\" : { \"unit\" : \"%\" , \"prec\" : 1 , \"range\" : [ 0 , 100 ], \"axes\" : { \"X\" : { \"sig\" : \"maf_cor\" , \"unit\" : \"g/s\" , \"range\" : [ 0 , 500 ], \"prec\" : 1 , }, \"Y\" : { \"sig\" : \"pr_throttle\" , \"unit\" : \"ratio\" , \"range\" : [ 0 , 1 ], \"prec\" : 2 , }, }, }, \"maf_nom\" : { \"unit\" : \"g/s\" , \"prec\" : 1 , \"range\" : [ 0 , 500 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 10000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"APS (Main)\" , \"unit\" : \"%\" , \"range\" : [ 0 , 100 ], \"prec\" : 1 , }, }, }, \"map_nom\" : { \"unit\" : \"kPa\" , \"prec\" : 1 , \"range\" : [ 0 , 300 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 10000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"maf_nom\" , \"unit\" : \"g/s\" , \"range\" : [ 0 , 500 ], \"prec\" : 1 , }, }, }, \"map_target_1\" : { \"unit\" : \"kPa\" , \"prec\" : 1 , \"range\" : [ 0 , 300 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 10000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"APS (Main)\" , \"unit\" : \"%\" , \"range\" : [ 0 , 100 ], \"prec\" : 1 , }, }, }, \"map_target_2\" : { \"unit\" : \"kPa\" , \"prec\" : 1 , \"range\" : [ 0 , 300 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 10000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"APS (Main)\" , \"unit\" : \"%\" , \"range\" : [ 0 , 100 ], \"prec\" : 1 , }, }, }, \"map_target_3\" : { \"unit\" : \"kPa\" , \"prec\" : 1 , \"range\" : [ 0 , 300 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 10000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"APS (Main)\" , \"unit\" : \"%\" , \"range\" : [ 0 , 100 ], \"prec\" : 1 , }, }, }, \"map_target_scaler\" : { \"unit\" : \"ratio\" , \"prec\" : 2 , \"range\" : [ 0 , 3 ], \"axes\" : { \"X\" : { \"sig\" : \"Active Boost Table\" , \"unit\" : \"\" , \"range\" : [ 1 , 3 ], \"prec\" : 0 , }, }, }, \"nturbo_target_scaler\" : { \"unit\" : \"ratio\" , \"prec\" : 2 , \"range\" : [ 0 , 3 ], \"axes\" : { \"X\" : { \"sig\" : \"APS (Main)\" , \"unit\" : \"%\" , \"range\" : [ 0 , 100 ], \"prec\" : 1 , }, }, }, \"pamb_ref\" : { \"unit\" : \"kPa\" , \"prec\" : 1 , \"range\" : [ 50 , 150 ], \"axes\" : {}, }, \"nturbo_max\" : { \"unit\" : \"krpm\" , \"prec\" : 1 , \"range\" : [ 0 , 300 ], \"axes\" : {}, }, } fueling_params = { # \"Fuel.Efficiency.Mode\": { # 0: \"Manifold Air Density\", # 1: \"Ambient Air Density\", # 2: \"Airbox Air Density\", # }, # \"Inlet.Manifold.Pressure.Mode\": { # 0: \"Automatic\", # 1: \"Estimate\", # 2: \"Sensor\", # }, # \"Engine.Rotors\": 2, # \"Engine.Rotor #.Bank\": 1, # \"Engine.Load.Normalised.Mode\": { # 0: \"Normal\", # 1: \"Inlet Manifold Pressure\", # 2: \"Throttle Position\", # }, # \"Inlet.Manifold.Pressure.Estimate.Mode\": { # 0: \"Ambient Pressure Relative\", # 1: \"100kPa Relative\", # }, } # TODO: complete calcd_sigs = [ \"Fueling.Error.Total\" , \"Fuel Table 1.Corrected\" , \"Wastegate %DC 1.Corrected\" , \"Wastegate %DC 2.Corrected\" , \"Wastegate %DC 3.Corrected\" , \"Boost Target 2.Corrected\" , \"Boost Target 2.Corrected\" , \"Boost Target 3.Corrected\" , \"Throttle PR.Corrected\" , \"Turbo Speed.Corrected\" , \"IAT Fuel Trim.Corrected\" , \"maf\" , \"rho_air\" , \"pr_comp\" , \"pr_throttle\" , \"maf_cor\" , \"fmaf_cor\" , \"maf\" , \"maf_est_cor\" , ] def __init__ ( self , caldir : str | Path = None , data : str | Path | Frame = None , gate : GateColl | str | Path = None , warning_dialog : Callable = None , ): super () . __init__ ( caldir = caldir , data = data , gate = gate , warning_dialog = warning_dialog , ) self . slow_sig = \"Engine Speed\" @property def n_cyl ( self ): return 4 @property def n_banks ( self ): return 1 @property def displacement ( self ): return 2.457 # @profile def check_substitute_sigs ( self ): \"\"\"Try to substitute for some common missing sigs.\"\"\" # Set units for pamb self . data [ \"CAN An 2\" ] . unit = \"mbar\" tmp = self . data [ \"CAN An 2\" ] . as_unit ( \"kPa\" ) tmp . name = \"pamb\" self . data . append ( tmp ) # Fix units that are mislabeled if self . data [ \"IAT Fuel Corr.\" ] . unit == \"%\" : self . data [ \"IAT Fuel Corr.\" ] . unit = \"%trim\" if self . data [ \"Post Start Enrich\" ] . unit == \"%\" : self . data [ \"Post Start Enrich\" ] . unit = \"%trim\" if self . data [ \"Warm Up Enrichment\" ] . unit == \"%\" : self . data [ \"Warm Up Enrichment\" ] . unit = \"%trim\" self . data [ \"IAT Fuel Corr.\" ] . convert_units ( \"ratio\" ) self . data [ \"Post Start Enrich\" ] . convert_units ( \"ratio\" ) self . data [ \"Warm Up Enrichment\" ] . convert_units ( \"ratio\" ) # @profile def check_sigs ( self ): \"\"\"Check that required input sigs are present.\"\"\" if self . table_data and self . data : self . check_substitute_sigs () required_sigs = set ( [ \"Lambda 1\" , \"Fuel Table 1\" , \"AFR/Lambda Target\" , \"CL Lambda Fuel Corr.\" , \"CL Lambda LT corr.\" , \"TPS (Main)\" , \"MAP\" , \"Engine Speed\" , \"IAT\" , \"Boost Target\" , \"GP Pressure 2 - Pboost\" , \"Boost Base DC\" , \"WGate DC\" , \"pamb\" , \"Turbo Speed\" , \"TPS (Main)\" , \"CAN An 2\" , \"GP Temperature 1 - Ambient Temp\" , \"Mass Air Flow Estimated\" , \"Load (Abs)\" , \"IAT Fuel Corr.\" , \"Post Start Enrich\" , \"Warm Up Enrichment\" , ] ) for table in self . fueling_tables : for axis in self . table_data [ table . replace ( \"#\" , \"1\" )] . axes : if axis . name not in self . calcd_sigs : required_sigs . add ( axis . name ) for table in self . reference_tables : for axis in self . table_data [ table . replace ( \"#\" , \"1\" )] . axes : if axis . name not in self . calcd_sigs : required_sigs . add ( axis . name ) for sig in self . gate . sigs : if sig not in self . calcd_sigs : required_sigs . add ( sig ) ok_slow = [] required_sigs = list ( required_sigs ) for sig in required_sigs : if sig not in ok_slow : self . slow_sig = sig break for sig in required_sigs : if ( sig not in ok_slow and self . data [ sig ] . period > self . data [ self . slow_sig ] . period ): self . slow_sig = sig missing = [] for sig in required_sigs : if sig not in self . data : missing . append ( sig ) if missing : raise ValueError ( f \"Missing required signals: { missing } \" ) # Build slower timeline for r-worded Link data slow_tline = TLine ( tstart = self . data . tstart , tend = self . data . tend , period = 0.04 ) self . resampled = self . data [ required_sigs ] . resample ( slow_tline ) self . data . math_tline = self . data [ self . slow_sig ] . tline self . resampled . math_tline = slow_tline self . resampled . name = \"resampled\" return True else : return False # @profile def update_calcd_data ( self , _ = None ): \"\"\"Update calculations for fitting/plotting.\"\"\" if self . _needs_calcs : tic = datetime . now () if self . check_sigs (): tmp = ( self . resampled [ \"IAT Fuel Corr.\" ] * self . resampled [ \"Post Start Enrich\" ] * self . resampled [ \"Warm Up Enrichment\" ] ) tmp . name = \"Fueling.Corr.logged\" self . resampled . append ( tmp ) tmp = self . table_data [ \"IAT Fuel Trim\" ] . interp ( self . resampled ) tmp . name = \"IAT Fuel Corr new\" self . resampled . append ( tmp . convert_units ( \"ratio\" )) tmp = self . table_data [ \"Warm Up Enrichment\" ] . interp ( self . resampled ) tmp . name = \"ECT Fuel Corr new\" self . resampled . append ( tmp . convert_units ( \"ratio\" )) tmp = self . table_data [ \"Fuel Table 1\" ] . interp ( self . resampled ) tmp . name = \"Fuel Table 1.new\" self . resampled . append ( tmp ) tmp = ( self . resampled [ \"IAT Fuel Corr new\" ] * self . resampled [ \"Post Start Enrich\" ] # Shortcut assumes const * self . resampled [ \"ECT Fuel Corr new\" ] ) tmp . name = \"Fueling.Corr.new\" self . resampled . append ( tmp ) tmp = ( ( self . resampled [ \"CL Lambda Fuel Corr.\" ] . convert_units ( \"ratio\" ) + 1 ) * ( self . resampled [ \"CL Lambda LT corr.\" ] . convert_units ( \"ratio\" ) + 1 ) * self . resampled [ \"Lambda 1\" ] / self . resampled [ \"AFR/Lambda Target\" ] ) tmp . name = \"Fueling.Error.Total\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ \"Fueling.Error.Total\" ] * self . resampled [ \"Fuel Table 1\" ] / self . resampled [ \"Fueling.Corr.new\" ] * self . resampled [ \"Fueling.Corr.logged\" ] ) tmp . name = \"Fuel Table 1.Corrected\" tmp . unit = \"%\" self . resampled . append ( tmp ) tmp = ( self . resampled [ \"Fueling.Error.Total\" ] * self . resampled [ \"Fuel Table 1\" ] / self . resampled [ \"Fuel Table 1.new\" ] * self . resampled [ \"Warm Up Enrichment\" ] / self . resampled [ \"ECT Fuel Corr.new\" ] * self . resampled [ \"IAT Fuel Corr.\" ] ) tmp . name = \"IAT Fuel Trim.Corrected\" self . resampled . append ( tmp . convert_units ( \"%trim\" )) tmp = ( self . resampled [ \"Fueling.Error.Total\" ] * self . resampled [ \"Fuel Table 1\" ] / self . resampled [ \"Fuel Table 1.new\" ] * self . resampled [ \"IAT Fuel Corr.\" ] / self . resampled [ \"IAT Fuel Corr.new\" ] * self . resampled [ \"Warm Up Enrichment\" ] ) tmp . name = \"Warm Up Enrichment.Corrected\" self . resampled . append ( tmp . convert_units ( \"%trim\" )) # WGC pboost_d = ( self . resampled [ \"GP Pressure 2 - Pboost\" ] - self . resampled [ \"Boost Target\" ] ) inds = abs ( pboost_d . data ) < 10 tmp = self . resampled [ \"Boost Base DC\" ] . data tmp [ inds ] = self . resampled [ \"WGate DC\" ][ inds ] tmpsig = Sig ( self . resampled [ \"Boost Base DC\" ]) tmpsig . name = \"Wastegate %DC 1.Corrected\" self . resampled . append ( tmpsig ) tmpsig = Sig ( self . resampled [ \"Boost Base DC\" ]) tmpsig . name = \"Wastegate %DC 2.Corrected\" self . resampled . append ( tmpsig ) tmpsig = Sig ( self . resampled [ \"Boost Base DC\" ]) tmpsig . name = \"Wastegate %DC 3.Corrected\" self . resampled . append ( tmpsig ) if self . table_data : self . resampled . append ( self . resampled [ \"Engine Speed\" ] . dot ( n_win = 9 )) self . resampled . remove ( \"MAP_dot\" ) self . resampled . append ( self . resampled [ \"MAP\" ] . dot ( n_win = 13 )) # Calcs for boost target tmpsig = Sig ( data = self . resampled [ \"Lambda 1\" ], name = \"AFR_Lambda Target.Corrected\" , ) self . resampled . append ( tmpsig ) tmpsig = ( self . resampled [ \"GP Pressure 2 - Pboost\" ] / self . resampled [ \"pamb\" ] ) tmpsig . name = \"pr_comp.Corrected\" self . resampled . append ( tmpsig ) tmpsig = Sig ( tmpsig , name = \"pr_comp\" ) self . resampled . append ( tmpsig ) tmpsig = Sig ( data = np . sqrt ( self . resampled [ \"GP Temperature 1 - Ambient Temp\" ] . as_unit ( \"k\" ) / 288 ) * self . resampled [ \"pamb\" ] / 101.3 , unit = \"ratio\" , name = \"fmaf_cor\" , tline = self . resampled [ \"pamb\" ] . tline , ) self . resampled . append ( tmpsig ) tmpsig = ( self . resampled [ \"Load (Abs)\" ] . as_unit ( \"ratio\" ) * ( self . resampled [ \"CL Lambda Fuel Corr.\" ] . as_unit ( \"ratio\" ) + 1 ) * ( self . resampled [ \"CL Lambda LT corr.\" ] . as_unit ( \"ratio\" ) + 1 ) * self . resampled [ \"Engine Speed\" ] / ( 60 * 2 ) * 1.188 # Density of dry air * self . displacement # Displacememt * 1.0 # Fudge factor ) tmpsig . name = \"maf\" tmpsig . unit = \"g/s\" self . resampled . append ( tmpsig ) tmpsig = self . resampled [ \"maf\" ] * self . resampled [ \"fmaf_cor\" ] tmpsig . name = \"maf_cor\" self . resampled . append ( tmpsig ) tmpsig = ( self . resampled [ \"Mass Air Flow Estimated\" ] * self . resampled [ \"fmaf_cor\" ] ) tmpsig . name = \"maf_est_cor\" self . resampled . append ( tmpsig ) tmpsig = Sig ( data = self . resampled [ \"Turbo Speed\" ], name = \"Turbo Speed.Corrected\" , ) self . resampled . append ( tmpsig ) tmpsig = Sig ( data = self . resampled [ \"MAP\" ] / self . resampled [ \"GP Pressure 2 - Pboost\" ], name = \"pr_throttle\" , unit = \"ratio\" , ) self . resampled . append ( tmpsig ) tmpsig = Sig ( data = self . resampled [ \"TPS (Main)\" ], name = \"Throttle PR.Corrected\" , unit = \"%\" , ) self . resampled . append ( tmpsig ) self . resampled . append ( self . table_data [ \"maf_nom\" ] . interp ( self . resampled )) [ nmots , maps ] = np . meshgrid ( np . arange ( min ( self . table_data [ \"Fuel Table 1\" ] . axes [ 0 ]), max ( self . table_data [ \"Fuel Table 1\" ] . axes [ 0 ]), 100 , ), np . arange ( min ( self . table_data [ \"Fuel Table 1\" ] . axes [ 1 ]), max ( self . table_data [ \"Fuel Table 1\" ] . axes [ 1 ]), 4 , ), ) nvmaps = np . append ( nmots . reshape (( - 1 , 1 )), maps . reshape (( - 1 , 1 )), axis = 1 , ) ves = self . table_data [ \"Fuel Table 1\" ] . interp ( nvmaps ) rls = ves * maps . ravel () / 101.3 # TODO: Add tint comp to this calc mafs = rls / 100 * self . displacement * nmots . ravel () / 60 / 2 * 1.188 mapscatter = ScatterData ( [ nmots . ravel (), mafs . ravel (), maps . ravel (), ], name = \"Calculated\" , color = ves , color_name = \"Vol Eff\" , ) self . table_data [ \"map_nom\" ] . scatter_data = mapscatter [ nmots , apss ] = np . meshgrid ( np . arange ( min ( self . table_data [ \"Fuel Table 1\" ] . axes [ 0 ]), max ( self . table_data [ \"Fuel Table 1\" ] . axes [ 0 ]), 100 , ), np . arange ( 0 , 100 , 2 ), ) nvapss = np . append ( nmots . reshape (( - 1 , 1 )), apss . reshape (( - 1 , 1 )), axis = 1 , ) for i , scaler in enumerate ( self . table_data [ \"map_target_scaler\" ] . data ): mafsnom : np . ndarray = ( self . table_data [ \"maf_nom\" ] . interp ( nvapss ) * scaler ) nvmafs = np . append ( nmots . reshape (( - 1 , 1 )), mafsnom . reshape (( - 1 , 1 )), axis = 1 , ) mapstarget = self . table_data [ \"map_nom\" ] . interp ( nvmafs ) maptgtscatter = ScatterData ( [ nmots . ravel (), apss . ravel (), mapstarget . ravel (), ], name = \"Calculated\" , color = mafsnom , color_name = \"Maf Target\" , color_unit = \"g/s\" , ) self . table_data [ f \"map_target_ { i + 1 } \" ] . scatter_data = maptgtscatter pr_wot_nom = ( mapstarget / self . table_data [ \"pamb_ref\" ] . data [ 0 ] ) # Target pr1 for wot prmafs = np . append ( mafsnom . reshape (( - 1 , 1 )), pr_wot_nom . reshape (( - 1 , 1 )), axis = 1 , ) nturbo_est = self . table_data [ \"Turbo Speed\" ] . interp ( prmafs ) nturbo_max = min ( [ max ( nturbo_est ), self . table_data [ \"nturbo_max\" ] . data [ 0 ]] ) fturbo = self . table_data [ \"nturbo_target_scaler\" ] . interp ( apss . reshape (( - 1 , 1 )) ) nturbo_nom = nturbo_max * fturbo mafvnts = np . append ( mafsnom . reshape (( - 1 , 1 )), nturbo_nom . reshape (( - 1 , 1 )), axis = 1 , ) pr_comp_nom = self . table_data [ \"pr_comp\" ] . interp ( mafvnts ) # ath_map = self.table_data['E-Throttle 1 Target'].interp(nvapss) # pr_map = self.table_data['Throttle PR'].interp() boosttgtsct = ScatterData ( [ nmots . ravel (), apss . ravel (), np . maximum ( pr_comp_nom . ravel () * self . table_data [ \"pamb_ref\" ] . data [ 0 ], mapstarget , ), ], name = \"Calculated\" , color = nturbo_nom , color_name = \"Nturbo Target\" , color_unit = \"krpm\" , ) self . table_data [ f \"Boost Target { i + 1 } \" ] . scatter_data = boosttgtsct pr_throttle_nom = pr_wot_nom / pr_comp_nom mafvprs = np . append ( mafsnom . reshape (( - 1 , 1 )), pr_throttle_nom . reshape (( - 1 , 1 )), axis = 1 , ) if i == 2 : # Calc throttle target for boost3 etcnom = self . table_data [ \"Throttle PR\" ] . interp ( mafvprs ) etctgt = ScatterData ( [ nmots . ravel (), apss . ravel (), etcnom . ravel ()], name = \"Calculated\" , color = nturbo_nom , color_name = \"Nturbo Target\" , color_unit = \"krpm\" , ) self . table_data [ \"E-Throttle 1 Target\" ] . scatter_data = etctgt # TODO: Fix here for boost 1 and 2 toc = datetime . now () - tic _LOGGER . debug ( \"Firmware calcs in %.3f \" , toc . total_seconds ()) # Set some ranges self . resampled [ \"Engine Speed\" ] . data_range = [ 0 , 9000 ] self . resampled [ \"AFR/Lambda Target\" ] . data_range = [ 0.6 , 1.4 , ] self . _needs_calcs = False self . update_scatter_data () def update_scatter_data ( self ): \"\"\"Update scatter data for fitting.\"\"\" # Build signal list if self . _needs_calcs : self . update_calcd_data () for table in self . table_data : if f \" { table . name } .Corrected\" in self . resampled : if self . tabs [ table . name ] . additional_gate : gate = GateCollAND ( [ self . gate , self . tabs [ table . name ] . additional_gate , ] ) else : gate = self . gate tmp = [] for axis in table . axes : tmp . append ( self . resampled [ f \" { axis . name } \" ] . valid ( gate ) . resample ( self . resampled . math_tline ) ) tmp . append ( self . resampled [ f \" { table . name } .Corrected\" ] . valid ( gate ) . resample ( self . resampled . math_tline ) ) if table . name == \"Fuel Table 1\" and False : color = self . resampled [ \"IAT\" ] color_unit = \"\u00b0C\" color_name = \"IAT\" color_range = [ 10 , 60 ] else : color = None color_name = None color_unit = None color_range = None table . scatter_data = ScatterData ( data = tmp , name = \"Measured\" , color = color , color_unit = color_unit , color_name = color_name , color_range = color_range , ) . clean () table . scatter_data [ - 1 ] . color_from_density () # else: # table.scatter_data = None # Removed 2/6/24 to allowe defining scatter data elsewhere def normalize_cyl_trims ( self ): pass","title":"G4xXtreme"},{"location":"reference/ccg/controllers/link/#ccg.controllers.link.G4xXtreme.check_sigs","text":"Check that required input sigs are present. Source code in ccg\\controllers\\link.py 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 def check_sigs ( self ): \"\"\"Check that required input sigs are present.\"\"\" if self . table_data and self . data : self . check_substitute_sigs () required_sigs = set ( [ \"Lambda 1\" , \"Fuel Table 1\" , \"AFR/Lambda Target\" , \"CL Lambda Fuel Corr.\" , \"CL Lambda LT corr.\" , \"TPS (Main)\" , \"MAP\" , \"Engine Speed\" , \"IAT\" , \"Boost Target\" , \"GP Pressure 2 - Pboost\" , \"Boost Base DC\" , \"WGate DC\" , \"pamb\" , \"Turbo Speed\" , \"TPS (Main)\" , \"CAN An 2\" , \"GP Temperature 1 - Ambient Temp\" , \"Mass Air Flow Estimated\" , \"Load (Abs)\" , \"IAT Fuel Corr.\" , \"Post Start Enrich\" , \"Warm Up Enrichment\" , ] ) for table in self . fueling_tables : for axis in self . table_data [ table . replace ( \"#\" , \"1\" )] . axes : if axis . name not in self . calcd_sigs : required_sigs . add ( axis . name ) for table in self . reference_tables : for axis in self . table_data [ table . replace ( \"#\" , \"1\" )] . axes : if axis . name not in self . calcd_sigs : required_sigs . add ( axis . name ) for sig in self . gate . sigs : if sig not in self . calcd_sigs : required_sigs . add ( sig ) ok_slow = [] required_sigs = list ( required_sigs ) for sig in required_sigs : if sig not in ok_slow : self . slow_sig = sig break for sig in required_sigs : if ( sig not in ok_slow and self . data [ sig ] . period > self . data [ self . slow_sig ] . period ): self . slow_sig = sig missing = [] for sig in required_sigs : if sig not in self . data : missing . append ( sig ) if missing : raise ValueError ( f \"Missing required signals: { missing } \" ) # Build slower timeline for r-worded Link data slow_tline = TLine ( tstart = self . data . tstart , tend = self . data . tend , period = 0.04 ) self . resampled = self . data [ required_sigs ] . resample ( slow_tline ) self . data . math_tline = self . data [ self . slow_sig ] . tline self . resampled . math_tline = slow_tline self . resampled . name = \"resampled\" return True else : return False","title":"check_sigs"},{"location":"reference/ccg/controllers/link/#ccg.controllers.link.G4xXtreme.check_substitute_sigs","text":"Try to substitute for some common missing sigs. Source code in ccg\\controllers\\link.py 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 def check_substitute_sigs ( self ): \"\"\"Try to substitute for some common missing sigs.\"\"\" # Set units for pamb self . data [ \"CAN An 2\" ] . unit = \"mbar\" tmp = self . data [ \"CAN An 2\" ] . as_unit ( \"kPa\" ) tmp . name = \"pamb\" self . data . append ( tmp ) # Fix units that are mislabeled if self . data [ \"IAT Fuel Corr.\" ] . unit == \"%\" : self . data [ \"IAT Fuel Corr.\" ] . unit = \"%trim\" if self . data [ \"Post Start Enrich\" ] . unit == \"%\" : self . data [ \"Post Start Enrich\" ] . unit = \"%trim\" if self . data [ \"Warm Up Enrichment\" ] . unit == \"%\" : self . data [ \"Warm Up Enrichment\" ] . unit = \"%trim\" self . data [ \"IAT Fuel Corr.\" ] . convert_units ( \"ratio\" ) self . data [ \"Post Start Enrich\" ] . convert_units ( \"ratio\" ) self . data [ \"Warm Up Enrichment\" ] . convert_units ( \"ratio\" )","title":"check_substitute_sigs"},{"location":"reference/ccg/controllers/link/#ccg.controllers.link.G4xXtreme.update_calcd_data","text":"Update calculations for fitting/plotting. Source code in ccg\\controllers\\link.py 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 def update_calcd_data ( self , _ = None ): \"\"\"Update calculations for fitting/plotting.\"\"\" if self . _needs_calcs : tic = datetime . now () if self . check_sigs (): tmp = ( self . resampled [ \"IAT Fuel Corr.\" ] * self . resampled [ \"Post Start Enrich\" ] * self . resampled [ \"Warm Up Enrichment\" ] ) tmp . name = \"Fueling.Corr.logged\" self . resampled . append ( tmp ) tmp = self . table_data [ \"IAT Fuel Trim\" ] . interp ( self . resampled ) tmp . name = \"IAT Fuel Corr new\" self . resampled . append ( tmp . convert_units ( \"ratio\" )) tmp = self . table_data [ \"Warm Up Enrichment\" ] . interp ( self . resampled ) tmp . name = \"ECT Fuel Corr new\" self . resampled . append ( tmp . convert_units ( \"ratio\" )) tmp = self . table_data [ \"Fuel Table 1\" ] . interp ( self . resampled ) tmp . name = \"Fuel Table 1.new\" self . resampled . append ( tmp ) tmp = ( self . resampled [ \"IAT Fuel Corr new\" ] * self . resampled [ \"Post Start Enrich\" ] # Shortcut assumes const * self . resampled [ \"ECT Fuel Corr new\" ] ) tmp . name = \"Fueling.Corr.new\" self . resampled . append ( tmp ) tmp = ( ( self . resampled [ \"CL Lambda Fuel Corr.\" ] . convert_units ( \"ratio\" ) + 1 ) * ( self . resampled [ \"CL Lambda LT corr.\" ] . convert_units ( \"ratio\" ) + 1 ) * self . resampled [ \"Lambda 1\" ] / self . resampled [ \"AFR/Lambda Target\" ] ) tmp . name = \"Fueling.Error.Total\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ \"Fueling.Error.Total\" ] * self . resampled [ \"Fuel Table 1\" ] / self . resampled [ \"Fueling.Corr.new\" ] * self . resampled [ \"Fueling.Corr.logged\" ] ) tmp . name = \"Fuel Table 1.Corrected\" tmp . unit = \"%\" self . resampled . append ( tmp ) tmp = ( self . resampled [ \"Fueling.Error.Total\" ] * self . resampled [ \"Fuel Table 1\" ] / self . resampled [ \"Fuel Table 1.new\" ] * self . resampled [ \"Warm Up Enrichment\" ] / self . resampled [ \"ECT Fuel Corr.new\" ] * self . resampled [ \"IAT Fuel Corr.\" ] ) tmp . name = \"IAT Fuel Trim.Corrected\" self . resampled . append ( tmp . convert_units ( \"%trim\" )) tmp = ( self . resampled [ \"Fueling.Error.Total\" ] * self . resampled [ \"Fuel Table 1\" ] / self . resampled [ \"Fuel Table 1.new\" ] * self . resampled [ \"IAT Fuel Corr.\" ] / self . resampled [ \"IAT Fuel Corr.new\" ] * self . resampled [ \"Warm Up Enrichment\" ] ) tmp . name = \"Warm Up Enrichment.Corrected\" self . resampled . append ( tmp . convert_units ( \"%trim\" )) # WGC pboost_d = ( self . resampled [ \"GP Pressure 2 - Pboost\" ] - self . resampled [ \"Boost Target\" ] ) inds = abs ( pboost_d . data ) < 10 tmp = self . resampled [ \"Boost Base DC\" ] . data tmp [ inds ] = self . resampled [ \"WGate DC\" ][ inds ] tmpsig = Sig ( self . resampled [ \"Boost Base DC\" ]) tmpsig . name = \"Wastegate %DC 1.Corrected\" self . resampled . append ( tmpsig ) tmpsig = Sig ( self . resampled [ \"Boost Base DC\" ]) tmpsig . name = \"Wastegate %DC 2.Corrected\" self . resampled . append ( tmpsig ) tmpsig = Sig ( self . resampled [ \"Boost Base DC\" ]) tmpsig . name = \"Wastegate %DC 3.Corrected\" self . resampled . append ( tmpsig ) if self . table_data : self . resampled . append ( self . resampled [ \"Engine Speed\" ] . dot ( n_win = 9 )) self . resampled . remove ( \"MAP_dot\" ) self . resampled . append ( self . resampled [ \"MAP\" ] . dot ( n_win = 13 )) # Calcs for boost target tmpsig = Sig ( data = self . resampled [ \"Lambda 1\" ], name = \"AFR_Lambda Target.Corrected\" , ) self . resampled . append ( tmpsig ) tmpsig = ( self . resampled [ \"GP Pressure 2 - Pboost\" ] / self . resampled [ \"pamb\" ] ) tmpsig . name = \"pr_comp.Corrected\" self . resampled . append ( tmpsig ) tmpsig = Sig ( tmpsig , name = \"pr_comp\" ) self . resampled . append ( tmpsig ) tmpsig = Sig ( data = np . sqrt ( self . resampled [ \"GP Temperature 1 - Ambient Temp\" ] . as_unit ( \"k\" ) / 288 ) * self . resampled [ \"pamb\" ] / 101.3 , unit = \"ratio\" , name = \"fmaf_cor\" , tline = self . resampled [ \"pamb\" ] . tline , ) self . resampled . append ( tmpsig ) tmpsig = ( self . resampled [ \"Load (Abs)\" ] . as_unit ( \"ratio\" ) * ( self . resampled [ \"CL Lambda Fuel Corr.\" ] . as_unit ( \"ratio\" ) + 1 ) * ( self . resampled [ \"CL Lambda LT corr.\" ] . as_unit ( \"ratio\" ) + 1 ) * self . resampled [ \"Engine Speed\" ] / ( 60 * 2 ) * 1.188 # Density of dry air * self . displacement # Displacememt * 1.0 # Fudge factor ) tmpsig . name = \"maf\" tmpsig . unit = \"g/s\" self . resampled . append ( tmpsig ) tmpsig = self . resampled [ \"maf\" ] * self . resampled [ \"fmaf_cor\" ] tmpsig . name = \"maf_cor\" self . resampled . append ( tmpsig ) tmpsig = ( self . resampled [ \"Mass Air Flow Estimated\" ] * self . resampled [ \"fmaf_cor\" ] ) tmpsig . name = \"maf_est_cor\" self . resampled . append ( tmpsig ) tmpsig = Sig ( data = self . resampled [ \"Turbo Speed\" ], name = \"Turbo Speed.Corrected\" , ) self . resampled . append ( tmpsig ) tmpsig = Sig ( data = self . resampled [ \"MAP\" ] / self . resampled [ \"GP Pressure 2 - Pboost\" ], name = \"pr_throttle\" , unit = \"ratio\" , ) self . resampled . append ( tmpsig ) tmpsig = Sig ( data = self . resampled [ \"TPS (Main)\" ], name = \"Throttle PR.Corrected\" , unit = \"%\" , ) self . resampled . append ( tmpsig ) self . resampled . append ( self . table_data [ \"maf_nom\" ] . interp ( self . resampled )) [ nmots , maps ] = np . meshgrid ( np . arange ( min ( self . table_data [ \"Fuel Table 1\" ] . axes [ 0 ]), max ( self . table_data [ \"Fuel Table 1\" ] . axes [ 0 ]), 100 , ), np . arange ( min ( self . table_data [ \"Fuel Table 1\" ] . axes [ 1 ]), max ( self . table_data [ \"Fuel Table 1\" ] . axes [ 1 ]), 4 , ), ) nvmaps = np . append ( nmots . reshape (( - 1 , 1 )), maps . reshape (( - 1 , 1 )), axis = 1 , ) ves = self . table_data [ \"Fuel Table 1\" ] . interp ( nvmaps ) rls = ves * maps . ravel () / 101.3 # TODO: Add tint comp to this calc mafs = rls / 100 * self . displacement * nmots . ravel () / 60 / 2 * 1.188 mapscatter = ScatterData ( [ nmots . ravel (), mafs . ravel (), maps . ravel (), ], name = \"Calculated\" , color = ves , color_name = \"Vol Eff\" , ) self . table_data [ \"map_nom\" ] . scatter_data = mapscatter [ nmots , apss ] = np . meshgrid ( np . arange ( min ( self . table_data [ \"Fuel Table 1\" ] . axes [ 0 ]), max ( self . table_data [ \"Fuel Table 1\" ] . axes [ 0 ]), 100 , ), np . arange ( 0 , 100 , 2 ), ) nvapss = np . append ( nmots . reshape (( - 1 , 1 )), apss . reshape (( - 1 , 1 )), axis = 1 , ) for i , scaler in enumerate ( self . table_data [ \"map_target_scaler\" ] . data ): mafsnom : np . ndarray = ( self . table_data [ \"maf_nom\" ] . interp ( nvapss ) * scaler ) nvmafs = np . append ( nmots . reshape (( - 1 , 1 )), mafsnom . reshape (( - 1 , 1 )), axis = 1 , ) mapstarget = self . table_data [ \"map_nom\" ] . interp ( nvmafs ) maptgtscatter = ScatterData ( [ nmots . ravel (), apss . ravel (), mapstarget . ravel (), ], name = \"Calculated\" , color = mafsnom , color_name = \"Maf Target\" , color_unit = \"g/s\" , ) self . table_data [ f \"map_target_ { i + 1 } \" ] . scatter_data = maptgtscatter pr_wot_nom = ( mapstarget / self . table_data [ \"pamb_ref\" ] . data [ 0 ] ) # Target pr1 for wot prmafs = np . append ( mafsnom . reshape (( - 1 , 1 )), pr_wot_nom . reshape (( - 1 , 1 )), axis = 1 , ) nturbo_est = self . table_data [ \"Turbo Speed\" ] . interp ( prmafs ) nturbo_max = min ( [ max ( nturbo_est ), self . table_data [ \"nturbo_max\" ] . data [ 0 ]] ) fturbo = self . table_data [ \"nturbo_target_scaler\" ] . interp ( apss . reshape (( - 1 , 1 )) ) nturbo_nom = nturbo_max * fturbo mafvnts = np . append ( mafsnom . reshape (( - 1 , 1 )), nturbo_nom . reshape (( - 1 , 1 )), axis = 1 , ) pr_comp_nom = self . table_data [ \"pr_comp\" ] . interp ( mafvnts ) # ath_map = self.table_data['E-Throttle 1 Target'].interp(nvapss) # pr_map = self.table_data['Throttle PR'].interp() boosttgtsct = ScatterData ( [ nmots . ravel (), apss . ravel (), np . maximum ( pr_comp_nom . ravel () * self . table_data [ \"pamb_ref\" ] . data [ 0 ], mapstarget , ), ], name = \"Calculated\" , color = nturbo_nom , color_name = \"Nturbo Target\" , color_unit = \"krpm\" , ) self . table_data [ f \"Boost Target { i + 1 } \" ] . scatter_data = boosttgtsct pr_throttle_nom = pr_wot_nom / pr_comp_nom mafvprs = np . append ( mafsnom . reshape (( - 1 , 1 )), pr_throttle_nom . reshape (( - 1 , 1 )), axis = 1 , ) if i == 2 : # Calc throttle target for boost3 etcnom = self . table_data [ \"Throttle PR\" ] . interp ( mafvprs ) etctgt = ScatterData ( [ nmots . ravel (), apss . ravel (), etcnom . ravel ()], name = \"Calculated\" , color = nturbo_nom , color_name = \"Nturbo Target\" , color_unit = \"krpm\" , ) self . table_data [ \"E-Throttle 1 Target\" ] . scatter_data = etctgt # TODO: Fix here for boost 1 and 2 toc = datetime . now () - tic _LOGGER . debug ( \"Firmware calcs in %.3f \" , toc . total_seconds ()) # Set some ranges self . resampled [ \"Engine Speed\" ] . data_range = [ 0 , 9000 ] self . resampled [ \"AFR/Lambda Target\" ] . data_range = [ 0.6 , 1.4 , ] self . _needs_calcs = False self . update_scatter_data ()","title":"update_calcd_data"},{"location":"reference/ccg/controllers/link/#ccg.controllers.link.G4xXtreme.update_scatter_data","text":"Update scatter data for fitting. Source code in ccg\\controllers\\link.py 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 def update_scatter_data ( self ): \"\"\"Update scatter data for fitting.\"\"\" # Build signal list if self . _needs_calcs : self . update_calcd_data () for table in self . table_data : if f \" { table . name } .Corrected\" in self . resampled : if self . tabs [ table . name ] . additional_gate : gate = GateCollAND ( [ self . gate , self . tabs [ table . name ] . additional_gate , ] ) else : gate = self . gate tmp = [] for axis in table . axes : tmp . append ( self . resampled [ f \" { axis . name } \" ] . valid ( gate ) . resample ( self . resampled . math_tline ) ) tmp . append ( self . resampled [ f \" { table . name } .Corrected\" ] . valid ( gate ) . resample ( self . resampled . math_tline ) ) if table . name == \"Fuel Table 1\" and False : color = self . resampled [ \"IAT\" ] color_unit = \"\u00b0C\" color_name = \"IAT\" color_range = [ 10 , 60 ] else : color = None color_name = None color_unit = None color_range = None table . scatter_data = ScatterData ( data = tmp , name = \"Measured\" , color = color , color_unit = color_unit , color_name = color_name , color_range = color_range , ) . clean () table . scatter_data [ - 1 ] . color_from_density ()","title":"update_scatter_data"},{"location":"reference/ccg/controllers/link/#ccg.controllers.link.read_cal_xml_async","text":"Read and parse a single cal XML file Parameters: caltbl ( str | Path ) \u2013 path to file Returns: Tbl \u2013 parsed Tbl Source code in ccg\\controllers\\link.py 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 async def read_cal_xml_async ( caltbl : Path ) -> Tbl : \"\"\"Read and parse a single cal XML file Parameters ---------- caltbl : str | Path path to file Returns ------- Tbl parsed Tbl \"\"\" tree = await asyncio . to_thread ( ET . parse , caltbl ) root = await asyncio . to_thread ( tree . getroot ) tmp = await asyncio . to_thread ( root . find , \"LinkTableImportExportInfoV2\" ) tmp = tmp . attrib # ncol = tmp['ColumnCount'] xs = np . array ( tmp [ \"XAxisValues\" ] . split ( \",\" ), dtype = np . float32 ) xs = xs [ np . append ( True , np . diff ( xs ) > 0 )] xs = Axis ( xs , name = \"X\" ) axes = [ xs ] size = len ( xs ) if ( \"YAxisValues\" in tmp and tmp [ \"YAxisFunction\" ] != \"0\" and len ( tmp [ \"YAxisValues\" ]) > 0 ): ys = np . array ( tmp [ \"YAxisValues\" ] . split ( \",\" ), dtype = np . float32 ) ys = ys [ np . append ( True , np . diff ( ys ) > 0 )] ys = Axis ( ys , name = \"Y\" ) axes . append ( ys ) size = ( len ( xs ), len ( ys )) data = np . array ( tmp [ \"CellValues\" ] . split ( \",\" ), dtype = np . float32 ) data = data . reshape ( size , order = \"F\" ) par = Tbl ( data = data , name = caltbl . stem , axes = axes ) return par","title":"read_cal_xml_async"},{"location":"reference/ccg/controllers/link/#ccg.controllers.link.read_cals","text":"This function is deprecated. Use read_cals_async() instead. Parameters: dirname ( Path ) \u2013 The directory name where the calibration tables are located. Returns: Tbls \u2013 The calibration tables. Notes .. deprecated:: 1.0.0 Use read_cals_async() instead. Source code in ccg\\controllers\\link.py 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 def read_cals ( dirname : Path | str ) -> Tbls : \"\"\" This function is deprecated. Use `read_cals_async()` instead. Parameters ---------- dirname : Path The directory name where the calibration tables are located. Returns ------- Tbls The calibration tables. Notes ----- .. deprecated:: 1.0.0 Use `read_cals_async()` instead. \"\"\" tbls = Tbls () for caltbl in Path ( dirname ) . glob ( \"*.lte\" ): tree = ET . parse ( caltbl ) root = tree . getroot () tmp = root . find ( \"LinkTableImportExportInfoV2\" ) . attrib # ncol = tmp['ColumnCount'] xs = np . array ( tmp [ \"XAxisValues\" ] . split ( \",\" ), dtype = np . float32 ) xs = xs [ np . append ( True , np . diff ( xs ) > 0 )] xs = Axis ( xs , name = \"X\" ) axes = [ xs ] size = len ( xs ) if ( \"YAxisValues\" in tmp and tmp [ \"YAxisFunction\" ] != \"0\" and len ( tmp [ \"YAxisValues\" ]) > 0 ): ys = np . array ( tmp [ \"YAxisValues\" ] . split ( \",\" ), dtype = np . float32 ) ys = ys [ np . append ( True , np . diff ( ys ) > 0 )] ys = Axis ( ys , name = \"Y\" ) axes . append ( ys ) size = ( len ( xs ), len ( ys )) data = np . array ( tmp [ \"CellValues\" ] . split ( \",\" ), dtype = np . float32 ) data = data . reshape ( size , order = \"F\" ) par = Tbl ( data = data , name = caltbl . stem , axes = axes ) tbls . append ( par ) for partbl in Path ( dirname ) . glob ( \"*tbl.json\" ): pars = Tbl () . from_file ( partbl ) tbls . append ( pars ) return tbls","title":"read_cals"},{"location":"reference/ccg/controllers/link/#ccg.controllers.link.read_cals_async","text":"Read cal's async Parameters: dirname ( str | Path ) \u2013 Directory of cal files Returns: Tbls \u2013 Table data Source code in ccg\\controllers\\link.py 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 async def read_cals_async ( dirname : str | Path ) -> Tbls : \"\"\"Read cal's async Parameters ---------- dirname : str | Path Directory of cal files Returns ------- Tbls Table data \"\"\" tbldata = Tbls () tasks = [ read_cal_xml_async ( caltbl ) for caltbl in Path ( dirname ) . glob ( \"*.lte\" )] tasks . extend ( [ Tbl () . from_file_async ( partbl ) for partbl in Path ( dirname ) . glob ( \"*.tbl.json\" )] ) pars = await asyncio . gather ( * tasks ) tbldata . append ( pars ) return tbldata","title":"read_cals_async"},{"location":"reference/ccg/controllers/link/#ccg.controllers.link.read_link_datafile","text":"Reads a link formatted data file Source code in ccg\\controllers\\link.py 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 @profile def read_link_datafile ( filename : str | Path ) -> Frame : \"\"\"Reads a link formatted data file\"\"\" tic = datetime . now () tline_col = 0 data_row = 4 if isinstance ( filename , str ): filename = Path ( filename ) res = Frame ( name = filename . stem ) try : with open ( filename , \"r\" , encoding = \"utf8\" ) as file : csvreader = csv . reader ( file , dialect = \"excel\" ) header = [ next ( csvreader ) for _ in range ( data_row )] # 4 rows of header info data = np . loadtxt ( file , skiprows = 0 , delimiter = \",\" ) # Can use loadtxt since uniform except ValueError as err : err . add_note ( \"Likely due to quoted numerics in Link file. Open and resave in Excel to correct\" ) raise # TODO: FIX HERE to automagically fix link's r-worded files toc = datetime . now () - tic _LOGGER . debug ( \"read %s in %.3f .\" , filename . stem , toc . total_seconds ()) tic = datetime . now () sig_args = [ { \"name\" : name , \"unit\" : unit } for name , unit in zip ( header [ 1 ], header [ 2 ]) ] # Check for duplicate names and add _dup existing = [] for sig in sig_args : if sig [ \"name\" ] not in existing : existing . append ( sig [ \"name\" ]) else : existing . append ( sig [ \"name\" ] + \"_dup\" ) sig [ \"name\" ] = sig [ \"name\" ] + \"_dup\" tmp = data [:, tline_col ] . ravel () tline = TLine ( tmp ) for i , kwargs in enumerate ( sig_args ): if i != tline_col : sigtype = type ( data [ 0 , i ]) sigdata = data [:, i ] . ravel () . astype ( sigtype ) if sigtype is str : try : sigdata = sigdata . astype ( float ) except ValueError : pass new_sig = Sig ( data = sigdata , tline = tline , ** kwargs , ) res . append ( new_sig ) toc = datetime . now () - tic _LOGGER . debug ( \"built frame in %.3f .\" , toc . total_seconds ()) tic = datetime . now () return res","title":"read_link_datafile"},{"location":"reference/ccg/controllers/motec/","text":"Functions and classes for working with MoTeC .ld data. DRE_JLM_V2 Bases: FirmwareModel M1 Firmware model for DRE JLM V2 TT Dual Sensors Package Source code in ccg\\controllers\\motec.py 2272 2273 2274 2275 2276 2277 2278 2279 2280 2281 2282 2283 2284 2285 2286 2287 2288 2289 2290 2291 2292 2293 2294 2295 2296 2297 2298 2299 2300 2301 2302 2303 2304 2305 2306 2307 2308 2309 2310 2311 2312 2313 2314 2315 2316 2317 2318 2319 2320 2321 2322 2323 2324 2325 2326 2327 2328 2329 2330 2331 2332 2333 2334 2335 2336 2337 2338 2339 2340 2341 2342 2343 2344 2345 2346 2347 2348 2349 2350 2351 2352 2353 2354 2355 2356 2357 2358 2359 2360 2361 2362 2363 2364 2365 2366 2367 2368 2369 2370 2371 2372 2373 2374 2375 2376 2377 2378 2379 2380 2381 2382 2383 2384 2385 2386 2387 2388 2389 2390 2391 2392 2393 2394 2395 2396 2397 2398 2399 2400 2401 2402 2403 2404 2405 2406 2407 2408 2409 2410 2411 2412 2413 2414 2415 2416 2417 2418 2419 2420 2421 2422 2423 2424 2425 2426 2427 2428 2429 2430 2431 2432 2433 2434 2435 2436 2437 2438 2439 2440 2441 2442 2443 2444 2445 2446 2447 2448 2449 2450 2451 2452 2453 2454 2455 2456 2457 2458 2459 2460 2461 2462 2463 2464 2465 2466 2467 2468 2469 2470 2471 2472 2473 2474 2475 2476 2477 2478 2479 2480 2481 2482 2483 2484 2485 2486 2487 2488 2489 2490 2491 2492 2493 2494 2495 2496 2497 2498 2499 2500 2501 2502 2503 2504 2505 2506 2507 2508 2509 2510 2511 2512 2513 2514 2515 2516 2517 2518 2519 2520 2521 2522 2523 2524 2525 2526 2527 2528 2529 2530 2531 2532 2533 2534 2535 2536 2537 2538 2539 2540 2541 2542 2543 2544 2545 2546 2547 2548 2549 2550 2551 2552 2553 2554 2555 2556 2557 2558 2559 2560 2561 2562 2563 2564 2565 2566 2567 2568 2569 2570 2571 2572 2573 2574 2575 2576 2577 2578 2579 2580 2581 2582 2583 2584 2585 2586 2587 2588 2589 2590 2591 2592 2593 2594 2595 2596 2597 2598 2599 2600 2601 2602 2603 2604 2605 2606 2607 2608 2609 2610 2611 2612 2613 2614 2615 2616 2617 2618 2619 2620 2621 2622 2623 2624 2625 2626 2627 2628 2629 2630 2631 2632 2633 2634 2635 2636 2637 2638 2639 2640 2641 2642 2643 2644 2645 2646 2647 2648 2649 2650 2651 2652 2653 2654 2655 2656 2657 2658 2659 2660 2661 2662 2663 2664 2665 2666 2667 2668 2669 2670 2671 2672 2673 2674 2675 2676 2677 2678 2679 2680 2681 2682 2683 2684 2685 2686 2687 2688 2689 2690 2691 2692 2693 2694 2695 2696 2697 2698 2699 2700 2701 2702 2703 2704 2705 2706 2707 2708 2709 2710 2711 2712 2713 2714 2715 2716 2717 2718 2719 2720 2721 2722 2723 2724 2725 2726 2727 2728 2729 2730 2731 2732 2733 2734 2735 2736 2737 2738 2739 2740 2741 2742 2743 2744 2745 2746 2747 2748 2749 2750 2751 2752 2753 2754 2755 2756 2757 2758 2759 2760 2761 2762 2763 2764 2765 2766 2767 2768 2769 2770 2771 2772 2773 2774 2775 2776 2777 2778 2779 2780 2781 2782 2783 2784 2785 2786 2787 2788 2789 2790 2791 2792 2793 2794 2795 2796 2797 2798 2799 2800 2801 2802 2803 2804 2805 2806 2807 2808 2809 2810 2811 2812 2813 2814 2815 2816 2817 2818 2819 2820 2821 2822 2823 2824 2825 2826 2827 2828 2829 2830 2831 2832 2833 2834 2835 2836 2837 2838 2839 2840 2841 2842 2843 2844 2845 2846 2847 2848 2849 2850 2851 2852 2853 2854 2855 2856 2857 2858 2859 2860 2861 2862 2863 2864 2865 2866 2867 2868 2869 2870 2871 2872 2873 2874 2875 2876 2877 2878 2879 2880 2881 2882 2883 2884 2885 2886 2887 2888 2889 2890 2891 2892 2893 2894 2895 2896 2897 2898 2899 2900 2901 2902 2903 2904 2905 2906 2907 2908 2909 2910 2911 2912 2913 2914 2915 2916 2917 2918 2919 2920 2921 2922 2923 2924 2925 2926 2927 2928 2929 2930 2931 2932 2933 2934 2935 2936 2937 2938 2939 2940 2941 2942 2943 2944 2945 2946 2947 2948 2949 2950 2951 2952 2953 2954 2955 2956 2957 2958 2959 2960 2961 2962 2963 2964 2965 2966 2967 2968 2969 2970 2971 2972 2973 2974 2975 2976 2977 2978 2979 2980 2981 2982 2983 2984 2985 2986 2987 2988 2989 2990 2991 2992 2993 2994 2995 2996 2997 2998 2999 3000 3001 3002 3003 3004 3005 3006 3007 3008 3009 3010 3011 3012 3013 3014 3015 3016 3017 3018 3019 3020 3021 3022 3023 3024 3025 3026 3027 3028 3029 3030 3031 3032 3033 3034 3035 3036 3037 3038 3039 3040 3041 3042 3043 3044 3045 3046 3047 3048 3049 3050 3051 3052 3053 3054 3055 3056 3057 3058 3059 3060 3061 3062 3063 3064 3065 3066 3067 3068 3069 3070 3071 3072 3073 3074 3075 3076 3077 3078 3079 3080 3081 3082 3083 3084 3085 3086 3087 3088 3089 3090 3091 3092 3093 3094 3095 3096 3097 3098 3099 3100 3101 3102 3103 3104 3105 3106 3107 3108 3109 3110 3111 3112 3113 3114 3115 3116 3117 3118 3119 3120 3121 3122 3123 3124 3125 3126 3127 3128 3129 3130 3131 3132 3133 3134 3135 3136 3137 3138 3139 3140 3141 3142 3143 3144 3145 3146 3147 3148 3149 3150 3151 3152 3153 3154 3155 3156 3157 3158 3159 3160 3161 3162 3163 3164 3165 3166 3167 3168 3169 3170 3171 3172 3173 3174 3175 3176 3177 3178 3179 3180 3181 3182 3183 3184 3185 3186 3187 3188 3189 3190 3191 3192 3193 3194 3195 3196 3197 3198 3199 3200 3201 3202 3203 3204 3205 3206 3207 3208 3209 3210 3211 3212 3213 3214 3215 3216 3217 3218 3219 3220 3221 3222 3223 3224 3225 3226 3227 3228 3229 3230 3231 3232 3233 3234 3235 3236 3237 3238 3239 3240 3241 3242 3243 3244 3245 3246 3247 3248 3249 3250 3251 3252 3253 3254 3255 3256 3257 3258 3259 3260 3261 3262 3263 3264 3265 3266 3267 3268 3269 3270 3271 3272 3273 3274 3275 3276 3277 3278 3279 3280 3281 3282 3283 3284 3285 3286 3287 3288 3289 3290 3291 3292 3293 3294 3295 3296 3297 3298 3299 3300 3301 3302 3303 3304 3305 3306 3307 3308 3309 3310 3311 3312 3313 3314 3315 3316 3317 3318 3319 3320 3321 3322 3323 3324 3325 3326 3327 3328 3329 3330 3331 3332 3333 3334 3335 3336 3337 3338 3339 3340 3341 3342 3343 3344 3345 3346 3347 3348 3349 3350 3351 3352 3353 3354 3355 3356 3357 3358 3359 3360 3361 3362 3363 3364 3365 3366 3367 3368 3369 3370 3371 3372 3373 3374 3375 3376 3377 3378 3379 3380 3381 3382 3383 3384 3385 3386 3387 3388 3389 3390 3391 3392 3393 3394 3395 3396 3397 3398 3399 3400 3401 3402 3403 3404 3405 3406 3407 3408 3409 3410 3411 3412 3413 3414 3415 3416 3417 3418 3419 3420 3421 3422 3423 3424 3425 3426 3427 3428 3429 3430 3431 3432 3433 3434 3435 3436 3437 3438 3439 3440 3441 3442 3443 3444 3445 3446 3447 3448 3449 3450 3451 3452 3453 3454 3455 3456 3457 3458 3459 3460 3461 3462 3463 3464 3465 3466 3467 3468 3469 3470 3471 3472 3473 3474 3475 3476 3477 3478 3479 3480 3481 3482 3483 3484 3485 3486 3487 3488 3489 3490 3491 3492 3493 3494 3495 3496 3497 3498 3499 3500 3501 3502 3503 3504 3505 3506 3507 3508 3509 3510 3511 3512 3513 3514 3515 3516 3517 3518 3519 3520 class DRE_JLM_V2 ( FirmwareModel ): \"\"\"M1 Firmware model for DRE JLM V2 TT Dual Sensors Package\"\"\" reference_tables = { \"Fuel.Mixture Aim.Main\" : { \"unit\" : \"LA\" , \"prec\" : 2 , \"range\" : [ 0.01 , 5 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine.Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"Inlet.Manifold.Pressure\" , \"unit\" : \"kPa\" , \"range\" : [ 0 , np . inf ], \"prec\" : 1 , }, \"Z\" : { \"sig\" : \"Driver.Fuel.Mixture Aim.Main.Switch\" , \"unit\" : \"\" , \"range\" : [ \"A\" , \"B\" ], \"prec\" : 0 , }, }, }, \"Fuel.Timing.Primary.Main\" : { \"unit\" : \"dBTDC\" , \"prec\" : 1 , \"range\" : [ 0 , 1440 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine.Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"Inlet.Manifold.Pressure\" , \"unit\" : \"kPa\" , \"range\" : [ 0 , np . inf ], \"prec\" : 1 , }, }, }, } fueling_tables = { \"Engine.Efficiency.Value\" : { \"unit\" : \"%\" , \"prec\" : 1 , \"range\" : [ 10 , 200 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine.Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"Inlet.Manifold.Pressure\" , \"unit\" : \"kPa\" , \"range\" : [ 0 , np . inf ], \"prec\" : 1 , }, \"Z\" : { \"sig\" : \"Ambient.Pressure\" , \"unit\" : \"kPa\" , \"range\" : [ 5 , 110 ], \"prec\" : 1 , }, }, }, \"Fuel.Cylinder #.Trim\" : { \"unit\" : \"%Trim\" , \"prec\" : 1 , \"range\" : [ - 100 , 50 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine.Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"Inlet.Manifold.Pressure\" , \"unit\" : \"kPa\" , \"range\" : [ 0 , np . inf ], \"prec\" : 1 , }, }, }, \"Inlet.Manifold.Pressure.Estimate.Main\" : { \"unit\" : \"%\" , \"prec\" : 1 , \"range\" : [ 0 , np . inf ], \"axes\" : { \"X\" : { \"sig\" : \"Throttle.Position\" , \"unit\" : \"%\" , \"range\" : [ 0 , 100 ], \"prec\" : 1 , }, \"Y\" : { \"sig\" : \"Engine.Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 0 , }, \"Z\" : { \"sig\" : \"Ambient.Pressure\" , \"unit\" : \"kPa\" , \"range\" : [ 5 , 110 ], \"prec\" : 1 , }, }, }, \"Fuel.Volume.Trim.Overall\" : { \"unit\" : \"%Trim\" , \"prec\" : 1 , \"range\" : [ - 99.9 , np . inf ], }, \"Coolant.Temperature.Fuel Volume Compensation\" : { \"unit\" : \"%Trim\" , \"prec\" : 1 , \"range\" : [ - 50 , 50 ], \"axes\" : { \"X\" : { \"sig\" : \"Coolant.Temperature\" , \"unit\" : \"F\" , \"range\" : [ - 58 , 482 ], \"prec\" : 1 , }, }, }, } fueling_params = { \"Fuel.Efficiency.Mode\" : { 0 : \"Manifold Air Density\" , 1 : \"Ambient Air Density\" , 2 : \"Airbox Air Density\" , }, \"Inlet.Manifold.Pressure.Mode\" : { 0 : \"Automatic\" , 1 : \"Estimate\" , 2 : \"Sensor\" , }, \"Engine.Cylinders\" : 8 , \"Engine.Cylinder #.Bank\" : 1 , \"Engine.Load.Normalised.Mode\" : { 0 : \"Normal\" , 1 : \"Inlet Manifold Pressure\" , 2 : \"Throttle PositioLambda.Indiv.Bank 2.AvgLambda.Indiv.Bank 2.Avgn\" , }, \"Inlet.Manifold.Pressure.Estimate.Mode\" : { 0 : \"Ambient Pressure Relative\" , 1 : \"100kPa Relative\" , 2 : \"Boost Pressure Relative\" , }, \"Fuel.Volume.Trim.Overall\" : 0 , \"Ambient.Pressure.Default.Value\" : 101.3 , } # TODO: complete calcd_sigs = [ \"Fueling.Error.Bank 1\" , \"Fueling.Error.Bank 2\" , \"Fueling.Error.Total\" , \"Engine.Efficiency.Value.Corrected\" , \"Lambda.Indiv.Bank 1.Avg\" , \"Lambda.Indiv.Bank 2.Avg\" , \"Cylinder.Trim.Avg\" , ] def __init__ ( self , m1cfg : str | Path = None , data : str | Path | Frame = None , gate : GateColl | str | Path = None , warning_dialog : Callable = None , ): super () . __init__ ( m1cfg = m1cfg , data = data , gate = gate , warning_dialog = warning_dialog , ) self . slow_sig = \"Engine.Speed\" self . use_tailpipes = [ False ] * self . n_banks @property def n_cyl ( self ): if self . table_data and \"Engine.Cylinders\" in self . table_data : return int ( self . table_data [ \"Engine.Cylinders\" ] . data ) return 8 @property def n_banks ( self ): if self . table_data : return int ( max ( self . table_data [ f \"Engine.Cylinder { i } .Bank\" ] . data for i in range ( 1 , self . n_cyl + 1 ) ) ) return 2 # @profile def check_substitute_sigs ( self ): \"\"\"Try to substitute for some common missing sigs.\"\"\" msgs = [] if self . table_data and self . data : try : mode = self . table_data [ \"Engine.Load.Normalised.Mode\" ] . data if mode == \"Normal\" : # Value = # p * # Engine.Efficiency * # Fuel Vapour Correction * # (Engine.Displacement / Engine.Cylinders) * // Displacement of one cylinder # (1 / (Constants.rAir * (Engine.Charge.Temperature + 273.15))); // Ideal gas law # when (Normalised.Mode) # { # is (Normal) # { # local ideal = # Ambient.Pressure.Standard * # 1.0 * # 1.0 * # (Engine.Displacement / Engine.Cylinders) * // Displacement of one cylinder # (1 / (Constants.rAir * (Constants.standardTemperature + 273.15))); // Ideal gas law # Normalised = Value / ideal; raise NotImplementedError elif mode == \"Inlet.Manifold.Pressure\" : sig = Sig ( name = \"Engine.Load.Normalised\" , data = self . data [ \"Inlet.Manifold.Pressure\" ] / ccg . util . convert_units ( 101.325 , \"kPa\" , self . data [ \"Inlet.Manifold.Pressure\" ] . unit , ), tline = self . data [ \"Inlet.Manifold.Pressure\" ] . tline , unit = \"ratio\" , ) elif mode == \"Throttle Position\" : sig = Sig ( name = \"Engine.Load.Normalised\" , data = self . data [ \"Throttle.Position\" ], ) sig . convert_units ( \"%\" ) if \"Engine.Load.Normalised\" not in self . data : self . data . append ( sig ) msgs . append ( \"`Engine.Load.Normalized` was not logged and has been calculated from input signals.\" ) elif sig . period < self . data [ \"Engine.Load.Normalised\" ] . period : self . data . remove ( \"Engine.Load.Normalised\" ) self . data . append ( sig ) msgs . append ( \"`Engine.Load.Normalized` was logged slowly and has been calculated from input signals.\" ) except KeyError : pass try : if \"Fuel.Volume.Trim\" not in self . data : sig = self . table_data [ \"Fuel.Volume.Trim.Overall\" ][ self . data ] sig . name = \"Fuel.Volume.Trim\" self . data . append ( sig ) msgs . append ( \"`Fuel.Volume.Trim` was not logged and has been calculated from the loaded calibration. ** Ensure that this matches the calibration that generated the data **\" ) except KeyError : pass try : if \"Engine.Efficiency\" not in self . data : sig = self . table_data [ \"Engine.Efficiency.Value\" ][ self . data ] sig . name = \"Engine.Efficiency\" self . data . append ( sig ) msgs . append ( \"`Engine.Efficiency` was not logged and has been calculated from the loaded calibration. ** Ensure that this matches the calibration that generated the data **\" ) except KeyError : pass try : if \"Fuel.Closed Loop.Control.Bank 1.Trim\" not in self . data : sig = Sig ( self . data [ self . slow_sig ]) sig . name = \"Fuel.Closed Loop.Control.Bank 1.Trim\" sig . data = np . ones ( sig . data . shape ) sig . unit = \"ratio\" self . data . append ( sig ) msgs . append ( \"`Fuel.Closed Loop.Control.Bank 1.Trim` was not logged and has been assumed to be disabled. ** Ensure that this matches the calibration that generated the data **\" ) except KeyError : pass try : if \"Fuel.Closed Loop.Control.Bank 2.Trim\" not in self . data : sig = Sig ( self . data [ self . slow_sig ]) sig . name = \"Fuel.Closed Loop.Control.Bank 2.Trim\" sig . data = np . ones ( sig . data . shape ) sig . unit = \"ratio\" self . data . append ( sig ) msgs . append ( \"`Fuel.Closed Loop.Control.Bank 2.Trim` was not logged and has been assumed to be disabled. ** Ensure that this matches the calibration that generated the data **\" ) except KeyError : pass for i in range ( 1 , self . n_cyl + 1 ): try : name = f \"Fuel.Cylinder { i } .Trim\" if name not in self . data : sig = self . table_data [ name ][ self . data ] self . data . append ( sig ) msgs . append ( f \"` { name } ` was not logged and has been calculated from the loaded calibration. ** Ensure that this matches the calibration that generated the data **\" ) except KeyError : pass try : if \"Coolant.Temperature.Fuel Volume Compensation\" not in self . data : sig = Sig ( self . data [ \"Fuel.Volume.Compensation\" ]) sig . name = \"Coolant.Temperature.Fuel Volume Compensation\" self . data . append ( sig ) msgs . append ( \"`Coolant.Temperature.Fuel Volume Compensation` was not logged and has been substituted with `Fuel.Volume.Compensation`. ** Ensure that no other volume compensation was active. **\" ) except KeyError : pass for i in range ( 1 , self . n_cyl + 1 ): try : name = f \"Exhaust.Lambda.Cylinder { i } \" if name not in self . data : sig = Sig ( self . data [ \"Exhaust.Lambda.Bank 1\" ]) * 0 sig . name = name self . data . append ( sig ) msgs . append ( f \"` { name } ` was not logged. Individual trims not possible.\" ) except KeyError : pass if msgs : msgs = [ \"## Substituted Signals \\n \" , * msgs ] return msgs @profile def check_sigs ( self ): \"\"\"Check that required input sigs are present.\"\"\" if self . table_data and self . data : msgs = self . check_substitute_sigs () required_sigs = set ( [ \"Fuel.Mixture Aim\" , \"Engine.Efficiency\" , \"Fuel.Volume.Trim\" , \"Fuel.Volume.Compensation\" , \"Coolant.Temperature.Fuel Volume Compensation\" , ] ) for table in self . fueling_tables : for axis in self . table_data [ table . replace ( \"#\" , \"1\" )] . axes : required_sigs . add ( axis . name ) for i in range ( 1 , self . n_cyl + 1 ): required_sigs . add ( f \"Fuel.Cylinder { i } .Trim\" ) required_sigs . add ( f \"Exhaust.Lambda.Cylinder { i } \" ) for i in range ( 1 , self . n_banks + 1 ): required_sigs . add ( f \"Exhaust.Lambda.Bank { i } \" ) required_sigs . add ( f \"Fuel.Closed Loop.Control.Bank { i } .Trim\" ) if ( \"Ambient Pressure Relative\" in self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Mode\" ] . data ): required_sigs . add ( \"Ambient.Pressure\" ) ok_slow = [ \"Ambient.Pressure\" , \"Fuel.Mixture Aim\" , \"Fuel.Volume.Trim\" , \"Fuel.Volume.Compensation\" , \"Inlet.Manifold.Pressure.Estimate\" , \"Coolant.Temperature.Fuel Volume Compensation\" , \"Coolant.Temperature\" , ] extras = [ \"Inlet.Manifold.Pressure.Estimate\" , \"Inlet.Air.Temperature\" , \"Vehicle.Speed\" , \"Ignition.Cut\" , \"Ignition.Timing\" , \"Idle.State\" , \"Fuel.Volume.Transient\" , \"Fuel.Volume.Trim\" , \"Fuel.Volume.Compensation\" , \"Fuel.Timing.Primary\" , \"Fuel.Temperature\" , \"Fuel.Pressure\" , \"Fuel.Injector.Primary.Duty.Cycle\" , \"Fuel.Film.Primary\" , \"Fuel.Cut\" , \"Engine.Load\" , \"Coolant.Pressure\" , \"Engine.Charge.Temperature\" , \"Engine.Oil.Temperature\" , \"Engine.Oil.Pressure\" , \"ECU.Batter.Voltage\" , \"Engine.Load.Normalised\" , ] required_sigs = list ( required_sigs ) missing = [] for sig in required_sigs : if sig not in self . data : missing . append ( sig ) for sig in self . gate . sigs : if sig not in self . data and sig not in self . calcd_sigs : missing . append ( sig ) if missing : missing . sort () # msg = \"<br>\".join(missing) if self . warning_dialog : msgs . extend ([ \" \\n ## Missing Required Signals \\n \" , * missing ]) self . warning_dialog ( title = \"# Missing Signals\" , msg = \"<br>\" . join ( msgs ) ) return False raise ValueError ( f \"Missing Required Signals \\n { missing } \" ) for sig in required_sigs : if sig not in ok_slow : self . slow_sig = sig break for sig in required_sigs : if ( sig not in ok_slow and self . data [ sig ] . period > self . data [ self . slow_sig ] . period ): self . slow_sig = sig for sig in self . gate . sigs : if sig not in self . calcd_sigs and sig not in required_sigs : required_sigs . append ( sig ) tline = self . data [ self . slow_sig ] . tline self . resampled = self . data [ required_sigs ] . resample ( tline ) self . resampled . name = \"Resampled Data for Calc's\" self . data . math_tline = tline self . resampled . math_tline = tline for sig in extras : try : self . resampled . append ( self . data [ sig ] . resample ( tline )) except KeyError : pass if self . slow_freq < 50 : msgs . extend ( [ \" \\n ## Slow Signal \\n \" , f \"Calculation rate limited to { self . slow_freq } Hz by ` { self . slow_sig } `\" , ] ) if msgs : self . warning_dialog ( title = \"# Missing Signals\" , msg = \"<br>\" . join ( msgs )) return True else : return False @profile def update_calcd_data ( self ): \"\"\"Update calculations for fitting/plotting.\"\"\" if self . _needs_calcs : tic = datetime . now () if self . check_sigs (): if self . table_data : acc = 0 n = 0 for cyl in range ( 1 , 1 + self . n_cyl ): tmp = self . resampled [ f \"Fuel.Cylinder { cyl } .Trim\" ] . as_unit ( \"ratio\" ) tmp . unit = \"ratio\" tmp . name = f \"Fuel.Cylinder { cyl } .Trim.Total\" self . resampled . append ( tmp ) acc = acc + tmp n += 1 acc = acc / n acc . name = \"Cylinder.Trim.Avg\" acc . unit = \"ratio\" self . resampled . append ( acc ) for bank in range ( 1 , self . n_banks + 1 ): tmp = 0 n = 0 for cyl in range ( 1 , 1 + self . n_cyl ): if ( self . table_data [ f \"Engine.Cylinder { cyl } .Bank\" ] . data == bank ): n += 1 tmp = ( tmp + self . resampled [ f \"Exhaust.Lambda.Cylinder { cyl } \" ] ) tmp = tmp / n tmp . name = f \"Lambda.Indiv.Bank { bank } .Avg\" tmp . unit = \"LA\" tmp . data_range = [ 0.6 , 1.4 ] self . resampled . append ( tmp ) tmp = 0 n = 0 for cyl in range ( 1 , 1 + self . n_cyl ): if ( self . table_data [ f \"Engine.Cylinder { cyl } .Bank\" ] . data == bank ): n += 1 tmp = tmp + self . resampled [ f \"Fuel.Cylinder { cyl } .Trim\" ] . as_unit ( \"ratio\" ) tmp = tmp / n tmp . name = f \"Cylinder.Trim.Bank { bank } .Avg\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) self . resampled [ f \"Exhaust.Lambda.Bank { bank } \" ] . data_range = [ 0.6 , 1.4 , ] tmp = self . table_data [ \"Coolant.Temperature.Fuel Volume Compensation\" ][ self . resampled ] . as_unit ( \"ratio\" ) / self . resampled [ \"Fuel.Volume.Compensation\" ] . as_unit ( \"ratio\" ) tmp . name = \"Volume.Comp.Delta\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ \"Fuel.Closed Loop.Control.Bank 1.Trim\" ] . as_unit ( \"ratio\" ) * self . resampled [ \"Fuel.Volume.Trim\" ] . as_unit ( \"ratio\" ) / self . resampled [ \"Volume.Comp.Delta\" ] . as_unit ( \"ratio\" ) * self . resampled [ \"Cylinder.Trim.Bank 1.Avg\" ] * self . resampled [ \"Exhaust.Lambda.Bank 1\" ] / self . resampled [ \"Fuel.Mixture Aim\" ] ) # TODO: Fix for only 1 bank tmp . name = \"Fueling.Error.Bank 1\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ \"Fuel.Closed Loop.Control.Bank 2.Trim\" ] . as_unit ( \"ratio\" ) * self . resampled [ \"Fuel.Volume.Trim\" ] . as_unit ( \"ratio\" ) / self . resampled [ \"Volume.Comp.Delta\" ] . as_unit ( \"ratio\" ) * self . resampled [ \"Cylinder.Trim.Bank 2.Avg\" ] * self . resampled [ \"Exhaust.Lambda.Bank 2\" ] / self . resampled [ \"Fuel.Mixture Aim\" ] ) tmp . name = \"Fueling.Error.Bank 2\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ \"Fueling.Error.Bank 1\" ] + self . resampled [ \"Fueling.Error.Bank 2\" ] ) / 2 tmp . name = \"Fueling.Error.Total\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = self . resampled [ \"Fueling.Error.Total\" ] * ( self . resampled [ \"Engine.Efficiency\" ] ) tmp . name = \"Engine.Efficiency.Value.Corrected\" tmp . unit = \"%\" self . resampled . append ( tmp ) self . resampled . append ( Sig ( self . resampled [ \"Engine.Efficiency\" ], name = \"Engine.Efficiency.Value\" , ) ) # copy with name to match table for cyl in range ( 1 , 1 + self . n_cyl ): bank = int ( self . table_data [ f \"Engine.Cylinder { cyl } .Bank\" ] . data ) tmp = ( self . resampled [ f \"Exhaust.Lambda.Cylinder { cyl } \" ] / self . resampled [ f \"Lambda.Indiv.Bank { bank } .Avg\" ] ) tmp . name = f \"Cyl { cyl } .Lam.Error\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ f \"Fuel.Cylinder { cyl } .Trim.Total\" ] / self . resampled [ f \"Cylinder.Trim.Bank { bank } .Avg\" ] ) tmp . name = f \"Fuel.Cylinder { cyl } .Trim.Bank Normalised\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ f \"Fuel.Cylinder { cyl } .Trim.Total\" ] / self . resampled [ \"Cylinder.Trim.Avg\" ] ) tmp . name = f \"Fuel.Cylinder { cyl } .Trim.Normalised\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ f \"Fuel.Cylinder { cyl } .Trim.Bank Normalised\" ] * self . resampled [ f \"Cyl { cyl } .Lam.Error\" ] * ( self . resampled [ f \"Fueling.Error.Bank { bank } \" ] / self . resampled [ \"Fueling.Error.Total\" ] ) ) tmp . name = f \"Fuel.Cylinder { cyl } .Trim.Corrected\" tmp . unit = \"ratio\" tmp . convert_units ( \"%Trim\" ) self . resampled . append ( tmp ) # Calc cyl trims from tailpipe data incase indiv missing tmp = self . resampled [ f \"Fuel.Cylinder { cyl } .Trim.Normalised\" ] * ( self . resampled [ f \"Fueling.Error.Bank { bank } \" ] / self . resampled [ \"Fueling.Error.Total\" ] ) tmp . name = f \"Fuel.Cylinder { cyl } .Trim.Corrected.Tailpipe\" tmp . unit = \"ratio\" tmp . convert_units ( \"%Trim\" ) self . resampled . append ( tmp ) self . resampled [ f \"Exhaust.Lambda.Cylinder { cyl } \" ] . data_range = [ 0.6 , 1.4 , ] self . resampled . append ( self . resampled [ \"Engine.Speed\" ] . dot ( n_win = 17 )) self . resampled . append ( self . resampled [ \"Throttle.Position\" ] . dot ( n_win = 7 ) ) # inlet manifold press ref try : if ( \"Ambient Pressure Relative\" in self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Mode\" ] . data ): tmp = ( self . resampled [ \"Inlet.Manifold.Pressure\" ] / self . resampled [ \"Ambient.Pressure\" ] ) else : tmp = self . resampled [ \"Inlet.Manifold.Pressure\" ] / 100 tmp . name = \"Inlet.Manifold.Pressure.Estimate.Main.Corrected\" tmp . unit = \"ratio\" tmp . convert_units ( \"%\" ) self . resampled . append ( tmp ) if ( \"Ambient Pressure Relative\" in self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Mode\" ] . data ): tmp = ( self . resampled [ \"Inlet.Manifold.Pressure.Estimate\" ] / self . resampled [ \"Ambient.Pressure\" ] ) else : tmp = ( self . resampled [ \"Inlet.Manifold.Pressure.Estimate\" ] / 100 ) tmp . name = \"Inlet.Manifold.Pressure.Estimate.Main\" tmp . unit = \"ratio\" tmp . convert_units ( \"%\" ) self . resampled . append ( tmp ) except KeyError : pass # Coolant temp comps tmp = ( self . resampled [ \"Engine.Efficiency.Value.Corrected\" ] . as_unit ( \"ratio\" ) / self . table_data [ \"Engine.Efficiency.Value\" ][ self . resampled ] . as_unit ( \"ratio\" ) * self . resampled [ \"Coolant.Temperature.Fuel Volume Compensation\" ] . as_unit ( \"ratio\" ) * self . resampled [ \"Volume.Comp.Delta\" ] . as_unit ( \"ratio\" ) ) tmp . name = \"Coolant.Temperature.Fuel Volume Compensation.Corrected\" tmp . unit = \"ratio\" tmp . convert_units ( \"%Trim\" ) self . resampled . append ( tmp ) toc = datetime . now () - tic _LOGGER . debug ( \"Firmware calcs in %.3f \" , toc . total_seconds ()) # Set some ranges self . resampled [ \"Engine.Speed\" ] . data_range = [ 0 , 8800 ] self . resampled [ \"Fuel.Mixture Aim\" ] . data_range = [ 0.6 , 1.4 ] # Add calc'd signals to data frame for general plot self . data . append ( self . resampled ) self . _needs_calcs = False if not self . _needs_calcs : self . update_scatter_data () if self . resampled : # Update options for scatter plots opts = [ \"Relative Density\" , * self . resampled . sigs . keys ()] for tab in self . tabs : tab . color_sig . options = opts @profile def update_scatter_data ( self ): \"\"\"Update scatter data for fitting.\"\"\" if self . _needs_scatter_update : # Build signal list bank_gate_tables = [ \"Fuel.Cylinder #.Trim\" ] remove_digits = str . maketrans ( \"0123456789\" , \"##########\" ) msg = [] self . use_tailpipes = [ False ] * self . n_banks if self . _needs_calcs : self . update_calcd_data () for table in self . table_data : if f \" { table . name } .Corrected\" in self . resampled . sigs : tmp : list [ Sig ] = [] ranges = [] if table . name . translate ( remove_digits ) in bank_gate_tables : cyl = \"\" . join ( filter ( lambda x : x . isdigit (), table . name )) bank_ind = ( self . table_data [ f \"Engine.Cylinder { cyl } .Bank\" ] . data [ 0 ] - 1 ) if self . tabs [ table . name ] . additional_gate : gate = GateCollAND ( [ self . bank_gates [ bank_ind ], self . tabs [ table . name ] . additional_gate , ] ) else : gate = self . bank_gates [ bank_ind ] tmp_sig = ( self . resampled [ f \" { table . name } .Corrected\" ] . valid ( gate ) . resample ( self . resampled . math_tline ) ) if ( tmp_sig . data . size - np . count_nonzero ( np . isnan ( tmp_sig . data )) < 1 ): msg . append ( f \" \\n ## Individual Cylinder Lambda signals out of limits on bank { bank_ind + 1 } . \\n Bank trim from tailpipe sensor only.\" ) self . use_tailpipes [ bank_ind ] = True if self . tabs [ table . name ] . additional_gate : gate = GateCollAND ( [ self . gate , self . tabs [ table . name ] . additional_gate ] ) else : gate = self . gate tmp_sig = ( self . resampled [ f \" { table . name } .Corrected.Tailpipe\" ] . valid ( gate ) . resample ( self . resampled . math_tline ) ) self . resampled . remove ( f \" { table . name } .Corrected\" ) self . resampled . append ( Sig ( self . resampled [ f \" { table . name } .Corrected.Tailpipe\" ], name = f \" { table . name } .Corrected\" , ) ) for axis in table . axes : tmp . append ( self . resampled [ f \" { axis . name } \" ] . valid ( gate ) . as_unit ( axis . unit ) . resample ( self . resampled . math_tline ) ) ranges . append ([ axis . min , axis . max ]) tmp . append ( tmp_sig ) ranges . append ([ table . min , table . max ]) else : if self . tabs [ table . name ] . additional_gate : gate = GateCollAND ( [ self . gate , self . tabs [ table . name ] . additional_gate ] ) else : gate = self . gate for axis in table . axes : tmp . append ( self . resampled [ f \" { axis . name } \" ] . valid ( gate ) . as_unit ( axis . unit ) . resample ( self . resampled . math_tline ) ) ranges . append ([ axis . min , axis . max ]) tmp_sig = ( self . resampled [ f \" { table . name } .Corrected\" ] . valid ( gate ) . resample ( self . resampled . math_tline ) ) if \"Coolant.Temperature.Fuel Volume Compensation\" in table . name : try : # Need to adjust offset to center at normal op temp op_temp = self . tabs [ table . name ] . op_temp . value ind = table . axes [ 0 ] . bins ( op_temp )[ 0 ] diff = table . axes [ 0 ] . diff [ ind ] zero_inds = np . logical_and ( np . greater ( tmp [ - 1 ] . data , op_temp - diff / 2 ), np . less ( tmp [ - 1 ] . data , op_temp + diff / 2 ), ) zero_val = np . mean ( tmp_sig . data [ zero_inds ]) if np . isnan ( zero_val ): zero_val = 0 tmp_sig -= zero_val except AttributeError : pass tmp . append ( tmp_sig ) ranges . append ([ table . min , table . max ]) color_data = None color_name = None color_unit = None color_range = None if self . tabs [ table . name ] . color_sig . value : name = self . tabs [ table . name ] . color_sig . value [ 0 ] if \"Relative Density\" in name : color_name = name n_bins = [ 70 ] * len ( tmp ) n_bins [ - 1 ] *= 2 bins = [] for vals , intv , n_bin in zip ( tmp , ranges , n_bins ): bins . append ( np . linspace ( np . minimum ( vals . min , intv [ 0 ]), np . maximum ( vals . max , intv [ 1 ]), n_bin , ) ) color_data = scatter_density ( ScatterData ( tmp ), n_bins = bins ) elif name in self . resampled : color_data = ( self . resampled [ name ] . valid ( gate ) . resample ( self . resampled . math_tline ) . data ) color_name = name color_unit = self . resampled [ name ] . unit color_range = self . resampled [ name ] . data_range table . scatter_data = ScatterData ( data = tmp , name = \"Corrected\" , color = color_data , color_unit = color_unit , color_name = color_name , color_range = color_range , ) . clean () # Add logged data trace if table . name in self . resampled : tmp [ - 1 ] = ( self . resampled [ table . name ] . valid ( gate ) . resample ( self . resampled . math_tline ) ) table . scatter_data . append ( ScatterData ( data = tmp , name = \"Logged\" ) . clean () ) else : table . scatter_data = None self . _needs_scatter_update = False if msg and self . _needs_bank_warning : msg = list ( set ( msg )) self . warning_dialog ( title = \"# Fit Data Warning\" , msg = \"<br>\" . join ( msg )) self . _needs_bank_warning = ( # pylint: disable=attribute-defined-outside-init False ) def normalize_cyl_trims ( self ): \"\"\"Normalizes cyl trims if bp's match.\"\"\" cyl_trim_min = self . fueling_tables [ \"Fuel.Cylinder #.Trim\" ][ \"range\" ][ 0 ] cyl_trim_max = self . fueling_tables [ \"Fuel.Cylinder #.Trim\" ][ \"range\" ][ 1 ] cyl_trim_unit = self . fueling_tables [ \"Fuel.Cylinder #.Trim\" ][ \"unit\" ] if self . check_axes (): avg = np . zeros ( self . table_data [ \"Fuel.Cylinder 1.Trim\" ] . data . shape ) n = 0 for cyl in range ( 1 , self . n_cyl + 1 ): avg += self . table_data [ f \"Fuel.Cylinder { cyl } .Trim\" ] . data n += 1 avg = ccg . util . convert_units ( avg / n , cyl_trim_unit , \"ratio\" ) for cyl in range ( 1 , self . n_cyl + 1 ): cyl_trim = ( self . table_data [ f \"Fuel.Cylinder { cyl } .Trim\" ] . as_unit ( \"ratio\" ) . data / avg ) cyl_trim = ccg . util . convert_units ( cyl_trim , \"ratio\" , cyl_trim_unit ) self . table_data [ f \"Fuel.Cylinder { cyl } .Trim\" ] . data = np . clip ( cyl_trim , cyl_trim_min , cyl_trim_max ) else : raise ValueError ( \"Cyl trim axes dont match, cant normalize\" ) def check_axes ( self ): \"\"\"Check if cyl trim axes match\"\"\" for i in range ( 2 , self . n_cyl + 1 ): for axis , axis1 in zip ( self . table_data [ f \"Fuel.Cylinder { i } .Trim\" ] . axes , self . table_data [ \"Fuel.Cylinder 1.Trim\" ] . axes , ): if axis1 != axis : return False return True @profile def build_delta_summary ( self ): \"\"\"Builds tables to review fit.\"\"\" if self . table_data : input_tables = Tbls () input_tables . append ( self . table_data [ \"Engine.Efficiency.Value\" ]) cyl_trim_unit = self . fueling_tables [ \"Fuel.Cylinder #.Trim\" ][ \"unit\" ] for cyl in range ( 1 , self . n_cyl + 1 ): # Convert indiv tables to base axes name = f \"Fuel.Cylinder { cyl } .Trim\" axes = input_tables [ \"Engine.Efficiency.Value\" ] . axes tmp = self . convert_table_to_axes ( self . table_data [ name ], axes ) tmp . name = name input_tables . append ( tmp ) result_tables = Tbls () tmp = Tbl ( input_tables [ \"Engine.Efficiency.Value\" ]) tmp . data *= 0 tmp . name = \"Overall\" tmp . unit = \"ratio\" tmp . snapshot ( \"orig\" ) result_tables . append ( tmp ) for bank in range ( 1 , self . n_banks + 1 ): avg = Tbl ( input_tables [ \"Engine.Efficiency.Value\" ]) avg . data *= 0 avg . name = f \"Bank { bank } .Trim.Avg\" avg . unit = \"ratio\" avg . snapshot ( \"orig\" ) n = 0 for cyl in range ( 1 , self . n_cyl + 1 ): indiv = f \"Fuel.Cylinder { cyl } .Trim\" tmp = ( input_tables [ \"Engine.Efficiency.Value\" ] . orig . as_unit ( \"ratio\" ) * input_tables [ indiv ] . orig . as_unit ( \"ratio\" ) * self . table_data [ \"Fuel.Volume.Trim.Overall\" ] . orig . as_unit ( \"ratio\" ) . data ) tmp . name = f \"Individual { cyl } \" tmp . unit = \"ratio\" tmp . snapshot ( \"orig\" ) tmp . data = ( input_tables [ \"Engine.Efficiency.Value\" ] . as_unit ( \"ratio\" ) * input_tables [ indiv ] . as_unit ( \"ratio\" ) * self . table_data [ \"Fuel.Volume.Trim.Overall\" ] . as_unit ( \"ratio\" ) . data ) . data result_tables . append ( tmp ) if self . table_data [ f \"Engine.Cylinder { cyl } .Bank\" ] . data [ 0 ] == bank : avg . _archive [ \"orig\" ][ - 1 ] += input_tables [ indiv ] . orig . as_unit ( \"ratio\" ) avg += input_tables [ indiv ] . as_unit ( \"ratio\" ) n += 1 result_tables [ \"Overall\" ] . _archive [ \"orig\" ][ - 1 ] += tmp . orig result_tables [ \"Overall\" ] += tmp avg . _archive [ \"orig\" ][ - 1 ] /= n avg /= n result_tables . append ( avg ) result_tables [ \"Overall\" ] . _archive [ \"orig\" ][ - 1 ] /= self . n_cyl result_tables [ \"Overall\" ] /= self . n_cyl # FINALLY res = [ ccg . ui . panel . pn . Spacer ( height = 0 ), ccg . ui . panel . pn . pane . Markdown ( \"\"\"# Overall Fueling Delta This accounts for deltas in the `Engine.Efficiency.Value` table, the mean of the `Fuel.Cylinder #.Trim` tables, and the `Fuel.Volume.Trim.Overall`.\"\"\" , align = \"start\" , ), ] table = result_tables [ \"Overall\" ] axes_data = table . axes prec_args = { \"axis_names\" : [ f \" { axis . name } [ { axis . unit } ]\" for axis in axes_data ], \"axis_breakpoints\" : [ axis . data . tolist () for axis in axes_data ], \"axis_precisions\" : [ axis . precision for axis in axes_data ], \"data_precision\" : table . precision , \"locked\" : table . locked . T . tolist (), } res . append ( ccg . ui . panel . CalDataTbl ( name = \"Overall Fueling Delta %\" , table_name = \"Overall Fueling Delta [%]\" , data = table . delta_perc . T . tolist (), editable = False , colorscale = \"RdBu\" , colorscale_center = 0 , align = \"center\" , ** prec_args , ) ) res . append ( ccg . ui . panel . pn . pane . Markdown ( \"\"\"# Bank Average Cyl Trims\"\"\" , align = \"start\" , ) ) for bank in range ( 1 , self . n_banks + 1 ): name = f \"Bank { bank } .Trim.Avg\" table = result_tables [ name ] . as_unit ( cyl_trim_unit ) axes_data = table . axes prec_args = { \"axis_names\" : [ f \" { axis . name } [ { axis . unit } ]\" for axis in axes_data ], \"axis_breakpoints\" : [ axis . data . tolist () for axis in axes_data ], \"axis_precisions\" : [ axis . precision for axis in axes_data ], \"data_precision\" : table . precision , \"locked\" : table . locked . T . tolist (), } res . append ( ccg . ui . panel . CalDataTbl ( name = name , table_name = f \" { name } [ { cyl_trim_unit } ]\" , data = table . data . T . tolist (), editable = False , colorscale = \"RdBu\" , colorscale_center = 0 , align = \"center\" , ** prec_args , ) ) res . append ( ccg . ui . panel . pn . pane . Markdown ( \"\"\"# Individual Cylinder Fueling Deltas These accounts for deltas in the `Engine.Efficiency.Value` table, the the `Fuel.Cylinder #.Trim` tables, and the `Fuel.Volume.Trim.Overall`.\"\"\" , align = \"start\" , ) ) for cyl in range ( 1 , self . n_cyl + 1 ): name = f \"Individual { cyl } \" table = result_tables [ name ] axes_data = table . axes prec_args = { \"axis_names\" : [ f \" { axis . name } [ { axis . unit } ]\" for axis in axes_data ], \"axis_breakpoints\" : [ axis . data . tolist () for axis in axes_data ], \"axis_precisions\" : [ axis . precision for axis in axes_data ], \"data_precision\" : table . precision , \"locked\" : table . locked . T . tolist (), } res . append ( ccg . ui . panel . CalDataTbl ( name = f \" { name } Fueling Delta %\" , table_name = f \" { name } Fueling Delta [%]\" , data = table . delta_perc . T . tolist (), editable = False , colorscale = \"RdBu\" , colorscale_center = 0 , align = \"center\" , ** prec_args , ) ) return res def convert_table_to_axes ( self , table : Tbl , target : Axes ): \"\"\"Convert a table to fit the target axes if possible.\"\"\" res = Tbl ( name = \"result\" , axes = target , unit = table . unit ) if target . n_dim > 2 : raise NotImplementedError if target . n_dim < table . n_dim : raise NotImplementedError if table . n_dim == 0 : res . data = np . ones ( target . shape ) * table . orig . data res . snapshot ( \"orig\" ) res . data = np . ones ( target . shape ) * table . data return res # Leave in target units, convert table before interpolating. target_grid = target . grid interp_grid = target . grid units = [ \"\" ] * table . n_dim for j , axis in enumerate ( target ): found = False for i , t_axis in enumerate ( table . axes ): if axis . name == t_axis . name : interp_grid [ i ] = target_grid [ j ] units [ i ] = axis . unit found = True break if not found : # Check for possible calc if axis . name == \"Inlet.Manifold.Pressure\" : if \"Engine.Load.Normalised\" in table . axes : i = table . axes . index ( \"Engine.Load.Normalised\" ) # Calc engine load normalized mode = self . table_data [ \"Engine.Load.Normalised.Mode\" ] . data if mode == \"Normal\" : raise NotImplementedError elif mode == \"Inlet Manifold Pressure\" : tmp = Axis ( axis ) tmp . data = axis . data / ccg . util . convert_units ( 101.325 , \"kPa\" , axis . unit , ) interp_grid [ i ] = target_grid [ j ] units [ i ] = \"ratio\" elif mode == \"Throttle Position\" : eng_speed_ind = target . index ( \"Engine.Speed\" ) imap_ind = target . index ( \"Inlet.Manifold.Pressure\" ) interp_grid [ i ] = self . tps_from_map ( eng_speed = target_grid [ eng_speed_ind ], imap = target_grid [ imap_ind ], ) units [ i ] = \"%\" for unit , axis in zip ( units , table . axes ): axis . convert_units ( unit ) interp_vals = np . array ([ x . flatten () for x in interp_grid ]) . T res . data = table . orig . interp ( interp_vals ) . reshape ( target . shape , order = \"f\" ) res . snapshot ( \"orig\" ) res . data = table . interp ( interp_vals ) . reshape ( target . shape , order = \"f\" ) # res.plot() return res def tps_from_map ( self , eng_speed : npt . NDArray , imap : npt . NDArray ): \"\"\"Estimate Throttle.Position from manifold air pressure.\"\"\" n = 100 tps_map = Tbl ( self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Main\" ]) tps_map . name = \"TPS Estimate\" tps_map . interp_on_axis_change = True tps_map . data *= 0 tps_map . f_orig = 0 tps_map . f_smooth = [ 0.001 , 0.001 ] map_unit = self . fueling_tables [ \"Engine.Efficiency.Value\" ][ \"axes\" ][ \"Z\" ][ \"unit\" ] tps_unit = tps_map . axes [ \"Throttle.Position\" ] . unit tps = np . linspace ( tps_map . axes [ \"Throttle.Position\" ] . data . min (), tps_map . axes [ \"Throttle.Position\" ] . data . max (), n , ) eng_spd = np . linspace ( tps_map . axes [ \"Engine.Speed\" ] . data . min (), tps_map . axes [ \"Engine.Speed\" ] . data . max (), n , ) bps = [ x . flatten () for x in np . meshgrid ( tps , eng_spd )] maps = ( self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Main\" ] . as_unit ( \"ratio\" ) . interp ( np . array ( bps ) . T ) * self . table_data [ \"Ambient.Pressure.Default.Value\" ] . as_unit ( map_unit ) . data ) map_bps = np . linspace ( 10 , 101 , 40 , ) tps_map . axes [ \"Throttle.Position\" ] . data = map_bps tps_map . axes [ \"Throttle.Position\" ] . name = \"Inlet.Manifold.Pressure\" tps_map . axes [ \"Inlet.Manifold.Pressure\" ] . unit = map_unit tps_map . unit = tps_unit new_grid = [ maps , bps [ 1 ], bps [ 0 ]] tps_map . scatter_data = ScatterData ( new_grid ) tps_map . fit () # tps_map.plot() interps = np . array ([ imap , eng_speed ]) . T return np . clip ( tps_map . interp ( interps ), 0 , 100 ) build_delta_summary () Builds tables to review fit. Source code in ccg\\controllers\\motec.py 3243 3244 3245 3246 3247 3248 3249 3250 3251 3252 3253 3254 3255 3256 3257 3258 3259 3260 3261 3262 3263 3264 3265 3266 3267 3268 3269 3270 3271 3272 3273 3274 3275 3276 3277 3278 3279 3280 3281 3282 3283 3284 3285 3286 3287 3288 3289 3290 3291 3292 3293 3294 3295 3296 3297 3298 3299 3300 3301 3302 3303 3304 3305 3306 3307 3308 3309 3310 3311 3312 3313 3314 3315 3316 3317 3318 3319 3320 3321 3322 3323 3324 3325 3326 3327 3328 3329 3330 3331 3332 3333 3334 3335 3336 3337 3338 3339 3340 3341 3342 3343 3344 3345 3346 3347 3348 3349 3350 3351 3352 3353 3354 3355 3356 3357 3358 3359 3360 3361 3362 3363 3364 3365 3366 3367 3368 3369 3370 3371 3372 3373 3374 3375 3376 3377 3378 3379 3380 3381 3382 3383 3384 3385 3386 3387 3388 3389 3390 3391 3392 3393 3394 3395 3396 3397 3398 3399 3400 3401 3402 3403 3404 3405 @profile def build_delta_summary ( self ): \"\"\"Builds tables to review fit.\"\"\" if self . table_data : input_tables = Tbls () input_tables . append ( self . table_data [ \"Engine.Efficiency.Value\" ]) cyl_trim_unit = self . fueling_tables [ \"Fuel.Cylinder #.Trim\" ][ \"unit\" ] for cyl in range ( 1 , self . n_cyl + 1 ): # Convert indiv tables to base axes name = f \"Fuel.Cylinder { cyl } .Trim\" axes = input_tables [ \"Engine.Efficiency.Value\" ] . axes tmp = self . convert_table_to_axes ( self . table_data [ name ], axes ) tmp . name = name input_tables . append ( tmp ) result_tables = Tbls () tmp = Tbl ( input_tables [ \"Engine.Efficiency.Value\" ]) tmp . data *= 0 tmp . name = \"Overall\" tmp . unit = \"ratio\" tmp . snapshot ( \"orig\" ) result_tables . append ( tmp ) for bank in range ( 1 , self . n_banks + 1 ): avg = Tbl ( input_tables [ \"Engine.Efficiency.Value\" ]) avg . data *= 0 avg . name = f \"Bank { bank } .Trim.Avg\" avg . unit = \"ratio\" avg . snapshot ( \"orig\" ) n = 0 for cyl in range ( 1 , self . n_cyl + 1 ): indiv = f \"Fuel.Cylinder { cyl } .Trim\" tmp = ( input_tables [ \"Engine.Efficiency.Value\" ] . orig . as_unit ( \"ratio\" ) * input_tables [ indiv ] . orig . as_unit ( \"ratio\" ) * self . table_data [ \"Fuel.Volume.Trim.Overall\" ] . orig . as_unit ( \"ratio\" ) . data ) tmp . name = f \"Individual { cyl } \" tmp . unit = \"ratio\" tmp . snapshot ( \"orig\" ) tmp . data = ( input_tables [ \"Engine.Efficiency.Value\" ] . as_unit ( \"ratio\" ) * input_tables [ indiv ] . as_unit ( \"ratio\" ) * self . table_data [ \"Fuel.Volume.Trim.Overall\" ] . as_unit ( \"ratio\" ) . data ) . data result_tables . append ( tmp ) if self . table_data [ f \"Engine.Cylinder { cyl } .Bank\" ] . data [ 0 ] == bank : avg . _archive [ \"orig\" ][ - 1 ] += input_tables [ indiv ] . orig . as_unit ( \"ratio\" ) avg += input_tables [ indiv ] . as_unit ( \"ratio\" ) n += 1 result_tables [ \"Overall\" ] . _archive [ \"orig\" ][ - 1 ] += tmp . orig result_tables [ \"Overall\" ] += tmp avg . _archive [ \"orig\" ][ - 1 ] /= n avg /= n result_tables . append ( avg ) result_tables [ \"Overall\" ] . _archive [ \"orig\" ][ - 1 ] /= self . n_cyl result_tables [ \"Overall\" ] /= self . n_cyl # FINALLY res = [ ccg . ui . panel . pn . Spacer ( height = 0 ), ccg . ui . panel . pn . pane . Markdown ( \"\"\"# Overall Fueling Delta This accounts for deltas in the `Engine.Efficiency.Value` table, the mean of the `Fuel.Cylinder #.Trim` tables, and the `Fuel.Volume.Trim.Overall`.\"\"\" , align = \"start\" , ), ] table = result_tables [ \"Overall\" ] axes_data = table . axes prec_args = { \"axis_names\" : [ f \" { axis . name } [ { axis . unit } ]\" for axis in axes_data ], \"axis_breakpoints\" : [ axis . data . tolist () for axis in axes_data ], \"axis_precisions\" : [ axis . precision for axis in axes_data ], \"data_precision\" : table . precision , \"locked\" : table . locked . T . tolist (), } res . append ( ccg . ui . panel . CalDataTbl ( name = \"Overall Fueling Delta %\" , table_name = \"Overall Fueling Delta [%]\" , data = table . delta_perc . T . tolist (), editable = False , colorscale = \"RdBu\" , colorscale_center = 0 , align = \"center\" , ** prec_args , ) ) res . append ( ccg . ui . panel . pn . pane . Markdown ( \"\"\"# Bank Average Cyl Trims\"\"\" , align = \"start\" , ) ) for bank in range ( 1 , self . n_banks + 1 ): name = f \"Bank { bank } .Trim.Avg\" table = result_tables [ name ] . as_unit ( cyl_trim_unit ) axes_data = table . axes prec_args = { \"axis_names\" : [ f \" { axis . name } [ { axis . unit } ]\" for axis in axes_data ], \"axis_breakpoints\" : [ axis . data . tolist () for axis in axes_data ], \"axis_precisions\" : [ axis . precision for axis in axes_data ], \"data_precision\" : table . precision , \"locked\" : table . locked . T . tolist (), } res . append ( ccg . ui . panel . CalDataTbl ( name = name , table_name = f \" { name } [ { cyl_trim_unit } ]\" , data = table . data . T . tolist (), editable = False , colorscale = \"RdBu\" , colorscale_center = 0 , align = \"center\" , ** prec_args , ) ) res . append ( ccg . ui . panel . pn . pane . Markdown ( \"\"\"# Individual Cylinder Fueling Deltas These accounts for deltas in the `Engine.Efficiency.Value` table, the the `Fuel.Cylinder #.Trim` tables, and the `Fuel.Volume.Trim.Overall`.\"\"\" , align = \"start\" , ) ) for cyl in range ( 1 , self . n_cyl + 1 ): name = f \"Individual { cyl } \" table = result_tables [ name ] axes_data = table . axes prec_args = { \"axis_names\" : [ f \" { axis . name } [ { axis . unit } ]\" for axis in axes_data ], \"axis_breakpoints\" : [ axis . data . tolist () for axis in axes_data ], \"axis_precisions\" : [ axis . precision for axis in axes_data ], \"data_precision\" : table . precision , \"locked\" : table . locked . T . tolist (), } res . append ( ccg . ui . panel . CalDataTbl ( name = f \" { name } Fueling Delta %\" , table_name = f \" { name } Fueling Delta [%]\" , data = table . delta_perc . T . tolist (), editable = False , colorscale = \"RdBu\" , colorscale_center = 0 , align = \"center\" , ** prec_args , ) ) return res check_axes () Check if cyl trim axes match Source code in ccg\\controllers\\motec.py 3231 3232 3233 3234 3235 3236 3237 3238 3239 3240 3241 def check_axes ( self ): \"\"\"Check if cyl trim axes match\"\"\" for i in range ( 2 , self . n_cyl + 1 ): for axis , axis1 in zip ( self . table_data [ f \"Fuel.Cylinder { i } .Trim\" ] . axes , self . table_data [ \"Fuel.Cylinder 1.Trim\" ] . axes , ): if axis1 != axis : return False return True check_sigs () Check that required input sigs are present. Source code in ccg\\controllers\\motec.py 2629 2630 2631 2632 2633 2634 2635 2636 2637 2638 2639 2640 2641 2642 2643 2644 2645 2646 2647 2648 2649 2650 2651 2652 2653 2654 2655 2656 2657 2658 2659 2660 2661 2662 2663 2664 2665 2666 2667 2668 2669 2670 2671 2672 2673 2674 2675 2676 2677 2678 2679 2680 2681 2682 2683 2684 2685 2686 2687 2688 2689 2690 2691 2692 2693 2694 2695 2696 2697 2698 2699 2700 2701 2702 2703 2704 2705 2706 2707 2708 2709 2710 2711 2712 2713 2714 2715 2716 2717 2718 2719 2720 2721 2722 2723 2724 2725 2726 2727 2728 2729 2730 2731 2732 2733 2734 2735 2736 2737 2738 2739 2740 2741 2742 2743 2744 2745 2746 2747 2748 2749 2750 2751 2752 2753 2754 2755 2756 2757 @profile def check_sigs ( self ): \"\"\"Check that required input sigs are present.\"\"\" if self . table_data and self . data : msgs = self . check_substitute_sigs () required_sigs = set ( [ \"Fuel.Mixture Aim\" , \"Engine.Efficiency\" , \"Fuel.Volume.Trim\" , \"Fuel.Volume.Compensation\" , \"Coolant.Temperature.Fuel Volume Compensation\" , ] ) for table in self . fueling_tables : for axis in self . table_data [ table . replace ( \"#\" , \"1\" )] . axes : required_sigs . add ( axis . name ) for i in range ( 1 , self . n_cyl + 1 ): required_sigs . add ( f \"Fuel.Cylinder { i } .Trim\" ) required_sigs . add ( f \"Exhaust.Lambda.Cylinder { i } \" ) for i in range ( 1 , self . n_banks + 1 ): required_sigs . add ( f \"Exhaust.Lambda.Bank { i } \" ) required_sigs . add ( f \"Fuel.Closed Loop.Control.Bank { i } .Trim\" ) if ( \"Ambient Pressure Relative\" in self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Mode\" ] . data ): required_sigs . add ( \"Ambient.Pressure\" ) ok_slow = [ \"Ambient.Pressure\" , \"Fuel.Mixture Aim\" , \"Fuel.Volume.Trim\" , \"Fuel.Volume.Compensation\" , \"Inlet.Manifold.Pressure.Estimate\" , \"Coolant.Temperature.Fuel Volume Compensation\" , \"Coolant.Temperature\" , ] extras = [ \"Inlet.Manifold.Pressure.Estimate\" , \"Inlet.Air.Temperature\" , \"Vehicle.Speed\" , \"Ignition.Cut\" , \"Ignition.Timing\" , \"Idle.State\" , \"Fuel.Volume.Transient\" , \"Fuel.Volume.Trim\" , \"Fuel.Volume.Compensation\" , \"Fuel.Timing.Primary\" , \"Fuel.Temperature\" , \"Fuel.Pressure\" , \"Fuel.Injector.Primary.Duty.Cycle\" , \"Fuel.Film.Primary\" , \"Fuel.Cut\" , \"Engine.Load\" , \"Coolant.Pressure\" , \"Engine.Charge.Temperature\" , \"Engine.Oil.Temperature\" , \"Engine.Oil.Pressure\" , \"ECU.Batter.Voltage\" , \"Engine.Load.Normalised\" , ] required_sigs = list ( required_sigs ) missing = [] for sig in required_sigs : if sig not in self . data : missing . append ( sig ) for sig in self . gate . sigs : if sig not in self . data and sig not in self . calcd_sigs : missing . append ( sig ) if missing : missing . sort () # msg = \"<br>\".join(missing) if self . warning_dialog : msgs . extend ([ \" \\n ## Missing Required Signals \\n \" , * missing ]) self . warning_dialog ( title = \"# Missing Signals\" , msg = \"<br>\" . join ( msgs ) ) return False raise ValueError ( f \"Missing Required Signals \\n { missing } \" ) for sig in required_sigs : if sig not in ok_slow : self . slow_sig = sig break for sig in required_sigs : if ( sig not in ok_slow and self . data [ sig ] . period > self . data [ self . slow_sig ] . period ): self . slow_sig = sig for sig in self . gate . sigs : if sig not in self . calcd_sigs and sig not in required_sigs : required_sigs . append ( sig ) tline = self . data [ self . slow_sig ] . tline self . resampled = self . data [ required_sigs ] . resample ( tline ) self . resampled . name = \"Resampled Data for Calc's\" self . data . math_tline = tline self . resampled . math_tline = tline for sig in extras : try : self . resampled . append ( self . data [ sig ] . resample ( tline )) except KeyError : pass if self . slow_freq < 50 : msgs . extend ( [ \" \\n ## Slow Signal \\n \" , f \"Calculation rate limited to { self . slow_freq } Hz by ` { self . slow_sig } `\" , ] ) if msgs : self . warning_dialog ( title = \"# Missing Signals\" , msg = \"<br>\" . join ( msgs )) return True else : return False check_substitute_sigs () Try to substitute for some common missing sigs. Source code in ccg\\controllers\\motec.py 2483 2484 2485 2486 2487 2488 2489 2490 2491 2492 2493 2494 2495 2496 2497 2498 2499 2500 2501 2502 2503 2504 2505 2506 2507 2508 2509 2510 2511 2512 2513 2514 2515 2516 2517 2518 2519 2520 2521 2522 2523 2524 2525 2526 2527 2528 2529 2530 2531 2532 2533 2534 2535 2536 2537 2538 2539 2540 2541 2542 2543 2544 2545 2546 2547 2548 2549 2550 2551 2552 2553 2554 2555 2556 2557 2558 2559 2560 2561 2562 2563 2564 2565 2566 2567 2568 2569 2570 2571 2572 2573 2574 2575 2576 2577 2578 2579 2580 2581 2582 2583 2584 2585 2586 2587 2588 2589 2590 2591 2592 2593 2594 2595 2596 2597 2598 2599 2600 2601 2602 2603 2604 2605 2606 2607 2608 2609 2610 2611 2612 2613 2614 2615 2616 2617 2618 2619 2620 2621 2622 2623 2624 2625 2626 2627 def check_substitute_sigs ( self ): \"\"\"Try to substitute for some common missing sigs.\"\"\" msgs = [] if self . table_data and self . data : try : mode = self . table_data [ \"Engine.Load.Normalised.Mode\" ] . data if mode == \"Normal\" : # Value = # p * # Engine.Efficiency * # Fuel Vapour Correction * # (Engine.Displacement / Engine.Cylinders) * // Displacement of one cylinder # (1 / (Constants.rAir * (Engine.Charge.Temperature + 273.15))); // Ideal gas law # when (Normalised.Mode) # { # is (Normal) # { # local ideal = # Ambient.Pressure.Standard * # 1.0 * # 1.0 * # (Engine.Displacement / Engine.Cylinders) * // Displacement of one cylinder # (1 / (Constants.rAir * (Constants.standardTemperature + 273.15))); // Ideal gas law # Normalised = Value / ideal; raise NotImplementedError elif mode == \"Inlet.Manifold.Pressure\" : sig = Sig ( name = \"Engine.Load.Normalised\" , data = self . data [ \"Inlet.Manifold.Pressure\" ] / ccg . util . convert_units ( 101.325 , \"kPa\" , self . data [ \"Inlet.Manifold.Pressure\" ] . unit , ), tline = self . data [ \"Inlet.Manifold.Pressure\" ] . tline , unit = \"ratio\" , ) elif mode == \"Throttle Position\" : sig = Sig ( name = \"Engine.Load.Normalised\" , data = self . data [ \"Throttle.Position\" ], ) sig . convert_units ( \"%\" ) if \"Engine.Load.Normalised\" not in self . data : self . data . append ( sig ) msgs . append ( \"`Engine.Load.Normalized` was not logged and has been calculated from input signals.\" ) elif sig . period < self . data [ \"Engine.Load.Normalised\" ] . period : self . data . remove ( \"Engine.Load.Normalised\" ) self . data . append ( sig ) msgs . append ( \"`Engine.Load.Normalized` was logged slowly and has been calculated from input signals.\" ) except KeyError : pass try : if \"Fuel.Volume.Trim\" not in self . data : sig = self . table_data [ \"Fuel.Volume.Trim.Overall\" ][ self . data ] sig . name = \"Fuel.Volume.Trim\" self . data . append ( sig ) msgs . append ( \"`Fuel.Volume.Trim` was not logged and has been calculated from the loaded calibration. ** Ensure that this matches the calibration that generated the data **\" ) except KeyError : pass try : if \"Engine.Efficiency\" not in self . data : sig = self . table_data [ \"Engine.Efficiency.Value\" ][ self . data ] sig . name = \"Engine.Efficiency\" self . data . append ( sig ) msgs . append ( \"`Engine.Efficiency` was not logged and has been calculated from the loaded calibration. ** Ensure that this matches the calibration that generated the data **\" ) except KeyError : pass try : if \"Fuel.Closed Loop.Control.Bank 1.Trim\" not in self . data : sig = Sig ( self . data [ self . slow_sig ]) sig . name = \"Fuel.Closed Loop.Control.Bank 1.Trim\" sig . data = np . ones ( sig . data . shape ) sig . unit = \"ratio\" self . data . append ( sig ) msgs . append ( \"`Fuel.Closed Loop.Control.Bank 1.Trim` was not logged and has been assumed to be disabled. ** Ensure that this matches the calibration that generated the data **\" ) except KeyError : pass try : if \"Fuel.Closed Loop.Control.Bank 2.Trim\" not in self . data : sig = Sig ( self . data [ self . slow_sig ]) sig . name = \"Fuel.Closed Loop.Control.Bank 2.Trim\" sig . data = np . ones ( sig . data . shape ) sig . unit = \"ratio\" self . data . append ( sig ) msgs . append ( \"`Fuel.Closed Loop.Control.Bank 2.Trim` was not logged and has been assumed to be disabled. ** Ensure that this matches the calibration that generated the data **\" ) except KeyError : pass for i in range ( 1 , self . n_cyl + 1 ): try : name = f \"Fuel.Cylinder { i } .Trim\" if name not in self . data : sig = self . table_data [ name ][ self . data ] self . data . append ( sig ) msgs . append ( f \"` { name } ` was not logged and has been calculated from the loaded calibration. ** Ensure that this matches the calibration that generated the data **\" ) except KeyError : pass try : if \"Coolant.Temperature.Fuel Volume Compensation\" not in self . data : sig = Sig ( self . data [ \"Fuel.Volume.Compensation\" ]) sig . name = \"Coolant.Temperature.Fuel Volume Compensation\" self . data . append ( sig ) msgs . append ( \"`Coolant.Temperature.Fuel Volume Compensation` was not logged and has been substituted with `Fuel.Volume.Compensation`. ** Ensure that no other volume compensation was active. **\" ) except KeyError : pass for i in range ( 1 , self . n_cyl + 1 ): try : name = f \"Exhaust.Lambda.Cylinder { i } \" if name not in self . data : sig = Sig ( self . data [ \"Exhaust.Lambda.Bank 1\" ]) * 0 sig . name = name self . data . append ( sig ) msgs . append ( f \"` { name } ` was not logged. Individual trims not possible.\" ) except KeyError : pass if msgs : msgs = [ \"## Substituted Signals \\n \" , * msgs ] return msgs convert_table_to_axes ( table , target ) Convert a table to fit the target axes if possible. Source code in ccg\\controllers\\motec.py 3407 3408 3409 3410 3411 3412 3413 3414 3415 3416 3417 3418 3419 3420 3421 3422 3423 3424 3425 3426 3427 3428 3429 3430 3431 3432 3433 3434 3435 3436 3437 3438 3439 3440 3441 3442 3443 3444 3445 3446 3447 3448 3449 3450 3451 3452 3453 3454 3455 3456 3457 3458 3459 3460 3461 3462 3463 3464 3465 3466 3467 3468 3469 3470 3471 def convert_table_to_axes ( self , table : Tbl , target : Axes ): \"\"\"Convert a table to fit the target axes if possible.\"\"\" res = Tbl ( name = \"result\" , axes = target , unit = table . unit ) if target . n_dim > 2 : raise NotImplementedError if target . n_dim < table . n_dim : raise NotImplementedError if table . n_dim == 0 : res . data = np . ones ( target . shape ) * table . orig . data res . snapshot ( \"orig\" ) res . data = np . ones ( target . shape ) * table . data return res # Leave in target units, convert table before interpolating. target_grid = target . grid interp_grid = target . grid units = [ \"\" ] * table . n_dim for j , axis in enumerate ( target ): found = False for i , t_axis in enumerate ( table . axes ): if axis . name == t_axis . name : interp_grid [ i ] = target_grid [ j ] units [ i ] = axis . unit found = True break if not found : # Check for possible calc if axis . name == \"Inlet.Manifold.Pressure\" : if \"Engine.Load.Normalised\" in table . axes : i = table . axes . index ( \"Engine.Load.Normalised\" ) # Calc engine load normalized mode = self . table_data [ \"Engine.Load.Normalised.Mode\" ] . data if mode == \"Normal\" : raise NotImplementedError elif mode == \"Inlet Manifold Pressure\" : tmp = Axis ( axis ) tmp . data = axis . data / ccg . util . convert_units ( 101.325 , \"kPa\" , axis . unit , ) interp_grid [ i ] = target_grid [ j ] units [ i ] = \"ratio\" elif mode == \"Throttle Position\" : eng_speed_ind = target . index ( \"Engine.Speed\" ) imap_ind = target . index ( \"Inlet.Manifold.Pressure\" ) interp_grid [ i ] = self . tps_from_map ( eng_speed = target_grid [ eng_speed_ind ], imap = target_grid [ imap_ind ], ) units [ i ] = \"%\" for unit , axis in zip ( units , table . axes ): axis . convert_units ( unit ) interp_vals = np . array ([ x . flatten () for x in interp_grid ]) . T res . data = table . orig . interp ( interp_vals ) . reshape ( target . shape , order = \"f\" ) res . snapshot ( \"orig\" ) res . data = table . interp ( interp_vals ) . reshape ( target . shape , order = \"f\" ) # res.plot() return res normalize_cyl_trims () Normalizes cyl trims if bp's match. Source code in ccg\\controllers\\motec.py 3203 3204 3205 3206 3207 3208 3209 3210 3211 3212 3213 3214 3215 3216 3217 3218 3219 3220 3221 3222 3223 3224 3225 3226 3227 3228 3229 def normalize_cyl_trims ( self ): \"\"\"Normalizes cyl trims if bp's match.\"\"\" cyl_trim_min = self . fueling_tables [ \"Fuel.Cylinder #.Trim\" ][ \"range\" ][ 0 ] cyl_trim_max = self . fueling_tables [ \"Fuel.Cylinder #.Trim\" ][ \"range\" ][ 1 ] cyl_trim_unit = self . fueling_tables [ \"Fuel.Cylinder #.Trim\" ][ \"unit\" ] if self . check_axes (): avg = np . zeros ( self . table_data [ \"Fuel.Cylinder 1.Trim\" ] . data . shape ) n = 0 for cyl in range ( 1 , self . n_cyl + 1 ): avg += self . table_data [ f \"Fuel.Cylinder { cyl } .Trim\" ] . data n += 1 avg = ccg . util . convert_units ( avg / n , cyl_trim_unit , \"ratio\" ) for cyl in range ( 1 , self . n_cyl + 1 ): cyl_trim = ( self . table_data [ f \"Fuel.Cylinder { cyl } .Trim\" ] . as_unit ( \"ratio\" ) . data / avg ) cyl_trim = ccg . util . convert_units ( cyl_trim , \"ratio\" , cyl_trim_unit ) self . table_data [ f \"Fuel.Cylinder { cyl } .Trim\" ] . data = np . clip ( cyl_trim , cyl_trim_min , cyl_trim_max ) else : raise ValueError ( \"Cyl trim axes dont match, cant normalize\" ) tps_from_map ( eng_speed , imap ) Estimate Throttle.Position from manifold air pressure. Source code in ccg\\controllers\\motec.py 3473 3474 3475 3476 3477 3478 3479 3480 3481 3482 3483 3484 3485 3486 3487 3488 3489 3490 3491 3492 3493 3494 3495 3496 3497 3498 3499 3500 3501 3502 3503 3504 3505 3506 3507 3508 3509 3510 3511 3512 3513 3514 3515 3516 3517 3518 3519 3520 def tps_from_map ( self , eng_speed : npt . NDArray , imap : npt . NDArray ): \"\"\"Estimate Throttle.Position from manifold air pressure.\"\"\" n = 100 tps_map = Tbl ( self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Main\" ]) tps_map . name = \"TPS Estimate\" tps_map . interp_on_axis_change = True tps_map . data *= 0 tps_map . f_orig = 0 tps_map . f_smooth = [ 0.001 , 0.001 ] map_unit = self . fueling_tables [ \"Engine.Efficiency.Value\" ][ \"axes\" ][ \"Z\" ][ \"unit\" ] tps_unit = tps_map . axes [ \"Throttle.Position\" ] . unit tps = np . linspace ( tps_map . axes [ \"Throttle.Position\" ] . data . min (), tps_map . axes [ \"Throttle.Position\" ] . data . max (), n , ) eng_spd = np . linspace ( tps_map . axes [ \"Engine.Speed\" ] . data . min (), tps_map . axes [ \"Engine.Speed\" ] . data . max (), n , ) bps = [ x . flatten () for x in np . meshgrid ( tps , eng_spd )] maps = ( self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Main\" ] . as_unit ( \"ratio\" ) . interp ( np . array ( bps ) . T ) * self . table_data [ \"Ambient.Pressure.Default.Value\" ] . as_unit ( map_unit ) . data ) map_bps = np . linspace ( 10 , 101 , 40 , ) tps_map . axes [ \"Throttle.Position\" ] . data = map_bps tps_map . axes [ \"Throttle.Position\" ] . name = \"Inlet.Manifold.Pressure\" tps_map . axes [ \"Inlet.Manifold.Pressure\" ] . unit = map_unit tps_map . unit = tps_unit new_grid = [ maps , bps [ 1 ], bps [ 0 ]] tps_map . scatter_data = ScatterData ( new_grid ) tps_map . fit () # tps_map.plot() interps = np . array ([ imap , eng_speed ]) . T return np . clip ( tps_map . interp ( interps ), 0 , 100 ) update_calcd_data () Update calculations for fitting/plotting. Source code in ccg\\controllers\\motec.py 2759 2760 2761 2762 2763 2764 2765 2766 2767 2768 2769 2770 2771 2772 2773 2774 2775 2776 2777 2778 2779 2780 2781 2782 2783 2784 2785 2786 2787 2788 2789 2790 2791 2792 2793 2794 2795 2796 2797 2798 2799 2800 2801 2802 2803 2804 2805 2806 2807 2808 2809 2810 2811 2812 2813 2814 2815 2816 2817 2818 2819 2820 2821 2822 2823 2824 2825 2826 2827 2828 2829 2830 2831 2832 2833 2834 2835 2836 2837 2838 2839 2840 2841 2842 2843 2844 2845 2846 2847 2848 2849 2850 2851 2852 2853 2854 2855 2856 2857 2858 2859 2860 2861 2862 2863 2864 2865 2866 2867 2868 2869 2870 2871 2872 2873 2874 2875 2876 2877 2878 2879 2880 2881 2882 2883 2884 2885 2886 2887 2888 2889 2890 2891 2892 2893 2894 2895 2896 2897 2898 2899 2900 2901 2902 2903 2904 2905 2906 2907 2908 2909 2910 2911 2912 2913 2914 2915 2916 2917 2918 2919 2920 2921 2922 2923 2924 2925 2926 2927 2928 2929 2930 2931 2932 2933 2934 2935 2936 2937 2938 2939 2940 2941 2942 2943 2944 2945 2946 2947 2948 2949 2950 2951 2952 2953 2954 2955 2956 2957 2958 2959 2960 2961 2962 2963 2964 2965 2966 2967 2968 2969 2970 2971 2972 2973 2974 2975 2976 2977 2978 2979 2980 2981 2982 2983 2984 2985 2986 2987 2988 2989 2990 2991 2992 2993 2994 2995 2996 2997 2998 2999 3000 3001 3002 3003 3004 3005 3006 3007 3008 3009 3010 3011 3012 3013 3014 3015 3016 3017 3018 3019 3020 @profile def update_calcd_data ( self ): \"\"\"Update calculations for fitting/plotting.\"\"\" if self . _needs_calcs : tic = datetime . now () if self . check_sigs (): if self . table_data : acc = 0 n = 0 for cyl in range ( 1 , 1 + self . n_cyl ): tmp = self . resampled [ f \"Fuel.Cylinder { cyl } .Trim\" ] . as_unit ( \"ratio\" ) tmp . unit = \"ratio\" tmp . name = f \"Fuel.Cylinder { cyl } .Trim.Total\" self . resampled . append ( tmp ) acc = acc + tmp n += 1 acc = acc / n acc . name = \"Cylinder.Trim.Avg\" acc . unit = \"ratio\" self . resampled . append ( acc ) for bank in range ( 1 , self . n_banks + 1 ): tmp = 0 n = 0 for cyl in range ( 1 , 1 + self . n_cyl ): if ( self . table_data [ f \"Engine.Cylinder { cyl } .Bank\" ] . data == bank ): n += 1 tmp = ( tmp + self . resampled [ f \"Exhaust.Lambda.Cylinder { cyl } \" ] ) tmp = tmp / n tmp . name = f \"Lambda.Indiv.Bank { bank } .Avg\" tmp . unit = \"LA\" tmp . data_range = [ 0.6 , 1.4 ] self . resampled . append ( tmp ) tmp = 0 n = 0 for cyl in range ( 1 , 1 + self . n_cyl ): if ( self . table_data [ f \"Engine.Cylinder { cyl } .Bank\" ] . data == bank ): n += 1 tmp = tmp + self . resampled [ f \"Fuel.Cylinder { cyl } .Trim\" ] . as_unit ( \"ratio\" ) tmp = tmp / n tmp . name = f \"Cylinder.Trim.Bank { bank } .Avg\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) self . resampled [ f \"Exhaust.Lambda.Bank { bank } \" ] . data_range = [ 0.6 , 1.4 , ] tmp = self . table_data [ \"Coolant.Temperature.Fuel Volume Compensation\" ][ self . resampled ] . as_unit ( \"ratio\" ) / self . resampled [ \"Fuel.Volume.Compensation\" ] . as_unit ( \"ratio\" ) tmp . name = \"Volume.Comp.Delta\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ \"Fuel.Closed Loop.Control.Bank 1.Trim\" ] . as_unit ( \"ratio\" ) * self . resampled [ \"Fuel.Volume.Trim\" ] . as_unit ( \"ratio\" ) / self . resampled [ \"Volume.Comp.Delta\" ] . as_unit ( \"ratio\" ) * self . resampled [ \"Cylinder.Trim.Bank 1.Avg\" ] * self . resampled [ \"Exhaust.Lambda.Bank 1\" ] / self . resampled [ \"Fuel.Mixture Aim\" ] ) # TODO: Fix for only 1 bank tmp . name = \"Fueling.Error.Bank 1\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ \"Fuel.Closed Loop.Control.Bank 2.Trim\" ] . as_unit ( \"ratio\" ) * self . resampled [ \"Fuel.Volume.Trim\" ] . as_unit ( \"ratio\" ) / self . resampled [ \"Volume.Comp.Delta\" ] . as_unit ( \"ratio\" ) * self . resampled [ \"Cylinder.Trim.Bank 2.Avg\" ] * self . resampled [ \"Exhaust.Lambda.Bank 2\" ] / self . resampled [ \"Fuel.Mixture Aim\" ] ) tmp . name = \"Fueling.Error.Bank 2\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ \"Fueling.Error.Bank 1\" ] + self . resampled [ \"Fueling.Error.Bank 2\" ] ) / 2 tmp . name = \"Fueling.Error.Total\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = self . resampled [ \"Fueling.Error.Total\" ] * ( self . resampled [ \"Engine.Efficiency\" ] ) tmp . name = \"Engine.Efficiency.Value.Corrected\" tmp . unit = \"%\" self . resampled . append ( tmp ) self . resampled . append ( Sig ( self . resampled [ \"Engine.Efficiency\" ], name = \"Engine.Efficiency.Value\" , ) ) # copy with name to match table for cyl in range ( 1 , 1 + self . n_cyl ): bank = int ( self . table_data [ f \"Engine.Cylinder { cyl } .Bank\" ] . data ) tmp = ( self . resampled [ f \"Exhaust.Lambda.Cylinder { cyl } \" ] / self . resampled [ f \"Lambda.Indiv.Bank { bank } .Avg\" ] ) tmp . name = f \"Cyl { cyl } .Lam.Error\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ f \"Fuel.Cylinder { cyl } .Trim.Total\" ] / self . resampled [ f \"Cylinder.Trim.Bank { bank } .Avg\" ] ) tmp . name = f \"Fuel.Cylinder { cyl } .Trim.Bank Normalised\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ f \"Fuel.Cylinder { cyl } .Trim.Total\" ] / self . resampled [ \"Cylinder.Trim.Avg\" ] ) tmp . name = f \"Fuel.Cylinder { cyl } .Trim.Normalised\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ f \"Fuel.Cylinder { cyl } .Trim.Bank Normalised\" ] * self . resampled [ f \"Cyl { cyl } .Lam.Error\" ] * ( self . resampled [ f \"Fueling.Error.Bank { bank } \" ] / self . resampled [ \"Fueling.Error.Total\" ] ) ) tmp . name = f \"Fuel.Cylinder { cyl } .Trim.Corrected\" tmp . unit = \"ratio\" tmp . convert_units ( \"%Trim\" ) self . resampled . append ( tmp ) # Calc cyl trims from tailpipe data incase indiv missing tmp = self . resampled [ f \"Fuel.Cylinder { cyl } .Trim.Normalised\" ] * ( self . resampled [ f \"Fueling.Error.Bank { bank } \" ] / self . resampled [ \"Fueling.Error.Total\" ] ) tmp . name = f \"Fuel.Cylinder { cyl } .Trim.Corrected.Tailpipe\" tmp . unit = \"ratio\" tmp . convert_units ( \"%Trim\" ) self . resampled . append ( tmp ) self . resampled [ f \"Exhaust.Lambda.Cylinder { cyl } \" ] . data_range = [ 0.6 , 1.4 , ] self . resampled . append ( self . resampled [ \"Engine.Speed\" ] . dot ( n_win = 17 )) self . resampled . append ( self . resampled [ \"Throttle.Position\" ] . dot ( n_win = 7 ) ) # inlet manifold press ref try : if ( \"Ambient Pressure Relative\" in self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Mode\" ] . data ): tmp = ( self . resampled [ \"Inlet.Manifold.Pressure\" ] / self . resampled [ \"Ambient.Pressure\" ] ) else : tmp = self . resampled [ \"Inlet.Manifold.Pressure\" ] / 100 tmp . name = \"Inlet.Manifold.Pressure.Estimate.Main.Corrected\" tmp . unit = \"ratio\" tmp . convert_units ( \"%\" ) self . resampled . append ( tmp ) if ( \"Ambient Pressure Relative\" in self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Mode\" ] . data ): tmp = ( self . resampled [ \"Inlet.Manifold.Pressure.Estimate\" ] / self . resampled [ \"Ambient.Pressure\" ] ) else : tmp = ( self . resampled [ \"Inlet.Manifold.Pressure.Estimate\" ] / 100 ) tmp . name = \"Inlet.Manifold.Pressure.Estimate.Main\" tmp . unit = \"ratio\" tmp . convert_units ( \"%\" ) self . resampled . append ( tmp ) except KeyError : pass # Coolant temp comps tmp = ( self . resampled [ \"Engine.Efficiency.Value.Corrected\" ] . as_unit ( \"ratio\" ) / self . table_data [ \"Engine.Efficiency.Value\" ][ self . resampled ] . as_unit ( \"ratio\" ) * self . resampled [ \"Coolant.Temperature.Fuel Volume Compensation\" ] . as_unit ( \"ratio\" ) * self . resampled [ \"Volume.Comp.Delta\" ] . as_unit ( \"ratio\" ) ) tmp . name = \"Coolant.Temperature.Fuel Volume Compensation.Corrected\" tmp . unit = \"ratio\" tmp . convert_units ( \"%Trim\" ) self . resampled . append ( tmp ) toc = datetime . now () - tic _LOGGER . debug ( \"Firmware calcs in %.3f \" , toc . total_seconds ()) # Set some ranges self . resampled [ \"Engine.Speed\" ] . data_range = [ 0 , 8800 ] self . resampled [ \"Fuel.Mixture Aim\" ] . data_range = [ 0.6 , 1.4 ] # Add calc'd signals to data frame for general plot self . data . append ( self . resampled ) self . _needs_calcs = False if not self . _needs_calcs : self . update_scatter_data () if self . resampled : # Update options for scatter plots opts = [ \"Relative Density\" , * self . resampled . sigs . keys ()] for tab in self . tabs : tab . color_sig . options = opts update_scatter_data () Update scatter data for fitting. Source code in ccg\\controllers\\motec.py 3022 3023 3024 3025 3026 3027 3028 3029 3030 3031 3032 3033 3034 3035 3036 3037 3038 3039 3040 3041 3042 3043 3044 3045 3046 3047 3048 3049 3050 3051 3052 3053 3054 3055 3056 3057 3058 3059 3060 3061 3062 3063 3064 3065 3066 3067 3068 3069 3070 3071 3072 3073 3074 3075 3076 3077 3078 3079 3080 3081 3082 3083 3084 3085 3086 3087 3088 3089 3090 3091 3092 3093 3094 3095 3096 3097 3098 3099 3100 3101 3102 3103 3104 3105 3106 3107 3108 3109 3110 3111 3112 3113 3114 3115 3116 3117 3118 3119 3120 3121 3122 3123 3124 3125 3126 3127 3128 3129 3130 3131 3132 3133 3134 3135 3136 3137 3138 3139 3140 3141 3142 3143 3144 3145 3146 3147 3148 3149 3150 3151 3152 3153 3154 3155 3156 3157 3158 3159 3160 3161 3162 3163 3164 3165 3166 3167 3168 3169 3170 3171 3172 3173 3174 3175 3176 3177 3178 3179 3180 3181 3182 3183 3184 3185 3186 3187 3188 3189 3190 3191 3192 3193 3194 3195 3196 3197 3198 3199 3200 3201 @profile def update_scatter_data ( self ): \"\"\"Update scatter data for fitting.\"\"\" if self . _needs_scatter_update : # Build signal list bank_gate_tables = [ \"Fuel.Cylinder #.Trim\" ] remove_digits = str . maketrans ( \"0123456789\" , \"##########\" ) msg = [] self . use_tailpipes = [ False ] * self . n_banks if self . _needs_calcs : self . update_calcd_data () for table in self . table_data : if f \" { table . name } .Corrected\" in self . resampled . sigs : tmp : list [ Sig ] = [] ranges = [] if table . name . translate ( remove_digits ) in bank_gate_tables : cyl = \"\" . join ( filter ( lambda x : x . isdigit (), table . name )) bank_ind = ( self . table_data [ f \"Engine.Cylinder { cyl } .Bank\" ] . data [ 0 ] - 1 ) if self . tabs [ table . name ] . additional_gate : gate = GateCollAND ( [ self . bank_gates [ bank_ind ], self . tabs [ table . name ] . additional_gate , ] ) else : gate = self . bank_gates [ bank_ind ] tmp_sig = ( self . resampled [ f \" { table . name } .Corrected\" ] . valid ( gate ) . resample ( self . resampled . math_tline ) ) if ( tmp_sig . data . size - np . count_nonzero ( np . isnan ( tmp_sig . data )) < 1 ): msg . append ( f \" \\n ## Individual Cylinder Lambda signals out of limits on bank { bank_ind + 1 } . \\n Bank trim from tailpipe sensor only.\" ) self . use_tailpipes [ bank_ind ] = True if self . tabs [ table . name ] . additional_gate : gate = GateCollAND ( [ self . gate , self . tabs [ table . name ] . additional_gate ] ) else : gate = self . gate tmp_sig = ( self . resampled [ f \" { table . name } .Corrected.Tailpipe\" ] . valid ( gate ) . resample ( self . resampled . math_tline ) ) self . resampled . remove ( f \" { table . name } .Corrected\" ) self . resampled . append ( Sig ( self . resampled [ f \" { table . name } .Corrected.Tailpipe\" ], name = f \" { table . name } .Corrected\" , ) ) for axis in table . axes : tmp . append ( self . resampled [ f \" { axis . name } \" ] . valid ( gate ) . as_unit ( axis . unit ) . resample ( self . resampled . math_tline ) ) ranges . append ([ axis . min , axis . max ]) tmp . append ( tmp_sig ) ranges . append ([ table . min , table . max ]) else : if self . tabs [ table . name ] . additional_gate : gate = GateCollAND ( [ self . gate , self . tabs [ table . name ] . additional_gate ] ) else : gate = self . gate for axis in table . axes : tmp . append ( self . resampled [ f \" { axis . name } \" ] . valid ( gate ) . as_unit ( axis . unit ) . resample ( self . resampled . math_tline ) ) ranges . append ([ axis . min , axis . max ]) tmp_sig = ( self . resampled [ f \" { table . name } .Corrected\" ] . valid ( gate ) . resample ( self . resampled . math_tline ) ) if \"Coolant.Temperature.Fuel Volume Compensation\" in table . name : try : # Need to adjust offset to center at normal op temp op_temp = self . tabs [ table . name ] . op_temp . value ind = table . axes [ 0 ] . bins ( op_temp )[ 0 ] diff = table . axes [ 0 ] . diff [ ind ] zero_inds = np . logical_and ( np . greater ( tmp [ - 1 ] . data , op_temp - diff / 2 ), np . less ( tmp [ - 1 ] . data , op_temp + diff / 2 ), ) zero_val = np . mean ( tmp_sig . data [ zero_inds ]) if np . isnan ( zero_val ): zero_val = 0 tmp_sig -= zero_val except AttributeError : pass tmp . append ( tmp_sig ) ranges . append ([ table . min , table . max ]) color_data = None color_name = None color_unit = None color_range = None if self . tabs [ table . name ] . color_sig . value : name = self . tabs [ table . name ] . color_sig . value [ 0 ] if \"Relative Density\" in name : color_name = name n_bins = [ 70 ] * len ( tmp ) n_bins [ - 1 ] *= 2 bins = [] for vals , intv , n_bin in zip ( tmp , ranges , n_bins ): bins . append ( np . linspace ( np . minimum ( vals . min , intv [ 0 ]), np . maximum ( vals . max , intv [ 1 ]), n_bin , ) ) color_data = scatter_density ( ScatterData ( tmp ), n_bins = bins ) elif name in self . resampled : color_data = ( self . resampled [ name ] . valid ( gate ) . resample ( self . resampled . math_tline ) . data ) color_name = name color_unit = self . resampled [ name ] . unit color_range = self . resampled [ name ] . data_range table . scatter_data = ScatterData ( data = tmp , name = \"Corrected\" , color = color_data , color_unit = color_unit , color_name = color_name , color_range = color_range , ) . clean () # Add logged data trace if table . name in self . resampled : tmp [ - 1 ] = ( self . resampled [ table . name ] . valid ( gate ) . resample ( self . resampled . math_tline ) ) table . scatter_data . append ( ScatterData ( data = tmp , name = \"Logged\" ) . clean () ) else : table . scatter_data = None self . _needs_scatter_update = False if msg and self . _needs_bank_warning : msg = list ( set ( msg )) self . warning_dialog ( title = \"# Fit Data Warning\" , msg = \"<br>\" . join ( msg )) self . _needs_bank_warning = ( # pylint: disable=attribute-defined-outside-init False ) FCM1 Bases: FirmwareModel M1 Firmware model for FCM1 Source code in ccg\\controllers\\motec.py 3523 3524 3525 3526 3527 3528 3529 3530 3531 3532 3533 3534 3535 3536 3537 3538 3539 3540 3541 3542 3543 3544 3545 3546 3547 3548 3549 3550 3551 3552 3553 3554 3555 3556 3557 3558 3559 3560 3561 3562 3563 3564 3565 3566 3567 3568 3569 3570 3571 3572 3573 3574 3575 3576 3577 3578 3579 3580 3581 3582 3583 3584 3585 3586 3587 3588 3589 3590 3591 3592 3593 3594 3595 3596 3597 3598 3599 3600 3601 3602 3603 3604 3605 3606 3607 3608 3609 3610 3611 3612 3613 3614 3615 3616 3617 3618 3619 3620 3621 3622 3623 3624 3625 3626 3627 3628 3629 3630 3631 3632 3633 3634 3635 3636 3637 3638 3639 3640 3641 3642 3643 3644 3645 3646 3647 3648 3649 3650 3651 3652 3653 3654 3655 3656 3657 3658 3659 3660 3661 3662 3663 3664 3665 3666 3667 3668 3669 3670 3671 3672 3673 3674 3675 3676 3677 3678 3679 3680 3681 3682 3683 3684 3685 3686 3687 3688 3689 3690 3691 3692 3693 3694 3695 3696 3697 3698 3699 3700 3701 3702 3703 3704 3705 3706 3707 3708 3709 3710 3711 3712 3713 3714 3715 3716 3717 3718 3719 3720 3721 3722 3723 3724 3725 3726 3727 3728 3729 3730 3731 3732 3733 3734 3735 3736 3737 3738 3739 3740 3741 3742 3743 3744 3745 3746 3747 3748 3749 3750 3751 3752 3753 3754 3755 3756 3757 3758 3759 3760 3761 3762 3763 3764 3765 3766 3767 3768 3769 3770 3771 3772 3773 3774 3775 3776 3777 3778 3779 3780 3781 3782 3783 3784 3785 3786 3787 3788 3789 3790 3791 3792 3793 3794 3795 3796 3797 3798 3799 3800 3801 3802 3803 3804 3805 3806 3807 3808 3809 3810 3811 3812 3813 3814 3815 3816 3817 3818 3819 3820 3821 3822 3823 3824 3825 3826 3827 3828 3829 3830 3831 3832 3833 3834 3835 3836 3837 3838 3839 3840 3841 3842 3843 3844 3845 3846 3847 3848 3849 3850 3851 3852 3853 3854 3855 3856 3857 3858 3859 3860 3861 3862 3863 3864 3865 3866 3867 3868 3869 3870 3871 3872 3873 3874 3875 3876 3877 3878 3879 3880 3881 3882 3883 3884 3885 3886 3887 3888 3889 3890 3891 3892 3893 3894 3895 3896 3897 3898 3899 3900 3901 3902 3903 3904 3905 3906 3907 3908 3909 3910 3911 3912 3913 3914 3915 3916 3917 3918 3919 3920 3921 3922 3923 3924 3925 3926 3927 3928 3929 3930 class FCM1 ( FirmwareModel ): \"\"\"M1 Firmware model for FCM1\"\"\" reference_tables = { \"Fuel.Mixture Aim.Main\" : { \"unit\" : \"LA\" , \"prec\" : 2 , \"range\" : [ 0.01 , 5 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine.Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 1 , }, \"Y\" : { \"sig\" : \"Inlet.Manifold.Pressure\" , \"unit\" : \"mbar\" , \"range\" : [ np . NINF , np . inf ], \"prec\" : 1 , }, \"Z\" : { \"sig\" : \"Driver.Fuel.Mixture Aim Main Switch\" , \"unit\" : \"\" , \"range\" : [ \"A\" , \"B\" ], \"prec\" : 0 , }, }, }, \"Fuel.Timing.Primary.Main\" : { \"unit\" : \"dBTDC\" , \"prec\" : 1 , \"range\" : [ 0 , 1440 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine.Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 1 , }, \"Y\" : { \"sig\" : \"Inlet.Manifold.Pressure\" , \"unit\" : \"mbar\" , \"range\" : [ 0 , np . inf ], \"prec\" : 1 , }, }, }, \"Fuel.Timing.Secondary.Main\" : { \"unit\" : \"dBTDC\" , \"prec\" : 1 , \"range\" : [ 0 , 1440 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine.Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 1 , }, \"Y\" : { \"sig\" : \"Inlet.Manifold.Pressure\" , \"unit\" : \"mbar\" , \"range\" : [ 0 , np . inf ], \"prec\" : 1 , }, }, }, } fueling_tables = { \"Engine.Efficiency.Value\" : { \"unit\" : \"%\" , \"prec\" : 1 , \"range\" : [ 10 , 200 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine.Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 1 , }, \"Y\" : { \"sig\" : \"Inlet.Manifold.Pressure\" , \"unit\" : \"mbar\" , \"range\" : [ 0 , np . inf ], \"prec\" : 1 , }, }, }, \"Coolant.Temperature.Fuel Volume Compensation\" : { \"unit\" : \"%Trim\" , \"prec\" : 1 , \"range\" : [ - 50 , 50 ], \"axes\" : { \"X\" : { \"sig\" : \"Coolant.Temperature\" , \"unit\" : \"C\" , \"range\" : [ - 50 , 200 ], \"prec\" : 1 , }, }, }, \"Fuel.Volume.Trim.Overall\" : { \"unit\" : \"%Trim\" , \"prec\" : 1 , \"range\" : [ - 99.9 , np . inf ], }, } fueling_params = { \"Fuel.Efficiency.Mode\" : { 0 : \"Manifold Air Density\" , 1 : \"Ambient Air Density\" , 2 : \"Airbox Air Density\" , }, \"Inlet.Manifold.Pressure.Mode\" : { 0 : \"Automatic\" , 1 : \"Estimate\" , 2 : \"Sensor\" , }, \"Engine.Rotors\" : 2 , \"Engine.Rotor #.Bank\" : 1 , \"Engine.Load.Normalised.Mode\" : { 0 : \"Normal\" , 1 : \"Inlet Manifold Pressure\" , 2 : \"Throttle Position\" , }, \"Inlet.Manifold.Pressure.Estimate.Mode\" : { 0 : \"Ambient Pressure Relative\" , 1 : \"100kPa Relative\" , }, } # TODO: complete calcd_sigs = [ \"Fueling.Error.Total\" , \"Engine.Efficiency.Value.Corrected\" , ] def __init__ ( self , m1cfg : str | Path = None , data : str | Path | Frame = None , gate : GateColl | str | Path = None , warning_dialog : Callable = None , ): super () . __init__ ( m1cfg = m1cfg , data = data , gate = gate , warning_dialog = warning_dialog , ) self . slow_sig = \"Engine.Speed\" @property def n_cyl ( self ): if self . table_data : return int ( self . table_data [ \"Engine.Rotors\" ] . data ) return 2 @property def n_banks ( self ): if self . table_data : return int ( max ( self . table_data [ f \"Engine.Rotor { i } .Bank\" ] . data for i in range ( 1 , self . n_cyl + 1 ) ) ) return 1 # @profile def check_substitute_sigs ( self ): \"\"\"Try to substitute for some common missing sigs.\"\"\" if self . table_data and self . data : try : mode = self . table_data [ \"Engine.Load.Normalised.Mode\" ] . data if mode == \"Normal\" : # Value = # p * # Engine.Efficiency * # Fuel Vapour Correction * # (Engine.Displacement / Engine.Cylinders) * // Displacement of one cylinder # (1 / (Constants.rAir * (Engine.Charge.Temperature + 273.15))); // Ideal gas law # when (Normalised.Mode) # { # is (Normal) # { # local ideal = # Ambient.Pressure.Standard * # 1.0 * # 1.0 * # (Engine.Displacement / Engine.Cylinders) * // Displacement of one cylinder # (1 / (Constants.rAir * (Constants.standardTemperature + 273.15))); // Ideal gas law # Normalised = Value / ideal; raise NotImplementedError elif mode == \"Inlet.Manifold.Pressure\" : sig = Sig ( name = \"Engine.Load.Normalised\" , data = self . data [ \"Inlet.Manifold.Pressure\" ] / ccg . util . convert_units ( 101.325 , \"kPa\" , self . data [ \"Inlet.Manifold.Pressure\" ] . unit , ), tline = self . data [ \"Inlet.Manifold.Pressure\" ] . tline , unit = \"ratio\" , ) elif mode == \"Throttle Position\" : sig = Sig ( name = \"Engine.Load.Normalised\" , data = self . data [ \"Throttle.Position\" ], ) sig . convert_units ( \"%\" ) if \"Engine.Load.Normalised\" not in self . data : self . data . append ( sig ) elif sig . period < self . data [ \"Engine.Load.Normalised\" ] . period : self . data . remove ( \"Engine.Load.Normalised\" ) self . data . append ( sig ) except ( KeyError , NotImplementedError ): pass # @profile def check_sigs ( self ): \"\"\"Check that required input sigs are present.\"\"\" if self . table_data and self . data : self . check_substitute_sigs () required_sigs = set ( [ \"Fuel.Lambda Control.Lambda Aim Delayed\" , \"Engine.Efficiency\" , \"Exhaust.Lambda\" , \"Fuel.Lambda Control.Factor\" , \"Fuel.Lambda Control.Adaptation\" , \"Throttle.Position\" , \"Inlet.Manifold.Temperature\" , \"Engine.Charge.Temperature\" , \"Fuel.Rotor 1.Primary.Film.Compensation\" , \"Fuel.Injector.Primary.Contribution\" , \"Fuel.Volume.Trim\" , ] ) for table in self . fueling_tables : for axis in self . table_data [ table . replace ( \"#\" , \"1\" )] . axes : required_sigs . add ( axis . name ) for sig in self . gate . sigs : if sig not in self . calcd_sigs : required_sigs . add ( sig ) if ( \"Ambient Pressure Relative\" in self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Mode\" ] . data ): required_sigs . add ( \"Ambient.Pressure\" ) ok_slow = [ \"Ambient.Pressure\" , \"Inlet.Manifold.Temperature\" , \"Fuel.Lambda Control.Lambda Aim Delayed\" , \"Engine.Charge.Temperature\" , \"Fuel.Rotor 1.Primary.Film.Compensation\" , \"Fuel.Injector.Primary.Contribution\" , \"Fuel.Volume.Trim\" , ] required_sigs = list ( required_sigs ) for sig in required_sigs : if sig not in ok_slow : self . slow_sig = sig break for sig in required_sigs : if ( sig not in ok_slow and self . data [ sig ] . period > self . data [ self . slow_sig ] . period ): self . slow_sig = sig missing = [] for sig in required_sigs : if sig not in self . data : missing . append ( sig ) if missing : raise ValueError ( f \"Missing required signals: { missing } \" ) self . resampled = self . data [ required_sigs ] . resample ( self . data [ self . slow_sig ] . tline ) self . data . math_tline = self . data [ self . slow_sig ] . tline self . resampled . math_tline = self . data [ self . slow_sig ] . tline return True else : return False # @profile def update_calcd_data ( self ): \"\"\"Update calculations for fitting/plotting.\"\"\" if self . _needs_calcs : tic = datetime . now () if self . check_sigs (): tmp = ( self . resampled [ \"Fuel.Lambda Control.Factor\" ] . convert_units ( \"ratio\" ) * self . resampled [ \"Fuel.Lambda Control.Adaptation\" ] . convert_units ( \"ratio\" ) * self . resampled [ \"Fuel.Volume.Trim\" ] . convert_units ( \"ratio\" ) * self . resampled [ \"Exhaust.Lambda\" ] / self . resampled [ \"Fuel.Lambda Control.Lambda Aim Delayed\" ] ) tmp . name = \"Fueling.Error.Total\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = self . resampled [ \"Fueling.Error.Total\" ] * ( 1 + self . resampled [ \"Engine.Efficiency\" ] ) tmp . name = \"Engine.Efficiency.Value.Corrected\" tmp . unit = \"%\" self . resampled . append ( tmp ) tmp = Sig ( self . resampled [ \"Fueling.Error.Total\" ]) . convert_units ( \"%Trim\" ) tmp . name = \"Fuel.Volume.Trim.Overall.Corrected\" self . resampled . append ( tmp ) tmp = Sig ( tmp ) # Be sure to copy... tmp . name = \"Coolant.Temperature.Fuel Volume Compensation.Corrected\" self . resampled . append ( tmp ) if self . table_data : self . resampled . append ( self . resampled [ \"Engine.Speed\" ] . dot ( n_win = 9 )) # inlet manifold press ref if ( \"Ambient Pressure Relative\" in self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Mode\" ] . data ): tmp = ( self . resampled [ \"Inlet.Manifold.Pressure\" ] / self . resampled [ \"Ambient.Pressure\" ] ) else : tmp = self . resampled [ \"Inlet.Manifold.Pressure\" ] / 1000 tmp . name = \"Inlet.Manifold.Pressure.Estimate.Main.Corrected\" tmp . unit = \"ratio\" tmp . convert_units ( \"%\" ) self . resampled . append ( tmp ) self . resampled . name = \"Resampled Data for calcs\" toc = datetime . now () - tic _LOGGER . debug ( \"Firmware calcs in %.3f \" , toc . total_seconds ()) # Set some ranges self . resampled [ \"Engine.Speed\" ] . data_range = [ 0 , 8000 ] self . resampled [ \"Fuel.Lambda Control.Lambda Aim Delayed\" ] . data_range = [ 0.6 , 1.4 , ] self . _needs_calcs = False self . update_scatter_data () def update_scatter_data ( self ): \"\"\"Update scatter data for fitting.\"\"\" # Build signal list if self . _needs_calcs : self . update_calcd_data () for table in self . table_data : if f \" { table . name } .Corrected\" in self . resampled : tmp = [] for axis in table . axes : tmp . append ( self . resampled [ f \" { axis . name } \" ] . valid ( self . gate ) . resample ( self . resampled . math_tline ) ) tmp . append ( self . resampled [ f \" { table . name } .Corrected\" ] . valid ( self . gate ) . resample ( self . resampled . math_tline ) ) if table . name == \"Engine.Efficiency.Value\" : color = self . resampled [ \"Inlet.Manifold.Temperature\" ] color_unit = \"%\" color_name = \"Primary Contr.\" color_range = [ 0 , 100 ] else : color = None color_name = None color_unit = None color_range = None table . scatter_data = ScatterData ( data = tmp , name = \"Measured\" , color = color , color_unit = color_unit , color_name = color_name , color_range = color_range , ) . clean () else : table . scatter_data = None def normalize_cyl_trims ( self ): pass check_sigs () Check that required input sigs are present. Source code in ccg\\controllers\\motec.py 3747 3748 3749 3750 3751 3752 3753 3754 3755 3756 3757 3758 3759 3760 3761 3762 3763 3764 3765 3766 3767 3768 3769 3770 3771 3772 3773 3774 3775 3776 3777 3778 3779 3780 3781 3782 3783 3784 3785 3786 3787 3788 3789 3790 3791 3792 3793 3794 3795 3796 3797 3798 3799 3800 3801 3802 3803 3804 3805 3806 3807 3808 3809 3810 3811 3812 3813 3814 3815 3816 3817 3818 3819 def check_sigs ( self ): \"\"\"Check that required input sigs are present.\"\"\" if self . table_data and self . data : self . check_substitute_sigs () required_sigs = set ( [ \"Fuel.Lambda Control.Lambda Aim Delayed\" , \"Engine.Efficiency\" , \"Exhaust.Lambda\" , \"Fuel.Lambda Control.Factor\" , \"Fuel.Lambda Control.Adaptation\" , \"Throttle.Position\" , \"Inlet.Manifold.Temperature\" , \"Engine.Charge.Temperature\" , \"Fuel.Rotor 1.Primary.Film.Compensation\" , \"Fuel.Injector.Primary.Contribution\" , \"Fuel.Volume.Trim\" , ] ) for table in self . fueling_tables : for axis in self . table_data [ table . replace ( \"#\" , \"1\" )] . axes : required_sigs . add ( axis . name ) for sig in self . gate . sigs : if sig not in self . calcd_sigs : required_sigs . add ( sig ) if ( \"Ambient Pressure Relative\" in self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Mode\" ] . data ): required_sigs . add ( \"Ambient.Pressure\" ) ok_slow = [ \"Ambient.Pressure\" , \"Inlet.Manifold.Temperature\" , \"Fuel.Lambda Control.Lambda Aim Delayed\" , \"Engine.Charge.Temperature\" , \"Fuel.Rotor 1.Primary.Film.Compensation\" , \"Fuel.Injector.Primary.Contribution\" , \"Fuel.Volume.Trim\" , ] required_sigs = list ( required_sigs ) for sig in required_sigs : if sig not in ok_slow : self . slow_sig = sig break for sig in required_sigs : if ( sig not in ok_slow and self . data [ sig ] . period > self . data [ self . slow_sig ] . period ): self . slow_sig = sig missing = [] for sig in required_sigs : if sig not in self . data : missing . append ( sig ) if missing : raise ValueError ( f \"Missing required signals: { missing } \" ) self . resampled = self . data [ required_sigs ] . resample ( self . data [ self . slow_sig ] . tline ) self . data . math_tline = self . data [ self . slow_sig ] . tline self . resampled . math_tline = self . data [ self . slow_sig ] . tline return True else : return False check_substitute_sigs () Try to substitute for some common missing sigs. Source code in ccg\\controllers\\motec.py 3694 3695 3696 3697 3698 3699 3700 3701 3702 3703 3704 3705 3706 3707 3708 3709 3710 3711 3712 3713 3714 3715 3716 3717 3718 3719 3720 3721 3722 3723 3724 3725 3726 3727 3728 3729 3730 3731 3732 3733 3734 3735 3736 3737 3738 3739 3740 3741 3742 3743 3744 def check_substitute_sigs ( self ): \"\"\"Try to substitute for some common missing sigs.\"\"\" if self . table_data and self . data : try : mode = self . table_data [ \"Engine.Load.Normalised.Mode\" ] . data if mode == \"Normal\" : # Value = # p * # Engine.Efficiency * # Fuel Vapour Correction * # (Engine.Displacement / Engine.Cylinders) * // Displacement of one cylinder # (1 / (Constants.rAir * (Engine.Charge.Temperature + 273.15))); // Ideal gas law # when (Normalised.Mode) # { # is (Normal) # { # local ideal = # Ambient.Pressure.Standard * # 1.0 * # 1.0 * # (Engine.Displacement / Engine.Cylinders) * // Displacement of one cylinder # (1 / (Constants.rAir * (Constants.standardTemperature + 273.15))); // Ideal gas law # Normalised = Value / ideal; raise NotImplementedError elif mode == \"Inlet.Manifold.Pressure\" : sig = Sig ( name = \"Engine.Load.Normalised\" , data = self . data [ \"Inlet.Manifold.Pressure\" ] / ccg . util . convert_units ( 101.325 , \"kPa\" , self . data [ \"Inlet.Manifold.Pressure\" ] . unit , ), tline = self . data [ \"Inlet.Manifold.Pressure\" ] . tline , unit = \"ratio\" , ) elif mode == \"Throttle Position\" : sig = Sig ( name = \"Engine.Load.Normalised\" , data = self . data [ \"Throttle.Position\" ], ) sig . convert_units ( \"%\" ) if \"Engine.Load.Normalised\" not in self . data : self . data . append ( sig ) elif sig . period < self . data [ \"Engine.Load.Normalised\" ] . period : self . data . remove ( \"Engine.Load.Normalised\" ) self . data . append ( sig ) except ( KeyError , NotImplementedError ): pass update_calcd_data () Update calculations for fitting/plotting. Source code in ccg\\controllers\\motec.py 3822 3823 3824 3825 3826 3827 3828 3829 3830 3831 3832 3833 3834 3835 3836 3837 3838 3839 3840 3841 3842 3843 3844 3845 3846 3847 3848 3849 3850 3851 3852 3853 3854 3855 3856 3857 3858 3859 3860 3861 3862 3863 3864 3865 3866 3867 3868 3869 3870 3871 3872 3873 3874 3875 3876 3877 3878 3879 3880 3881 3882 3883 3884 def update_calcd_data ( self ): \"\"\"Update calculations for fitting/plotting.\"\"\" if self . _needs_calcs : tic = datetime . now () if self . check_sigs (): tmp = ( self . resampled [ \"Fuel.Lambda Control.Factor\" ] . convert_units ( \"ratio\" ) * self . resampled [ \"Fuel.Lambda Control.Adaptation\" ] . convert_units ( \"ratio\" ) * self . resampled [ \"Fuel.Volume.Trim\" ] . convert_units ( \"ratio\" ) * self . resampled [ \"Exhaust.Lambda\" ] / self . resampled [ \"Fuel.Lambda Control.Lambda Aim Delayed\" ] ) tmp . name = \"Fueling.Error.Total\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = self . resampled [ \"Fueling.Error.Total\" ] * ( 1 + self . resampled [ \"Engine.Efficiency\" ] ) tmp . name = \"Engine.Efficiency.Value.Corrected\" tmp . unit = \"%\" self . resampled . append ( tmp ) tmp = Sig ( self . resampled [ \"Fueling.Error.Total\" ]) . convert_units ( \"%Trim\" ) tmp . name = \"Fuel.Volume.Trim.Overall.Corrected\" self . resampled . append ( tmp ) tmp = Sig ( tmp ) # Be sure to copy... tmp . name = \"Coolant.Temperature.Fuel Volume Compensation.Corrected\" self . resampled . append ( tmp ) if self . table_data : self . resampled . append ( self . resampled [ \"Engine.Speed\" ] . dot ( n_win = 9 )) # inlet manifold press ref if ( \"Ambient Pressure Relative\" in self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Mode\" ] . data ): tmp = ( self . resampled [ \"Inlet.Manifold.Pressure\" ] / self . resampled [ \"Ambient.Pressure\" ] ) else : tmp = self . resampled [ \"Inlet.Manifold.Pressure\" ] / 1000 tmp . name = \"Inlet.Manifold.Pressure.Estimate.Main.Corrected\" tmp . unit = \"ratio\" tmp . convert_units ( \"%\" ) self . resampled . append ( tmp ) self . resampled . name = \"Resampled Data for calcs\" toc = datetime . now () - tic _LOGGER . debug ( \"Firmware calcs in %.3f \" , toc . total_seconds ()) # Set some ranges self . resampled [ \"Engine.Speed\" ] . data_range = [ 0 , 8000 ] self . resampled [ \"Fuel.Lambda Control.Lambda Aim Delayed\" ] . data_range = [ 0.6 , 1.4 , ] self . _needs_calcs = False self . update_scatter_data () update_scatter_data () Update scatter data for fitting. Source code in ccg\\controllers\\motec.py 3886 3887 3888 3889 3890 3891 3892 3893 3894 3895 3896 3897 3898 3899 3900 3901 3902 3903 3904 3905 3906 3907 3908 3909 3910 3911 3912 3913 3914 3915 3916 3917 3918 3919 3920 3921 3922 3923 3924 3925 3926 3927 def update_scatter_data ( self ): \"\"\"Update scatter data for fitting.\"\"\" # Build signal list if self . _needs_calcs : self . update_calcd_data () for table in self . table_data : if f \" { table . name } .Corrected\" in self . resampled : tmp = [] for axis in table . axes : tmp . append ( self . resampled [ f \" { axis . name } \" ] . valid ( self . gate ) . resample ( self . resampled . math_tline ) ) tmp . append ( self . resampled [ f \" { table . name } .Corrected\" ] . valid ( self . gate ) . resample ( self . resampled . math_tline ) ) if table . name == \"Engine.Efficiency.Value\" : color = self . resampled [ \"Inlet.Manifold.Temperature\" ] color_unit = \"%\" color_name = \"Primary Contr.\" color_range = [ 0 , 100 ] else : color = None color_name = None color_unit = None color_range = None table . scatter_data = ScatterData ( data = tmp , name = \"Measured\" , color = color , color_unit = color_unit , color_name = color_name , color_range = color_range , ) . clean () else : table . scatter_data = None FirmwareModel Bases: ABC Base class for M1 firmware model. Source code in ccg\\controllers\\motec.py 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 class FirmwareModel ( ABC ): \"\"\"Base class for M1 firmware model.\"\"\" reference_tables = {} fueling_tables = { \"Engine.Efficiency.Value\" : { \"unit\" : \"%\" , \"prec\" : 1 , \"range\" : [ 10 , 200 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine.Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 1 , }, \"Y\" : { \"sig\" : \"Throttle.Position\" , \"unit\" : \"%\" , \"range\" : [ 0 , 100 ], \"prec\" : 1 , }, \"Z\" : { \"sig\" : \"Inlet.Manifold.Pressure\" , \"unit\" : \"kPa\" , \"range\" : [ 0 , np . inf ], \"prec\" : 1 , }, }, } } fueling_params = { \"Engine.Cylinders\" : 8 } def __init__ ( self , m1cfg : str | Path = None , data : str | Path | Frame = None , gate : GateColl | str | Path = None , warning_dialog : Callable = None , ): self . table_data = None self . read_cal ( m1cfg ) self . tabs = ccg . ui . panel . CalDataTabs () self . _needs_calcs = True self . _needs_scatter_update = True self . _data = None self . warning_dialog = warning_dialog if data is None : self . data = None elif isinstance ( data , Frame ): self . data = data else : self . read_data ( data ) if gate is None : self . gate = None elif isinstance ( gate , GateColl ): self . gate = gate else : self . read_gate ( gate ) self . bank_gates = [] self . resampled = None self . slow_sig : str @property def slow_freq ( self ): \"\"\"return freq of slow signal.\"\"\" return round ( 1 / self . data [ self . slow_sig ] . period ) @property @abstractmethod def n_cyl ( self ): \"\"\"Returns num of cyls\"\"\" @property @abstractmethod def n_banks ( self ): \"\"\"Returns n_banks\"\"\" @property def data ( self ): \"\"\"data\"\"\" return self . _data @data . setter def data ( self , value : Frame ): \"\"\"data setter\"\"\" self . _needs_calcs = True self . _needs_scatter_update = True self . _needs_bank_warning = True self . _data = value def read_gate ( self , filename : str | Path ): \"\"\"Read Gate File\"\"\" self . gate = GateCollAND () . from_file ( filename ) self . _needs_calcs = True self . _needs_scatter_update = True self . _needs_bank_warning = True def read_data ( self , filename : str | Path ): \"\"\"Read data file\"\"\" self . data = read_ld ( filename ) # self._needs_calcs set in data.setter def read_cal ( self , m1cfg : str | Path ): \"\"\"Read the calibration data into table_data.\"\"\" if m1cfg is not None : self . table_data = read_m1cgf ( m1cfg , param_names = self . param_names ) self . convert_tables () self . _needs_calcs = True self . _needs_scatter_update = True self . _needs_bank_warning = True @property def fueling_names ( self ): \"\"\"return names of fueling tables\"\"\" param_names = [] for param in self . fueling_tables : if \"#\" in param : param_names . extend ( param . replace ( \"#\" , str ( i + 1 )) for i in range ( self . n_cyl ) ) else : param_names . append ( param ) return param_names @property def param_names ( self ): \"\"\"Return the names of the parameters\"\"\" param_names = self . fueling_names for param in self . fueling_params : if \"#\" in param : param_names . extend ( param . replace ( \"#\" , str ( i + 1 )) for i in range ( self . n_cyl ) ) else : param_names . append ( param ) for param in self . reference_tables : if \"#\" in param : param_names . extend ( param . replace ( \"#\" , str ( i + 1 )) for i in range ( self . n_cyl ) ) else : param_names . append ( param ) return param_names def convert_tables ( self ): \"\"\"Convert tables using configurations in self.fueling_tables.\"\"\" for name , config in dict ( self . fueling_tables , ** self . reference_tables ) . items (): if \"#\" in name : names = [ name . replace ( \"#\" , str ( i )) for i in range ( 1 , self . n_cyl + 1 )] else : names = [ name ] for name in names : self . table_data [ name ] . convert_units ( config [ \"unit\" ]) self . table_data [ name ] . precision = config [ \"prec\" ] self . table_data [ name ] . data_range = config [ \"range\" ] if \"axes\" in config : for axes , ax_cfg in config [ \"axes\" ] . items (): if axes in self . table_data [ name ] . axes : self . table_data [ name ] . axes [ axes ] . convert_units ( ax_cfg [ \"unit\" ] ) self . table_data [ name ] . axes [ axes ] . precision = ax_cfg [ \"prec\" ] self . table_data [ name ] . axes [ axes ] . data_range = ax_cfg [ \"range\" ] self . table_data [ name ] . axes [ axes ] . name = ax_cfg [ \"sig\" ] # to avoid ctrl-z back to old units self . table_data [ name ] . _archive [ \"prev\" ] = [] self . table_data [ name ] . snapshot ( \"orig\" ) def build_tabs ( self ): \"\"\"build tabs widget\"\"\" if self . table_data : tmp = [] for name in self . fueling_names : cdata = ccg . ui . panel . CalData ( self . table_data [ name ]) self . tabs . tabs [ name ] = cdata if len ( name ) > 25 : # name = re.sub(\"[aeiou]\", \"\", name) name = \"...\" + name [ - 25 :] tmp . append (( name , cdata . widget )) self . tabs . widget [:] = tmp [:] else : self . tabs . tabs = ccg . ui . panel . CalDataTabs () . tabs self . tabs . widget [:] = ccg . ui . panel . CalDataTabs () . widget [:] return self . tabs @abstractmethod def update_calcd_data ( self ): \"\"\"Update calcs for fitting/plotting.\"\"\" @abstractmethod def update_scatter_data ( self ): \"\"\"Update scatter data for fitting/plotting.\"\"\" data property writable data fueling_names property return names of fueling tables n_banks abstractmethod property Returns n_banks n_cyl abstractmethod property Returns num of cyls param_names property Return the names of the parameters slow_freq property return freq of slow signal. build_tabs () build tabs widget Source code in ccg\\controllers\\motec.py 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 def build_tabs ( self ): \"\"\"build tabs widget\"\"\" if self . table_data : tmp = [] for name in self . fueling_names : cdata = ccg . ui . panel . CalData ( self . table_data [ name ]) self . tabs . tabs [ name ] = cdata if len ( name ) > 25 : # name = re.sub(\"[aeiou]\", \"\", name) name = \"...\" + name [ - 25 :] tmp . append (( name , cdata . widget )) self . tabs . widget [:] = tmp [:] else : self . tabs . tabs = ccg . ui . panel . CalDataTabs () . tabs self . tabs . widget [:] = ccg . ui . panel . CalDataTabs () . widget [:] return self . tabs convert_tables () Convert tables using configurations in self.fueling_tables. Source code in ccg\\controllers\\motec.py 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 def convert_tables ( self ): \"\"\"Convert tables using configurations in self.fueling_tables.\"\"\" for name , config in dict ( self . fueling_tables , ** self . reference_tables ) . items (): if \"#\" in name : names = [ name . replace ( \"#\" , str ( i )) for i in range ( 1 , self . n_cyl + 1 )] else : names = [ name ] for name in names : self . table_data [ name ] . convert_units ( config [ \"unit\" ]) self . table_data [ name ] . precision = config [ \"prec\" ] self . table_data [ name ] . data_range = config [ \"range\" ] if \"axes\" in config : for axes , ax_cfg in config [ \"axes\" ] . items (): if axes in self . table_data [ name ] . axes : self . table_data [ name ] . axes [ axes ] . convert_units ( ax_cfg [ \"unit\" ] ) self . table_data [ name ] . axes [ axes ] . precision = ax_cfg [ \"prec\" ] self . table_data [ name ] . axes [ axes ] . data_range = ax_cfg [ \"range\" ] self . table_data [ name ] . axes [ axes ] . name = ax_cfg [ \"sig\" ] # to avoid ctrl-z back to old units self . table_data [ name ] . _archive [ \"prev\" ] = [] self . table_data [ name ] . snapshot ( \"orig\" ) read_cal ( m1cfg ) Read the calibration data into table_data. Source code in ccg\\controllers\\motec.py 880 881 882 883 884 885 886 887 def read_cal ( self , m1cfg : str | Path ): \"\"\"Read the calibration data into table_data.\"\"\" if m1cfg is not None : self . table_data = read_m1cgf ( m1cfg , param_names = self . param_names ) self . convert_tables () self . _needs_calcs = True self . _needs_scatter_update = True self . _needs_bank_warning = True read_data ( filename ) Read data file Source code in ccg\\controllers\\motec.py 875 876 877 def read_data ( self , filename : str | Path ): \"\"\"Read data file\"\"\" self . data = read_ld ( filename ) read_gate ( filename ) Read Gate File Source code in ccg\\controllers\\motec.py 868 869 870 871 872 873 def read_gate ( self , filename : str | Path ): \"\"\"Read Gate File\"\"\" self . gate = GateCollAND () . from_file ( filename ) self . _needs_calcs = True self . _needs_scatter_update = True self . _needs_bank_warning = True update_calcd_data () abstractmethod Update calcs for fitting/plotting. Source code in ccg\\controllers\\motec.py 967 968 969 @abstractmethod def update_calcd_data ( self ): \"\"\"Update calcs for fitting/plotting.\"\"\" update_scatter_data () abstractmethod Update scatter data for fitting/plotting. Source code in ccg\\controllers\\motec.py 971 972 973 @abstractmethod def update_scatter_data ( self ): \"\"\"Update scatter data for fitting/plotting.\"\"\" LOORRS Bases: FirmwareModel M1 Firmware model for LOORRS_Pro2_Pro4 01.02.0006, March 2019 Source code in ccg\\controllers\\motec.py 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622 1623 1624 1625 1626 1627 1628 1629 1630 1631 1632 1633 1634 1635 1636 1637 1638 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 1649 1650 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664 1665 1666 1667 1668 1669 1670 1671 1672 1673 1674 1675 1676 1677 1678 1679 1680 1681 1682 1683 1684 1685 1686 1687 1688 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699 1700 1701 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711 1712 1713 1714 1715 1716 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741 1742 1743 1744 1745 1746 1747 1748 1749 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 1767 1768 1769 1770 1771 1772 1773 1774 1775 1776 1777 1778 1779 1780 1781 1782 1783 1784 1785 1786 1787 1788 1789 1790 1791 1792 1793 1794 1795 1796 1797 1798 1799 1800 1801 1802 1803 1804 1805 1806 1807 1808 1809 1810 1811 1812 1813 1814 1815 1816 1817 1818 1819 1820 1821 1822 1823 1824 1825 1826 1827 1828 1829 1830 1831 1832 1833 1834 1835 1836 1837 1838 1839 1840 1841 1842 1843 1844 1845 1846 1847 1848 1849 1850 1851 1852 1853 1854 1855 1856 1857 1858 1859 1860 1861 1862 1863 1864 1865 1866 1867 1868 1869 1870 1871 1872 1873 1874 1875 1876 1877 1878 1879 1880 1881 1882 1883 1884 1885 1886 1887 1888 1889 1890 1891 1892 1893 1894 1895 1896 1897 1898 1899 1900 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 2025 2026 2027 2028 2029 2030 2031 2032 2033 2034 2035 2036 2037 2038 2039 2040 2041 2042 2043 2044 2045 2046 2047 2048 2049 2050 2051 2052 2053 2054 2055 2056 2057 2058 2059 2060 2061 2062 2063 2064 2065 2066 2067 2068 2069 2070 2071 2072 2073 2074 2075 2076 2077 2078 2079 2080 2081 2082 2083 2084 2085 2086 2087 2088 2089 2090 2091 2092 2093 2094 2095 2096 2097 2098 2099 2100 2101 2102 2103 2104 2105 2106 2107 2108 2109 2110 2111 2112 2113 2114 2115 2116 2117 2118 2119 2120 2121 2122 2123 2124 2125 2126 2127 2128 2129 2130 2131 2132 2133 2134 2135 2136 2137 2138 2139 2140 2141 2142 2143 2144 2145 2146 2147 2148 2149 2150 2151 2152 2153 2154 2155 2156 2157 2158 2159 2160 2161 2162 2163 2164 2165 2166 2167 2168 2169 2170 2171 2172 2173 2174 2175 2176 2177 2178 2179 2180 2181 2182 2183 2184 2185 2186 2187 2188 2189 2190 2191 2192 2193 2194 2195 2196 2197 2198 2199 2200 2201 2202 2203 2204 2205 2206 2207 2208 2209 2210 2211 2212 2213 2214 2215 2216 2217 2218 2219 2220 2221 2222 2223 2224 2225 2226 2227 2228 2229 2230 2231 2232 2233 2234 2235 2236 2237 2238 2239 2240 2241 2242 2243 2244 2245 2246 2247 2248 2249 2250 2251 2252 2253 2254 2255 2256 2257 2258 2259 2260 2261 2262 2263 2264 2265 2266 2267 2268 2269 class LOORRS ( FirmwareModel ): \"\"\"M1 Firmware model for LOORRS_Pro2_Pro4 01.02.0006, March 2019\"\"\" reference_tables = { \"Fuel.Mixture Aim.Main\" : { \"unit\" : \"LA\" , \"prec\" : 2 , \"range\" : [ 0.01 , 5 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine.Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"Engine.Load.Normalised\" , \"unit\" : \"%\" , \"range\" : [ np . NINF , np . inf ], \"prec\" : 1 , }, \"Z\" : { \"sig\" : \"Driver.Fuel.Mixture Aim.Main.Switch\" , \"unit\" : \"\" , \"range\" : [ \"A\" , \"B\" ], \"prec\" : 0 , }, }, }, \"Fuel.Timing.Primary.Main\" : { \"unit\" : \"dBTDC\" , \"prec\" : 1 , \"range\" : [ 0 , 1440 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine.Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"Inlet.Manifold.Pressure\" , \"unit\" : \"kPa\" , \"range\" : [ 0 , np . inf ], \"prec\" : 1 , }, \"Z\" : { \"sig\" : \"Engine.Load.Normalised\" , \"unit\" : \"%\" , \"range\" : [ np . NINF , np . inf ], \"prec\" : 1 , }, }, }, } fueling_tables = { \"Engine.Efficiency.Value\" : { \"unit\" : \"%\" , \"prec\" : 1 , \"range\" : [ 10 , 200 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine.Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"Throttle.Position\" , \"unit\" : \"%\" , \"range\" : [ 0 , 100 ], \"prec\" : 1 , }, \"Z\" : { \"sig\" : \"Inlet.Manifold.Pressure\" , \"unit\" : \"kPa\" , \"range\" : [ 0 , np . inf ], \"prec\" : 1 , }, }, }, \"Fuel.Cylinder #.Trim\" : { \"unit\" : \"%Trim\" , \"prec\" : 1 , \"range\" : [ - 100 , 50 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine.Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"Inlet.Manifold.Pressure\" , \"unit\" : \"kPa\" , \"range\" : [ 0 , np . inf ], \"prec\" : 1 , }, \"Z\" : { \"sig\" : \"Engine.Load.Normalised\" , \"unit\" : \"%\" , \"range\" : [ np . NINF , np . inf ], \"prec\" : 1 , }, }, }, \"Fuel.Cylinder #.Primary.Trim\" : { \"unit\" : \"%Trim\" , \"prec\" : 1 , \"range\" : [ - 100 , 200 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine.Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"Engine.Load.Normalised\" , \"unit\" : \"%\" , \"range\" : [ np . NINF , np . inf ], \"prec\" : 1 , }, }, }, \"Inlet.Manifold.Pressure.Estimate.Main\" : { \"unit\" : \"%\" , \"prec\" : 1 , \"range\" : [ 0 , np . inf ], \"axes\" : { \"X\" : { \"sig\" : \"Throttle.Position\" , \"unit\" : \"%\" , \"range\" : [ 0 , 100 ], \"prec\" : 1 , }, \"Y\" : { \"sig\" : \"Engine.Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 0 , }, \"Z\" : { \"sig\" : \"Ambient.Pressure\" , \"unit\" : \"kPa\" , \"range\" : [ 5 , 110 ], \"prec\" : 1 , }, }, }, \"Fuel.Volume.Trim.Overall\" : { \"unit\" : \"%Trim\" , \"prec\" : 1 , \"range\" : [ - 99.9 , np . inf ], }, \"Coolant.Temperature.Fuel Volume Compensation\" : { \"unit\" : \"%Trim\" , \"prec\" : 1 , \"range\" : [ - 50 , 50 ], \"axes\" : { \"X\" : { \"sig\" : \"Coolant.Temperature\" , \"unit\" : \"F\" , \"range\" : [ - 58 , 482 ], \"prec\" : 1 , }, }, }, } fueling_params = { \"Fuel.Efficiency.Mode\" : { 0 : \"Manifold Air Density\" , 1 : \"Ambient Air Density\" , 2 : \"Airbox Air Density\" , }, \"Inlet.Manifold.Pressure.Mode\" : { 0 : \"Automatic\" , 1 : \"Estimate\" , 2 : \"Sensor\" , }, \"Engine.Cylinders\" : 8 , \"Engine.Cylinder #.Bank\" : 1 , \"Engine.Load.Normalised.Mode\" : { 0 : \"Normal\" , 1 : \"Inlet Manifold Pressure\" , 2 : \"Throttle PositioLambda.Indiv.Bank 2.AvgLambda.Indiv.Bank 2.Avgn\" , }, \"Inlet.Manifold.Pressure.Estimate.Mode\" : { 0 : \"Ambient Pressure Relative\" , 1 : \"100kPa Relative\" , }, \"Fuel.Volume.Trim.Overall\" : 0 , \"Ambient.Pressure.Default.Value\" : 101.3 , } # TODO: complete calcd_sigs = [ \"Fueling.Error.Bank 1\" , \"Fueling.Error.Bank 2\" , \"Fueling.Error.Total\" , \"Engine.Efficiency.Value.Corrected\" , \"Lambda.Indiv.Bank 1.Avg\" , \"Lambda.Indiv.Bank 2.Avg\" , \"Cylinder.Trim.Avg\" , ] def __init__ ( self , m1cfg : str | Path = None , data : str | Path | Frame = None , gate : GateColl | str | Path = None , warning_dialog : Callable = None , ): super () . __init__ ( m1cfg = m1cfg , data = data , gate = gate , warning_dialog = warning_dialog , ) self . slow_sig = \"Engine.Speed\" self . use_tailpipes = [ False ] * self . n_banks @property def n_cyl ( self ): if self . table_data and \"Engine.Cylinders\" in self . table_data : return int ( self . table_data [ \"Engine.Cylinders\" ] . data ) return 8 @property def n_banks ( self ): if self . table_data : return int ( max ( self . table_data [ f \"Engine.Cylinder { i } .Bank\" ] . data for i in range ( 1 , self . n_cyl + 1 ) ) ) return 2 # @profile def check_substitute_sigs ( self ): \"\"\"Try to substitute for some common missing sigs.\"\"\" msgs = [] if self . table_data and self . data : try : mode = self . table_data [ \"Engine.Load.Normalised.Mode\" ] . data if mode == \"Normal\" : # Value = # p * # Engine.Efficiency * # Fuel Vapour Correction * # (Engine.Displacement / Engine.Cylinders) * // Displacement of one cylinder # (1 / (Constants.rAir * (Engine.Charge.Temperature + 273.15))); // Ideal gas law # when (Normalised.Mode) # { # is (Normal) # { # local ideal = # Ambient.Pressure.Standard * # 1.0 * # 1.0 * # (Engine.Displacement / Engine.Cylinders) * // Displacement of one cylinder # (1 / (Constants.rAir * (Constants.standardTemperature + 273.15))); // Ideal gas law # Normalised = Value / ideal; raise NotImplementedError elif mode == \"Inlet.Manifold.Pressure\" : sig = Sig ( name = \"Engine.Load.Normalised\" , data = self . data [ \"Inlet.Manifold.Pressure\" ] / ccg . util . convert_units ( 101.325 , \"kPa\" , self . data [ \"Inlet.Manifold.Pressure\" ] . unit , ), tline = self . data [ \"Inlet.Manifold.Pressure\" ] . tline , unit = \"ratio\" , ) elif mode == \"Throttle Position\" : sig = Sig ( name = \"Engine.Load.Normalised\" , data = self . data [ \"Throttle.Position\" ], ) sig . convert_units ( \"%\" ) if \"Engine.Load.Normalised\" not in self . data : self . data . append ( sig ) msgs . append ( \"`Engine.Load.Normalized` was not logged and has been calculated from input signals.\" ) elif sig . period < self . data [ \"Engine.Load.Normalised\" ] . period : self . data . remove ( \"Engine.Load.Normalised\" ) self . data . append ( sig ) msgs . append ( \"`Engine.Load.Normalized` was logged slowly and has been calculated from input signals.\" ) except KeyError : pass try : if \"Fuel.Volume.Trim\" not in self . data : sig = self . table_data [ \"Fuel.Volume.Trim.Overall\" ][ self . data ] sig . name = \"Fuel.Volume.Trim\" self . data . append ( sig ) msgs . append ( \"`Fuel.Volume.Trim` was not logged and has been calculated from the loaded calibration. ** Ensure that this matches the calibration that generated the data **\" ) except KeyError : pass for i in range ( 1 , self . n_cyl + 1 ): try : name = f \"Fuel.Cylinder { i } .Trim\" if name not in self . data : sig = self . table_data [ name ][ self . data ] self . data . append ( sig ) msgs . append ( f \"` { name } ` was not logged and has been calculated from the loaded calibration. ** Ensure that this matches the calibration that generated the data **\" ) except KeyError : pass try : name = f \"Fuel.Cylinder { i } .Primary.Trim\" if name not in self . data : sig = self . table_data [ name ][ self . data ] self . data . append ( sig ) msgs . append ( f \"` { name } ` was not logged and has been calculated from the loaded calibration. ** Ensure that this matches the calibration that generated the data **\" ) except KeyError : pass try : if \"Coolant.Temperature.Fuel Volume Compensation\" not in self . data : sig = Sig ( self . data [ \"Fuel.Volume.Compensation\" ]) sig . name = \"Coolant.Temperature.Fuel Volume Compensation\" self . data . append ( sig ) msgs . append ( \"`Coolant.Temperature.Fuel Volume Compensation` was not logged and has been substituted with `Fuel.Volume.Compensation`. ** Ensure that no other volume compensation was active. **\" ) except KeyError : pass if msgs : msgs = [ \"## Substituted Signals \\n \" , * msgs ] return msgs @profile def check_sigs ( self ): \"\"\"Check that required input sigs are present.\"\"\" if self . table_data and self . data : msgs = self . check_substitute_sigs () required_sigs = set ( [ \"Fuel.Mixture Aim\" , \"Engine.Efficiency\" , \"Fuel.Volume.Trim\" , \"Fuel.Volume.Compensation\" , \"Coolant.Temperature.Fuel Volume Compensation\" , ] ) for table in self . fueling_tables : for axis in self . table_data [ table . replace ( \"#\" , \"1\" )] . axes : required_sigs . add ( axis . name ) for i in range ( 1 , self . n_cyl + 1 ): required_sigs . add ( f \"Fuel.Cylinder { i } .Trim\" ) required_sigs . add ( f \"Fuel.Cylinder { i } .Primary.Trim\" ) required_sigs . add ( f \"Exhaust.Lambda.Cylinder { i } \" ) for i in range ( 1 , self . n_banks + 1 ): required_sigs . add ( f \"Exhaust.Lambda.Bank { i } \" ) required_sigs . add ( f \"Fuel.Closed Loop.Control.Bank { i } .Trim\" ) if ( \"Ambient Pressure Relative\" in self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Mode\" ] . data ): required_sigs . add ( \"Ambient.Pressure\" ) ok_slow = [ \"Ambient.Pressure\" , \"Fuel.Mixture Aim\" , \"Fuel.Volume.Trim\" , \"Fuel.Volume.Compensation\" , \"Inlet.Manifold.Pressure.Estimate\" , \"Coolant.Temperature.Fuel Volume Compensation\" , \"Coolant.Temperature\" , ] extras = [ \"Inlet.Manifold.Pressure.Estimate\" , \"Inlet.Air.Temperature\" , \"Vehicle.Speed\" , \"Ignition.Cut\" , \"Ignition.Timing\" , \"Idle.State\" , \"Fuel.Volume.Transient\" , \"Fuel.Volume.Trim\" , \"Fuel.Volume.Compensation\" , \"Fuel.Timing.Primary\" , \"Fuel.Temperature\" , \"Fuel.Pressure\" , \"Fuel.Injector.Primary.Duty.Cycle\" , \"Fuel.Film.Primary\" , \"Fuel.Cut\" , \"Engine.Load\" , \"Coolant.Pressure\" , \"Engine.Charge.Temperature\" , \"Engine.Oil.Temperature\" , \"Engine.Oil.Pressure\" , \"ECU.Batter.Voltage\" , ] required_sigs = list ( required_sigs ) missing = [] for sig in required_sigs : if sig not in self . data : missing . append ( sig ) for sig in self . gate . sigs : if sig not in self . data and sig not in self . calcd_sigs : missing . append ( sig ) if missing : missing . sort () # msg = \"<br>\".join(missing) if self . warning_dialog : msgs . extend ([ \" \\n ## Missing Required Signals \\n \" , * missing ]) self . warning_dialog ( title = \"# Missing Signals\" , msg = \"<br>\" . join ( msgs ) ) return False raise ValueError ( f \"Missing Required Signals \\n { missing } \" ) for sig in required_sigs : if sig not in ok_slow : self . slow_sig = sig break for sig in required_sigs : if ( sig not in ok_slow and self . data [ sig ] . period > self . data [ self . slow_sig ] . period ): self . slow_sig = sig for sig in self . gate . sigs : if sig not in self . calcd_sigs and sig not in required_sigs : required_sigs . append ( sig ) tline = self . data [ self . slow_sig ] . tline self . resampled = self . data [ required_sigs ] . resample ( tline ) self . resampled . name = \"Resampled Data for Calc's\" self . data . math_tline = tline self . resampled . math_tline = tline for sig in extras : try : self . resampled . append ( self . data [ sig ] . resample ( tline )) except KeyError : pass if self . slow_freq < 50 : msgs . extend ( [ \" \\n ## Slow Signal \\n \" , f \"Calculation rate limited to { self . slow_freq } Hz by ` { self . slow_sig } `\" , ] ) if msgs : self . warning_dialog ( title = \"# Missing Signals\" , msg = \"<br>\" . join ( msgs )) return True else : return False @profile def update_calcd_data ( self ): \"\"\"Update calculations for fitting/plotting.\"\"\" if self . _needs_calcs : tic = datetime . now () if self . check_sigs (): if self . table_data : acc = 0 n = 0 for cyl in range ( 1 , 1 + self . n_cyl ): tmp = self . resampled [ f \"Fuel.Cylinder { cyl } .Trim\" ] . as_unit ( \"ratio\" ) * self . resampled [ f \"Fuel.Cylinder { cyl } .Primary.Trim\" ] . as_unit ( \"ratio\" ) tmp . unit = \"ratio\" tmp . name = f \"Fuel.Cylinder { cyl } .Trim.Total\" self . resampled . append ( tmp ) acc = acc + tmp n += 1 acc = acc / n acc . name = \"Cylinder.Trim.Avg\" acc . unit = \"ratio\" self . resampled . append ( acc ) for bank in range ( 1 , self . n_banks + 1 ): tmp = 0 n = 0 for cyl in range ( 1 , 1 + self . n_cyl ): if ( self . table_data [ f \"Engine.Cylinder { cyl } .Bank\" ] . data == bank ): n += 1 tmp = ( tmp + self . resampled [ f \"Exhaust.Lambda.Cylinder { cyl } \" ] ) tmp = tmp / n tmp . name = f \"Lambda.Indiv.Bank { bank } .Avg\" tmp . unit = \"LA\" tmp . data_range = [ 0.6 , 1.4 ] self . resampled . append ( tmp ) tmp = 0 n = 0 for cyl in range ( 1 , 1 + self . n_cyl ): if ( self . table_data [ f \"Engine.Cylinder { cyl } .Bank\" ] . data == bank ): n += 1 tmp = tmp + self . resampled [ f \"Fuel.Cylinder { cyl } .Trim\" ] . as_unit ( \"ratio\" ) * self . resampled [ f \"Fuel.Cylinder { cyl } .Primary.Trim\" ] . as_unit ( \"ratio\" ) tmp = tmp / n tmp . name = f \"Cylinder.Trim.Bank { bank } .Avg\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) self . resampled [ f \"Exhaust.Lambda.Bank { bank } \" ] . data_range = [ 0.6 , 1.4 , ] tmp = self . table_data [ \"Coolant.Temperature.Fuel Volume Compensation\" ][ self . resampled ] . as_unit ( \"ratio\" ) / self . resampled [ \"Fuel.Volume.Compensation\" ] . as_unit ( \"ratio\" ) tmp . name = \"Volume.Comp.Delta\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ \"Fuel.Closed Loop.Control.Bank 1.Trim\" ] . as_unit ( \"ratio\" ) * self . resampled [ \"Fuel.Volume.Trim\" ] . as_unit ( \"ratio\" ) / self . resampled [ \"Volume.Comp.Delta\" ] . as_unit ( \"ratio\" ) * self . resampled [ \"Cylinder.Trim.Bank 1.Avg\" ] * self . resampled [ \"Exhaust.Lambda.Bank 1\" ] / self . resampled [ \"Fuel.Mixture Aim\" ] ) # TODO: Fix for only 1 bank tmp . name = \"Fueling.Error.Bank 1\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ \"Fuel.Closed Loop.Control.Bank 2.Trim\" ] . as_unit ( \"ratio\" ) * self . resampled [ \"Fuel.Volume.Trim\" ] . as_unit ( \"ratio\" ) / self . resampled [ \"Volume.Comp.Delta\" ] . as_unit ( \"ratio\" ) * self . resampled [ \"Cylinder.Trim.Bank 2.Avg\" ] * self . resampled [ \"Exhaust.Lambda.Bank 2\" ] / self . resampled [ \"Fuel.Mixture Aim\" ] ) tmp . name = \"Fueling.Error.Bank 2\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ \"Fueling.Error.Bank 1\" ] + self . resampled [ \"Fueling.Error.Bank 2\" ] ) / 2 tmp . name = \"Fueling.Error.Total\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = self . resampled [ \"Fueling.Error.Total\" ] * ( self . resampled [ \"Engine.Efficiency\" ] ) tmp . name = \"Engine.Efficiency.Value.Corrected\" tmp . unit = \"%\" self . resampled . append ( tmp ) self . resampled . append ( Sig ( self . resampled [ \"Engine.Efficiency\" ], name = \"Engine.Efficiency.Value\" , ) ) # copy with name to match table for cyl in range ( 1 , 1 + self . n_cyl ): bank = int ( self . table_data [ f \"Engine.Cylinder { cyl } .Bank\" ] . data ) tmp = ( self . resampled [ f \"Exhaust.Lambda.Cylinder { cyl } \" ] / self . resampled [ f \"Lambda.Indiv.Bank { bank } .Avg\" ] ) tmp . name = f \"Cyl { cyl } .Lam.Error\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ f \"Fuel.Cylinder { cyl } .Trim.Total\" ] / self . resampled [ f \"Cylinder.Trim.Bank { bank } .Avg\" ] ) tmp . name = f \"Fuel.Cylinder { cyl } .Trim.Bank Normalised\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ f \"Fuel.Cylinder { cyl } .Trim.Total\" ] / self . resampled [ \"Cylinder.Trim.Avg\" ] ) tmp . name = f \"Fuel.Cylinder { cyl } .Trim.Normalised\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ f \"Fuel.Cylinder { cyl } .Trim.Bank Normalised\" ] * self . resampled [ f \"Cyl { cyl } .Lam.Error\" ] * ( self . resampled [ f \"Fueling.Error.Bank { bank } \" ] / self . resampled [ \"Fueling.Error.Total\" ] ) ) tmp . name = f \"Fuel.Cylinder { cyl } .Trim.Corrected\" tmp . unit = \"ratio\" tmp . convert_units ( \"%Trim\" ) self . resampled . append ( tmp ) # Calc cyl trims from tailpipe data incase indiv missing tmp = self . resampled [ f \"Fuel.Cylinder { cyl } .Trim.Normalised\" ] * ( self . resampled [ f \"Fueling.Error.Bank { bank } \" ] / self . resampled [ \"Fueling.Error.Total\" ] ) tmp . name = f \"Fuel.Cylinder { cyl } .Trim.Corrected.Tailpipe\" tmp . unit = \"ratio\" tmp . convert_units ( \"%Trim\" ) self . resampled . append ( tmp ) self . resampled [ f \"Exhaust.Lambda.Cylinder { cyl } \" ] . data_range = [ 0.6 , 1.4 , ] self . resampled . append ( self . resampled [ \"Engine.Speed\" ] . dot ( n_win = 17 )) self . resampled . append ( self . resampled [ \"Throttle.Position\" ] . dot ( n_win = 7 ) ) # inlet manifold press ref try : if ( \"Ambient Pressure Relative\" in self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Mode\" ] . data ): tmp = ( self . resampled [ \"Inlet.Manifold.Pressure\" ] / self . resampled [ \"Ambient.Pressure\" ] ) else : tmp = self . resampled [ \"Inlet.Manifold.Pressure\" ] / 100 tmp . name = \"Inlet.Manifold.Pressure.Estimate.Main.Corrected\" tmp . unit = \"ratio\" tmp . convert_units ( \"%\" ) self . resampled . append ( tmp ) if ( \"Ambient Pressure Relative\" in self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Mode\" ] . data ): tmp = ( self . resampled [ \"Inlet.Manifold.Pressure.Estimate\" ] / self . resampled [ \"Ambient.Pressure\" ] ) else : tmp = ( self . resampled [ \"Inlet.Manifold.Pressure.Estimate\" ] / 100 ) tmp . name = \"Inlet.Manifold.Pressure.Estimate.Main\" tmp . unit = \"ratio\" tmp . convert_units ( \"%\" ) self . resampled . append ( tmp ) except KeyError : pass # Coolant temp comps tmp = ( self . resampled [ \"Engine.Efficiency.Value.Corrected\" ] . as_unit ( \"ratio\" ) / self . table_data [ \"Engine.Efficiency.Value\" ][ self . resampled ] . as_unit ( \"ratio\" ) * self . resampled [ \"Coolant.Temperature.Fuel Volume Compensation\" ] . as_unit ( \"ratio\" ) * self . resampled [ \"Volume.Comp.Delta\" ] . as_unit ( \"ratio\" ) ) tmp . name = \"Coolant.Temperature.Fuel Volume Compensation.Corrected\" tmp . unit = \"ratio\" tmp . convert_units ( \"%Trim\" ) self . resampled . append ( tmp ) toc = datetime . now () - tic _LOGGER . debug ( \"Firmware calcs in %.3f \" , toc . total_seconds ()) # Set some ranges self . resampled [ \"Engine.Speed\" ] . data_range = [ 0 , 8800 ] self . resampled [ \"Fuel.Mixture Aim\" ] . data_range = [ 0.6 , 1.4 ] # Add calc'd signals to data frame for general plot self . data . append ( self . resampled ) self . _needs_calcs = False if not self . _needs_calcs : self . update_scatter_data () # Update options for scatter plots opts = [ \"Relative Density\" , * self . resampled . sigs . keys ()] for tab in self . tabs : tab . color_sig . options = opts @profile def update_scatter_data ( self ): \"\"\"Update scatter data for fitting.\"\"\" if self . _needs_scatter_update : # Build signal list bank_gate_tables = [ \"Fuel.Cylinder #.Trim\" ] remove_digits = str . maketrans ( \"0123456789\" , \"##########\" ) msg = [] self . use_tailpipes = [ False ] * self . n_banks if self . _needs_calcs : self . update_calcd_data () for table in self . table_data : if f \" { table . name } .Corrected\" in self . resampled . sigs : tmp : list [ Sig ] = [] ranges = [] if table . name . translate ( remove_digits ) in bank_gate_tables : cyl = \"\" . join ( filter ( lambda x : x . isdigit (), table . name )) bank_ind = ( self . table_data [ f \"Engine.Cylinder { cyl } .Bank\" ] . data [ 0 ] - 1 ) if self . tabs [ table . name ] . additional_gate : gate = GateCollAND ( [ self . bank_gates [ bank_ind ], self . tabs [ table . name ] . additional_gate , ] ) else : gate = self . bank_gates [ bank_ind ] tmp_sig = ( self . resampled [ f \" { table . name } .Corrected\" ] . valid ( gate ) . resample ( self . resampled . math_tline ) ) if ( tmp_sig . data . size - np . count_nonzero ( np . isnan ( tmp_sig . data )) < 1 ): msg . append ( f \" \\n ## Individual Cylinder Lambda signals out of limits on bank { bank_ind + 1 } . \\n Bank trim from tailpipe sensor only.\" ) self . use_tailpipes [ bank_ind ] = True if self . tabs [ table . name ] . additional_gate : gate = GateCollAND ( [ self . gate , self . tabs [ table . name ] . additional_gate ] ) else : gate = self . gate tmp_sig = ( self . resampled [ f \" { table . name } .Corrected.Tailpipe\" ] . valid ( gate ) . resample ( self . resampled . math_tline ) ) self . resampled . remove ( f \" { table . name } .Corrected\" ) self . resampled . append ( Sig ( self . resampled [ f \" { table . name } .Corrected.Tailpipe\" ], name = f \" { table . name } .Corrected\" , ) ) for axis in table . axes : tmp . append ( self . resampled [ f \" { axis . name } \" ] . valid ( gate ) . as_unit ( axis . unit ) . resample ( self . resampled . math_tline ) ) ranges . append ([ axis . min , axis . max ]) tmp . append ( tmp_sig ) ranges . append ([ table . min , table . max ]) else : if self . tabs [ table . name ] . additional_gate : gate = GateCollAND ( [ self . gate , self . tabs [ table . name ] . additional_gate ] ) else : gate = self . gate for axis in table . axes : tmp . append ( self . resampled [ f \" { axis . name } \" ] . valid ( gate ) . as_unit ( axis . unit ) . resample ( self . resampled . math_tline ) ) ranges . append ([ axis . min , axis . max ]) tmp_sig = ( self . resampled [ f \" { table . name } .Corrected\" ] . valid ( gate ) . resample ( self . resampled . math_tline ) ) if \"Coolant.Temperature.Fuel Volume Compensation\" in table . name : try : # Need to adjust offset to center at normal op temp op_temp = self . tabs [ table . name ] . op_temp . value ind = table . axes [ 0 ] . bins ( op_temp )[ 0 ] diff = table . axes [ 0 ] . diff [ ind ] zero_inds = np . logical_and ( np . greater ( tmp [ - 1 ] . data , op_temp - diff / 2 ), np . less ( tmp [ - 1 ] . data , op_temp + diff / 2 ), ) zero_val = np . mean ( tmp_sig . data [ zero_inds ]) if np . isnan ( zero_val ): zero_val = 0 tmp_sig -= zero_val except AttributeError : pass tmp . append ( tmp_sig ) ranges . append ([ table . min , table . max ]) color_data = None color_name = None color_unit = None color_range = None if self . tabs [ table . name ] . color_sig . value : name = self . tabs [ table . name ] . color_sig . value [ 0 ] if \"Relative Density\" in name : color_name = name n_bins = [ 70 ] * len ( tmp ) n_bins [ - 1 ] *= 2 bins = [] for vals , intv , n_bin in zip ( tmp , ranges , n_bins ): bins . append ( np . linspace ( np . minimum ( vals . min , intv [ 0 ]), np . maximum ( vals . max , intv [ 1 ]), n_bin , ) ) color_data = scatter_density ( ScatterData ( tmp ), n_bins = bins ) elif name in self . resampled : color_data = ( self . resampled [ name ] . valid ( gate ) . resample ( self . resampled . math_tline ) . data ) color_name = name color_unit = self . resampled [ name ] . unit color_range = self . resampled [ name ] . data_range table . scatter_data = ScatterData ( data = tmp , name = \"Corrected\" , color = color_data , color_unit = color_unit , color_name = color_name , color_range = color_range , ) . clean () # Add logged data trace if table . name in self . resampled : tmp [ - 1 ] = ( self . resampled [ table . name ] . valid ( gate ) . resample ( self . resampled . math_tline ) ) table . scatter_data . append ( ScatterData ( data = tmp , name = \"Logged\" ) . clean () ) else : table . scatter_data = None self . _needs_scatter_update = False if msg and self . _needs_bank_warning : msg = list ( set ( msg )) self . warning_dialog ( title = \"# Fit Data Warning\" , msg = \"<br>\" . join ( msg )) self . _needs_bank_warning = ( # pylint: disable=attribute-defined-outside-init False ) def normalize_cyl_trims ( self ): \"\"\"Normalizes cyl trims if bp's match.\"\"\" cyl_trim_min = self . fueling_tables [ \"Fuel.Cylinder #.Trim\" ][ \"range\" ][ 0 ] cyl_trim_max = self . fueling_tables [ \"Fuel.Cylinder #.Trim\" ][ \"range\" ][ 1 ] cyl_trim_unit = self . fueling_tables [ \"Fuel.Cylinder #.Trim\" ][ \"unit\" ] prim_trim_unit = self . fueling_tables [ \"Fuel.Cylinder #.Primary.Trim\" ][ \"unit\" ] if self . check_axes (): avg = np . zeros ( self . table_data [ \"Fuel.Cylinder 1.Trim\" ] . data . shape ) n = 0 for cyl in range ( 1 , self . n_cyl + 1 ): avg += self . table_data [ f \"Fuel.Cylinder { cyl } .Trim\" ] . data n += 1 avg = ccg . util . convert_units ( avg / n , cyl_trim_unit , \"ratio\" ) axes_names_equal = True for cyl in range ( 1 , self . n_cyl + 1 ): cyl_trim = ( self . table_data [ f \"Fuel.Cylinder { cyl } .Trim\" ] . as_unit ( \"ratio\" ) . data / avg ) cyl_trim = ccg . util . convert_units ( cyl_trim , \"ratio\" , cyl_trim_unit ) if np . any ( cyl_trim > cyl_trim_max ): prim_trim = ( np . maximum ( cyl_trim - cyl_trim_max , 0 ) / cyl_trim_max + 1 ) prim_trim = ccg . util . convert_units ( prim_trim , \"ratio\" , prim_trim_unit ) for i , axis in enumerate ( self . table_data [ f \"Fuel.Cylinder { cyl } .Trim\" ] . axes ): axes_names_equal = ( axes_names_equal and self . table_data [ f \"Fuel.Cylinder { cyl } .Primary.Trim\" ] . axes [ i ] . name == axis . name ) if axes_names_equal : self . table_data [ f \"Fuel.Cylinder { cyl } .Primary.Trim\" ] . axes = ( self . table_data [ f \"Fuel.Cylinder { cyl } .Trim\" ] . axes ) self . table_data [ f \"Fuel.Cylinder { cyl } .Primary.Trim\" ] . data = ( prim_trim ) else : self . table_data [ f \"Fuel.Cylinder { cyl } .Primary.Trim\" ] . data *= 0 self . table_data [ f \"Fuel.Cylinder { cyl } .Trim\" ] . data = np . clip ( cyl_trim , cyl_trim_min , cyl_trim_max ) if not axes_names_equal : self . warning_dialog ( title = \"# Primary Trim Issue\" , msg = \"`Fuel.Cylinder #.Primary.Trim` required, but axes conflict. \\n Set `Fuel.Cylinder #.Primary.Trim` axes to match `Fuel.Cylinder #.Trim` in M1 Tune before exporting config.\" , ) else : raise ValueError ( \"Cyl trim axes dont match, cant normalize\" ) def check_axes ( self ): \"\"\"Check if cyl trim axes match\"\"\" for i in range ( 2 , self . n_cyl + 1 ): for axis , axis1 in zip ( self . table_data [ f \"Fuel.Cylinder { i } .Trim\" ] . axes , self . table_data [ \"Fuel.Cylinder 1.Trim\" ] . axes , ): if axis1 != axis : return False return True @profile def build_delta_summary ( self ): \"\"\"Builds tables to review fit.\"\"\" if self . table_data : input_tables = Tbls () input_tables . append ( self . table_data [ \"Engine.Efficiency.Value\" ]) cyl_trim_unit = self . fueling_tables [ \"Fuel.Cylinder #.Trim\" ][ \"unit\" ] for cyl in range ( 1 , self . n_cyl + 1 ): # Convert indiv tables to base axes name = f \"Fuel.Cylinder { cyl } .Trim\" axes = input_tables [ \"Engine.Efficiency.Value\" ] . axes tmp = self . convert_table_to_axes ( self . table_data [ name ], axes ) tmp . name = name input_tables . append ( tmp ) name = f \"Fuel.Cylinder { cyl } .Primary.Trim\" axes = input_tables [ \"Engine.Efficiency.Value\" ] . axes tmp = self . convert_table_to_axes ( self . table_data [ name ], axes ) tmp . name = name input_tables . append ( tmp ) result_tables = Tbls () tmp = Tbl ( input_tables [ \"Engine.Efficiency.Value\" ]) tmp . data *= 0 tmp . name = \"Overall\" tmp . unit = \"ratio\" tmp . snapshot ( \"orig\" ) result_tables . append ( tmp ) for bank in range ( 1 , self . n_banks + 1 ): avg = Tbl ( input_tables [ \"Engine.Efficiency.Value\" ]) avg . data *= 0 avg . name = f \"Bank { bank } .Trim.Avg\" avg . unit = \"ratio\" avg . snapshot ( \"orig\" ) n = 0 for cyl in range ( 1 , self . n_cyl + 1 ): indiv = f \"Fuel.Cylinder { cyl } .Trim\" indiv_prim = f \"Fuel.Cylinder { cyl } .Primary.Trim\" tmp = ( input_tables [ \"Engine.Efficiency.Value\" ] . orig . as_unit ( \"ratio\" ) * input_tables [ indiv ] . orig . as_unit ( \"ratio\" ) * input_tables [ indiv_prim ] . orig . as_unit ( \"ratio\" ) * self . table_data [ \"Fuel.Volume.Trim.Overall\" ] . orig . as_unit ( \"ratio\" ) . data ) tmp . name = f \"Individual { cyl } \" tmp . unit = \"ratio\" tmp . snapshot ( \"orig\" ) tmp . data = ( input_tables [ \"Engine.Efficiency.Value\" ] . as_unit ( \"ratio\" ) * input_tables [ indiv ] . as_unit ( \"ratio\" ) * input_tables [ indiv_prim ] . as_unit ( \"ratio\" ) * self . table_data [ \"Fuel.Volume.Trim.Overall\" ] . as_unit ( \"ratio\" ) . data ) . data result_tables . append ( tmp ) if self . table_data [ f \"Engine.Cylinder { cyl } .Bank\" ] . data [ 0 ] == bank : avg . _archive [ \"orig\" ][ - 1 ] += input_tables [ indiv ] . orig . as_unit ( \"ratio\" ) * input_tables [ indiv_prim ] . orig . as_unit ( \"ratio\" ) avg += input_tables [ indiv ] . as_unit ( \"ratio\" ) * input_tables [ indiv_prim ] . as_unit ( \"ratio\" ) n += 1 result_tables [ \"Overall\" ] . _archive [ \"orig\" ][ - 1 ] += tmp . orig result_tables [ \"Overall\" ] += tmp avg . _archive [ \"orig\" ][ - 1 ] /= n avg /= n result_tables . append ( avg ) result_tables [ \"Overall\" ] . _archive [ \"orig\" ][ - 1 ] /= self . n_cyl result_tables [ \"Overall\" ] /= self . n_cyl # FINALLY res = [ ccg . ui . panel . pn . Spacer ( height = 0 ), ccg . ui . panel . pn . pane . Markdown ( \"\"\"# Overall Fueling Delta This accounts for deltas in the `Engine.Efficiency.Value` table, the mean of the `Fuel.Cylinder #.Trim` and `Fuel.Cylinder #.Primary.Trim` tables, and the `Fuel.Volume.Trim.Overall`.\"\"\" , align = \"start\" , ), ] table = result_tables [ \"Overall\" ] axes_data = table . axes prec_args = { \"axis_names\" : [ f \" { axis . name } [ { axis . unit } ]\" for axis in axes_data ], \"axis_breakpoints\" : [ axis . data . tolist () for axis in axes_data ], \"axis_precisions\" : [ axis . precision for axis in axes_data ], \"data_precision\" : table . precision , \"locked\" : table . locked . T . tolist (), } res . append ( ccg . ui . panel . CalDataTbl ( name = \"Overall Fueling Delta %\" , table_name = \"Overall Fueling Delta [%]\" , data = table . delta_perc . T . tolist (), editable = False , colorscale = \"RdBu\" , colorscale_center = 0 , align = \"center\" , ** prec_args , ) ) res . append ( ccg . ui . panel . pn . pane . Markdown ( \"\"\"# Bank Average Cyl Trims Includes both `Trim` and `Primary.Trim`.\"\"\" , align = \"start\" , ) ) for bank in range ( 1 , self . n_banks + 1 ): name = f \"Bank { bank } .Trim.Avg\" table = result_tables [ name ] . as_unit ( cyl_trim_unit ) axes_data = table . axes prec_args = { \"axis_names\" : [ f \" { axis . name } [ { axis . unit } ]\" for axis in axes_data ], \"axis_breakpoints\" : [ axis . data . tolist () for axis in axes_data ], \"axis_precisions\" : [ axis . precision for axis in axes_data ], \"data_precision\" : table . precision , \"locked\" : table . locked . T . tolist (), } res . append ( ccg . ui . panel . CalDataTbl ( name = name , table_name = f \" { name } [ { cyl_trim_unit } ]\" , data = table . data . T . tolist (), editable = False , colorscale = \"RdBu\" , colorscale_center = 0 , align = \"center\" , ** prec_args , ) ) res . append ( ccg . ui . panel . pn . pane . Markdown ( \"\"\"# Individual Cylinder Fueling Deltas These accounts for deltas in the `Engine.Efficiency.Value` table, the the `Fuel.Cylinder #.Trim` and `Fuel.Cylinder #.Primary.Trim` tables, and the `Fuel.Volume.Trim.Overall`.\"\"\" , align = \"start\" , ) ) for cyl in range ( 1 , self . n_cyl + 1 ): name = f \"Individual { cyl } \" table = result_tables [ name ] axes_data = table . axes prec_args = { \"axis_names\" : [ f \" { axis . name } [ { axis . unit } ]\" for axis in axes_data ], \"axis_breakpoints\" : [ axis . data . tolist () for axis in axes_data ], \"axis_precisions\" : [ axis . precision for axis in axes_data ], \"data_precision\" : table . precision , \"locked\" : table . locked . T . tolist (), } res . append ( ccg . ui . panel . CalDataTbl ( name = f \" { name } Fueling Delta %\" , table_name = f \" { name } Fueling Delta [%]\" , data = table . delta_perc . T . tolist (), editable = False , colorscale = \"RdBu\" , colorscale_center = 0 , align = \"center\" , ** prec_args , ) ) return res def convert_table_to_axes ( self , table : Tbl , target : Axes ): \"\"\"Convert a table to fit the target axes if possible.\"\"\" res = Tbl ( name = \"result\" , axes = target , unit = table . unit ) if target . n_dim > 2 : raise NotImplementedError if target . n_dim < table . n_dim : raise NotImplementedError if table . n_dim == 0 : res . data = np . ones ( target . shape ) * table . orig . data res . snapshot ( \"orig\" ) res . data = np . ones ( target . shape ) * table . data return res # Leave in target units, convert table before interpolating. target_grid = target . grid interp_grid = target . grid units = [ \"\" ] * table . n_dim for j , axis in enumerate ( target ): found = False for i , t_axis in enumerate ( table . axes ): if axis . name == t_axis . name : interp_grid [ i ] = target_grid [ j ] units [ i ] = axis . unit found = True break if not found : # Check for possible calc if axis . name == \"Inlet.Manifold.Pressure\" : if \"Engine.Load.Normalised\" in table . axes : i = table . axes . index ( \"Engine.Load.Normalised\" ) # Calc engine load normalized mode = self . table_data [ \"Engine.Load.Normalised.Mode\" ] . data if mode == \"Normal\" : raise NotImplementedError elif mode == \"Inlet Manifold Pressure\" : tmp = Axis ( axis ) tmp . data = axis . data / ccg . util . convert_units ( 101.325 , \"kPa\" , axis . unit , ) interp_grid [ i ] = target_grid [ j ] units [ i ] = \"ratio\" elif mode == \"Throttle Position\" : eng_speed_ind = target . index ( \"Engine.Speed\" ) imap_ind = target . index ( \"Inlet.Manifold.Pressure\" ) interp_grid [ i ] = self . tps_from_map ( eng_speed = target_grid [ eng_speed_ind ], imap = target_grid [ imap_ind ], ) units [ i ] = \"%\" for unit , axis in zip ( units , table . axes ): axis . convert_units ( unit ) interp_vals = np . array ([ x . flatten () for x in interp_grid ]) . T res . data = table . orig . interp ( interp_vals ) . reshape ( target . shape , order = \"f\" ) res . snapshot ( \"orig\" ) res . data = table . interp ( interp_vals ) . reshape ( target . shape , order = \"f\" ) # res.plot() return res def tps_from_map ( self , eng_speed : npt . NDArray , imap : npt . NDArray ): \"\"\"Estimate Throttle.Position from manifold air pressure.\"\"\" n = 100 tps_map = Tbl ( self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Main\" ]) tps_map . name = \"TPS Estimate\" tps_map . interp_on_axis_change = True tps_map . data *= 0 tps_map . f_orig = 0 tps_map . f_smooth = [ 0.001 , 0.001 ] map_unit = self . fueling_tables [ \"Engine.Efficiency.Value\" ][ \"axes\" ][ \"Z\" ][ \"unit\" ] tps_unit = tps_map . axes [ \"Throttle.Position\" ] . unit tps = np . linspace ( tps_map . axes [ \"Throttle.Position\" ] . data . min (), tps_map . axes [ \"Throttle.Position\" ] . data . max (), n , ) eng_spd = np . linspace ( tps_map . axes [ \"Engine.Speed\" ] . data . min (), tps_map . axes [ \"Engine.Speed\" ] . data . max (), n , ) bps = [ x . flatten () for x in np . meshgrid ( tps , eng_spd )] maps = ( self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Main\" ] . as_unit ( \"ratio\" ) . interp ( np . array ( bps ) . T ) * self . table_data [ \"Ambient.Pressure.Default.Value\" ] . as_unit ( map_unit ) . data ) map_bps = np . linspace ( 10 , 101 , 40 , ) tps_map . axes [ \"Throttle.Position\" ] . data = map_bps tps_map . axes [ \"Throttle.Position\" ] . name = \"Inlet.Manifold.Pressure\" tps_map . axes [ \"Inlet.Manifold.Pressure\" ] . unit = map_unit tps_map . unit = tps_unit new_grid = [ maps , bps [ 1 ], bps [ 0 ]] tps_map . scatter_data = ScatterData ( new_grid ) tps_map . fit () # tps_map.plot() interps = np . array ([ imap , eng_speed ]) . T return np . clip ( tps_map . interp ( interps ), 0 , 100 ) build_delta_summary () Builds tables to review fit. Source code in ccg\\controllers\\motec.py 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 2025 2026 2027 2028 2029 2030 2031 2032 2033 2034 2035 2036 2037 2038 2039 2040 2041 2042 2043 2044 2045 2046 2047 2048 2049 2050 2051 2052 2053 2054 2055 2056 2057 2058 2059 2060 2061 2062 2063 2064 2065 2066 2067 2068 2069 2070 2071 2072 2073 2074 2075 2076 2077 2078 2079 2080 2081 2082 2083 2084 2085 2086 2087 2088 2089 2090 2091 2092 2093 2094 2095 2096 2097 2098 2099 2100 2101 2102 2103 2104 2105 2106 2107 2108 2109 2110 2111 2112 2113 2114 2115 2116 2117 2118 2119 2120 2121 2122 2123 2124 2125 2126 2127 2128 2129 2130 2131 2132 2133 2134 2135 2136 2137 2138 2139 2140 2141 2142 2143 2144 2145 2146 2147 2148 2149 2150 2151 2152 2153 2154 @profile def build_delta_summary ( self ): \"\"\"Builds tables to review fit.\"\"\" if self . table_data : input_tables = Tbls () input_tables . append ( self . table_data [ \"Engine.Efficiency.Value\" ]) cyl_trim_unit = self . fueling_tables [ \"Fuel.Cylinder #.Trim\" ][ \"unit\" ] for cyl in range ( 1 , self . n_cyl + 1 ): # Convert indiv tables to base axes name = f \"Fuel.Cylinder { cyl } .Trim\" axes = input_tables [ \"Engine.Efficiency.Value\" ] . axes tmp = self . convert_table_to_axes ( self . table_data [ name ], axes ) tmp . name = name input_tables . append ( tmp ) name = f \"Fuel.Cylinder { cyl } .Primary.Trim\" axes = input_tables [ \"Engine.Efficiency.Value\" ] . axes tmp = self . convert_table_to_axes ( self . table_data [ name ], axes ) tmp . name = name input_tables . append ( tmp ) result_tables = Tbls () tmp = Tbl ( input_tables [ \"Engine.Efficiency.Value\" ]) tmp . data *= 0 tmp . name = \"Overall\" tmp . unit = \"ratio\" tmp . snapshot ( \"orig\" ) result_tables . append ( tmp ) for bank in range ( 1 , self . n_banks + 1 ): avg = Tbl ( input_tables [ \"Engine.Efficiency.Value\" ]) avg . data *= 0 avg . name = f \"Bank { bank } .Trim.Avg\" avg . unit = \"ratio\" avg . snapshot ( \"orig\" ) n = 0 for cyl in range ( 1 , self . n_cyl + 1 ): indiv = f \"Fuel.Cylinder { cyl } .Trim\" indiv_prim = f \"Fuel.Cylinder { cyl } .Primary.Trim\" tmp = ( input_tables [ \"Engine.Efficiency.Value\" ] . orig . as_unit ( \"ratio\" ) * input_tables [ indiv ] . orig . as_unit ( \"ratio\" ) * input_tables [ indiv_prim ] . orig . as_unit ( \"ratio\" ) * self . table_data [ \"Fuel.Volume.Trim.Overall\" ] . orig . as_unit ( \"ratio\" ) . data ) tmp . name = f \"Individual { cyl } \" tmp . unit = \"ratio\" tmp . snapshot ( \"orig\" ) tmp . data = ( input_tables [ \"Engine.Efficiency.Value\" ] . as_unit ( \"ratio\" ) * input_tables [ indiv ] . as_unit ( \"ratio\" ) * input_tables [ indiv_prim ] . as_unit ( \"ratio\" ) * self . table_data [ \"Fuel.Volume.Trim.Overall\" ] . as_unit ( \"ratio\" ) . data ) . data result_tables . append ( tmp ) if self . table_data [ f \"Engine.Cylinder { cyl } .Bank\" ] . data [ 0 ] == bank : avg . _archive [ \"orig\" ][ - 1 ] += input_tables [ indiv ] . orig . as_unit ( \"ratio\" ) * input_tables [ indiv_prim ] . orig . as_unit ( \"ratio\" ) avg += input_tables [ indiv ] . as_unit ( \"ratio\" ) * input_tables [ indiv_prim ] . as_unit ( \"ratio\" ) n += 1 result_tables [ \"Overall\" ] . _archive [ \"orig\" ][ - 1 ] += tmp . orig result_tables [ \"Overall\" ] += tmp avg . _archive [ \"orig\" ][ - 1 ] /= n avg /= n result_tables . append ( avg ) result_tables [ \"Overall\" ] . _archive [ \"orig\" ][ - 1 ] /= self . n_cyl result_tables [ \"Overall\" ] /= self . n_cyl # FINALLY res = [ ccg . ui . panel . pn . Spacer ( height = 0 ), ccg . ui . panel . pn . pane . Markdown ( \"\"\"# Overall Fueling Delta This accounts for deltas in the `Engine.Efficiency.Value` table, the mean of the `Fuel.Cylinder #.Trim` and `Fuel.Cylinder #.Primary.Trim` tables, and the `Fuel.Volume.Trim.Overall`.\"\"\" , align = \"start\" , ), ] table = result_tables [ \"Overall\" ] axes_data = table . axes prec_args = { \"axis_names\" : [ f \" { axis . name } [ { axis . unit } ]\" for axis in axes_data ], \"axis_breakpoints\" : [ axis . data . tolist () for axis in axes_data ], \"axis_precisions\" : [ axis . precision for axis in axes_data ], \"data_precision\" : table . precision , \"locked\" : table . locked . T . tolist (), } res . append ( ccg . ui . panel . CalDataTbl ( name = \"Overall Fueling Delta %\" , table_name = \"Overall Fueling Delta [%]\" , data = table . delta_perc . T . tolist (), editable = False , colorscale = \"RdBu\" , colorscale_center = 0 , align = \"center\" , ** prec_args , ) ) res . append ( ccg . ui . panel . pn . pane . Markdown ( \"\"\"# Bank Average Cyl Trims Includes both `Trim` and `Primary.Trim`.\"\"\" , align = \"start\" , ) ) for bank in range ( 1 , self . n_banks + 1 ): name = f \"Bank { bank } .Trim.Avg\" table = result_tables [ name ] . as_unit ( cyl_trim_unit ) axes_data = table . axes prec_args = { \"axis_names\" : [ f \" { axis . name } [ { axis . unit } ]\" for axis in axes_data ], \"axis_breakpoints\" : [ axis . data . tolist () for axis in axes_data ], \"axis_precisions\" : [ axis . precision for axis in axes_data ], \"data_precision\" : table . precision , \"locked\" : table . locked . T . tolist (), } res . append ( ccg . ui . panel . CalDataTbl ( name = name , table_name = f \" { name } [ { cyl_trim_unit } ]\" , data = table . data . T . tolist (), editable = False , colorscale = \"RdBu\" , colorscale_center = 0 , align = \"center\" , ** prec_args , ) ) res . append ( ccg . ui . panel . pn . pane . Markdown ( \"\"\"# Individual Cylinder Fueling Deltas These accounts for deltas in the `Engine.Efficiency.Value` table, the the `Fuel.Cylinder #.Trim` and `Fuel.Cylinder #.Primary.Trim` tables, and the `Fuel.Volume.Trim.Overall`.\"\"\" , align = \"start\" , ) ) for cyl in range ( 1 , self . n_cyl + 1 ): name = f \"Individual { cyl } \" table = result_tables [ name ] axes_data = table . axes prec_args = { \"axis_names\" : [ f \" { axis . name } [ { axis . unit } ]\" for axis in axes_data ], \"axis_breakpoints\" : [ axis . data . tolist () for axis in axes_data ], \"axis_precisions\" : [ axis . precision for axis in axes_data ], \"data_precision\" : table . precision , \"locked\" : table . locked . T . tolist (), } res . append ( ccg . ui . panel . CalDataTbl ( name = f \" { name } Fueling Delta %\" , table_name = f \" { name } Fueling Delta [%]\" , data = table . delta_perc . T . tolist (), editable = False , colorscale = \"RdBu\" , colorscale_center = 0 , align = \"center\" , ** prec_args , ) ) return res check_axes () Check if cyl trim axes match Source code in ccg\\controllers\\motec.py 1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978 def check_axes ( self ): \"\"\"Check if cyl trim axes match\"\"\" for i in range ( 2 , self . n_cyl + 1 ): for axis , axis1 in zip ( self . table_data [ f \"Fuel.Cylinder { i } .Trim\" ] . axes , self . table_data [ \"Fuel.Cylinder 1.Trim\" ] . axes , ): if axis1 != axis : return False return True check_sigs () Check that required input sigs are present. Source code in ccg\\controllers\\motec.py 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 @profile def check_sigs ( self ): \"\"\"Check that required input sigs are present.\"\"\" if self . table_data and self . data : msgs = self . check_substitute_sigs () required_sigs = set ( [ \"Fuel.Mixture Aim\" , \"Engine.Efficiency\" , \"Fuel.Volume.Trim\" , \"Fuel.Volume.Compensation\" , \"Coolant.Temperature.Fuel Volume Compensation\" , ] ) for table in self . fueling_tables : for axis in self . table_data [ table . replace ( \"#\" , \"1\" )] . axes : required_sigs . add ( axis . name ) for i in range ( 1 , self . n_cyl + 1 ): required_sigs . add ( f \"Fuel.Cylinder { i } .Trim\" ) required_sigs . add ( f \"Fuel.Cylinder { i } .Primary.Trim\" ) required_sigs . add ( f \"Exhaust.Lambda.Cylinder { i } \" ) for i in range ( 1 , self . n_banks + 1 ): required_sigs . add ( f \"Exhaust.Lambda.Bank { i } \" ) required_sigs . add ( f \"Fuel.Closed Loop.Control.Bank { i } .Trim\" ) if ( \"Ambient Pressure Relative\" in self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Mode\" ] . data ): required_sigs . add ( \"Ambient.Pressure\" ) ok_slow = [ \"Ambient.Pressure\" , \"Fuel.Mixture Aim\" , \"Fuel.Volume.Trim\" , \"Fuel.Volume.Compensation\" , \"Inlet.Manifold.Pressure.Estimate\" , \"Coolant.Temperature.Fuel Volume Compensation\" , \"Coolant.Temperature\" , ] extras = [ \"Inlet.Manifold.Pressure.Estimate\" , \"Inlet.Air.Temperature\" , \"Vehicle.Speed\" , \"Ignition.Cut\" , \"Ignition.Timing\" , \"Idle.State\" , \"Fuel.Volume.Transient\" , \"Fuel.Volume.Trim\" , \"Fuel.Volume.Compensation\" , \"Fuel.Timing.Primary\" , \"Fuel.Temperature\" , \"Fuel.Pressure\" , \"Fuel.Injector.Primary.Duty.Cycle\" , \"Fuel.Film.Primary\" , \"Fuel.Cut\" , \"Engine.Load\" , \"Coolant.Pressure\" , \"Engine.Charge.Temperature\" , \"Engine.Oil.Temperature\" , \"Engine.Oil.Pressure\" , \"ECU.Batter.Voltage\" , ] required_sigs = list ( required_sigs ) missing = [] for sig in required_sigs : if sig not in self . data : missing . append ( sig ) for sig in self . gate . sigs : if sig not in self . data and sig not in self . calcd_sigs : missing . append ( sig ) if missing : missing . sort () # msg = \"<br>\".join(missing) if self . warning_dialog : msgs . extend ([ \" \\n ## Missing Required Signals \\n \" , * missing ]) self . warning_dialog ( title = \"# Missing Signals\" , msg = \"<br>\" . join ( msgs ) ) return False raise ValueError ( f \"Missing Required Signals \\n { missing } \" ) for sig in required_sigs : if sig not in ok_slow : self . slow_sig = sig break for sig in required_sigs : if ( sig not in ok_slow and self . data [ sig ] . period > self . data [ self . slow_sig ] . period ): self . slow_sig = sig for sig in self . gate . sigs : if sig not in self . calcd_sigs and sig not in required_sigs : required_sigs . append ( sig ) tline = self . data [ self . slow_sig ] . tline self . resampled = self . data [ required_sigs ] . resample ( tline ) self . resampled . name = \"Resampled Data for Calc's\" self . data . math_tline = tline self . resampled . math_tline = tline for sig in extras : try : self . resampled . append ( self . data [ sig ] . resample ( tline )) except KeyError : pass if self . slow_freq < 50 : msgs . extend ( [ \" \\n ## Slow Signal \\n \" , f \"Calculation rate limited to { self . slow_freq } Hz by ` { self . slow_sig } `\" , ] ) if msgs : self . warning_dialog ( title = \"# Missing Signals\" , msg = \"<br>\" . join ( msgs )) return True else : return False check_substitute_sigs () Try to substitute for some common missing sigs. Source code in ccg\\controllers\\motec.py 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 def check_substitute_sigs ( self ): \"\"\"Try to substitute for some common missing sigs.\"\"\" msgs = [] if self . table_data and self . data : try : mode = self . table_data [ \"Engine.Load.Normalised.Mode\" ] . data if mode == \"Normal\" : # Value = # p * # Engine.Efficiency * # Fuel Vapour Correction * # (Engine.Displacement / Engine.Cylinders) * // Displacement of one cylinder # (1 / (Constants.rAir * (Engine.Charge.Temperature + 273.15))); // Ideal gas law # when (Normalised.Mode) # { # is (Normal) # { # local ideal = # Ambient.Pressure.Standard * # 1.0 * # 1.0 * # (Engine.Displacement / Engine.Cylinders) * // Displacement of one cylinder # (1 / (Constants.rAir * (Constants.standardTemperature + 273.15))); // Ideal gas law # Normalised = Value / ideal; raise NotImplementedError elif mode == \"Inlet.Manifold.Pressure\" : sig = Sig ( name = \"Engine.Load.Normalised\" , data = self . data [ \"Inlet.Manifold.Pressure\" ] / ccg . util . convert_units ( 101.325 , \"kPa\" , self . data [ \"Inlet.Manifold.Pressure\" ] . unit , ), tline = self . data [ \"Inlet.Manifold.Pressure\" ] . tline , unit = \"ratio\" , ) elif mode == \"Throttle Position\" : sig = Sig ( name = \"Engine.Load.Normalised\" , data = self . data [ \"Throttle.Position\" ], ) sig . convert_units ( \"%\" ) if \"Engine.Load.Normalised\" not in self . data : self . data . append ( sig ) msgs . append ( \"`Engine.Load.Normalized` was not logged and has been calculated from input signals.\" ) elif sig . period < self . data [ \"Engine.Load.Normalised\" ] . period : self . data . remove ( \"Engine.Load.Normalised\" ) self . data . append ( sig ) msgs . append ( \"`Engine.Load.Normalized` was logged slowly and has been calculated from input signals.\" ) except KeyError : pass try : if \"Fuel.Volume.Trim\" not in self . data : sig = self . table_data [ \"Fuel.Volume.Trim.Overall\" ][ self . data ] sig . name = \"Fuel.Volume.Trim\" self . data . append ( sig ) msgs . append ( \"`Fuel.Volume.Trim` was not logged and has been calculated from the loaded calibration. ** Ensure that this matches the calibration that generated the data **\" ) except KeyError : pass for i in range ( 1 , self . n_cyl + 1 ): try : name = f \"Fuel.Cylinder { i } .Trim\" if name not in self . data : sig = self . table_data [ name ][ self . data ] self . data . append ( sig ) msgs . append ( f \"` { name } ` was not logged and has been calculated from the loaded calibration. ** Ensure that this matches the calibration that generated the data **\" ) except KeyError : pass try : name = f \"Fuel.Cylinder { i } .Primary.Trim\" if name not in self . data : sig = self . table_data [ name ][ self . data ] self . data . append ( sig ) msgs . append ( f \"` { name } ` was not logged and has been calculated from the loaded calibration. ** Ensure that this matches the calibration that generated the data **\" ) except KeyError : pass try : if \"Coolant.Temperature.Fuel Volume Compensation\" not in self . data : sig = Sig ( self . data [ \"Fuel.Volume.Compensation\" ]) sig . name = \"Coolant.Temperature.Fuel Volume Compensation\" self . data . append ( sig ) msgs . append ( \"`Coolant.Temperature.Fuel Volume Compensation` was not logged and has been substituted with `Fuel.Volume.Compensation`. ** Ensure that no other volume compensation was active. **\" ) except KeyError : pass if msgs : msgs = [ \"## Substituted Signals \\n \" , * msgs ] return msgs convert_table_to_axes ( table , target ) Convert a table to fit the target axes if possible. Source code in ccg\\controllers\\motec.py 2156 2157 2158 2159 2160 2161 2162 2163 2164 2165 2166 2167 2168 2169 2170 2171 2172 2173 2174 2175 2176 2177 2178 2179 2180 2181 2182 2183 2184 2185 2186 2187 2188 2189 2190 2191 2192 2193 2194 2195 2196 2197 2198 2199 2200 2201 2202 2203 2204 2205 2206 2207 2208 2209 2210 2211 2212 2213 2214 2215 2216 2217 2218 2219 2220 def convert_table_to_axes ( self , table : Tbl , target : Axes ): \"\"\"Convert a table to fit the target axes if possible.\"\"\" res = Tbl ( name = \"result\" , axes = target , unit = table . unit ) if target . n_dim > 2 : raise NotImplementedError if target . n_dim < table . n_dim : raise NotImplementedError if table . n_dim == 0 : res . data = np . ones ( target . shape ) * table . orig . data res . snapshot ( \"orig\" ) res . data = np . ones ( target . shape ) * table . data return res # Leave in target units, convert table before interpolating. target_grid = target . grid interp_grid = target . grid units = [ \"\" ] * table . n_dim for j , axis in enumerate ( target ): found = False for i , t_axis in enumerate ( table . axes ): if axis . name == t_axis . name : interp_grid [ i ] = target_grid [ j ] units [ i ] = axis . unit found = True break if not found : # Check for possible calc if axis . name == \"Inlet.Manifold.Pressure\" : if \"Engine.Load.Normalised\" in table . axes : i = table . axes . index ( \"Engine.Load.Normalised\" ) # Calc engine load normalized mode = self . table_data [ \"Engine.Load.Normalised.Mode\" ] . data if mode == \"Normal\" : raise NotImplementedError elif mode == \"Inlet Manifold Pressure\" : tmp = Axis ( axis ) tmp . data = axis . data / ccg . util . convert_units ( 101.325 , \"kPa\" , axis . unit , ) interp_grid [ i ] = target_grid [ j ] units [ i ] = \"ratio\" elif mode == \"Throttle Position\" : eng_speed_ind = target . index ( \"Engine.Speed\" ) imap_ind = target . index ( \"Inlet.Manifold.Pressure\" ) interp_grid [ i ] = self . tps_from_map ( eng_speed = target_grid [ eng_speed_ind ], imap = target_grid [ imap_ind ], ) units [ i ] = \"%\" for unit , axis in zip ( units , table . axes ): axis . convert_units ( unit ) interp_vals = np . array ([ x . flatten () for x in interp_grid ]) . T res . data = table . orig . interp ( interp_vals ) . reshape ( target . shape , order = \"f\" ) res . snapshot ( \"orig\" ) res . data = table . interp ( interp_vals ) . reshape ( target . shape , order = \"f\" ) # res.plot() return res normalize_cyl_trims () Normalizes cyl trims if bp's match. Source code in ccg\\controllers\\motec.py 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 1961 1962 1963 1964 1965 1966 def normalize_cyl_trims ( self ): \"\"\"Normalizes cyl trims if bp's match.\"\"\" cyl_trim_min = self . fueling_tables [ \"Fuel.Cylinder #.Trim\" ][ \"range\" ][ 0 ] cyl_trim_max = self . fueling_tables [ \"Fuel.Cylinder #.Trim\" ][ \"range\" ][ 1 ] cyl_trim_unit = self . fueling_tables [ \"Fuel.Cylinder #.Trim\" ][ \"unit\" ] prim_trim_unit = self . fueling_tables [ \"Fuel.Cylinder #.Primary.Trim\" ][ \"unit\" ] if self . check_axes (): avg = np . zeros ( self . table_data [ \"Fuel.Cylinder 1.Trim\" ] . data . shape ) n = 0 for cyl in range ( 1 , self . n_cyl + 1 ): avg += self . table_data [ f \"Fuel.Cylinder { cyl } .Trim\" ] . data n += 1 avg = ccg . util . convert_units ( avg / n , cyl_trim_unit , \"ratio\" ) axes_names_equal = True for cyl in range ( 1 , self . n_cyl + 1 ): cyl_trim = ( self . table_data [ f \"Fuel.Cylinder { cyl } .Trim\" ] . as_unit ( \"ratio\" ) . data / avg ) cyl_trim = ccg . util . convert_units ( cyl_trim , \"ratio\" , cyl_trim_unit ) if np . any ( cyl_trim > cyl_trim_max ): prim_trim = ( np . maximum ( cyl_trim - cyl_trim_max , 0 ) / cyl_trim_max + 1 ) prim_trim = ccg . util . convert_units ( prim_trim , \"ratio\" , prim_trim_unit ) for i , axis in enumerate ( self . table_data [ f \"Fuel.Cylinder { cyl } .Trim\" ] . axes ): axes_names_equal = ( axes_names_equal and self . table_data [ f \"Fuel.Cylinder { cyl } .Primary.Trim\" ] . axes [ i ] . name == axis . name ) if axes_names_equal : self . table_data [ f \"Fuel.Cylinder { cyl } .Primary.Trim\" ] . axes = ( self . table_data [ f \"Fuel.Cylinder { cyl } .Trim\" ] . axes ) self . table_data [ f \"Fuel.Cylinder { cyl } .Primary.Trim\" ] . data = ( prim_trim ) else : self . table_data [ f \"Fuel.Cylinder { cyl } .Primary.Trim\" ] . data *= 0 self . table_data [ f \"Fuel.Cylinder { cyl } .Trim\" ] . data = np . clip ( cyl_trim , cyl_trim_min , cyl_trim_max ) if not axes_names_equal : self . warning_dialog ( title = \"# Primary Trim Issue\" , msg = \"`Fuel.Cylinder #.Primary.Trim` required, but axes conflict. \\n Set `Fuel.Cylinder #.Primary.Trim` axes to match `Fuel.Cylinder #.Trim` in M1 Tune before exporting config.\" , ) else : raise ValueError ( \"Cyl trim axes dont match, cant normalize\" ) tps_from_map ( eng_speed , imap ) Estimate Throttle.Position from manifold air pressure. Source code in ccg\\controllers\\motec.py 2222 2223 2224 2225 2226 2227 2228 2229 2230 2231 2232 2233 2234 2235 2236 2237 2238 2239 2240 2241 2242 2243 2244 2245 2246 2247 2248 2249 2250 2251 2252 2253 2254 2255 2256 2257 2258 2259 2260 2261 2262 2263 2264 2265 2266 2267 2268 2269 def tps_from_map ( self , eng_speed : npt . NDArray , imap : npt . NDArray ): \"\"\"Estimate Throttle.Position from manifold air pressure.\"\"\" n = 100 tps_map = Tbl ( self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Main\" ]) tps_map . name = \"TPS Estimate\" tps_map . interp_on_axis_change = True tps_map . data *= 0 tps_map . f_orig = 0 tps_map . f_smooth = [ 0.001 , 0.001 ] map_unit = self . fueling_tables [ \"Engine.Efficiency.Value\" ][ \"axes\" ][ \"Z\" ][ \"unit\" ] tps_unit = tps_map . axes [ \"Throttle.Position\" ] . unit tps = np . linspace ( tps_map . axes [ \"Throttle.Position\" ] . data . min (), tps_map . axes [ \"Throttle.Position\" ] . data . max (), n , ) eng_spd = np . linspace ( tps_map . axes [ \"Engine.Speed\" ] . data . min (), tps_map . axes [ \"Engine.Speed\" ] . data . max (), n , ) bps = [ x . flatten () for x in np . meshgrid ( tps , eng_spd )] maps = ( self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Main\" ] . as_unit ( \"ratio\" ) . interp ( np . array ( bps ) . T ) * self . table_data [ \"Ambient.Pressure.Default.Value\" ] . as_unit ( map_unit ) . data ) map_bps = np . linspace ( 10 , 101 , 40 , ) tps_map . axes [ \"Throttle.Position\" ] . data = map_bps tps_map . axes [ \"Throttle.Position\" ] . name = \"Inlet.Manifold.Pressure\" tps_map . axes [ \"Inlet.Manifold.Pressure\" ] . unit = map_unit tps_map . unit = tps_unit new_grid = [ maps , bps [ 1 ], bps [ 0 ]] tps_map . scatter_data = ScatterData ( new_grid ) tps_map . fit () # tps_map.plot() interps = np . array ([ imap , eng_speed ]) . T return np . clip ( tps_map . interp ( interps ), 0 , 100 ) update_calcd_data () Update calculations for fitting/plotting. Source code in ccg\\controllers\\motec.py 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622 1623 1624 1625 1626 1627 1628 1629 1630 1631 1632 1633 1634 1635 1636 1637 1638 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 1649 1650 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664 1665 1666 1667 1668 1669 1670 1671 1672 1673 1674 1675 1676 1677 1678 1679 1680 1681 1682 1683 1684 1685 1686 1687 1688 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699 1700 1701 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711 1712 1713 1714 1715 1716 1717 1718 1719 1720 @profile def update_calcd_data ( self ): \"\"\"Update calculations for fitting/plotting.\"\"\" if self . _needs_calcs : tic = datetime . now () if self . check_sigs (): if self . table_data : acc = 0 n = 0 for cyl in range ( 1 , 1 + self . n_cyl ): tmp = self . resampled [ f \"Fuel.Cylinder { cyl } .Trim\" ] . as_unit ( \"ratio\" ) * self . resampled [ f \"Fuel.Cylinder { cyl } .Primary.Trim\" ] . as_unit ( \"ratio\" ) tmp . unit = \"ratio\" tmp . name = f \"Fuel.Cylinder { cyl } .Trim.Total\" self . resampled . append ( tmp ) acc = acc + tmp n += 1 acc = acc / n acc . name = \"Cylinder.Trim.Avg\" acc . unit = \"ratio\" self . resampled . append ( acc ) for bank in range ( 1 , self . n_banks + 1 ): tmp = 0 n = 0 for cyl in range ( 1 , 1 + self . n_cyl ): if ( self . table_data [ f \"Engine.Cylinder { cyl } .Bank\" ] . data == bank ): n += 1 tmp = ( tmp + self . resampled [ f \"Exhaust.Lambda.Cylinder { cyl } \" ] ) tmp = tmp / n tmp . name = f \"Lambda.Indiv.Bank { bank } .Avg\" tmp . unit = \"LA\" tmp . data_range = [ 0.6 , 1.4 ] self . resampled . append ( tmp ) tmp = 0 n = 0 for cyl in range ( 1 , 1 + self . n_cyl ): if ( self . table_data [ f \"Engine.Cylinder { cyl } .Bank\" ] . data == bank ): n += 1 tmp = tmp + self . resampled [ f \"Fuel.Cylinder { cyl } .Trim\" ] . as_unit ( \"ratio\" ) * self . resampled [ f \"Fuel.Cylinder { cyl } .Primary.Trim\" ] . as_unit ( \"ratio\" ) tmp = tmp / n tmp . name = f \"Cylinder.Trim.Bank { bank } .Avg\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) self . resampled [ f \"Exhaust.Lambda.Bank { bank } \" ] . data_range = [ 0.6 , 1.4 , ] tmp = self . table_data [ \"Coolant.Temperature.Fuel Volume Compensation\" ][ self . resampled ] . as_unit ( \"ratio\" ) / self . resampled [ \"Fuel.Volume.Compensation\" ] . as_unit ( \"ratio\" ) tmp . name = \"Volume.Comp.Delta\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ \"Fuel.Closed Loop.Control.Bank 1.Trim\" ] . as_unit ( \"ratio\" ) * self . resampled [ \"Fuel.Volume.Trim\" ] . as_unit ( \"ratio\" ) / self . resampled [ \"Volume.Comp.Delta\" ] . as_unit ( \"ratio\" ) * self . resampled [ \"Cylinder.Trim.Bank 1.Avg\" ] * self . resampled [ \"Exhaust.Lambda.Bank 1\" ] / self . resampled [ \"Fuel.Mixture Aim\" ] ) # TODO: Fix for only 1 bank tmp . name = \"Fueling.Error.Bank 1\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ \"Fuel.Closed Loop.Control.Bank 2.Trim\" ] . as_unit ( \"ratio\" ) * self . resampled [ \"Fuel.Volume.Trim\" ] . as_unit ( \"ratio\" ) / self . resampled [ \"Volume.Comp.Delta\" ] . as_unit ( \"ratio\" ) * self . resampled [ \"Cylinder.Trim.Bank 2.Avg\" ] * self . resampled [ \"Exhaust.Lambda.Bank 2\" ] / self . resampled [ \"Fuel.Mixture Aim\" ] ) tmp . name = \"Fueling.Error.Bank 2\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ \"Fueling.Error.Bank 1\" ] + self . resampled [ \"Fueling.Error.Bank 2\" ] ) / 2 tmp . name = \"Fueling.Error.Total\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = self . resampled [ \"Fueling.Error.Total\" ] * ( self . resampled [ \"Engine.Efficiency\" ] ) tmp . name = \"Engine.Efficiency.Value.Corrected\" tmp . unit = \"%\" self . resampled . append ( tmp ) self . resampled . append ( Sig ( self . resampled [ \"Engine.Efficiency\" ], name = \"Engine.Efficiency.Value\" , ) ) # copy with name to match table for cyl in range ( 1 , 1 + self . n_cyl ): bank = int ( self . table_data [ f \"Engine.Cylinder { cyl } .Bank\" ] . data ) tmp = ( self . resampled [ f \"Exhaust.Lambda.Cylinder { cyl } \" ] / self . resampled [ f \"Lambda.Indiv.Bank { bank } .Avg\" ] ) tmp . name = f \"Cyl { cyl } .Lam.Error\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ f \"Fuel.Cylinder { cyl } .Trim.Total\" ] / self . resampled [ f \"Cylinder.Trim.Bank { bank } .Avg\" ] ) tmp . name = f \"Fuel.Cylinder { cyl } .Trim.Bank Normalised\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ f \"Fuel.Cylinder { cyl } .Trim.Total\" ] / self . resampled [ \"Cylinder.Trim.Avg\" ] ) tmp . name = f \"Fuel.Cylinder { cyl } .Trim.Normalised\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ f \"Fuel.Cylinder { cyl } .Trim.Bank Normalised\" ] * self . resampled [ f \"Cyl { cyl } .Lam.Error\" ] * ( self . resampled [ f \"Fueling.Error.Bank { bank } \" ] / self . resampled [ \"Fueling.Error.Total\" ] ) ) tmp . name = f \"Fuel.Cylinder { cyl } .Trim.Corrected\" tmp . unit = \"ratio\" tmp . convert_units ( \"%Trim\" ) self . resampled . append ( tmp ) # Calc cyl trims from tailpipe data incase indiv missing tmp = self . resampled [ f \"Fuel.Cylinder { cyl } .Trim.Normalised\" ] * ( self . resampled [ f \"Fueling.Error.Bank { bank } \" ] / self . resampled [ \"Fueling.Error.Total\" ] ) tmp . name = f \"Fuel.Cylinder { cyl } .Trim.Corrected.Tailpipe\" tmp . unit = \"ratio\" tmp . convert_units ( \"%Trim\" ) self . resampled . append ( tmp ) self . resampled [ f \"Exhaust.Lambda.Cylinder { cyl } \" ] . data_range = [ 0.6 , 1.4 , ] self . resampled . append ( self . resampled [ \"Engine.Speed\" ] . dot ( n_win = 17 )) self . resampled . append ( self . resampled [ \"Throttle.Position\" ] . dot ( n_win = 7 ) ) # inlet manifold press ref try : if ( \"Ambient Pressure Relative\" in self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Mode\" ] . data ): tmp = ( self . resampled [ \"Inlet.Manifold.Pressure\" ] / self . resampled [ \"Ambient.Pressure\" ] ) else : tmp = self . resampled [ \"Inlet.Manifold.Pressure\" ] / 100 tmp . name = \"Inlet.Manifold.Pressure.Estimate.Main.Corrected\" tmp . unit = \"ratio\" tmp . convert_units ( \"%\" ) self . resampled . append ( tmp ) if ( \"Ambient Pressure Relative\" in self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Mode\" ] . data ): tmp = ( self . resampled [ \"Inlet.Manifold.Pressure.Estimate\" ] / self . resampled [ \"Ambient.Pressure\" ] ) else : tmp = ( self . resampled [ \"Inlet.Manifold.Pressure.Estimate\" ] / 100 ) tmp . name = \"Inlet.Manifold.Pressure.Estimate.Main\" tmp . unit = \"ratio\" tmp . convert_units ( \"%\" ) self . resampled . append ( tmp ) except KeyError : pass # Coolant temp comps tmp = ( self . resampled [ \"Engine.Efficiency.Value.Corrected\" ] . as_unit ( \"ratio\" ) / self . table_data [ \"Engine.Efficiency.Value\" ][ self . resampled ] . as_unit ( \"ratio\" ) * self . resampled [ \"Coolant.Temperature.Fuel Volume Compensation\" ] . as_unit ( \"ratio\" ) * self . resampled [ \"Volume.Comp.Delta\" ] . as_unit ( \"ratio\" ) ) tmp . name = \"Coolant.Temperature.Fuel Volume Compensation.Corrected\" tmp . unit = \"ratio\" tmp . convert_units ( \"%Trim\" ) self . resampled . append ( tmp ) toc = datetime . now () - tic _LOGGER . debug ( \"Firmware calcs in %.3f \" , toc . total_seconds ()) # Set some ranges self . resampled [ \"Engine.Speed\" ] . data_range = [ 0 , 8800 ] self . resampled [ \"Fuel.Mixture Aim\" ] . data_range = [ 0.6 , 1.4 ] # Add calc'd signals to data frame for general plot self . data . append ( self . resampled ) self . _needs_calcs = False if not self . _needs_calcs : self . update_scatter_data () # Update options for scatter plots opts = [ \"Relative Density\" , * self . resampled . sigs . keys ()] for tab in self . tabs : tab . color_sig . options = opts update_scatter_data () Update scatter data for fitting. Source code in ccg\\controllers\\motec.py 1722 1723 1724 1725 1726 1727 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741 1742 1743 1744 1745 1746 1747 1748 1749 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 1767 1768 1769 1770 1771 1772 1773 1774 1775 1776 1777 1778 1779 1780 1781 1782 1783 1784 1785 1786 1787 1788 1789 1790 1791 1792 1793 1794 1795 1796 1797 1798 1799 1800 1801 1802 1803 1804 1805 1806 1807 1808 1809 1810 1811 1812 1813 1814 1815 1816 1817 1818 1819 1820 1821 1822 1823 1824 1825 1826 1827 1828 1829 1830 1831 1832 1833 1834 1835 1836 1837 1838 1839 1840 1841 1842 1843 1844 1845 1846 1847 1848 1849 1850 1851 1852 1853 1854 1855 1856 1857 1858 1859 1860 1861 1862 1863 1864 1865 1866 1867 1868 1869 1870 1871 1872 1873 1874 1875 1876 1877 1878 1879 1880 1881 1882 1883 1884 1885 1886 1887 1888 1889 1890 1891 1892 1893 1894 1895 1896 1897 1898 1899 1900 1901 @profile def update_scatter_data ( self ): \"\"\"Update scatter data for fitting.\"\"\" if self . _needs_scatter_update : # Build signal list bank_gate_tables = [ \"Fuel.Cylinder #.Trim\" ] remove_digits = str . maketrans ( \"0123456789\" , \"##########\" ) msg = [] self . use_tailpipes = [ False ] * self . n_banks if self . _needs_calcs : self . update_calcd_data () for table in self . table_data : if f \" { table . name } .Corrected\" in self . resampled . sigs : tmp : list [ Sig ] = [] ranges = [] if table . name . translate ( remove_digits ) in bank_gate_tables : cyl = \"\" . join ( filter ( lambda x : x . isdigit (), table . name )) bank_ind = ( self . table_data [ f \"Engine.Cylinder { cyl } .Bank\" ] . data [ 0 ] - 1 ) if self . tabs [ table . name ] . additional_gate : gate = GateCollAND ( [ self . bank_gates [ bank_ind ], self . tabs [ table . name ] . additional_gate , ] ) else : gate = self . bank_gates [ bank_ind ] tmp_sig = ( self . resampled [ f \" { table . name } .Corrected\" ] . valid ( gate ) . resample ( self . resampled . math_tline ) ) if ( tmp_sig . data . size - np . count_nonzero ( np . isnan ( tmp_sig . data )) < 1 ): msg . append ( f \" \\n ## Individual Cylinder Lambda signals out of limits on bank { bank_ind + 1 } . \\n Bank trim from tailpipe sensor only.\" ) self . use_tailpipes [ bank_ind ] = True if self . tabs [ table . name ] . additional_gate : gate = GateCollAND ( [ self . gate , self . tabs [ table . name ] . additional_gate ] ) else : gate = self . gate tmp_sig = ( self . resampled [ f \" { table . name } .Corrected.Tailpipe\" ] . valid ( gate ) . resample ( self . resampled . math_tline ) ) self . resampled . remove ( f \" { table . name } .Corrected\" ) self . resampled . append ( Sig ( self . resampled [ f \" { table . name } .Corrected.Tailpipe\" ], name = f \" { table . name } .Corrected\" , ) ) for axis in table . axes : tmp . append ( self . resampled [ f \" { axis . name } \" ] . valid ( gate ) . as_unit ( axis . unit ) . resample ( self . resampled . math_tline ) ) ranges . append ([ axis . min , axis . max ]) tmp . append ( tmp_sig ) ranges . append ([ table . min , table . max ]) else : if self . tabs [ table . name ] . additional_gate : gate = GateCollAND ( [ self . gate , self . tabs [ table . name ] . additional_gate ] ) else : gate = self . gate for axis in table . axes : tmp . append ( self . resampled [ f \" { axis . name } \" ] . valid ( gate ) . as_unit ( axis . unit ) . resample ( self . resampled . math_tline ) ) ranges . append ([ axis . min , axis . max ]) tmp_sig = ( self . resampled [ f \" { table . name } .Corrected\" ] . valid ( gate ) . resample ( self . resampled . math_tline ) ) if \"Coolant.Temperature.Fuel Volume Compensation\" in table . name : try : # Need to adjust offset to center at normal op temp op_temp = self . tabs [ table . name ] . op_temp . value ind = table . axes [ 0 ] . bins ( op_temp )[ 0 ] diff = table . axes [ 0 ] . diff [ ind ] zero_inds = np . logical_and ( np . greater ( tmp [ - 1 ] . data , op_temp - diff / 2 ), np . less ( tmp [ - 1 ] . data , op_temp + diff / 2 ), ) zero_val = np . mean ( tmp_sig . data [ zero_inds ]) if np . isnan ( zero_val ): zero_val = 0 tmp_sig -= zero_val except AttributeError : pass tmp . append ( tmp_sig ) ranges . append ([ table . min , table . max ]) color_data = None color_name = None color_unit = None color_range = None if self . tabs [ table . name ] . color_sig . value : name = self . tabs [ table . name ] . color_sig . value [ 0 ] if \"Relative Density\" in name : color_name = name n_bins = [ 70 ] * len ( tmp ) n_bins [ - 1 ] *= 2 bins = [] for vals , intv , n_bin in zip ( tmp , ranges , n_bins ): bins . append ( np . linspace ( np . minimum ( vals . min , intv [ 0 ]), np . maximum ( vals . max , intv [ 1 ]), n_bin , ) ) color_data = scatter_density ( ScatterData ( tmp ), n_bins = bins ) elif name in self . resampled : color_data = ( self . resampled [ name ] . valid ( gate ) . resample ( self . resampled . math_tline ) . data ) color_name = name color_unit = self . resampled [ name ] . unit color_range = self . resampled [ name ] . data_range table . scatter_data = ScatterData ( data = tmp , name = \"Corrected\" , color = color_data , color_unit = color_unit , color_name = color_name , color_range = color_range , ) . clean () # Add logged data trace if table . name in self . resampled : tmp [ - 1 ] = ( self . resampled [ table . name ] . valid ( gate ) . resample ( self . resampled . math_tline ) ) table . scatter_data . append ( ScatterData ( data = tmp , name = \"Logged\" ) . clean () ) else : table . scatter_data = None self . _needs_scatter_update = False if msg and self . _needs_bank_warning : msg = list ( set ( msg )) self . warning_dialog ( title = \"# Fit Data Warning\" , msg = \"<br>\" . join ( msg )) self . _needs_bank_warning = ( # pylint: disable=attribute-defined-outside-init False ) device_data_reader ( file , _event_loc , device_loc , sig = None ) Reads the device data from file. Source code in ccg\\controllers\\motec.py 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 def device_data_reader ( file : BufferedReader , _event_loc : int , device_loc : int , sig : Sig = None ) -> Sig : \"\"\"Reads the device data from file.\"\"\" if sig is None : sig = Sig () dev_size = _event_loc - device_loc dev_format = str ( dev_size ) + \"s\" file . seek ( device_loc ) dev_raw = struct . unpack ( dev_format , file . read ( dev_size )) dets = [ 0 , 0 , 1 , 0 , 0 , 14 , dev_size ] # Starting dets dev_data = parse_device_data ( {}, dev_raw [ 0 ], DEVICE_FORMAT , struct . calcsize ( DEVICE_FORMAT ), dets ) if \"lastKey\" in dev_data : del dev_data [ \"lastKey\" ] # we can elim this for key , val in dev_data . items (): setattr ( sig , key , val ) return sig parse_device_data ( dev , data , det_format , det_size , dets ) Recursive parsing function for device details dev: device info dictionary data: data to parse in bytes frmDet: section details format szDet: size of details dets: section details looks for keyword 'Mo' Source code in ccg\\controllers\\motec.py 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 def parse_device_data ( dev : dict , data : bytes , det_format : int , det_size : int , dets : list ) -> dict : \"\"\"Recursive parsing function for device details dev: device info dictionary data: data to parse in bytes frmDet: section details format szDet: size of details dets: section details looks for keyword 'Mo' \"\"\" i = 0 t = 0 while i < len ( data ) - 1 : i_new = data . find ( b \"Mo\" , i ) if ( i_new < i - 1 ): # no Mo in remainder of data... not sure why its missing the escape seq if ( t > 10 ): # If t is greater than 10, then last try was a false alarm, so Mo is missing i = i_new t = 0 else : t = 999 i = len ( data ) else : i = i_new if i >= 0 : t = data [ i + 2 ] # If t is >10, then this likely isnt a real keyword else : t = 0 if t < 10 : if i == - 1 : # no Mo in this section, so its probably a key or value if ( dets [ - 2 ] == 8 ): # This is a #. seems to be 5 bytes, often 0x02 followed by 4B of # keyfrm = \"<BI\" debugger = \"5s\" elif dets [ - 2 ] == 0 : # String keyfrm = str ( dets [ - 1 ]) + \"s\" debugger = keyfrm elif dets [ - 2 ] == 7 and dets [ - 1 ] == 16 : # Datetime? keyfrm = \"<HHHHHHHH\" debugger = \"16s\" else : # Dont decode the more unusual types return dev key_size = struct . calcsize ( keyfrm ) key_name = struct . unpack ( keyfrm , data [ 0 : key_size ]) t = struct . unpack ( debugger , data [ 0 : key_size ]) if ( dets [ - 2 ] == 8 ): # This is a #. seems to be 5 bytes, often 0x02 followed by 4B of # key_name = key_name [ 1 ] # /(10**keyName[0]) elif dets [ - 2 ] == 0 : # String key_name = ccg . util . byte2str ( key_name [ 0 ]) elif dets [ - 2 ] == 7 and dets [ - 1 ] == 16 : # Datetime? tz = timezone ( - timedelta ( hours = key_name [ 2 ])) key_name = datetime ( key_name [ 0 ], key_name [ 1 ], key_name [ 3 ], key_name [ 4 ], key_name [ 5 ], key_name [ 6 ], key_name [ 7 ] * 1000 , tz , ) if \"lastKey\" in dev : # Then this is a value in lastKey if ( dev [ \"lastKey\" ] in dev ): # If its already in the dev dict then it has _multiple entries if isinstance ( dev [ dev [ \"lastKey\" ]], list ): # If its already a list, append new entry dev [ dev [ \"lastKey\" ]] . append ( key_name ) else : # then this is the second entry, make it into a list dev [ dev [ \"lastKey\" ]] = [ dev [ dev [ \"lastKey\" ]], key_name ] else : dev [ dev [ \"lastKey\" ]] = key_name else : # Then this is a keyName dev [ \"lastKey\" ] = key_name return dev elif i == len ( data ) - 1 : # no Mo in this section return dev i += 2 # length of Mo keyword dets = list ( struct . unpack ( det_format , data [ i : i + det_size ])) i += det_size if dets [ 0 ] < 10 : # this is probably real if dets [ - 2 ] == 10 : # Escape from this level if \"lastKey\" in dev : del dev [ \"lastKey\" ] dev = parse_device_data ( dev , data [ i : i + dets [ - 1 ]], det_format , det_size , dets ) i += dets [ - 1 ] else : i += 1 return dev parse_value ( text , d_type ) Convert string to appropriate data type. Source code in ccg\\controllers\\motec.py 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 def parse_value ( text : str , d_type : str ): \"\"\"Convert string to appropriate data type.\"\"\" if d_type in [ DTYPES_TABLE [ \"enum\" ], DTYPES_TABLE [ \"f32\" ]]: try : return float ( text . strip ()) except ValueError as err : if \"-1.#INF\" in text : return np . NINF if \"INF\" in text : return np . Inf raise ValueError from err if d_type in [ DTYPES_TABLE [ \"u32\" ]]: return int ( text . strip (), 0 ) if d_type in [ DTYPES_TABLE [ \"str\" ]]: return text . strip () if d_type in [ DTYPES_TABLE [ \"s32\" ]]: return int ( text . strip ()) raise TypeError ( f \" { d_type } not understood.\" ) read_ld ( filenames ) Read and parse .ld file. Source code in ccg\\controllers\\motec.py 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 def read_ld ( filenames : str | tuple [ str ] | list [ str ]) -> Frame : \"\"\"Read and parse .ld file.\"\"\" if not ( isinstance ( filenames , list ) or isinstance ( filenames , tuple )): filenames = ( filenames ,) tstart = 0 data = Frame () frame_name = \"\" for filename in filenames : fname = Path ( filename ) with open ( fname , \"rb\" ) as file : frame_name += fname . name + \", \" # Read header data header = seg_reader ( file , 0 , HEADER_FORMAT , HEADER_NAMES , Sig ( name = \"header_data\" ), ) header . tline = TLine ([ tstart ]) # datetime.strptime( # # pylint: disable= no-member # f\"{header.date} {header.time}\", # \"%d/%m/%Y %H:%M:%S\", # ) # # pylint:enable=no-member # .astimezone().astimezone(timezone.utc) # ) # assumes local setting for TZ, then converts to UTC for db header . dev_ver = ( header . dev_ver / 100 # pylint: disable= no-member ) # Dev version seems to have 2 decimals header . filename = filename header . import_time = datetime . now () . astimezone () . astimezone ( timezone . utc ) data . append ( header , append_existing_signals = True ) data . append ( seg_reader ( file , data . header_data . file_event_loc , EVENT_FORMAT , EVENT_NAMES , Sig ( name = \"event_data\" , tline = header . tline ), ), append_existing_signals = True , ) data . append ( seg_reader ( file , data . event_data . file_venue_loc , VENUE_FORMAT , VENUE_NAMES , Sig ( name = \"venue_data\" , tline = header . tline ), ), append_existing_signals = True , ) data . append ( seg_reader ( file , data . venue_data . file_vehicle_loc , VEHICLE_FORMAT , VEHICLE_NAMES , Sig ( name = \"vehicle_data\" , tline = header . tline ), ), append_existing_signals = True , ) data . append ( device_data_reader ( file , data . header_data . file_event_loc , data . header_data . file_dev_loc , Sig ( name = \"device_data\" , tline = header . tline ), ), append_existing_signals = True , ) sigs = sig_reader ( file = file , strt_loc = data . header_data . file_sig_loc , device = data . header_data . dev , start_time = tstart , ) data . append ( sigs , append_existing_signals = True , interweave_tlines = True ) tstart = sigs . tend + 1.0 data . name = frame_name return data read_m1cgf ( filename , param_names = None ) Read .m1cfg xml file to Params. If param_names is not None, only those parameters will be imported. Source code in ccg\\controllers\\motec.py 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 def read_m1cgf ( filename : str | Path , param_names : list [ str ] = None ): \"\"\"Read .m1cfg xml file to Params. If param_names is not None, only those parameters will be imported.\"\"\" tic = datetime . now () if not isinstance ( filename , Path ): filename = Path ( filename ) xml = ET . parse ( filename ) . getroot () pars = [] if param_names is not None : n_par_rem = len ( param_names ) else : n_par_rem = - 1 for table in xml . iter ( \"Table\" ): if param_names is None or table . get ( \"Name\" ) in param_names : n_par_rem -= 1 axes_data = [] axes_units = [] axes_names = [] inds = [] n_axis = - 1 inds = [ 1 , 1 , 1 ] for elem in table . findall ( \"./\" ): d_type = DTYPES_TABLE [ elem [ 0 ] . get ( \"Type\" )] unit = elem [ 0 ] . get ( \"Unit\" ) values = [] for cell in elem . iter ( \"Cell\" ): values . append ( parse_value ( cell . text , d_type )) shp = cell . get ( \"Site\" ) data = np . atleast_1d ( np . array ( values , dtype = d_type )) if elem . tag != \"Body\" : # Axis # Motec data doesnt need to use all available bps axis_ind = [ \"X\" , \"Y\" , \"Z\" ] . index ( elem . tag ) n_axis += 1 diff = data [ 1 :] - data [: - 1 ] ind = np . where ( np . logical_or ( np . append ( False , diff [ 1 :] * diff [: - 1 ] < 0 ), diff == 0 ) )[ 0 ] if np . any ( diff != 0 ): if ind . size > 0 : inds [ axis_ind ] = ind [ 0 ] + 1 data = data [: ind [ 0 ] + 1 ] else : inds [ axis_ind ] = data . size axes_data . append ( data ) axes_units . append ( unit ) axes_names . append ( elem . tag ) else : inds [ axis_ind ] = 1 _LOGGER . debug ( \" %s axis dropped from %s \" , elem . tag , table . get ( \"Name\" ) ) flip_axis = [ False ] * len ( axes_data ) for i , axis in enumerate ( axes_data ): if not ccg . util . monotonic_increasing ( axis ): # motec data can be reversed, but must be monoton flip_axis [ i ] = True axes_data [ i ] = axis [:: - 1 ] axes = Axes ( axes_data = [ Axis ( data = data , unit = unit , name = name ) for data , unit , name in zip ( axes_data , axes_units , axes_names ) ], ) # need to reshape, then trim to active bps, then flip if needed. shp = [ int ( x ) for x in shp . split ( \",\" )] motec_shape = tuple ( x + 1 for x in shp ) max_dim = max ( i if x else 0 for i , x in enumerate ( shp )) + 1 shp = tuple ( x + 1 for x in shp [: max_dim ]) data : npt . NDArray = data . reshape ( shp , order = \"f\" ) # since ij indexing data = np . atleast_1d ( np . squeeze ( data [ np . ix_ ( * [ range ( i ) for i in inds [: max_dim ]])]) ) for i , flip in enumerate ( flip_axis ): if flip : data = np . flip ( data , axis = i ) par = Tbl ( name = table . get ( \"Name\" ), data = data , axes = axes , unit = unit ) par . motec_shape = motec_shape pars . append ( par ) if n_par_rem == 0 : break # Escape early for parameter in xml . iter ( \"Parameter\" ): if param_names is None or parameter . get ( \"Name\" ) in param_names : n_par_rem -= 1 name = parameter . get ( \"Name\" ) for cell in parameter . iter ( \"Cell\" ): tmp = cell . get ( \"Type\" ) tmp = \"str\" if tmp == \"enum\" else tmp d_type = DTYPES_TABLE [ tmp ] unit = cell . get ( \"Unit\" ) data = np . atleast_1d ( np . array ( parse_value ( cell . text , d_type ), dtype = d_type ) ) par = Tbl ( name = name , data = data , unit = unit ) par . motec_shape = ( 0 ,) pars . append ( par ) if n_par_rem == 0 : break # Escape early res = Tbls ( pars , name = filename . name ) toc = datetime . now () - tic _LOGGER . debug ( \"read %s in %.3f \" , res . name , toc . total_seconds ()) return res seg_reader ( file , strt_loc , unpk_format , format_names , data = None ) Read segment from binary file. Parameters: file ( BufferedReader ) \u2013 open file to read segment from. strt_location \u2013 starting location to read from. format \u2013 format string to unpack data with. format_names ( list [ str ] ) \u2013 attribute names corresponding to format. Names starting with '_' will be ignored. data ( Sig , default: None ) \u2013 optional CCGSig to put data into. Returns: CCGSig with unpacked data. \u2013 Source code in ccg\\controllers\\motec.py 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 def seg_reader ( file : BufferedReader , strt_loc : int , unpk_format : str , format_names : list [ str ], data : Sig = None , ) -> Sig : \"\"\"Read segment from binary file. Parameters ---------- file open file to read segment from. strt_location starting location to read from. format format string to unpack data with. format_names attribute names corresponding to format. Names starting with '_' will be ignored. data optional CCGSig to put data into. Returns ------- CCGSig with unpacked data. \"\"\" if data is None : data = Sig () file . seek ( strt_loc ) for i , field in enumerate ( struct . unpack ( unpk_format , file . read ( struct . calcsize ( unpk_format ))) ): if not format_names [ i ] . startswith ( \"__\" ): if isinstance ( field , bytes ): field = ccg . util . byte2str ( field ) setattr ( data , format_names [ i ], field ) return data sig_reader ( file , strt_loc , device , file_time = None , start_time = None ) Read signal data from file. Source code in ccg\\controllers\\motec.py 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 def sig_reader ( file : BufferedReader , strt_loc : int , device : str , file_time : datetime = None , start_time : float | datetime = None , ) -> Frame : \"\"\"Read signal data from file.\"\"\" _next_loc = strt_loc frm_sz = struct . calcsize ( SIG_FORMAT ) data = Frame () tstart = None # pylint: disable=no-member while _next_loc : sig = seg_reader ( file , _next_loc , SIG_FORMAT , SIG_NAMES ) if sig . _nsamples > 0 : # Why did the layout change with m1??? if device != \"M1\" : sig . short_name = sig . unit sig . unit = sig . __unk1 # sig.name = ccg.util.clean_name(sig.short_name) sig . name = sig . short_name # Check for longer than std frame full_len = sig . _next_loc - _next_loc if full_len > frm_sz : # import the remaining sig header region # i dont really know what this region is yet, import as bytes ext_len = full_len - frm_sz file . seek ( _next_loc + frm_sz ) ext = file . read ( ext_len ) # Check for long name t_ind = ext . rfind ( b \" \\x00 \" , 0 , - 1 ) t_len = ext [ max ( t_ind , 1 ) - 1 ] if t_len > 32 and t_len < ext_len - t_ind : sig . long_name = ccg . util . byte2str ( ext [ t_ind + 1 : - 1 ]) # sig.name = ccg.util.clean_name(sig.long_name) sig . name = sig . long_name # Read the data file . seek ( sig . _data_loc ) if sig . _data_type == 7 : if sig . _data_type2 == 4 : d_type = np . float32 elif sig . _data_type2 == 2 : d_type = np . float16 else : raise TypeError ( f \"Unexpected data type \\n _sig: % { sig . short_name } \" ) elif sig . _data_type in [ 0 , 3 , 4 , 5 , 6 , 8 ]: if sig . _data_type2 == 4 : d_type = np . int32 elif sig . _data_type2 == 2 : d_type = np . int16 elif sig . _data_type2 == 8 : d_type = np . int64 else : raise TypeError ( f \"Unexpected data type \\n _sig: { sig . short_name } \" ) else : raise TypeError ( f \"Unexpected data type \\n _sig: { sig . short_name } \" ) sig . data = np . fromfile ( file , count = sig . _nsamples , dtype = d_type ) # Choose an efficient data type in case of _ndec>0 if d_type in [ np . int16 , np . int32 ] and sig . _ndec > 0 : d_type = np . float32 elif d_type in [ np . int64 ] and sig . _ndec > 0 : d_type = np . float64 # Scaling for .ld without float type, tries to preserve data type # check if req'd if not ( sig . _denom == 1 and sig . _zero_off == 0 and sig . _multi == 1 and sig . _ndec == 0 ): sig . data = d_type ( ((( sig . data / sig . _denom ) - sig . _zero_off ) * sig . _multi ) * 10 **- sig . _ndec ) if file_time is not None : # No start time info in the file. There is download time, so we can make a bad guess that # it was downloaded immediately. # only calc this once, since different rate signals have a tiny bit different end time. tstart = file_time . timestamp () - sig . nsamples * sig . _freq else : tstart = 0 if start_time is not None : tstart = start_time sig . tline = TLine ( tstart = tstart , nsamples = sig . nsamples , period = 1 / sig . _freq ) data . append ( sig ) _next_loc = sig . _next_loc return data write_m1cfg ( filename , params , param_names = None ) Write .m1cfg xml of params. First converts back to units in orig archive. This works well for Params imported with read_m1cfg. Use param_names to export a subset or params. Source code in ccg\\controllers\\motec.py 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 def write_m1cfg ( filename : str | Path , params : Tbls , param_names : list [ str ] = None ): \"\"\"Write .m1cfg xml of params. First converts back to units in `orig` archive. This works well for Params imported with read_m1cfg. Use param_names to export a subset or params.\"\"\" # convert units back # First make a copy to avoid changing base tmp = [] for par in params : tmppar = Tbl ( par ) if hasattr ( par , \"mark\" ): tmppar . mark = par . mark tmp . append ( tmppar ) tmp_params = Tbls ( tmp ) for par , orig in zip ( tmp_params , params ): orig_par = orig . _archive [ \"orig\" ][ 0 ] par . convert_units ( orig_par . unit ) for i in range ( par . n_dim ): par . axes [ i ] . convert_units ( orig_par . axes [ i ] . unit ) par . axes [ i ] . name = orig_par . axes [ i ] . name xml = ET . Element ( \"Configuration\" , attrib = { \"Locale\" : \"English_United States.1252\" , \"DefaultLocale\" : \"C\" }, ) grp = ET . SubElement ( xml , \"Group\" , attrib = { \"Name\" : \"\" }) for param in tmp_params : if param_names is not None and param . name in param_names : if param . motec_shape != ( 0 ,): tbl = ET . SubElement ( grp , \"Table\" , attrib = { \"Name\" : param . name }) expand = [] shp = [ 1 , 1 , 1 ] for i , axis in enumerate ( param . axes ): ax_el = ET . SubElement ( tbl , axis . name ) cells = ET . SubElement ( ax_el , \"Cells\" , attrib = { \"Type\" : MOTEC_TYPE [ axis . data . dtype . str ], \"Unit\" : axis . unit , }, ) ind = [ \"X\" , \"Y\" , \"Z\" ] . index ( axis . name ) if ind > i : expand . append ( i ) shp [ ind ] = axis . n_bps for j , value in enumerate ( axis . data ): site = [ 0 ] * 3 site [ ind ] = j attrib = { \"Site\" : str ( site )[ 1 : - 1 ] . replace ( \" \" , \"\" )} if hasattr ( axis , \"mark\" ): if axis . mark [ j ]: attrib . update ({ \"State\" : \"4\" }) cell = ET . SubElement ( cells , \"Cell\" , attrib = attrib , ) cell . text = str ( value ) for j in range ( 2 - ind ): expand . append ( j + ind + 1 ) bdy = ET . SubElement ( tbl , \"Body\" ) cells = ET . SubElement ( bdy , \"Cells\" , attrib = { \"Type\" : MOTEC_TYPE [ param . dtype . str ], \"Unit\" : param . unit }, ) # shp = param.axes.shape + (1,) * (3 - param.n_dim) # to make 3d full = np . zeros ( param . motec_shape , dtype = param . dtype ) full_mark = np . zeros ( param . motec_shape , dtype = np . bool_ ) if np . any ( expand ): tmp_data = np . expand_dims ( param . data , tuple ( expand )) if hasattr ( param , \"mark\" ): tmp_mark = np . expand_dims ( param . mark , tuple ( expand )) else : tmp_data = param . data if hasattr ( param , \"mark\" ): tmp_mark = param . mark full [ np . ix_ ( * [ range ( i ) for i in shp ])] = tmp_data it = np . nditer ( full , flags = [ \"multi_index\" ], order = \"F\" ) if hasattr ( param , \"mark\" ): full_mark [ np . ix_ ( * [ range ( i ) for i in shp ])] = tmp_mark mark_it = np . nditer ( full_mark , flags = [ \"multi_index\" ], order = \"F\" ) for val , mark in zip ( it , mark_it ): attrib = { \"Site\" : str ( it . multi_index )[ 1 : - 1 ] . replace ( \" \" , \"\" )} if mark : attrib . update ({ \"State\" : \"4\" }) cell = ET . SubElement ( cells , \"Cell\" , attrib = attrib , ) cell . text = str ( val ) else : # Param param_elem = ET . SubElement ( grp , \"Parameter\" , attrib = { \"Name\" : param . name } ) attrib = { \"Type\" : MOTEC_TYPE [ param . data . dtype . str ], } if param . unit is not None : attrib . update ({ \"Unit\" : param . unit }) cell = ET . SubElement ( param_elem , \"Cell\" , attrib = attrib , ) cell . text = str ( param . data [ 0 ]) tree = ET . ElementTree ( xml ) ET . indent ( tree ) filename = Path ( filename ) . with_suffix ( \".m1cfg\" ) tree . write ( filename , xml_declaration = True , encoding = \"ascii\" )","title":"motec"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.DRE_JLM_V2","text":"Bases: FirmwareModel M1 Firmware model for DRE JLM V2 TT Dual Sensors Package Source code in ccg\\controllers\\motec.py 2272 2273 2274 2275 2276 2277 2278 2279 2280 2281 2282 2283 2284 2285 2286 2287 2288 2289 2290 2291 2292 2293 2294 2295 2296 2297 2298 2299 2300 2301 2302 2303 2304 2305 2306 2307 2308 2309 2310 2311 2312 2313 2314 2315 2316 2317 2318 2319 2320 2321 2322 2323 2324 2325 2326 2327 2328 2329 2330 2331 2332 2333 2334 2335 2336 2337 2338 2339 2340 2341 2342 2343 2344 2345 2346 2347 2348 2349 2350 2351 2352 2353 2354 2355 2356 2357 2358 2359 2360 2361 2362 2363 2364 2365 2366 2367 2368 2369 2370 2371 2372 2373 2374 2375 2376 2377 2378 2379 2380 2381 2382 2383 2384 2385 2386 2387 2388 2389 2390 2391 2392 2393 2394 2395 2396 2397 2398 2399 2400 2401 2402 2403 2404 2405 2406 2407 2408 2409 2410 2411 2412 2413 2414 2415 2416 2417 2418 2419 2420 2421 2422 2423 2424 2425 2426 2427 2428 2429 2430 2431 2432 2433 2434 2435 2436 2437 2438 2439 2440 2441 2442 2443 2444 2445 2446 2447 2448 2449 2450 2451 2452 2453 2454 2455 2456 2457 2458 2459 2460 2461 2462 2463 2464 2465 2466 2467 2468 2469 2470 2471 2472 2473 2474 2475 2476 2477 2478 2479 2480 2481 2482 2483 2484 2485 2486 2487 2488 2489 2490 2491 2492 2493 2494 2495 2496 2497 2498 2499 2500 2501 2502 2503 2504 2505 2506 2507 2508 2509 2510 2511 2512 2513 2514 2515 2516 2517 2518 2519 2520 2521 2522 2523 2524 2525 2526 2527 2528 2529 2530 2531 2532 2533 2534 2535 2536 2537 2538 2539 2540 2541 2542 2543 2544 2545 2546 2547 2548 2549 2550 2551 2552 2553 2554 2555 2556 2557 2558 2559 2560 2561 2562 2563 2564 2565 2566 2567 2568 2569 2570 2571 2572 2573 2574 2575 2576 2577 2578 2579 2580 2581 2582 2583 2584 2585 2586 2587 2588 2589 2590 2591 2592 2593 2594 2595 2596 2597 2598 2599 2600 2601 2602 2603 2604 2605 2606 2607 2608 2609 2610 2611 2612 2613 2614 2615 2616 2617 2618 2619 2620 2621 2622 2623 2624 2625 2626 2627 2628 2629 2630 2631 2632 2633 2634 2635 2636 2637 2638 2639 2640 2641 2642 2643 2644 2645 2646 2647 2648 2649 2650 2651 2652 2653 2654 2655 2656 2657 2658 2659 2660 2661 2662 2663 2664 2665 2666 2667 2668 2669 2670 2671 2672 2673 2674 2675 2676 2677 2678 2679 2680 2681 2682 2683 2684 2685 2686 2687 2688 2689 2690 2691 2692 2693 2694 2695 2696 2697 2698 2699 2700 2701 2702 2703 2704 2705 2706 2707 2708 2709 2710 2711 2712 2713 2714 2715 2716 2717 2718 2719 2720 2721 2722 2723 2724 2725 2726 2727 2728 2729 2730 2731 2732 2733 2734 2735 2736 2737 2738 2739 2740 2741 2742 2743 2744 2745 2746 2747 2748 2749 2750 2751 2752 2753 2754 2755 2756 2757 2758 2759 2760 2761 2762 2763 2764 2765 2766 2767 2768 2769 2770 2771 2772 2773 2774 2775 2776 2777 2778 2779 2780 2781 2782 2783 2784 2785 2786 2787 2788 2789 2790 2791 2792 2793 2794 2795 2796 2797 2798 2799 2800 2801 2802 2803 2804 2805 2806 2807 2808 2809 2810 2811 2812 2813 2814 2815 2816 2817 2818 2819 2820 2821 2822 2823 2824 2825 2826 2827 2828 2829 2830 2831 2832 2833 2834 2835 2836 2837 2838 2839 2840 2841 2842 2843 2844 2845 2846 2847 2848 2849 2850 2851 2852 2853 2854 2855 2856 2857 2858 2859 2860 2861 2862 2863 2864 2865 2866 2867 2868 2869 2870 2871 2872 2873 2874 2875 2876 2877 2878 2879 2880 2881 2882 2883 2884 2885 2886 2887 2888 2889 2890 2891 2892 2893 2894 2895 2896 2897 2898 2899 2900 2901 2902 2903 2904 2905 2906 2907 2908 2909 2910 2911 2912 2913 2914 2915 2916 2917 2918 2919 2920 2921 2922 2923 2924 2925 2926 2927 2928 2929 2930 2931 2932 2933 2934 2935 2936 2937 2938 2939 2940 2941 2942 2943 2944 2945 2946 2947 2948 2949 2950 2951 2952 2953 2954 2955 2956 2957 2958 2959 2960 2961 2962 2963 2964 2965 2966 2967 2968 2969 2970 2971 2972 2973 2974 2975 2976 2977 2978 2979 2980 2981 2982 2983 2984 2985 2986 2987 2988 2989 2990 2991 2992 2993 2994 2995 2996 2997 2998 2999 3000 3001 3002 3003 3004 3005 3006 3007 3008 3009 3010 3011 3012 3013 3014 3015 3016 3017 3018 3019 3020 3021 3022 3023 3024 3025 3026 3027 3028 3029 3030 3031 3032 3033 3034 3035 3036 3037 3038 3039 3040 3041 3042 3043 3044 3045 3046 3047 3048 3049 3050 3051 3052 3053 3054 3055 3056 3057 3058 3059 3060 3061 3062 3063 3064 3065 3066 3067 3068 3069 3070 3071 3072 3073 3074 3075 3076 3077 3078 3079 3080 3081 3082 3083 3084 3085 3086 3087 3088 3089 3090 3091 3092 3093 3094 3095 3096 3097 3098 3099 3100 3101 3102 3103 3104 3105 3106 3107 3108 3109 3110 3111 3112 3113 3114 3115 3116 3117 3118 3119 3120 3121 3122 3123 3124 3125 3126 3127 3128 3129 3130 3131 3132 3133 3134 3135 3136 3137 3138 3139 3140 3141 3142 3143 3144 3145 3146 3147 3148 3149 3150 3151 3152 3153 3154 3155 3156 3157 3158 3159 3160 3161 3162 3163 3164 3165 3166 3167 3168 3169 3170 3171 3172 3173 3174 3175 3176 3177 3178 3179 3180 3181 3182 3183 3184 3185 3186 3187 3188 3189 3190 3191 3192 3193 3194 3195 3196 3197 3198 3199 3200 3201 3202 3203 3204 3205 3206 3207 3208 3209 3210 3211 3212 3213 3214 3215 3216 3217 3218 3219 3220 3221 3222 3223 3224 3225 3226 3227 3228 3229 3230 3231 3232 3233 3234 3235 3236 3237 3238 3239 3240 3241 3242 3243 3244 3245 3246 3247 3248 3249 3250 3251 3252 3253 3254 3255 3256 3257 3258 3259 3260 3261 3262 3263 3264 3265 3266 3267 3268 3269 3270 3271 3272 3273 3274 3275 3276 3277 3278 3279 3280 3281 3282 3283 3284 3285 3286 3287 3288 3289 3290 3291 3292 3293 3294 3295 3296 3297 3298 3299 3300 3301 3302 3303 3304 3305 3306 3307 3308 3309 3310 3311 3312 3313 3314 3315 3316 3317 3318 3319 3320 3321 3322 3323 3324 3325 3326 3327 3328 3329 3330 3331 3332 3333 3334 3335 3336 3337 3338 3339 3340 3341 3342 3343 3344 3345 3346 3347 3348 3349 3350 3351 3352 3353 3354 3355 3356 3357 3358 3359 3360 3361 3362 3363 3364 3365 3366 3367 3368 3369 3370 3371 3372 3373 3374 3375 3376 3377 3378 3379 3380 3381 3382 3383 3384 3385 3386 3387 3388 3389 3390 3391 3392 3393 3394 3395 3396 3397 3398 3399 3400 3401 3402 3403 3404 3405 3406 3407 3408 3409 3410 3411 3412 3413 3414 3415 3416 3417 3418 3419 3420 3421 3422 3423 3424 3425 3426 3427 3428 3429 3430 3431 3432 3433 3434 3435 3436 3437 3438 3439 3440 3441 3442 3443 3444 3445 3446 3447 3448 3449 3450 3451 3452 3453 3454 3455 3456 3457 3458 3459 3460 3461 3462 3463 3464 3465 3466 3467 3468 3469 3470 3471 3472 3473 3474 3475 3476 3477 3478 3479 3480 3481 3482 3483 3484 3485 3486 3487 3488 3489 3490 3491 3492 3493 3494 3495 3496 3497 3498 3499 3500 3501 3502 3503 3504 3505 3506 3507 3508 3509 3510 3511 3512 3513 3514 3515 3516 3517 3518 3519 3520 class DRE_JLM_V2 ( FirmwareModel ): \"\"\"M1 Firmware model for DRE JLM V2 TT Dual Sensors Package\"\"\" reference_tables = { \"Fuel.Mixture Aim.Main\" : { \"unit\" : \"LA\" , \"prec\" : 2 , \"range\" : [ 0.01 , 5 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine.Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"Inlet.Manifold.Pressure\" , \"unit\" : \"kPa\" , \"range\" : [ 0 , np . inf ], \"prec\" : 1 , }, \"Z\" : { \"sig\" : \"Driver.Fuel.Mixture Aim.Main.Switch\" , \"unit\" : \"\" , \"range\" : [ \"A\" , \"B\" ], \"prec\" : 0 , }, }, }, \"Fuel.Timing.Primary.Main\" : { \"unit\" : \"dBTDC\" , \"prec\" : 1 , \"range\" : [ 0 , 1440 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine.Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"Inlet.Manifold.Pressure\" , \"unit\" : \"kPa\" , \"range\" : [ 0 , np . inf ], \"prec\" : 1 , }, }, }, } fueling_tables = { \"Engine.Efficiency.Value\" : { \"unit\" : \"%\" , \"prec\" : 1 , \"range\" : [ 10 , 200 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine.Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"Inlet.Manifold.Pressure\" , \"unit\" : \"kPa\" , \"range\" : [ 0 , np . inf ], \"prec\" : 1 , }, \"Z\" : { \"sig\" : \"Ambient.Pressure\" , \"unit\" : \"kPa\" , \"range\" : [ 5 , 110 ], \"prec\" : 1 , }, }, }, \"Fuel.Cylinder #.Trim\" : { \"unit\" : \"%Trim\" , \"prec\" : 1 , \"range\" : [ - 100 , 50 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine.Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"Inlet.Manifold.Pressure\" , \"unit\" : \"kPa\" , \"range\" : [ 0 , np . inf ], \"prec\" : 1 , }, }, }, \"Inlet.Manifold.Pressure.Estimate.Main\" : { \"unit\" : \"%\" , \"prec\" : 1 , \"range\" : [ 0 , np . inf ], \"axes\" : { \"X\" : { \"sig\" : \"Throttle.Position\" , \"unit\" : \"%\" , \"range\" : [ 0 , 100 ], \"prec\" : 1 , }, \"Y\" : { \"sig\" : \"Engine.Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 0 , }, \"Z\" : { \"sig\" : \"Ambient.Pressure\" , \"unit\" : \"kPa\" , \"range\" : [ 5 , 110 ], \"prec\" : 1 , }, }, }, \"Fuel.Volume.Trim.Overall\" : { \"unit\" : \"%Trim\" , \"prec\" : 1 , \"range\" : [ - 99.9 , np . inf ], }, \"Coolant.Temperature.Fuel Volume Compensation\" : { \"unit\" : \"%Trim\" , \"prec\" : 1 , \"range\" : [ - 50 , 50 ], \"axes\" : { \"X\" : { \"sig\" : \"Coolant.Temperature\" , \"unit\" : \"F\" , \"range\" : [ - 58 , 482 ], \"prec\" : 1 , }, }, }, } fueling_params = { \"Fuel.Efficiency.Mode\" : { 0 : \"Manifold Air Density\" , 1 : \"Ambient Air Density\" , 2 : \"Airbox Air Density\" , }, \"Inlet.Manifold.Pressure.Mode\" : { 0 : \"Automatic\" , 1 : \"Estimate\" , 2 : \"Sensor\" , }, \"Engine.Cylinders\" : 8 , \"Engine.Cylinder #.Bank\" : 1 , \"Engine.Load.Normalised.Mode\" : { 0 : \"Normal\" , 1 : \"Inlet Manifold Pressure\" , 2 : \"Throttle PositioLambda.Indiv.Bank 2.AvgLambda.Indiv.Bank 2.Avgn\" , }, \"Inlet.Manifold.Pressure.Estimate.Mode\" : { 0 : \"Ambient Pressure Relative\" , 1 : \"100kPa Relative\" , 2 : \"Boost Pressure Relative\" , }, \"Fuel.Volume.Trim.Overall\" : 0 , \"Ambient.Pressure.Default.Value\" : 101.3 , } # TODO: complete calcd_sigs = [ \"Fueling.Error.Bank 1\" , \"Fueling.Error.Bank 2\" , \"Fueling.Error.Total\" , \"Engine.Efficiency.Value.Corrected\" , \"Lambda.Indiv.Bank 1.Avg\" , \"Lambda.Indiv.Bank 2.Avg\" , \"Cylinder.Trim.Avg\" , ] def __init__ ( self , m1cfg : str | Path = None , data : str | Path | Frame = None , gate : GateColl | str | Path = None , warning_dialog : Callable = None , ): super () . __init__ ( m1cfg = m1cfg , data = data , gate = gate , warning_dialog = warning_dialog , ) self . slow_sig = \"Engine.Speed\" self . use_tailpipes = [ False ] * self . n_banks @property def n_cyl ( self ): if self . table_data and \"Engine.Cylinders\" in self . table_data : return int ( self . table_data [ \"Engine.Cylinders\" ] . data ) return 8 @property def n_banks ( self ): if self . table_data : return int ( max ( self . table_data [ f \"Engine.Cylinder { i } .Bank\" ] . data for i in range ( 1 , self . n_cyl + 1 ) ) ) return 2 # @profile def check_substitute_sigs ( self ): \"\"\"Try to substitute for some common missing sigs.\"\"\" msgs = [] if self . table_data and self . data : try : mode = self . table_data [ \"Engine.Load.Normalised.Mode\" ] . data if mode == \"Normal\" : # Value = # p * # Engine.Efficiency * # Fuel Vapour Correction * # (Engine.Displacement / Engine.Cylinders) * // Displacement of one cylinder # (1 / (Constants.rAir * (Engine.Charge.Temperature + 273.15))); // Ideal gas law # when (Normalised.Mode) # { # is (Normal) # { # local ideal = # Ambient.Pressure.Standard * # 1.0 * # 1.0 * # (Engine.Displacement / Engine.Cylinders) * // Displacement of one cylinder # (1 / (Constants.rAir * (Constants.standardTemperature + 273.15))); // Ideal gas law # Normalised = Value / ideal; raise NotImplementedError elif mode == \"Inlet.Manifold.Pressure\" : sig = Sig ( name = \"Engine.Load.Normalised\" , data = self . data [ \"Inlet.Manifold.Pressure\" ] / ccg . util . convert_units ( 101.325 , \"kPa\" , self . data [ \"Inlet.Manifold.Pressure\" ] . unit , ), tline = self . data [ \"Inlet.Manifold.Pressure\" ] . tline , unit = \"ratio\" , ) elif mode == \"Throttle Position\" : sig = Sig ( name = \"Engine.Load.Normalised\" , data = self . data [ \"Throttle.Position\" ], ) sig . convert_units ( \"%\" ) if \"Engine.Load.Normalised\" not in self . data : self . data . append ( sig ) msgs . append ( \"`Engine.Load.Normalized` was not logged and has been calculated from input signals.\" ) elif sig . period < self . data [ \"Engine.Load.Normalised\" ] . period : self . data . remove ( \"Engine.Load.Normalised\" ) self . data . append ( sig ) msgs . append ( \"`Engine.Load.Normalized` was logged slowly and has been calculated from input signals.\" ) except KeyError : pass try : if \"Fuel.Volume.Trim\" not in self . data : sig = self . table_data [ \"Fuel.Volume.Trim.Overall\" ][ self . data ] sig . name = \"Fuel.Volume.Trim\" self . data . append ( sig ) msgs . append ( \"`Fuel.Volume.Trim` was not logged and has been calculated from the loaded calibration. ** Ensure that this matches the calibration that generated the data **\" ) except KeyError : pass try : if \"Engine.Efficiency\" not in self . data : sig = self . table_data [ \"Engine.Efficiency.Value\" ][ self . data ] sig . name = \"Engine.Efficiency\" self . data . append ( sig ) msgs . append ( \"`Engine.Efficiency` was not logged and has been calculated from the loaded calibration. ** Ensure that this matches the calibration that generated the data **\" ) except KeyError : pass try : if \"Fuel.Closed Loop.Control.Bank 1.Trim\" not in self . data : sig = Sig ( self . data [ self . slow_sig ]) sig . name = \"Fuel.Closed Loop.Control.Bank 1.Trim\" sig . data = np . ones ( sig . data . shape ) sig . unit = \"ratio\" self . data . append ( sig ) msgs . append ( \"`Fuel.Closed Loop.Control.Bank 1.Trim` was not logged and has been assumed to be disabled. ** Ensure that this matches the calibration that generated the data **\" ) except KeyError : pass try : if \"Fuel.Closed Loop.Control.Bank 2.Trim\" not in self . data : sig = Sig ( self . data [ self . slow_sig ]) sig . name = \"Fuel.Closed Loop.Control.Bank 2.Trim\" sig . data = np . ones ( sig . data . shape ) sig . unit = \"ratio\" self . data . append ( sig ) msgs . append ( \"`Fuel.Closed Loop.Control.Bank 2.Trim` was not logged and has been assumed to be disabled. ** Ensure that this matches the calibration that generated the data **\" ) except KeyError : pass for i in range ( 1 , self . n_cyl + 1 ): try : name = f \"Fuel.Cylinder { i } .Trim\" if name not in self . data : sig = self . table_data [ name ][ self . data ] self . data . append ( sig ) msgs . append ( f \"` { name } ` was not logged and has been calculated from the loaded calibration. ** Ensure that this matches the calibration that generated the data **\" ) except KeyError : pass try : if \"Coolant.Temperature.Fuel Volume Compensation\" not in self . data : sig = Sig ( self . data [ \"Fuel.Volume.Compensation\" ]) sig . name = \"Coolant.Temperature.Fuel Volume Compensation\" self . data . append ( sig ) msgs . append ( \"`Coolant.Temperature.Fuel Volume Compensation` was not logged and has been substituted with `Fuel.Volume.Compensation`. ** Ensure that no other volume compensation was active. **\" ) except KeyError : pass for i in range ( 1 , self . n_cyl + 1 ): try : name = f \"Exhaust.Lambda.Cylinder { i } \" if name not in self . data : sig = Sig ( self . data [ \"Exhaust.Lambda.Bank 1\" ]) * 0 sig . name = name self . data . append ( sig ) msgs . append ( f \"` { name } ` was not logged. Individual trims not possible.\" ) except KeyError : pass if msgs : msgs = [ \"## Substituted Signals \\n \" , * msgs ] return msgs @profile def check_sigs ( self ): \"\"\"Check that required input sigs are present.\"\"\" if self . table_data and self . data : msgs = self . check_substitute_sigs () required_sigs = set ( [ \"Fuel.Mixture Aim\" , \"Engine.Efficiency\" , \"Fuel.Volume.Trim\" , \"Fuel.Volume.Compensation\" , \"Coolant.Temperature.Fuel Volume Compensation\" , ] ) for table in self . fueling_tables : for axis in self . table_data [ table . replace ( \"#\" , \"1\" )] . axes : required_sigs . add ( axis . name ) for i in range ( 1 , self . n_cyl + 1 ): required_sigs . add ( f \"Fuel.Cylinder { i } .Trim\" ) required_sigs . add ( f \"Exhaust.Lambda.Cylinder { i } \" ) for i in range ( 1 , self . n_banks + 1 ): required_sigs . add ( f \"Exhaust.Lambda.Bank { i } \" ) required_sigs . add ( f \"Fuel.Closed Loop.Control.Bank { i } .Trim\" ) if ( \"Ambient Pressure Relative\" in self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Mode\" ] . data ): required_sigs . add ( \"Ambient.Pressure\" ) ok_slow = [ \"Ambient.Pressure\" , \"Fuel.Mixture Aim\" , \"Fuel.Volume.Trim\" , \"Fuel.Volume.Compensation\" , \"Inlet.Manifold.Pressure.Estimate\" , \"Coolant.Temperature.Fuel Volume Compensation\" , \"Coolant.Temperature\" , ] extras = [ \"Inlet.Manifold.Pressure.Estimate\" , \"Inlet.Air.Temperature\" , \"Vehicle.Speed\" , \"Ignition.Cut\" , \"Ignition.Timing\" , \"Idle.State\" , \"Fuel.Volume.Transient\" , \"Fuel.Volume.Trim\" , \"Fuel.Volume.Compensation\" , \"Fuel.Timing.Primary\" , \"Fuel.Temperature\" , \"Fuel.Pressure\" , \"Fuel.Injector.Primary.Duty.Cycle\" , \"Fuel.Film.Primary\" , \"Fuel.Cut\" , \"Engine.Load\" , \"Coolant.Pressure\" , \"Engine.Charge.Temperature\" , \"Engine.Oil.Temperature\" , \"Engine.Oil.Pressure\" , \"ECU.Batter.Voltage\" , \"Engine.Load.Normalised\" , ] required_sigs = list ( required_sigs ) missing = [] for sig in required_sigs : if sig not in self . data : missing . append ( sig ) for sig in self . gate . sigs : if sig not in self . data and sig not in self . calcd_sigs : missing . append ( sig ) if missing : missing . sort () # msg = \"<br>\".join(missing) if self . warning_dialog : msgs . extend ([ \" \\n ## Missing Required Signals \\n \" , * missing ]) self . warning_dialog ( title = \"# Missing Signals\" , msg = \"<br>\" . join ( msgs ) ) return False raise ValueError ( f \"Missing Required Signals \\n { missing } \" ) for sig in required_sigs : if sig not in ok_slow : self . slow_sig = sig break for sig in required_sigs : if ( sig not in ok_slow and self . data [ sig ] . period > self . data [ self . slow_sig ] . period ): self . slow_sig = sig for sig in self . gate . sigs : if sig not in self . calcd_sigs and sig not in required_sigs : required_sigs . append ( sig ) tline = self . data [ self . slow_sig ] . tline self . resampled = self . data [ required_sigs ] . resample ( tline ) self . resampled . name = \"Resampled Data for Calc's\" self . data . math_tline = tline self . resampled . math_tline = tline for sig in extras : try : self . resampled . append ( self . data [ sig ] . resample ( tline )) except KeyError : pass if self . slow_freq < 50 : msgs . extend ( [ \" \\n ## Slow Signal \\n \" , f \"Calculation rate limited to { self . slow_freq } Hz by ` { self . slow_sig } `\" , ] ) if msgs : self . warning_dialog ( title = \"# Missing Signals\" , msg = \"<br>\" . join ( msgs )) return True else : return False @profile def update_calcd_data ( self ): \"\"\"Update calculations for fitting/plotting.\"\"\" if self . _needs_calcs : tic = datetime . now () if self . check_sigs (): if self . table_data : acc = 0 n = 0 for cyl in range ( 1 , 1 + self . n_cyl ): tmp = self . resampled [ f \"Fuel.Cylinder { cyl } .Trim\" ] . as_unit ( \"ratio\" ) tmp . unit = \"ratio\" tmp . name = f \"Fuel.Cylinder { cyl } .Trim.Total\" self . resampled . append ( tmp ) acc = acc + tmp n += 1 acc = acc / n acc . name = \"Cylinder.Trim.Avg\" acc . unit = \"ratio\" self . resampled . append ( acc ) for bank in range ( 1 , self . n_banks + 1 ): tmp = 0 n = 0 for cyl in range ( 1 , 1 + self . n_cyl ): if ( self . table_data [ f \"Engine.Cylinder { cyl } .Bank\" ] . data == bank ): n += 1 tmp = ( tmp + self . resampled [ f \"Exhaust.Lambda.Cylinder { cyl } \" ] ) tmp = tmp / n tmp . name = f \"Lambda.Indiv.Bank { bank } .Avg\" tmp . unit = \"LA\" tmp . data_range = [ 0.6 , 1.4 ] self . resampled . append ( tmp ) tmp = 0 n = 0 for cyl in range ( 1 , 1 + self . n_cyl ): if ( self . table_data [ f \"Engine.Cylinder { cyl } .Bank\" ] . data == bank ): n += 1 tmp = tmp + self . resampled [ f \"Fuel.Cylinder { cyl } .Trim\" ] . as_unit ( \"ratio\" ) tmp = tmp / n tmp . name = f \"Cylinder.Trim.Bank { bank } .Avg\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) self . resampled [ f \"Exhaust.Lambda.Bank { bank } \" ] . data_range = [ 0.6 , 1.4 , ] tmp = self . table_data [ \"Coolant.Temperature.Fuel Volume Compensation\" ][ self . resampled ] . as_unit ( \"ratio\" ) / self . resampled [ \"Fuel.Volume.Compensation\" ] . as_unit ( \"ratio\" ) tmp . name = \"Volume.Comp.Delta\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ \"Fuel.Closed Loop.Control.Bank 1.Trim\" ] . as_unit ( \"ratio\" ) * self . resampled [ \"Fuel.Volume.Trim\" ] . as_unit ( \"ratio\" ) / self . resampled [ \"Volume.Comp.Delta\" ] . as_unit ( \"ratio\" ) * self . resampled [ \"Cylinder.Trim.Bank 1.Avg\" ] * self . resampled [ \"Exhaust.Lambda.Bank 1\" ] / self . resampled [ \"Fuel.Mixture Aim\" ] ) # TODO: Fix for only 1 bank tmp . name = \"Fueling.Error.Bank 1\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ \"Fuel.Closed Loop.Control.Bank 2.Trim\" ] . as_unit ( \"ratio\" ) * self . resampled [ \"Fuel.Volume.Trim\" ] . as_unit ( \"ratio\" ) / self . resampled [ \"Volume.Comp.Delta\" ] . as_unit ( \"ratio\" ) * self . resampled [ \"Cylinder.Trim.Bank 2.Avg\" ] * self . resampled [ \"Exhaust.Lambda.Bank 2\" ] / self . resampled [ \"Fuel.Mixture Aim\" ] ) tmp . name = \"Fueling.Error.Bank 2\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ \"Fueling.Error.Bank 1\" ] + self . resampled [ \"Fueling.Error.Bank 2\" ] ) / 2 tmp . name = \"Fueling.Error.Total\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = self . resampled [ \"Fueling.Error.Total\" ] * ( self . resampled [ \"Engine.Efficiency\" ] ) tmp . name = \"Engine.Efficiency.Value.Corrected\" tmp . unit = \"%\" self . resampled . append ( tmp ) self . resampled . append ( Sig ( self . resampled [ \"Engine.Efficiency\" ], name = \"Engine.Efficiency.Value\" , ) ) # copy with name to match table for cyl in range ( 1 , 1 + self . n_cyl ): bank = int ( self . table_data [ f \"Engine.Cylinder { cyl } .Bank\" ] . data ) tmp = ( self . resampled [ f \"Exhaust.Lambda.Cylinder { cyl } \" ] / self . resampled [ f \"Lambda.Indiv.Bank { bank } .Avg\" ] ) tmp . name = f \"Cyl { cyl } .Lam.Error\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ f \"Fuel.Cylinder { cyl } .Trim.Total\" ] / self . resampled [ f \"Cylinder.Trim.Bank { bank } .Avg\" ] ) tmp . name = f \"Fuel.Cylinder { cyl } .Trim.Bank Normalised\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ f \"Fuel.Cylinder { cyl } .Trim.Total\" ] / self . resampled [ \"Cylinder.Trim.Avg\" ] ) tmp . name = f \"Fuel.Cylinder { cyl } .Trim.Normalised\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ f \"Fuel.Cylinder { cyl } .Trim.Bank Normalised\" ] * self . resampled [ f \"Cyl { cyl } .Lam.Error\" ] * ( self . resampled [ f \"Fueling.Error.Bank { bank } \" ] / self . resampled [ \"Fueling.Error.Total\" ] ) ) tmp . name = f \"Fuel.Cylinder { cyl } .Trim.Corrected\" tmp . unit = \"ratio\" tmp . convert_units ( \"%Trim\" ) self . resampled . append ( tmp ) # Calc cyl trims from tailpipe data incase indiv missing tmp = self . resampled [ f \"Fuel.Cylinder { cyl } .Trim.Normalised\" ] * ( self . resampled [ f \"Fueling.Error.Bank { bank } \" ] / self . resampled [ \"Fueling.Error.Total\" ] ) tmp . name = f \"Fuel.Cylinder { cyl } .Trim.Corrected.Tailpipe\" tmp . unit = \"ratio\" tmp . convert_units ( \"%Trim\" ) self . resampled . append ( tmp ) self . resampled [ f \"Exhaust.Lambda.Cylinder { cyl } \" ] . data_range = [ 0.6 , 1.4 , ] self . resampled . append ( self . resampled [ \"Engine.Speed\" ] . dot ( n_win = 17 )) self . resampled . append ( self . resampled [ \"Throttle.Position\" ] . dot ( n_win = 7 ) ) # inlet manifold press ref try : if ( \"Ambient Pressure Relative\" in self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Mode\" ] . data ): tmp = ( self . resampled [ \"Inlet.Manifold.Pressure\" ] / self . resampled [ \"Ambient.Pressure\" ] ) else : tmp = self . resampled [ \"Inlet.Manifold.Pressure\" ] / 100 tmp . name = \"Inlet.Manifold.Pressure.Estimate.Main.Corrected\" tmp . unit = \"ratio\" tmp . convert_units ( \"%\" ) self . resampled . append ( tmp ) if ( \"Ambient Pressure Relative\" in self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Mode\" ] . data ): tmp = ( self . resampled [ \"Inlet.Manifold.Pressure.Estimate\" ] / self . resampled [ \"Ambient.Pressure\" ] ) else : tmp = ( self . resampled [ \"Inlet.Manifold.Pressure.Estimate\" ] / 100 ) tmp . name = \"Inlet.Manifold.Pressure.Estimate.Main\" tmp . unit = \"ratio\" tmp . convert_units ( \"%\" ) self . resampled . append ( tmp ) except KeyError : pass # Coolant temp comps tmp = ( self . resampled [ \"Engine.Efficiency.Value.Corrected\" ] . as_unit ( \"ratio\" ) / self . table_data [ \"Engine.Efficiency.Value\" ][ self . resampled ] . as_unit ( \"ratio\" ) * self . resampled [ \"Coolant.Temperature.Fuel Volume Compensation\" ] . as_unit ( \"ratio\" ) * self . resampled [ \"Volume.Comp.Delta\" ] . as_unit ( \"ratio\" ) ) tmp . name = \"Coolant.Temperature.Fuel Volume Compensation.Corrected\" tmp . unit = \"ratio\" tmp . convert_units ( \"%Trim\" ) self . resampled . append ( tmp ) toc = datetime . now () - tic _LOGGER . debug ( \"Firmware calcs in %.3f \" , toc . total_seconds ()) # Set some ranges self . resampled [ \"Engine.Speed\" ] . data_range = [ 0 , 8800 ] self . resampled [ \"Fuel.Mixture Aim\" ] . data_range = [ 0.6 , 1.4 ] # Add calc'd signals to data frame for general plot self . data . append ( self . resampled ) self . _needs_calcs = False if not self . _needs_calcs : self . update_scatter_data () if self . resampled : # Update options for scatter plots opts = [ \"Relative Density\" , * self . resampled . sigs . keys ()] for tab in self . tabs : tab . color_sig . options = opts @profile def update_scatter_data ( self ): \"\"\"Update scatter data for fitting.\"\"\" if self . _needs_scatter_update : # Build signal list bank_gate_tables = [ \"Fuel.Cylinder #.Trim\" ] remove_digits = str . maketrans ( \"0123456789\" , \"##########\" ) msg = [] self . use_tailpipes = [ False ] * self . n_banks if self . _needs_calcs : self . update_calcd_data () for table in self . table_data : if f \" { table . name } .Corrected\" in self . resampled . sigs : tmp : list [ Sig ] = [] ranges = [] if table . name . translate ( remove_digits ) in bank_gate_tables : cyl = \"\" . join ( filter ( lambda x : x . isdigit (), table . name )) bank_ind = ( self . table_data [ f \"Engine.Cylinder { cyl } .Bank\" ] . data [ 0 ] - 1 ) if self . tabs [ table . name ] . additional_gate : gate = GateCollAND ( [ self . bank_gates [ bank_ind ], self . tabs [ table . name ] . additional_gate , ] ) else : gate = self . bank_gates [ bank_ind ] tmp_sig = ( self . resampled [ f \" { table . name } .Corrected\" ] . valid ( gate ) . resample ( self . resampled . math_tline ) ) if ( tmp_sig . data . size - np . count_nonzero ( np . isnan ( tmp_sig . data )) < 1 ): msg . append ( f \" \\n ## Individual Cylinder Lambda signals out of limits on bank { bank_ind + 1 } . \\n Bank trim from tailpipe sensor only.\" ) self . use_tailpipes [ bank_ind ] = True if self . tabs [ table . name ] . additional_gate : gate = GateCollAND ( [ self . gate , self . tabs [ table . name ] . additional_gate ] ) else : gate = self . gate tmp_sig = ( self . resampled [ f \" { table . name } .Corrected.Tailpipe\" ] . valid ( gate ) . resample ( self . resampled . math_tline ) ) self . resampled . remove ( f \" { table . name } .Corrected\" ) self . resampled . append ( Sig ( self . resampled [ f \" { table . name } .Corrected.Tailpipe\" ], name = f \" { table . name } .Corrected\" , ) ) for axis in table . axes : tmp . append ( self . resampled [ f \" { axis . name } \" ] . valid ( gate ) . as_unit ( axis . unit ) . resample ( self . resampled . math_tline ) ) ranges . append ([ axis . min , axis . max ]) tmp . append ( tmp_sig ) ranges . append ([ table . min , table . max ]) else : if self . tabs [ table . name ] . additional_gate : gate = GateCollAND ( [ self . gate , self . tabs [ table . name ] . additional_gate ] ) else : gate = self . gate for axis in table . axes : tmp . append ( self . resampled [ f \" { axis . name } \" ] . valid ( gate ) . as_unit ( axis . unit ) . resample ( self . resampled . math_tline ) ) ranges . append ([ axis . min , axis . max ]) tmp_sig = ( self . resampled [ f \" { table . name } .Corrected\" ] . valid ( gate ) . resample ( self . resampled . math_tline ) ) if \"Coolant.Temperature.Fuel Volume Compensation\" in table . name : try : # Need to adjust offset to center at normal op temp op_temp = self . tabs [ table . name ] . op_temp . value ind = table . axes [ 0 ] . bins ( op_temp )[ 0 ] diff = table . axes [ 0 ] . diff [ ind ] zero_inds = np . logical_and ( np . greater ( tmp [ - 1 ] . data , op_temp - diff / 2 ), np . less ( tmp [ - 1 ] . data , op_temp + diff / 2 ), ) zero_val = np . mean ( tmp_sig . data [ zero_inds ]) if np . isnan ( zero_val ): zero_val = 0 tmp_sig -= zero_val except AttributeError : pass tmp . append ( tmp_sig ) ranges . append ([ table . min , table . max ]) color_data = None color_name = None color_unit = None color_range = None if self . tabs [ table . name ] . color_sig . value : name = self . tabs [ table . name ] . color_sig . value [ 0 ] if \"Relative Density\" in name : color_name = name n_bins = [ 70 ] * len ( tmp ) n_bins [ - 1 ] *= 2 bins = [] for vals , intv , n_bin in zip ( tmp , ranges , n_bins ): bins . append ( np . linspace ( np . minimum ( vals . min , intv [ 0 ]), np . maximum ( vals . max , intv [ 1 ]), n_bin , ) ) color_data = scatter_density ( ScatterData ( tmp ), n_bins = bins ) elif name in self . resampled : color_data = ( self . resampled [ name ] . valid ( gate ) . resample ( self . resampled . math_tline ) . data ) color_name = name color_unit = self . resampled [ name ] . unit color_range = self . resampled [ name ] . data_range table . scatter_data = ScatterData ( data = tmp , name = \"Corrected\" , color = color_data , color_unit = color_unit , color_name = color_name , color_range = color_range , ) . clean () # Add logged data trace if table . name in self . resampled : tmp [ - 1 ] = ( self . resampled [ table . name ] . valid ( gate ) . resample ( self . resampled . math_tline ) ) table . scatter_data . append ( ScatterData ( data = tmp , name = \"Logged\" ) . clean () ) else : table . scatter_data = None self . _needs_scatter_update = False if msg and self . _needs_bank_warning : msg = list ( set ( msg )) self . warning_dialog ( title = \"# Fit Data Warning\" , msg = \"<br>\" . join ( msg )) self . _needs_bank_warning = ( # pylint: disable=attribute-defined-outside-init False ) def normalize_cyl_trims ( self ): \"\"\"Normalizes cyl trims if bp's match.\"\"\" cyl_trim_min = self . fueling_tables [ \"Fuel.Cylinder #.Trim\" ][ \"range\" ][ 0 ] cyl_trim_max = self . fueling_tables [ \"Fuel.Cylinder #.Trim\" ][ \"range\" ][ 1 ] cyl_trim_unit = self . fueling_tables [ \"Fuel.Cylinder #.Trim\" ][ \"unit\" ] if self . check_axes (): avg = np . zeros ( self . table_data [ \"Fuel.Cylinder 1.Trim\" ] . data . shape ) n = 0 for cyl in range ( 1 , self . n_cyl + 1 ): avg += self . table_data [ f \"Fuel.Cylinder { cyl } .Trim\" ] . data n += 1 avg = ccg . util . convert_units ( avg / n , cyl_trim_unit , \"ratio\" ) for cyl in range ( 1 , self . n_cyl + 1 ): cyl_trim = ( self . table_data [ f \"Fuel.Cylinder { cyl } .Trim\" ] . as_unit ( \"ratio\" ) . data / avg ) cyl_trim = ccg . util . convert_units ( cyl_trim , \"ratio\" , cyl_trim_unit ) self . table_data [ f \"Fuel.Cylinder { cyl } .Trim\" ] . data = np . clip ( cyl_trim , cyl_trim_min , cyl_trim_max ) else : raise ValueError ( \"Cyl trim axes dont match, cant normalize\" ) def check_axes ( self ): \"\"\"Check if cyl trim axes match\"\"\" for i in range ( 2 , self . n_cyl + 1 ): for axis , axis1 in zip ( self . table_data [ f \"Fuel.Cylinder { i } .Trim\" ] . axes , self . table_data [ \"Fuel.Cylinder 1.Trim\" ] . axes , ): if axis1 != axis : return False return True @profile def build_delta_summary ( self ): \"\"\"Builds tables to review fit.\"\"\" if self . table_data : input_tables = Tbls () input_tables . append ( self . table_data [ \"Engine.Efficiency.Value\" ]) cyl_trim_unit = self . fueling_tables [ \"Fuel.Cylinder #.Trim\" ][ \"unit\" ] for cyl in range ( 1 , self . n_cyl + 1 ): # Convert indiv tables to base axes name = f \"Fuel.Cylinder { cyl } .Trim\" axes = input_tables [ \"Engine.Efficiency.Value\" ] . axes tmp = self . convert_table_to_axes ( self . table_data [ name ], axes ) tmp . name = name input_tables . append ( tmp ) result_tables = Tbls () tmp = Tbl ( input_tables [ \"Engine.Efficiency.Value\" ]) tmp . data *= 0 tmp . name = \"Overall\" tmp . unit = \"ratio\" tmp . snapshot ( \"orig\" ) result_tables . append ( tmp ) for bank in range ( 1 , self . n_banks + 1 ): avg = Tbl ( input_tables [ \"Engine.Efficiency.Value\" ]) avg . data *= 0 avg . name = f \"Bank { bank } .Trim.Avg\" avg . unit = \"ratio\" avg . snapshot ( \"orig\" ) n = 0 for cyl in range ( 1 , self . n_cyl + 1 ): indiv = f \"Fuel.Cylinder { cyl } .Trim\" tmp = ( input_tables [ \"Engine.Efficiency.Value\" ] . orig . as_unit ( \"ratio\" ) * input_tables [ indiv ] . orig . as_unit ( \"ratio\" ) * self . table_data [ \"Fuel.Volume.Trim.Overall\" ] . orig . as_unit ( \"ratio\" ) . data ) tmp . name = f \"Individual { cyl } \" tmp . unit = \"ratio\" tmp . snapshot ( \"orig\" ) tmp . data = ( input_tables [ \"Engine.Efficiency.Value\" ] . as_unit ( \"ratio\" ) * input_tables [ indiv ] . as_unit ( \"ratio\" ) * self . table_data [ \"Fuel.Volume.Trim.Overall\" ] . as_unit ( \"ratio\" ) . data ) . data result_tables . append ( tmp ) if self . table_data [ f \"Engine.Cylinder { cyl } .Bank\" ] . data [ 0 ] == bank : avg . _archive [ \"orig\" ][ - 1 ] += input_tables [ indiv ] . orig . as_unit ( \"ratio\" ) avg += input_tables [ indiv ] . as_unit ( \"ratio\" ) n += 1 result_tables [ \"Overall\" ] . _archive [ \"orig\" ][ - 1 ] += tmp . orig result_tables [ \"Overall\" ] += tmp avg . _archive [ \"orig\" ][ - 1 ] /= n avg /= n result_tables . append ( avg ) result_tables [ \"Overall\" ] . _archive [ \"orig\" ][ - 1 ] /= self . n_cyl result_tables [ \"Overall\" ] /= self . n_cyl # FINALLY res = [ ccg . ui . panel . pn . Spacer ( height = 0 ), ccg . ui . panel . pn . pane . Markdown ( \"\"\"# Overall Fueling Delta This accounts for deltas in the `Engine.Efficiency.Value` table, the mean of the `Fuel.Cylinder #.Trim` tables, and the `Fuel.Volume.Trim.Overall`.\"\"\" , align = \"start\" , ), ] table = result_tables [ \"Overall\" ] axes_data = table . axes prec_args = { \"axis_names\" : [ f \" { axis . name } [ { axis . unit } ]\" for axis in axes_data ], \"axis_breakpoints\" : [ axis . data . tolist () for axis in axes_data ], \"axis_precisions\" : [ axis . precision for axis in axes_data ], \"data_precision\" : table . precision , \"locked\" : table . locked . T . tolist (), } res . append ( ccg . ui . panel . CalDataTbl ( name = \"Overall Fueling Delta %\" , table_name = \"Overall Fueling Delta [%]\" , data = table . delta_perc . T . tolist (), editable = False , colorscale = \"RdBu\" , colorscale_center = 0 , align = \"center\" , ** prec_args , ) ) res . append ( ccg . ui . panel . pn . pane . Markdown ( \"\"\"# Bank Average Cyl Trims\"\"\" , align = \"start\" , ) ) for bank in range ( 1 , self . n_banks + 1 ): name = f \"Bank { bank } .Trim.Avg\" table = result_tables [ name ] . as_unit ( cyl_trim_unit ) axes_data = table . axes prec_args = { \"axis_names\" : [ f \" { axis . name } [ { axis . unit } ]\" for axis in axes_data ], \"axis_breakpoints\" : [ axis . data . tolist () for axis in axes_data ], \"axis_precisions\" : [ axis . precision for axis in axes_data ], \"data_precision\" : table . precision , \"locked\" : table . locked . T . tolist (), } res . append ( ccg . ui . panel . CalDataTbl ( name = name , table_name = f \" { name } [ { cyl_trim_unit } ]\" , data = table . data . T . tolist (), editable = False , colorscale = \"RdBu\" , colorscale_center = 0 , align = \"center\" , ** prec_args , ) ) res . append ( ccg . ui . panel . pn . pane . Markdown ( \"\"\"# Individual Cylinder Fueling Deltas These accounts for deltas in the `Engine.Efficiency.Value` table, the the `Fuel.Cylinder #.Trim` tables, and the `Fuel.Volume.Trim.Overall`.\"\"\" , align = \"start\" , ) ) for cyl in range ( 1 , self . n_cyl + 1 ): name = f \"Individual { cyl } \" table = result_tables [ name ] axes_data = table . axes prec_args = { \"axis_names\" : [ f \" { axis . name } [ { axis . unit } ]\" for axis in axes_data ], \"axis_breakpoints\" : [ axis . data . tolist () for axis in axes_data ], \"axis_precisions\" : [ axis . precision for axis in axes_data ], \"data_precision\" : table . precision , \"locked\" : table . locked . T . tolist (), } res . append ( ccg . ui . panel . CalDataTbl ( name = f \" { name } Fueling Delta %\" , table_name = f \" { name } Fueling Delta [%]\" , data = table . delta_perc . T . tolist (), editable = False , colorscale = \"RdBu\" , colorscale_center = 0 , align = \"center\" , ** prec_args , ) ) return res def convert_table_to_axes ( self , table : Tbl , target : Axes ): \"\"\"Convert a table to fit the target axes if possible.\"\"\" res = Tbl ( name = \"result\" , axes = target , unit = table . unit ) if target . n_dim > 2 : raise NotImplementedError if target . n_dim < table . n_dim : raise NotImplementedError if table . n_dim == 0 : res . data = np . ones ( target . shape ) * table . orig . data res . snapshot ( \"orig\" ) res . data = np . ones ( target . shape ) * table . data return res # Leave in target units, convert table before interpolating. target_grid = target . grid interp_grid = target . grid units = [ \"\" ] * table . n_dim for j , axis in enumerate ( target ): found = False for i , t_axis in enumerate ( table . axes ): if axis . name == t_axis . name : interp_grid [ i ] = target_grid [ j ] units [ i ] = axis . unit found = True break if not found : # Check for possible calc if axis . name == \"Inlet.Manifold.Pressure\" : if \"Engine.Load.Normalised\" in table . axes : i = table . axes . index ( \"Engine.Load.Normalised\" ) # Calc engine load normalized mode = self . table_data [ \"Engine.Load.Normalised.Mode\" ] . data if mode == \"Normal\" : raise NotImplementedError elif mode == \"Inlet Manifold Pressure\" : tmp = Axis ( axis ) tmp . data = axis . data / ccg . util . convert_units ( 101.325 , \"kPa\" , axis . unit , ) interp_grid [ i ] = target_grid [ j ] units [ i ] = \"ratio\" elif mode == \"Throttle Position\" : eng_speed_ind = target . index ( \"Engine.Speed\" ) imap_ind = target . index ( \"Inlet.Manifold.Pressure\" ) interp_grid [ i ] = self . tps_from_map ( eng_speed = target_grid [ eng_speed_ind ], imap = target_grid [ imap_ind ], ) units [ i ] = \"%\" for unit , axis in zip ( units , table . axes ): axis . convert_units ( unit ) interp_vals = np . array ([ x . flatten () for x in interp_grid ]) . T res . data = table . orig . interp ( interp_vals ) . reshape ( target . shape , order = \"f\" ) res . snapshot ( \"orig\" ) res . data = table . interp ( interp_vals ) . reshape ( target . shape , order = \"f\" ) # res.plot() return res def tps_from_map ( self , eng_speed : npt . NDArray , imap : npt . NDArray ): \"\"\"Estimate Throttle.Position from manifold air pressure.\"\"\" n = 100 tps_map = Tbl ( self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Main\" ]) tps_map . name = \"TPS Estimate\" tps_map . interp_on_axis_change = True tps_map . data *= 0 tps_map . f_orig = 0 tps_map . f_smooth = [ 0.001 , 0.001 ] map_unit = self . fueling_tables [ \"Engine.Efficiency.Value\" ][ \"axes\" ][ \"Z\" ][ \"unit\" ] tps_unit = tps_map . axes [ \"Throttle.Position\" ] . unit tps = np . linspace ( tps_map . axes [ \"Throttle.Position\" ] . data . min (), tps_map . axes [ \"Throttle.Position\" ] . data . max (), n , ) eng_spd = np . linspace ( tps_map . axes [ \"Engine.Speed\" ] . data . min (), tps_map . axes [ \"Engine.Speed\" ] . data . max (), n , ) bps = [ x . flatten () for x in np . meshgrid ( tps , eng_spd )] maps = ( self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Main\" ] . as_unit ( \"ratio\" ) . interp ( np . array ( bps ) . T ) * self . table_data [ \"Ambient.Pressure.Default.Value\" ] . as_unit ( map_unit ) . data ) map_bps = np . linspace ( 10 , 101 , 40 , ) tps_map . axes [ \"Throttle.Position\" ] . data = map_bps tps_map . axes [ \"Throttle.Position\" ] . name = \"Inlet.Manifold.Pressure\" tps_map . axes [ \"Inlet.Manifold.Pressure\" ] . unit = map_unit tps_map . unit = tps_unit new_grid = [ maps , bps [ 1 ], bps [ 0 ]] tps_map . scatter_data = ScatterData ( new_grid ) tps_map . fit () # tps_map.plot() interps = np . array ([ imap , eng_speed ]) . T return np . clip ( tps_map . interp ( interps ), 0 , 100 )","title":"DRE_JLM_V2"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.DRE_JLM_V2.build_delta_summary","text":"Builds tables to review fit. Source code in ccg\\controllers\\motec.py 3243 3244 3245 3246 3247 3248 3249 3250 3251 3252 3253 3254 3255 3256 3257 3258 3259 3260 3261 3262 3263 3264 3265 3266 3267 3268 3269 3270 3271 3272 3273 3274 3275 3276 3277 3278 3279 3280 3281 3282 3283 3284 3285 3286 3287 3288 3289 3290 3291 3292 3293 3294 3295 3296 3297 3298 3299 3300 3301 3302 3303 3304 3305 3306 3307 3308 3309 3310 3311 3312 3313 3314 3315 3316 3317 3318 3319 3320 3321 3322 3323 3324 3325 3326 3327 3328 3329 3330 3331 3332 3333 3334 3335 3336 3337 3338 3339 3340 3341 3342 3343 3344 3345 3346 3347 3348 3349 3350 3351 3352 3353 3354 3355 3356 3357 3358 3359 3360 3361 3362 3363 3364 3365 3366 3367 3368 3369 3370 3371 3372 3373 3374 3375 3376 3377 3378 3379 3380 3381 3382 3383 3384 3385 3386 3387 3388 3389 3390 3391 3392 3393 3394 3395 3396 3397 3398 3399 3400 3401 3402 3403 3404 3405 @profile def build_delta_summary ( self ): \"\"\"Builds tables to review fit.\"\"\" if self . table_data : input_tables = Tbls () input_tables . append ( self . table_data [ \"Engine.Efficiency.Value\" ]) cyl_trim_unit = self . fueling_tables [ \"Fuel.Cylinder #.Trim\" ][ \"unit\" ] for cyl in range ( 1 , self . n_cyl + 1 ): # Convert indiv tables to base axes name = f \"Fuel.Cylinder { cyl } .Trim\" axes = input_tables [ \"Engine.Efficiency.Value\" ] . axes tmp = self . convert_table_to_axes ( self . table_data [ name ], axes ) tmp . name = name input_tables . append ( tmp ) result_tables = Tbls () tmp = Tbl ( input_tables [ \"Engine.Efficiency.Value\" ]) tmp . data *= 0 tmp . name = \"Overall\" tmp . unit = \"ratio\" tmp . snapshot ( \"orig\" ) result_tables . append ( tmp ) for bank in range ( 1 , self . n_banks + 1 ): avg = Tbl ( input_tables [ \"Engine.Efficiency.Value\" ]) avg . data *= 0 avg . name = f \"Bank { bank } .Trim.Avg\" avg . unit = \"ratio\" avg . snapshot ( \"orig\" ) n = 0 for cyl in range ( 1 , self . n_cyl + 1 ): indiv = f \"Fuel.Cylinder { cyl } .Trim\" tmp = ( input_tables [ \"Engine.Efficiency.Value\" ] . orig . as_unit ( \"ratio\" ) * input_tables [ indiv ] . orig . as_unit ( \"ratio\" ) * self . table_data [ \"Fuel.Volume.Trim.Overall\" ] . orig . as_unit ( \"ratio\" ) . data ) tmp . name = f \"Individual { cyl } \" tmp . unit = \"ratio\" tmp . snapshot ( \"orig\" ) tmp . data = ( input_tables [ \"Engine.Efficiency.Value\" ] . as_unit ( \"ratio\" ) * input_tables [ indiv ] . as_unit ( \"ratio\" ) * self . table_data [ \"Fuel.Volume.Trim.Overall\" ] . as_unit ( \"ratio\" ) . data ) . data result_tables . append ( tmp ) if self . table_data [ f \"Engine.Cylinder { cyl } .Bank\" ] . data [ 0 ] == bank : avg . _archive [ \"orig\" ][ - 1 ] += input_tables [ indiv ] . orig . as_unit ( \"ratio\" ) avg += input_tables [ indiv ] . as_unit ( \"ratio\" ) n += 1 result_tables [ \"Overall\" ] . _archive [ \"orig\" ][ - 1 ] += tmp . orig result_tables [ \"Overall\" ] += tmp avg . _archive [ \"orig\" ][ - 1 ] /= n avg /= n result_tables . append ( avg ) result_tables [ \"Overall\" ] . _archive [ \"orig\" ][ - 1 ] /= self . n_cyl result_tables [ \"Overall\" ] /= self . n_cyl # FINALLY res = [ ccg . ui . panel . pn . Spacer ( height = 0 ), ccg . ui . panel . pn . pane . Markdown ( \"\"\"# Overall Fueling Delta This accounts for deltas in the `Engine.Efficiency.Value` table, the mean of the `Fuel.Cylinder #.Trim` tables, and the `Fuel.Volume.Trim.Overall`.\"\"\" , align = \"start\" , ), ] table = result_tables [ \"Overall\" ] axes_data = table . axes prec_args = { \"axis_names\" : [ f \" { axis . name } [ { axis . unit } ]\" for axis in axes_data ], \"axis_breakpoints\" : [ axis . data . tolist () for axis in axes_data ], \"axis_precisions\" : [ axis . precision for axis in axes_data ], \"data_precision\" : table . precision , \"locked\" : table . locked . T . tolist (), } res . append ( ccg . ui . panel . CalDataTbl ( name = \"Overall Fueling Delta %\" , table_name = \"Overall Fueling Delta [%]\" , data = table . delta_perc . T . tolist (), editable = False , colorscale = \"RdBu\" , colorscale_center = 0 , align = \"center\" , ** prec_args , ) ) res . append ( ccg . ui . panel . pn . pane . Markdown ( \"\"\"# Bank Average Cyl Trims\"\"\" , align = \"start\" , ) ) for bank in range ( 1 , self . n_banks + 1 ): name = f \"Bank { bank } .Trim.Avg\" table = result_tables [ name ] . as_unit ( cyl_trim_unit ) axes_data = table . axes prec_args = { \"axis_names\" : [ f \" { axis . name } [ { axis . unit } ]\" for axis in axes_data ], \"axis_breakpoints\" : [ axis . data . tolist () for axis in axes_data ], \"axis_precisions\" : [ axis . precision for axis in axes_data ], \"data_precision\" : table . precision , \"locked\" : table . locked . T . tolist (), } res . append ( ccg . ui . panel . CalDataTbl ( name = name , table_name = f \" { name } [ { cyl_trim_unit } ]\" , data = table . data . T . tolist (), editable = False , colorscale = \"RdBu\" , colorscale_center = 0 , align = \"center\" , ** prec_args , ) ) res . append ( ccg . ui . panel . pn . pane . Markdown ( \"\"\"# Individual Cylinder Fueling Deltas These accounts for deltas in the `Engine.Efficiency.Value` table, the the `Fuel.Cylinder #.Trim` tables, and the `Fuel.Volume.Trim.Overall`.\"\"\" , align = \"start\" , ) ) for cyl in range ( 1 , self . n_cyl + 1 ): name = f \"Individual { cyl } \" table = result_tables [ name ] axes_data = table . axes prec_args = { \"axis_names\" : [ f \" { axis . name } [ { axis . unit } ]\" for axis in axes_data ], \"axis_breakpoints\" : [ axis . data . tolist () for axis in axes_data ], \"axis_precisions\" : [ axis . precision for axis in axes_data ], \"data_precision\" : table . precision , \"locked\" : table . locked . T . tolist (), } res . append ( ccg . ui . panel . CalDataTbl ( name = f \" { name } Fueling Delta %\" , table_name = f \" { name } Fueling Delta [%]\" , data = table . delta_perc . T . tolist (), editable = False , colorscale = \"RdBu\" , colorscale_center = 0 , align = \"center\" , ** prec_args , ) ) return res","title":"build_delta_summary"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.DRE_JLM_V2.check_axes","text":"Check if cyl trim axes match Source code in ccg\\controllers\\motec.py 3231 3232 3233 3234 3235 3236 3237 3238 3239 3240 3241 def check_axes ( self ): \"\"\"Check if cyl trim axes match\"\"\" for i in range ( 2 , self . n_cyl + 1 ): for axis , axis1 in zip ( self . table_data [ f \"Fuel.Cylinder { i } .Trim\" ] . axes , self . table_data [ \"Fuel.Cylinder 1.Trim\" ] . axes , ): if axis1 != axis : return False return True","title":"check_axes"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.DRE_JLM_V2.check_sigs","text":"Check that required input sigs are present. Source code in ccg\\controllers\\motec.py 2629 2630 2631 2632 2633 2634 2635 2636 2637 2638 2639 2640 2641 2642 2643 2644 2645 2646 2647 2648 2649 2650 2651 2652 2653 2654 2655 2656 2657 2658 2659 2660 2661 2662 2663 2664 2665 2666 2667 2668 2669 2670 2671 2672 2673 2674 2675 2676 2677 2678 2679 2680 2681 2682 2683 2684 2685 2686 2687 2688 2689 2690 2691 2692 2693 2694 2695 2696 2697 2698 2699 2700 2701 2702 2703 2704 2705 2706 2707 2708 2709 2710 2711 2712 2713 2714 2715 2716 2717 2718 2719 2720 2721 2722 2723 2724 2725 2726 2727 2728 2729 2730 2731 2732 2733 2734 2735 2736 2737 2738 2739 2740 2741 2742 2743 2744 2745 2746 2747 2748 2749 2750 2751 2752 2753 2754 2755 2756 2757 @profile def check_sigs ( self ): \"\"\"Check that required input sigs are present.\"\"\" if self . table_data and self . data : msgs = self . check_substitute_sigs () required_sigs = set ( [ \"Fuel.Mixture Aim\" , \"Engine.Efficiency\" , \"Fuel.Volume.Trim\" , \"Fuel.Volume.Compensation\" , \"Coolant.Temperature.Fuel Volume Compensation\" , ] ) for table in self . fueling_tables : for axis in self . table_data [ table . replace ( \"#\" , \"1\" )] . axes : required_sigs . add ( axis . name ) for i in range ( 1 , self . n_cyl + 1 ): required_sigs . add ( f \"Fuel.Cylinder { i } .Trim\" ) required_sigs . add ( f \"Exhaust.Lambda.Cylinder { i } \" ) for i in range ( 1 , self . n_banks + 1 ): required_sigs . add ( f \"Exhaust.Lambda.Bank { i } \" ) required_sigs . add ( f \"Fuel.Closed Loop.Control.Bank { i } .Trim\" ) if ( \"Ambient Pressure Relative\" in self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Mode\" ] . data ): required_sigs . add ( \"Ambient.Pressure\" ) ok_slow = [ \"Ambient.Pressure\" , \"Fuel.Mixture Aim\" , \"Fuel.Volume.Trim\" , \"Fuel.Volume.Compensation\" , \"Inlet.Manifold.Pressure.Estimate\" , \"Coolant.Temperature.Fuel Volume Compensation\" , \"Coolant.Temperature\" , ] extras = [ \"Inlet.Manifold.Pressure.Estimate\" , \"Inlet.Air.Temperature\" , \"Vehicle.Speed\" , \"Ignition.Cut\" , \"Ignition.Timing\" , \"Idle.State\" , \"Fuel.Volume.Transient\" , \"Fuel.Volume.Trim\" , \"Fuel.Volume.Compensation\" , \"Fuel.Timing.Primary\" , \"Fuel.Temperature\" , \"Fuel.Pressure\" , \"Fuel.Injector.Primary.Duty.Cycle\" , \"Fuel.Film.Primary\" , \"Fuel.Cut\" , \"Engine.Load\" , \"Coolant.Pressure\" , \"Engine.Charge.Temperature\" , \"Engine.Oil.Temperature\" , \"Engine.Oil.Pressure\" , \"ECU.Batter.Voltage\" , \"Engine.Load.Normalised\" , ] required_sigs = list ( required_sigs ) missing = [] for sig in required_sigs : if sig not in self . data : missing . append ( sig ) for sig in self . gate . sigs : if sig not in self . data and sig not in self . calcd_sigs : missing . append ( sig ) if missing : missing . sort () # msg = \"<br>\".join(missing) if self . warning_dialog : msgs . extend ([ \" \\n ## Missing Required Signals \\n \" , * missing ]) self . warning_dialog ( title = \"# Missing Signals\" , msg = \"<br>\" . join ( msgs ) ) return False raise ValueError ( f \"Missing Required Signals \\n { missing } \" ) for sig in required_sigs : if sig not in ok_slow : self . slow_sig = sig break for sig in required_sigs : if ( sig not in ok_slow and self . data [ sig ] . period > self . data [ self . slow_sig ] . period ): self . slow_sig = sig for sig in self . gate . sigs : if sig not in self . calcd_sigs and sig not in required_sigs : required_sigs . append ( sig ) tline = self . data [ self . slow_sig ] . tline self . resampled = self . data [ required_sigs ] . resample ( tline ) self . resampled . name = \"Resampled Data for Calc's\" self . data . math_tline = tline self . resampled . math_tline = tline for sig in extras : try : self . resampled . append ( self . data [ sig ] . resample ( tline )) except KeyError : pass if self . slow_freq < 50 : msgs . extend ( [ \" \\n ## Slow Signal \\n \" , f \"Calculation rate limited to { self . slow_freq } Hz by ` { self . slow_sig } `\" , ] ) if msgs : self . warning_dialog ( title = \"# Missing Signals\" , msg = \"<br>\" . join ( msgs )) return True else : return False","title":"check_sigs"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.DRE_JLM_V2.check_substitute_sigs","text":"Try to substitute for some common missing sigs. Source code in ccg\\controllers\\motec.py 2483 2484 2485 2486 2487 2488 2489 2490 2491 2492 2493 2494 2495 2496 2497 2498 2499 2500 2501 2502 2503 2504 2505 2506 2507 2508 2509 2510 2511 2512 2513 2514 2515 2516 2517 2518 2519 2520 2521 2522 2523 2524 2525 2526 2527 2528 2529 2530 2531 2532 2533 2534 2535 2536 2537 2538 2539 2540 2541 2542 2543 2544 2545 2546 2547 2548 2549 2550 2551 2552 2553 2554 2555 2556 2557 2558 2559 2560 2561 2562 2563 2564 2565 2566 2567 2568 2569 2570 2571 2572 2573 2574 2575 2576 2577 2578 2579 2580 2581 2582 2583 2584 2585 2586 2587 2588 2589 2590 2591 2592 2593 2594 2595 2596 2597 2598 2599 2600 2601 2602 2603 2604 2605 2606 2607 2608 2609 2610 2611 2612 2613 2614 2615 2616 2617 2618 2619 2620 2621 2622 2623 2624 2625 2626 2627 def check_substitute_sigs ( self ): \"\"\"Try to substitute for some common missing sigs.\"\"\" msgs = [] if self . table_data and self . data : try : mode = self . table_data [ \"Engine.Load.Normalised.Mode\" ] . data if mode == \"Normal\" : # Value = # p * # Engine.Efficiency * # Fuel Vapour Correction * # (Engine.Displacement / Engine.Cylinders) * // Displacement of one cylinder # (1 / (Constants.rAir * (Engine.Charge.Temperature + 273.15))); // Ideal gas law # when (Normalised.Mode) # { # is (Normal) # { # local ideal = # Ambient.Pressure.Standard * # 1.0 * # 1.0 * # (Engine.Displacement / Engine.Cylinders) * // Displacement of one cylinder # (1 / (Constants.rAir * (Constants.standardTemperature + 273.15))); // Ideal gas law # Normalised = Value / ideal; raise NotImplementedError elif mode == \"Inlet.Manifold.Pressure\" : sig = Sig ( name = \"Engine.Load.Normalised\" , data = self . data [ \"Inlet.Manifold.Pressure\" ] / ccg . util . convert_units ( 101.325 , \"kPa\" , self . data [ \"Inlet.Manifold.Pressure\" ] . unit , ), tline = self . data [ \"Inlet.Manifold.Pressure\" ] . tline , unit = \"ratio\" , ) elif mode == \"Throttle Position\" : sig = Sig ( name = \"Engine.Load.Normalised\" , data = self . data [ \"Throttle.Position\" ], ) sig . convert_units ( \"%\" ) if \"Engine.Load.Normalised\" not in self . data : self . data . append ( sig ) msgs . append ( \"`Engine.Load.Normalized` was not logged and has been calculated from input signals.\" ) elif sig . period < self . data [ \"Engine.Load.Normalised\" ] . period : self . data . remove ( \"Engine.Load.Normalised\" ) self . data . append ( sig ) msgs . append ( \"`Engine.Load.Normalized` was logged slowly and has been calculated from input signals.\" ) except KeyError : pass try : if \"Fuel.Volume.Trim\" not in self . data : sig = self . table_data [ \"Fuel.Volume.Trim.Overall\" ][ self . data ] sig . name = \"Fuel.Volume.Trim\" self . data . append ( sig ) msgs . append ( \"`Fuel.Volume.Trim` was not logged and has been calculated from the loaded calibration. ** Ensure that this matches the calibration that generated the data **\" ) except KeyError : pass try : if \"Engine.Efficiency\" not in self . data : sig = self . table_data [ \"Engine.Efficiency.Value\" ][ self . data ] sig . name = \"Engine.Efficiency\" self . data . append ( sig ) msgs . append ( \"`Engine.Efficiency` was not logged and has been calculated from the loaded calibration. ** Ensure that this matches the calibration that generated the data **\" ) except KeyError : pass try : if \"Fuel.Closed Loop.Control.Bank 1.Trim\" not in self . data : sig = Sig ( self . data [ self . slow_sig ]) sig . name = \"Fuel.Closed Loop.Control.Bank 1.Trim\" sig . data = np . ones ( sig . data . shape ) sig . unit = \"ratio\" self . data . append ( sig ) msgs . append ( \"`Fuel.Closed Loop.Control.Bank 1.Trim` was not logged and has been assumed to be disabled. ** Ensure that this matches the calibration that generated the data **\" ) except KeyError : pass try : if \"Fuel.Closed Loop.Control.Bank 2.Trim\" not in self . data : sig = Sig ( self . data [ self . slow_sig ]) sig . name = \"Fuel.Closed Loop.Control.Bank 2.Trim\" sig . data = np . ones ( sig . data . shape ) sig . unit = \"ratio\" self . data . append ( sig ) msgs . append ( \"`Fuel.Closed Loop.Control.Bank 2.Trim` was not logged and has been assumed to be disabled. ** Ensure that this matches the calibration that generated the data **\" ) except KeyError : pass for i in range ( 1 , self . n_cyl + 1 ): try : name = f \"Fuel.Cylinder { i } .Trim\" if name not in self . data : sig = self . table_data [ name ][ self . data ] self . data . append ( sig ) msgs . append ( f \"` { name } ` was not logged and has been calculated from the loaded calibration. ** Ensure that this matches the calibration that generated the data **\" ) except KeyError : pass try : if \"Coolant.Temperature.Fuel Volume Compensation\" not in self . data : sig = Sig ( self . data [ \"Fuel.Volume.Compensation\" ]) sig . name = \"Coolant.Temperature.Fuel Volume Compensation\" self . data . append ( sig ) msgs . append ( \"`Coolant.Temperature.Fuel Volume Compensation` was not logged and has been substituted with `Fuel.Volume.Compensation`. ** Ensure that no other volume compensation was active. **\" ) except KeyError : pass for i in range ( 1 , self . n_cyl + 1 ): try : name = f \"Exhaust.Lambda.Cylinder { i } \" if name not in self . data : sig = Sig ( self . data [ \"Exhaust.Lambda.Bank 1\" ]) * 0 sig . name = name self . data . append ( sig ) msgs . append ( f \"` { name } ` was not logged. Individual trims not possible.\" ) except KeyError : pass if msgs : msgs = [ \"## Substituted Signals \\n \" , * msgs ] return msgs","title":"check_substitute_sigs"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.DRE_JLM_V2.convert_table_to_axes","text":"Convert a table to fit the target axes if possible. Source code in ccg\\controllers\\motec.py 3407 3408 3409 3410 3411 3412 3413 3414 3415 3416 3417 3418 3419 3420 3421 3422 3423 3424 3425 3426 3427 3428 3429 3430 3431 3432 3433 3434 3435 3436 3437 3438 3439 3440 3441 3442 3443 3444 3445 3446 3447 3448 3449 3450 3451 3452 3453 3454 3455 3456 3457 3458 3459 3460 3461 3462 3463 3464 3465 3466 3467 3468 3469 3470 3471 def convert_table_to_axes ( self , table : Tbl , target : Axes ): \"\"\"Convert a table to fit the target axes if possible.\"\"\" res = Tbl ( name = \"result\" , axes = target , unit = table . unit ) if target . n_dim > 2 : raise NotImplementedError if target . n_dim < table . n_dim : raise NotImplementedError if table . n_dim == 0 : res . data = np . ones ( target . shape ) * table . orig . data res . snapshot ( \"orig\" ) res . data = np . ones ( target . shape ) * table . data return res # Leave in target units, convert table before interpolating. target_grid = target . grid interp_grid = target . grid units = [ \"\" ] * table . n_dim for j , axis in enumerate ( target ): found = False for i , t_axis in enumerate ( table . axes ): if axis . name == t_axis . name : interp_grid [ i ] = target_grid [ j ] units [ i ] = axis . unit found = True break if not found : # Check for possible calc if axis . name == \"Inlet.Manifold.Pressure\" : if \"Engine.Load.Normalised\" in table . axes : i = table . axes . index ( \"Engine.Load.Normalised\" ) # Calc engine load normalized mode = self . table_data [ \"Engine.Load.Normalised.Mode\" ] . data if mode == \"Normal\" : raise NotImplementedError elif mode == \"Inlet Manifold Pressure\" : tmp = Axis ( axis ) tmp . data = axis . data / ccg . util . convert_units ( 101.325 , \"kPa\" , axis . unit , ) interp_grid [ i ] = target_grid [ j ] units [ i ] = \"ratio\" elif mode == \"Throttle Position\" : eng_speed_ind = target . index ( \"Engine.Speed\" ) imap_ind = target . index ( \"Inlet.Manifold.Pressure\" ) interp_grid [ i ] = self . tps_from_map ( eng_speed = target_grid [ eng_speed_ind ], imap = target_grid [ imap_ind ], ) units [ i ] = \"%\" for unit , axis in zip ( units , table . axes ): axis . convert_units ( unit ) interp_vals = np . array ([ x . flatten () for x in interp_grid ]) . T res . data = table . orig . interp ( interp_vals ) . reshape ( target . shape , order = \"f\" ) res . snapshot ( \"orig\" ) res . data = table . interp ( interp_vals ) . reshape ( target . shape , order = \"f\" ) # res.plot() return res","title":"convert_table_to_axes"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.DRE_JLM_V2.normalize_cyl_trims","text":"Normalizes cyl trims if bp's match. Source code in ccg\\controllers\\motec.py 3203 3204 3205 3206 3207 3208 3209 3210 3211 3212 3213 3214 3215 3216 3217 3218 3219 3220 3221 3222 3223 3224 3225 3226 3227 3228 3229 def normalize_cyl_trims ( self ): \"\"\"Normalizes cyl trims if bp's match.\"\"\" cyl_trim_min = self . fueling_tables [ \"Fuel.Cylinder #.Trim\" ][ \"range\" ][ 0 ] cyl_trim_max = self . fueling_tables [ \"Fuel.Cylinder #.Trim\" ][ \"range\" ][ 1 ] cyl_trim_unit = self . fueling_tables [ \"Fuel.Cylinder #.Trim\" ][ \"unit\" ] if self . check_axes (): avg = np . zeros ( self . table_data [ \"Fuel.Cylinder 1.Trim\" ] . data . shape ) n = 0 for cyl in range ( 1 , self . n_cyl + 1 ): avg += self . table_data [ f \"Fuel.Cylinder { cyl } .Trim\" ] . data n += 1 avg = ccg . util . convert_units ( avg / n , cyl_trim_unit , \"ratio\" ) for cyl in range ( 1 , self . n_cyl + 1 ): cyl_trim = ( self . table_data [ f \"Fuel.Cylinder { cyl } .Trim\" ] . as_unit ( \"ratio\" ) . data / avg ) cyl_trim = ccg . util . convert_units ( cyl_trim , \"ratio\" , cyl_trim_unit ) self . table_data [ f \"Fuel.Cylinder { cyl } .Trim\" ] . data = np . clip ( cyl_trim , cyl_trim_min , cyl_trim_max ) else : raise ValueError ( \"Cyl trim axes dont match, cant normalize\" )","title":"normalize_cyl_trims"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.DRE_JLM_V2.tps_from_map","text":"Estimate Throttle.Position from manifold air pressure. Source code in ccg\\controllers\\motec.py 3473 3474 3475 3476 3477 3478 3479 3480 3481 3482 3483 3484 3485 3486 3487 3488 3489 3490 3491 3492 3493 3494 3495 3496 3497 3498 3499 3500 3501 3502 3503 3504 3505 3506 3507 3508 3509 3510 3511 3512 3513 3514 3515 3516 3517 3518 3519 3520 def tps_from_map ( self , eng_speed : npt . NDArray , imap : npt . NDArray ): \"\"\"Estimate Throttle.Position from manifold air pressure.\"\"\" n = 100 tps_map = Tbl ( self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Main\" ]) tps_map . name = \"TPS Estimate\" tps_map . interp_on_axis_change = True tps_map . data *= 0 tps_map . f_orig = 0 tps_map . f_smooth = [ 0.001 , 0.001 ] map_unit = self . fueling_tables [ \"Engine.Efficiency.Value\" ][ \"axes\" ][ \"Z\" ][ \"unit\" ] tps_unit = tps_map . axes [ \"Throttle.Position\" ] . unit tps = np . linspace ( tps_map . axes [ \"Throttle.Position\" ] . data . min (), tps_map . axes [ \"Throttle.Position\" ] . data . max (), n , ) eng_spd = np . linspace ( tps_map . axes [ \"Engine.Speed\" ] . data . min (), tps_map . axes [ \"Engine.Speed\" ] . data . max (), n , ) bps = [ x . flatten () for x in np . meshgrid ( tps , eng_spd )] maps = ( self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Main\" ] . as_unit ( \"ratio\" ) . interp ( np . array ( bps ) . T ) * self . table_data [ \"Ambient.Pressure.Default.Value\" ] . as_unit ( map_unit ) . data ) map_bps = np . linspace ( 10 , 101 , 40 , ) tps_map . axes [ \"Throttle.Position\" ] . data = map_bps tps_map . axes [ \"Throttle.Position\" ] . name = \"Inlet.Manifold.Pressure\" tps_map . axes [ \"Inlet.Manifold.Pressure\" ] . unit = map_unit tps_map . unit = tps_unit new_grid = [ maps , bps [ 1 ], bps [ 0 ]] tps_map . scatter_data = ScatterData ( new_grid ) tps_map . fit () # tps_map.plot() interps = np . array ([ imap , eng_speed ]) . T return np . clip ( tps_map . interp ( interps ), 0 , 100 )","title":"tps_from_map"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.DRE_JLM_V2.update_calcd_data","text":"Update calculations for fitting/plotting. Source code in ccg\\controllers\\motec.py 2759 2760 2761 2762 2763 2764 2765 2766 2767 2768 2769 2770 2771 2772 2773 2774 2775 2776 2777 2778 2779 2780 2781 2782 2783 2784 2785 2786 2787 2788 2789 2790 2791 2792 2793 2794 2795 2796 2797 2798 2799 2800 2801 2802 2803 2804 2805 2806 2807 2808 2809 2810 2811 2812 2813 2814 2815 2816 2817 2818 2819 2820 2821 2822 2823 2824 2825 2826 2827 2828 2829 2830 2831 2832 2833 2834 2835 2836 2837 2838 2839 2840 2841 2842 2843 2844 2845 2846 2847 2848 2849 2850 2851 2852 2853 2854 2855 2856 2857 2858 2859 2860 2861 2862 2863 2864 2865 2866 2867 2868 2869 2870 2871 2872 2873 2874 2875 2876 2877 2878 2879 2880 2881 2882 2883 2884 2885 2886 2887 2888 2889 2890 2891 2892 2893 2894 2895 2896 2897 2898 2899 2900 2901 2902 2903 2904 2905 2906 2907 2908 2909 2910 2911 2912 2913 2914 2915 2916 2917 2918 2919 2920 2921 2922 2923 2924 2925 2926 2927 2928 2929 2930 2931 2932 2933 2934 2935 2936 2937 2938 2939 2940 2941 2942 2943 2944 2945 2946 2947 2948 2949 2950 2951 2952 2953 2954 2955 2956 2957 2958 2959 2960 2961 2962 2963 2964 2965 2966 2967 2968 2969 2970 2971 2972 2973 2974 2975 2976 2977 2978 2979 2980 2981 2982 2983 2984 2985 2986 2987 2988 2989 2990 2991 2992 2993 2994 2995 2996 2997 2998 2999 3000 3001 3002 3003 3004 3005 3006 3007 3008 3009 3010 3011 3012 3013 3014 3015 3016 3017 3018 3019 3020 @profile def update_calcd_data ( self ): \"\"\"Update calculations for fitting/plotting.\"\"\" if self . _needs_calcs : tic = datetime . now () if self . check_sigs (): if self . table_data : acc = 0 n = 0 for cyl in range ( 1 , 1 + self . n_cyl ): tmp = self . resampled [ f \"Fuel.Cylinder { cyl } .Trim\" ] . as_unit ( \"ratio\" ) tmp . unit = \"ratio\" tmp . name = f \"Fuel.Cylinder { cyl } .Trim.Total\" self . resampled . append ( tmp ) acc = acc + tmp n += 1 acc = acc / n acc . name = \"Cylinder.Trim.Avg\" acc . unit = \"ratio\" self . resampled . append ( acc ) for bank in range ( 1 , self . n_banks + 1 ): tmp = 0 n = 0 for cyl in range ( 1 , 1 + self . n_cyl ): if ( self . table_data [ f \"Engine.Cylinder { cyl } .Bank\" ] . data == bank ): n += 1 tmp = ( tmp + self . resampled [ f \"Exhaust.Lambda.Cylinder { cyl } \" ] ) tmp = tmp / n tmp . name = f \"Lambda.Indiv.Bank { bank } .Avg\" tmp . unit = \"LA\" tmp . data_range = [ 0.6 , 1.4 ] self . resampled . append ( tmp ) tmp = 0 n = 0 for cyl in range ( 1 , 1 + self . n_cyl ): if ( self . table_data [ f \"Engine.Cylinder { cyl } .Bank\" ] . data == bank ): n += 1 tmp = tmp + self . resampled [ f \"Fuel.Cylinder { cyl } .Trim\" ] . as_unit ( \"ratio\" ) tmp = tmp / n tmp . name = f \"Cylinder.Trim.Bank { bank } .Avg\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) self . resampled [ f \"Exhaust.Lambda.Bank { bank } \" ] . data_range = [ 0.6 , 1.4 , ] tmp = self . table_data [ \"Coolant.Temperature.Fuel Volume Compensation\" ][ self . resampled ] . as_unit ( \"ratio\" ) / self . resampled [ \"Fuel.Volume.Compensation\" ] . as_unit ( \"ratio\" ) tmp . name = \"Volume.Comp.Delta\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ \"Fuel.Closed Loop.Control.Bank 1.Trim\" ] . as_unit ( \"ratio\" ) * self . resampled [ \"Fuel.Volume.Trim\" ] . as_unit ( \"ratio\" ) / self . resampled [ \"Volume.Comp.Delta\" ] . as_unit ( \"ratio\" ) * self . resampled [ \"Cylinder.Trim.Bank 1.Avg\" ] * self . resampled [ \"Exhaust.Lambda.Bank 1\" ] / self . resampled [ \"Fuel.Mixture Aim\" ] ) # TODO: Fix for only 1 bank tmp . name = \"Fueling.Error.Bank 1\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ \"Fuel.Closed Loop.Control.Bank 2.Trim\" ] . as_unit ( \"ratio\" ) * self . resampled [ \"Fuel.Volume.Trim\" ] . as_unit ( \"ratio\" ) / self . resampled [ \"Volume.Comp.Delta\" ] . as_unit ( \"ratio\" ) * self . resampled [ \"Cylinder.Trim.Bank 2.Avg\" ] * self . resampled [ \"Exhaust.Lambda.Bank 2\" ] / self . resampled [ \"Fuel.Mixture Aim\" ] ) tmp . name = \"Fueling.Error.Bank 2\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ \"Fueling.Error.Bank 1\" ] + self . resampled [ \"Fueling.Error.Bank 2\" ] ) / 2 tmp . name = \"Fueling.Error.Total\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = self . resampled [ \"Fueling.Error.Total\" ] * ( self . resampled [ \"Engine.Efficiency\" ] ) tmp . name = \"Engine.Efficiency.Value.Corrected\" tmp . unit = \"%\" self . resampled . append ( tmp ) self . resampled . append ( Sig ( self . resampled [ \"Engine.Efficiency\" ], name = \"Engine.Efficiency.Value\" , ) ) # copy with name to match table for cyl in range ( 1 , 1 + self . n_cyl ): bank = int ( self . table_data [ f \"Engine.Cylinder { cyl } .Bank\" ] . data ) tmp = ( self . resampled [ f \"Exhaust.Lambda.Cylinder { cyl } \" ] / self . resampled [ f \"Lambda.Indiv.Bank { bank } .Avg\" ] ) tmp . name = f \"Cyl { cyl } .Lam.Error\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ f \"Fuel.Cylinder { cyl } .Trim.Total\" ] / self . resampled [ f \"Cylinder.Trim.Bank { bank } .Avg\" ] ) tmp . name = f \"Fuel.Cylinder { cyl } .Trim.Bank Normalised\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ f \"Fuel.Cylinder { cyl } .Trim.Total\" ] / self . resampled [ \"Cylinder.Trim.Avg\" ] ) tmp . name = f \"Fuel.Cylinder { cyl } .Trim.Normalised\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ f \"Fuel.Cylinder { cyl } .Trim.Bank Normalised\" ] * self . resampled [ f \"Cyl { cyl } .Lam.Error\" ] * ( self . resampled [ f \"Fueling.Error.Bank { bank } \" ] / self . resampled [ \"Fueling.Error.Total\" ] ) ) tmp . name = f \"Fuel.Cylinder { cyl } .Trim.Corrected\" tmp . unit = \"ratio\" tmp . convert_units ( \"%Trim\" ) self . resampled . append ( tmp ) # Calc cyl trims from tailpipe data incase indiv missing tmp = self . resampled [ f \"Fuel.Cylinder { cyl } .Trim.Normalised\" ] * ( self . resampled [ f \"Fueling.Error.Bank { bank } \" ] / self . resampled [ \"Fueling.Error.Total\" ] ) tmp . name = f \"Fuel.Cylinder { cyl } .Trim.Corrected.Tailpipe\" tmp . unit = \"ratio\" tmp . convert_units ( \"%Trim\" ) self . resampled . append ( tmp ) self . resampled [ f \"Exhaust.Lambda.Cylinder { cyl } \" ] . data_range = [ 0.6 , 1.4 , ] self . resampled . append ( self . resampled [ \"Engine.Speed\" ] . dot ( n_win = 17 )) self . resampled . append ( self . resampled [ \"Throttle.Position\" ] . dot ( n_win = 7 ) ) # inlet manifold press ref try : if ( \"Ambient Pressure Relative\" in self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Mode\" ] . data ): tmp = ( self . resampled [ \"Inlet.Manifold.Pressure\" ] / self . resampled [ \"Ambient.Pressure\" ] ) else : tmp = self . resampled [ \"Inlet.Manifold.Pressure\" ] / 100 tmp . name = \"Inlet.Manifold.Pressure.Estimate.Main.Corrected\" tmp . unit = \"ratio\" tmp . convert_units ( \"%\" ) self . resampled . append ( tmp ) if ( \"Ambient Pressure Relative\" in self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Mode\" ] . data ): tmp = ( self . resampled [ \"Inlet.Manifold.Pressure.Estimate\" ] / self . resampled [ \"Ambient.Pressure\" ] ) else : tmp = ( self . resampled [ \"Inlet.Manifold.Pressure.Estimate\" ] / 100 ) tmp . name = \"Inlet.Manifold.Pressure.Estimate.Main\" tmp . unit = \"ratio\" tmp . convert_units ( \"%\" ) self . resampled . append ( tmp ) except KeyError : pass # Coolant temp comps tmp = ( self . resampled [ \"Engine.Efficiency.Value.Corrected\" ] . as_unit ( \"ratio\" ) / self . table_data [ \"Engine.Efficiency.Value\" ][ self . resampled ] . as_unit ( \"ratio\" ) * self . resampled [ \"Coolant.Temperature.Fuel Volume Compensation\" ] . as_unit ( \"ratio\" ) * self . resampled [ \"Volume.Comp.Delta\" ] . as_unit ( \"ratio\" ) ) tmp . name = \"Coolant.Temperature.Fuel Volume Compensation.Corrected\" tmp . unit = \"ratio\" tmp . convert_units ( \"%Trim\" ) self . resampled . append ( tmp ) toc = datetime . now () - tic _LOGGER . debug ( \"Firmware calcs in %.3f \" , toc . total_seconds ()) # Set some ranges self . resampled [ \"Engine.Speed\" ] . data_range = [ 0 , 8800 ] self . resampled [ \"Fuel.Mixture Aim\" ] . data_range = [ 0.6 , 1.4 ] # Add calc'd signals to data frame for general plot self . data . append ( self . resampled ) self . _needs_calcs = False if not self . _needs_calcs : self . update_scatter_data () if self . resampled : # Update options for scatter plots opts = [ \"Relative Density\" , * self . resampled . sigs . keys ()] for tab in self . tabs : tab . color_sig . options = opts","title":"update_calcd_data"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.DRE_JLM_V2.update_scatter_data","text":"Update scatter data for fitting. Source code in ccg\\controllers\\motec.py 3022 3023 3024 3025 3026 3027 3028 3029 3030 3031 3032 3033 3034 3035 3036 3037 3038 3039 3040 3041 3042 3043 3044 3045 3046 3047 3048 3049 3050 3051 3052 3053 3054 3055 3056 3057 3058 3059 3060 3061 3062 3063 3064 3065 3066 3067 3068 3069 3070 3071 3072 3073 3074 3075 3076 3077 3078 3079 3080 3081 3082 3083 3084 3085 3086 3087 3088 3089 3090 3091 3092 3093 3094 3095 3096 3097 3098 3099 3100 3101 3102 3103 3104 3105 3106 3107 3108 3109 3110 3111 3112 3113 3114 3115 3116 3117 3118 3119 3120 3121 3122 3123 3124 3125 3126 3127 3128 3129 3130 3131 3132 3133 3134 3135 3136 3137 3138 3139 3140 3141 3142 3143 3144 3145 3146 3147 3148 3149 3150 3151 3152 3153 3154 3155 3156 3157 3158 3159 3160 3161 3162 3163 3164 3165 3166 3167 3168 3169 3170 3171 3172 3173 3174 3175 3176 3177 3178 3179 3180 3181 3182 3183 3184 3185 3186 3187 3188 3189 3190 3191 3192 3193 3194 3195 3196 3197 3198 3199 3200 3201 @profile def update_scatter_data ( self ): \"\"\"Update scatter data for fitting.\"\"\" if self . _needs_scatter_update : # Build signal list bank_gate_tables = [ \"Fuel.Cylinder #.Trim\" ] remove_digits = str . maketrans ( \"0123456789\" , \"##########\" ) msg = [] self . use_tailpipes = [ False ] * self . n_banks if self . _needs_calcs : self . update_calcd_data () for table in self . table_data : if f \" { table . name } .Corrected\" in self . resampled . sigs : tmp : list [ Sig ] = [] ranges = [] if table . name . translate ( remove_digits ) in bank_gate_tables : cyl = \"\" . join ( filter ( lambda x : x . isdigit (), table . name )) bank_ind = ( self . table_data [ f \"Engine.Cylinder { cyl } .Bank\" ] . data [ 0 ] - 1 ) if self . tabs [ table . name ] . additional_gate : gate = GateCollAND ( [ self . bank_gates [ bank_ind ], self . tabs [ table . name ] . additional_gate , ] ) else : gate = self . bank_gates [ bank_ind ] tmp_sig = ( self . resampled [ f \" { table . name } .Corrected\" ] . valid ( gate ) . resample ( self . resampled . math_tline ) ) if ( tmp_sig . data . size - np . count_nonzero ( np . isnan ( tmp_sig . data )) < 1 ): msg . append ( f \" \\n ## Individual Cylinder Lambda signals out of limits on bank { bank_ind + 1 } . \\n Bank trim from tailpipe sensor only.\" ) self . use_tailpipes [ bank_ind ] = True if self . tabs [ table . name ] . additional_gate : gate = GateCollAND ( [ self . gate , self . tabs [ table . name ] . additional_gate ] ) else : gate = self . gate tmp_sig = ( self . resampled [ f \" { table . name } .Corrected.Tailpipe\" ] . valid ( gate ) . resample ( self . resampled . math_tline ) ) self . resampled . remove ( f \" { table . name } .Corrected\" ) self . resampled . append ( Sig ( self . resampled [ f \" { table . name } .Corrected.Tailpipe\" ], name = f \" { table . name } .Corrected\" , ) ) for axis in table . axes : tmp . append ( self . resampled [ f \" { axis . name } \" ] . valid ( gate ) . as_unit ( axis . unit ) . resample ( self . resampled . math_tline ) ) ranges . append ([ axis . min , axis . max ]) tmp . append ( tmp_sig ) ranges . append ([ table . min , table . max ]) else : if self . tabs [ table . name ] . additional_gate : gate = GateCollAND ( [ self . gate , self . tabs [ table . name ] . additional_gate ] ) else : gate = self . gate for axis in table . axes : tmp . append ( self . resampled [ f \" { axis . name } \" ] . valid ( gate ) . as_unit ( axis . unit ) . resample ( self . resampled . math_tline ) ) ranges . append ([ axis . min , axis . max ]) tmp_sig = ( self . resampled [ f \" { table . name } .Corrected\" ] . valid ( gate ) . resample ( self . resampled . math_tline ) ) if \"Coolant.Temperature.Fuel Volume Compensation\" in table . name : try : # Need to adjust offset to center at normal op temp op_temp = self . tabs [ table . name ] . op_temp . value ind = table . axes [ 0 ] . bins ( op_temp )[ 0 ] diff = table . axes [ 0 ] . diff [ ind ] zero_inds = np . logical_and ( np . greater ( tmp [ - 1 ] . data , op_temp - diff / 2 ), np . less ( tmp [ - 1 ] . data , op_temp + diff / 2 ), ) zero_val = np . mean ( tmp_sig . data [ zero_inds ]) if np . isnan ( zero_val ): zero_val = 0 tmp_sig -= zero_val except AttributeError : pass tmp . append ( tmp_sig ) ranges . append ([ table . min , table . max ]) color_data = None color_name = None color_unit = None color_range = None if self . tabs [ table . name ] . color_sig . value : name = self . tabs [ table . name ] . color_sig . value [ 0 ] if \"Relative Density\" in name : color_name = name n_bins = [ 70 ] * len ( tmp ) n_bins [ - 1 ] *= 2 bins = [] for vals , intv , n_bin in zip ( tmp , ranges , n_bins ): bins . append ( np . linspace ( np . minimum ( vals . min , intv [ 0 ]), np . maximum ( vals . max , intv [ 1 ]), n_bin , ) ) color_data = scatter_density ( ScatterData ( tmp ), n_bins = bins ) elif name in self . resampled : color_data = ( self . resampled [ name ] . valid ( gate ) . resample ( self . resampled . math_tline ) . data ) color_name = name color_unit = self . resampled [ name ] . unit color_range = self . resampled [ name ] . data_range table . scatter_data = ScatterData ( data = tmp , name = \"Corrected\" , color = color_data , color_unit = color_unit , color_name = color_name , color_range = color_range , ) . clean () # Add logged data trace if table . name in self . resampled : tmp [ - 1 ] = ( self . resampled [ table . name ] . valid ( gate ) . resample ( self . resampled . math_tline ) ) table . scatter_data . append ( ScatterData ( data = tmp , name = \"Logged\" ) . clean () ) else : table . scatter_data = None self . _needs_scatter_update = False if msg and self . _needs_bank_warning : msg = list ( set ( msg )) self . warning_dialog ( title = \"# Fit Data Warning\" , msg = \"<br>\" . join ( msg )) self . _needs_bank_warning = ( # pylint: disable=attribute-defined-outside-init False )","title":"update_scatter_data"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.FCM1","text":"Bases: FirmwareModel M1 Firmware model for FCM1 Source code in ccg\\controllers\\motec.py 3523 3524 3525 3526 3527 3528 3529 3530 3531 3532 3533 3534 3535 3536 3537 3538 3539 3540 3541 3542 3543 3544 3545 3546 3547 3548 3549 3550 3551 3552 3553 3554 3555 3556 3557 3558 3559 3560 3561 3562 3563 3564 3565 3566 3567 3568 3569 3570 3571 3572 3573 3574 3575 3576 3577 3578 3579 3580 3581 3582 3583 3584 3585 3586 3587 3588 3589 3590 3591 3592 3593 3594 3595 3596 3597 3598 3599 3600 3601 3602 3603 3604 3605 3606 3607 3608 3609 3610 3611 3612 3613 3614 3615 3616 3617 3618 3619 3620 3621 3622 3623 3624 3625 3626 3627 3628 3629 3630 3631 3632 3633 3634 3635 3636 3637 3638 3639 3640 3641 3642 3643 3644 3645 3646 3647 3648 3649 3650 3651 3652 3653 3654 3655 3656 3657 3658 3659 3660 3661 3662 3663 3664 3665 3666 3667 3668 3669 3670 3671 3672 3673 3674 3675 3676 3677 3678 3679 3680 3681 3682 3683 3684 3685 3686 3687 3688 3689 3690 3691 3692 3693 3694 3695 3696 3697 3698 3699 3700 3701 3702 3703 3704 3705 3706 3707 3708 3709 3710 3711 3712 3713 3714 3715 3716 3717 3718 3719 3720 3721 3722 3723 3724 3725 3726 3727 3728 3729 3730 3731 3732 3733 3734 3735 3736 3737 3738 3739 3740 3741 3742 3743 3744 3745 3746 3747 3748 3749 3750 3751 3752 3753 3754 3755 3756 3757 3758 3759 3760 3761 3762 3763 3764 3765 3766 3767 3768 3769 3770 3771 3772 3773 3774 3775 3776 3777 3778 3779 3780 3781 3782 3783 3784 3785 3786 3787 3788 3789 3790 3791 3792 3793 3794 3795 3796 3797 3798 3799 3800 3801 3802 3803 3804 3805 3806 3807 3808 3809 3810 3811 3812 3813 3814 3815 3816 3817 3818 3819 3820 3821 3822 3823 3824 3825 3826 3827 3828 3829 3830 3831 3832 3833 3834 3835 3836 3837 3838 3839 3840 3841 3842 3843 3844 3845 3846 3847 3848 3849 3850 3851 3852 3853 3854 3855 3856 3857 3858 3859 3860 3861 3862 3863 3864 3865 3866 3867 3868 3869 3870 3871 3872 3873 3874 3875 3876 3877 3878 3879 3880 3881 3882 3883 3884 3885 3886 3887 3888 3889 3890 3891 3892 3893 3894 3895 3896 3897 3898 3899 3900 3901 3902 3903 3904 3905 3906 3907 3908 3909 3910 3911 3912 3913 3914 3915 3916 3917 3918 3919 3920 3921 3922 3923 3924 3925 3926 3927 3928 3929 3930 class FCM1 ( FirmwareModel ): \"\"\"M1 Firmware model for FCM1\"\"\" reference_tables = { \"Fuel.Mixture Aim.Main\" : { \"unit\" : \"LA\" , \"prec\" : 2 , \"range\" : [ 0.01 , 5 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine.Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 1 , }, \"Y\" : { \"sig\" : \"Inlet.Manifold.Pressure\" , \"unit\" : \"mbar\" , \"range\" : [ np . NINF , np . inf ], \"prec\" : 1 , }, \"Z\" : { \"sig\" : \"Driver.Fuel.Mixture Aim Main Switch\" , \"unit\" : \"\" , \"range\" : [ \"A\" , \"B\" ], \"prec\" : 0 , }, }, }, \"Fuel.Timing.Primary.Main\" : { \"unit\" : \"dBTDC\" , \"prec\" : 1 , \"range\" : [ 0 , 1440 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine.Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 1 , }, \"Y\" : { \"sig\" : \"Inlet.Manifold.Pressure\" , \"unit\" : \"mbar\" , \"range\" : [ 0 , np . inf ], \"prec\" : 1 , }, }, }, \"Fuel.Timing.Secondary.Main\" : { \"unit\" : \"dBTDC\" , \"prec\" : 1 , \"range\" : [ 0 , 1440 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine.Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 1 , }, \"Y\" : { \"sig\" : \"Inlet.Manifold.Pressure\" , \"unit\" : \"mbar\" , \"range\" : [ 0 , np . inf ], \"prec\" : 1 , }, }, }, } fueling_tables = { \"Engine.Efficiency.Value\" : { \"unit\" : \"%\" , \"prec\" : 1 , \"range\" : [ 10 , 200 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine.Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 1 , }, \"Y\" : { \"sig\" : \"Inlet.Manifold.Pressure\" , \"unit\" : \"mbar\" , \"range\" : [ 0 , np . inf ], \"prec\" : 1 , }, }, }, \"Coolant.Temperature.Fuel Volume Compensation\" : { \"unit\" : \"%Trim\" , \"prec\" : 1 , \"range\" : [ - 50 , 50 ], \"axes\" : { \"X\" : { \"sig\" : \"Coolant.Temperature\" , \"unit\" : \"C\" , \"range\" : [ - 50 , 200 ], \"prec\" : 1 , }, }, }, \"Fuel.Volume.Trim.Overall\" : { \"unit\" : \"%Trim\" , \"prec\" : 1 , \"range\" : [ - 99.9 , np . inf ], }, } fueling_params = { \"Fuel.Efficiency.Mode\" : { 0 : \"Manifold Air Density\" , 1 : \"Ambient Air Density\" , 2 : \"Airbox Air Density\" , }, \"Inlet.Manifold.Pressure.Mode\" : { 0 : \"Automatic\" , 1 : \"Estimate\" , 2 : \"Sensor\" , }, \"Engine.Rotors\" : 2 , \"Engine.Rotor #.Bank\" : 1 , \"Engine.Load.Normalised.Mode\" : { 0 : \"Normal\" , 1 : \"Inlet Manifold Pressure\" , 2 : \"Throttle Position\" , }, \"Inlet.Manifold.Pressure.Estimate.Mode\" : { 0 : \"Ambient Pressure Relative\" , 1 : \"100kPa Relative\" , }, } # TODO: complete calcd_sigs = [ \"Fueling.Error.Total\" , \"Engine.Efficiency.Value.Corrected\" , ] def __init__ ( self , m1cfg : str | Path = None , data : str | Path | Frame = None , gate : GateColl | str | Path = None , warning_dialog : Callable = None , ): super () . __init__ ( m1cfg = m1cfg , data = data , gate = gate , warning_dialog = warning_dialog , ) self . slow_sig = \"Engine.Speed\" @property def n_cyl ( self ): if self . table_data : return int ( self . table_data [ \"Engine.Rotors\" ] . data ) return 2 @property def n_banks ( self ): if self . table_data : return int ( max ( self . table_data [ f \"Engine.Rotor { i } .Bank\" ] . data for i in range ( 1 , self . n_cyl + 1 ) ) ) return 1 # @profile def check_substitute_sigs ( self ): \"\"\"Try to substitute for some common missing sigs.\"\"\" if self . table_data and self . data : try : mode = self . table_data [ \"Engine.Load.Normalised.Mode\" ] . data if mode == \"Normal\" : # Value = # p * # Engine.Efficiency * # Fuel Vapour Correction * # (Engine.Displacement / Engine.Cylinders) * // Displacement of one cylinder # (1 / (Constants.rAir * (Engine.Charge.Temperature + 273.15))); // Ideal gas law # when (Normalised.Mode) # { # is (Normal) # { # local ideal = # Ambient.Pressure.Standard * # 1.0 * # 1.0 * # (Engine.Displacement / Engine.Cylinders) * // Displacement of one cylinder # (1 / (Constants.rAir * (Constants.standardTemperature + 273.15))); // Ideal gas law # Normalised = Value / ideal; raise NotImplementedError elif mode == \"Inlet.Manifold.Pressure\" : sig = Sig ( name = \"Engine.Load.Normalised\" , data = self . data [ \"Inlet.Manifold.Pressure\" ] / ccg . util . convert_units ( 101.325 , \"kPa\" , self . data [ \"Inlet.Manifold.Pressure\" ] . unit , ), tline = self . data [ \"Inlet.Manifold.Pressure\" ] . tline , unit = \"ratio\" , ) elif mode == \"Throttle Position\" : sig = Sig ( name = \"Engine.Load.Normalised\" , data = self . data [ \"Throttle.Position\" ], ) sig . convert_units ( \"%\" ) if \"Engine.Load.Normalised\" not in self . data : self . data . append ( sig ) elif sig . period < self . data [ \"Engine.Load.Normalised\" ] . period : self . data . remove ( \"Engine.Load.Normalised\" ) self . data . append ( sig ) except ( KeyError , NotImplementedError ): pass # @profile def check_sigs ( self ): \"\"\"Check that required input sigs are present.\"\"\" if self . table_data and self . data : self . check_substitute_sigs () required_sigs = set ( [ \"Fuel.Lambda Control.Lambda Aim Delayed\" , \"Engine.Efficiency\" , \"Exhaust.Lambda\" , \"Fuel.Lambda Control.Factor\" , \"Fuel.Lambda Control.Adaptation\" , \"Throttle.Position\" , \"Inlet.Manifold.Temperature\" , \"Engine.Charge.Temperature\" , \"Fuel.Rotor 1.Primary.Film.Compensation\" , \"Fuel.Injector.Primary.Contribution\" , \"Fuel.Volume.Trim\" , ] ) for table in self . fueling_tables : for axis in self . table_data [ table . replace ( \"#\" , \"1\" )] . axes : required_sigs . add ( axis . name ) for sig in self . gate . sigs : if sig not in self . calcd_sigs : required_sigs . add ( sig ) if ( \"Ambient Pressure Relative\" in self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Mode\" ] . data ): required_sigs . add ( \"Ambient.Pressure\" ) ok_slow = [ \"Ambient.Pressure\" , \"Inlet.Manifold.Temperature\" , \"Fuel.Lambda Control.Lambda Aim Delayed\" , \"Engine.Charge.Temperature\" , \"Fuel.Rotor 1.Primary.Film.Compensation\" , \"Fuel.Injector.Primary.Contribution\" , \"Fuel.Volume.Trim\" , ] required_sigs = list ( required_sigs ) for sig in required_sigs : if sig not in ok_slow : self . slow_sig = sig break for sig in required_sigs : if ( sig not in ok_slow and self . data [ sig ] . period > self . data [ self . slow_sig ] . period ): self . slow_sig = sig missing = [] for sig in required_sigs : if sig not in self . data : missing . append ( sig ) if missing : raise ValueError ( f \"Missing required signals: { missing } \" ) self . resampled = self . data [ required_sigs ] . resample ( self . data [ self . slow_sig ] . tline ) self . data . math_tline = self . data [ self . slow_sig ] . tline self . resampled . math_tline = self . data [ self . slow_sig ] . tline return True else : return False # @profile def update_calcd_data ( self ): \"\"\"Update calculations for fitting/plotting.\"\"\" if self . _needs_calcs : tic = datetime . now () if self . check_sigs (): tmp = ( self . resampled [ \"Fuel.Lambda Control.Factor\" ] . convert_units ( \"ratio\" ) * self . resampled [ \"Fuel.Lambda Control.Adaptation\" ] . convert_units ( \"ratio\" ) * self . resampled [ \"Fuel.Volume.Trim\" ] . convert_units ( \"ratio\" ) * self . resampled [ \"Exhaust.Lambda\" ] / self . resampled [ \"Fuel.Lambda Control.Lambda Aim Delayed\" ] ) tmp . name = \"Fueling.Error.Total\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = self . resampled [ \"Fueling.Error.Total\" ] * ( 1 + self . resampled [ \"Engine.Efficiency\" ] ) tmp . name = \"Engine.Efficiency.Value.Corrected\" tmp . unit = \"%\" self . resampled . append ( tmp ) tmp = Sig ( self . resampled [ \"Fueling.Error.Total\" ]) . convert_units ( \"%Trim\" ) tmp . name = \"Fuel.Volume.Trim.Overall.Corrected\" self . resampled . append ( tmp ) tmp = Sig ( tmp ) # Be sure to copy... tmp . name = \"Coolant.Temperature.Fuel Volume Compensation.Corrected\" self . resampled . append ( tmp ) if self . table_data : self . resampled . append ( self . resampled [ \"Engine.Speed\" ] . dot ( n_win = 9 )) # inlet manifold press ref if ( \"Ambient Pressure Relative\" in self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Mode\" ] . data ): tmp = ( self . resampled [ \"Inlet.Manifold.Pressure\" ] / self . resampled [ \"Ambient.Pressure\" ] ) else : tmp = self . resampled [ \"Inlet.Manifold.Pressure\" ] / 1000 tmp . name = \"Inlet.Manifold.Pressure.Estimate.Main.Corrected\" tmp . unit = \"ratio\" tmp . convert_units ( \"%\" ) self . resampled . append ( tmp ) self . resampled . name = \"Resampled Data for calcs\" toc = datetime . now () - tic _LOGGER . debug ( \"Firmware calcs in %.3f \" , toc . total_seconds ()) # Set some ranges self . resampled [ \"Engine.Speed\" ] . data_range = [ 0 , 8000 ] self . resampled [ \"Fuel.Lambda Control.Lambda Aim Delayed\" ] . data_range = [ 0.6 , 1.4 , ] self . _needs_calcs = False self . update_scatter_data () def update_scatter_data ( self ): \"\"\"Update scatter data for fitting.\"\"\" # Build signal list if self . _needs_calcs : self . update_calcd_data () for table in self . table_data : if f \" { table . name } .Corrected\" in self . resampled : tmp = [] for axis in table . axes : tmp . append ( self . resampled [ f \" { axis . name } \" ] . valid ( self . gate ) . resample ( self . resampled . math_tline ) ) tmp . append ( self . resampled [ f \" { table . name } .Corrected\" ] . valid ( self . gate ) . resample ( self . resampled . math_tline ) ) if table . name == \"Engine.Efficiency.Value\" : color = self . resampled [ \"Inlet.Manifold.Temperature\" ] color_unit = \"%\" color_name = \"Primary Contr.\" color_range = [ 0 , 100 ] else : color = None color_name = None color_unit = None color_range = None table . scatter_data = ScatterData ( data = tmp , name = \"Measured\" , color = color , color_unit = color_unit , color_name = color_name , color_range = color_range , ) . clean () else : table . scatter_data = None def normalize_cyl_trims ( self ): pass","title":"FCM1"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.FCM1.check_sigs","text":"Check that required input sigs are present. Source code in ccg\\controllers\\motec.py 3747 3748 3749 3750 3751 3752 3753 3754 3755 3756 3757 3758 3759 3760 3761 3762 3763 3764 3765 3766 3767 3768 3769 3770 3771 3772 3773 3774 3775 3776 3777 3778 3779 3780 3781 3782 3783 3784 3785 3786 3787 3788 3789 3790 3791 3792 3793 3794 3795 3796 3797 3798 3799 3800 3801 3802 3803 3804 3805 3806 3807 3808 3809 3810 3811 3812 3813 3814 3815 3816 3817 3818 3819 def check_sigs ( self ): \"\"\"Check that required input sigs are present.\"\"\" if self . table_data and self . data : self . check_substitute_sigs () required_sigs = set ( [ \"Fuel.Lambda Control.Lambda Aim Delayed\" , \"Engine.Efficiency\" , \"Exhaust.Lambda\" , \"Fuel.Lambda Control.Factor\" , \"Fuel.Lambda Control.Adaptation\" , \"Throttle.Position\" , \"Inlet.Manifold.Temperature\" , \"Engine.Charge.Temperature\" , \"Fuel.Rotor 1.Primary.Film.Compensation\" , \"Fuel.Injector.Primary.Contribution\" , \"Fuel.Volume.Trim\" , ] ) for table in self . fueling_tables : for axis in self . table_data [ table . replace ( \"#\" , \"1\" )] . axes : required_sigs . add ( axis . name ) for sig in self . gate . sigs : if sig not in self . calcd_sigs : required_sigs . add ( sig ) if ( \"Ambient Pressure Relative\" in self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Mode\" ] . data ): required_sigs . add ( \"Ambient.Pressure\" ) ok_slow = [ \"Ambient.Pressure\" , \"Inlet.Manifold.Temperature\" , \"Fuel.Lambda Control.Lambda Aim Delayed\" , \"Engine.Charge.Temperature\" , \"Fuel.Rotor 1.Primary.Film.Compensation\" , \"Fuel.Injector.Primary.Contribution\" , \"Fuel.Volume.Trim\" , ] required_sigs = list ( required_sigs ) for sig in required_sigs : if sig not in ok_slow : self . slow_sig = sig break for sig in required_sigs : if ( sig not in ok_slow and self . data [ sig ] . period > self . data [ self . slow_sig ] . period ): self . slow_sig = sig missing = [] for sig in required_sigs : if sig not in self . data : missing . append ( sig ) if missing : raise ValueError ( f \"Missing required signals: { missing } \" ) self . resampled = self . data [ required_sigs ] . resample ( self . data [ self . slow_sig ] . tline ) self . data . math_tline = self . data [ self . slow_sig ] . tline self . resampled . math_tline = self . data [ self . slow_sig ] . tline return True else : return False","title":"check_sigs"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.FCM1.check_substitute_sigs","text":"Try to substitute for some common missing sigs. Source code in ccg\\controllers\\motec.py 3694 3695 3696 3697 3698 3699 3700 3701 3702 3703 3704 3705 3706 3707 3708 3709 3710 3711 3712 3713 3714 3715 3716 3717 3718 3719 3720 3721 3722 3723 3724 3725 3726 3727 3728 3729 3730 3731 3732 3733 3734 3735 3736 3737 3738 3739 3740 3741 3742 3743 3744 def check_substitute_sigs ( self ): \"\"\"Try to substitute for some common missing sigs.\"\"\" if self . table_data and self . data : try : mode = self . table_data [ \"Engine.Load.Normalised.Mode\" ] . data if mode == \"Normal\" : # Value = # p * # Engine.Efficiency * # Fuel Vapour Correction * # (Engine.Displacement / Engine.Cylinders) * // Displacement of one cylinder # (1 / (Constants.rAir * (Engine.Charge.Temperature + 273.15))); // Ideal gas law # when (Normalised.Mode) # { # is (Normal) # { # local ideal = # Ambient.Pressure.Standard * # 1.0 * # 1.0 * # (Engine.Displacement / Engine.Cylinders) * // Displacement of one cylinder # (1 / (Constants.rAir * (Constants.standardTemperature + 273.15))); // Ideal gas law # Normalised = Value / ideal; raise NotImplementedError elif mode == \"Inlet.Manifold.Pressure\" : sig = Sig ( name = \"Engine.Load.Normalised\" , data = self . data [ \"Inlet.Manifold.Pressure\" ] / ccg . util . convert_units ( 101.325 , \"kPa\" , self . data [ \"Inlet.Manifold.Pressure\" ] . unit , ), tline = self . data [ \"Inlet.Manifold.Pressure\" ] . tline , unit = \"ratio\" , ) elif mode == \"Throttle Position\" : sig = Sig ( name = \"Engine.Load.Normalised\" , data = self . data [ \"Throttle.Position\" ], ) sig . convert_units ( \"%\" ) if \"Engine.Load.Normalised\" not in self . data : self . data . append ( sig ) elif sig . period < self . data [ \"Engine.Load.Normalised\" ] . period : self . data . remove ( \"Engine.Load.Normalised\" ) self . data . append ( sig ) except ( KeyError , NotImplementedError ): pass","title":"check_substitute_sigs"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.FCM1.update_calcd_data","text":"Update calculations for fitting/plotting. Source code in ccg\\controllers\\motec.py 3822 3823 3824 3825 3826 3827 3828 3829 3830 3831 3832 3833 3834 3835 3836 3837 3838 3839 3840 3841 3842 3843 3844 3845 3846 3847 3848 3849 3850 3851 3852 3853 3854 3855 3856 3857 3858 3859 3860 3861 3862 3863 3864 3865 3866 3867 3868 3869 3870 3871 3872 3873 3874 3875 3876 3877 3878 3879 3880 3881 3882 3883 3884 def update_calcd_data ( self ): \"\"\"Update calculations for fitting/plotting.\"\"\" if self . _needs_calcs : tic = datetime . now () if self . check_sigs (): tmp = ( self . resampled [ \"Fuel.Lambda Control.Factor\" ] . convert_units ( \"ratio\" ) * self . resampled [ \"Fuel.Lambda Control.Adaptation\" ] . convert_units ( \"ratio\" ) * self . resampled [ \"Fuel.Volume.Trim\" ] . convert_units ( \"ratio\" ) * self . resampled [ \"Exhaust.Lambda\" ] / self . resampled [ \"Fuel.Lambda Control.Lambda Aim Delayed\" ] ) tmp . name = \"Fueling.Error.Total\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = self . resampled [ \"Fueling.Error.Total\" ] * ( 1 + self . resampled [ \"Engine.Efficiency\" ] ) tmp . name = \"Engine.Efficiency.Value.Corrected\" tmp . unit = \"%\" self . resampled . append ( tmp ) tmp = Sig ( self . resampled [ \"Fueling.Error.Total\" ]) . convert_units ( \"%Trim\" ) tmp . name = \"Fuel.Volume.Trim.Overall.Corrected\" self . resampled . append ( tmp ) tmp = Sig ( tmp ) # Be sure to copy... tmp . name = \"Coolant.Temperature.Fuel Volume Compensation.Corrected\" self . resampled . append ( tmp ) if self . table_data : self . resampled . append ( self . resampled [ \"Engine.Speed\" ] . dot ( n_win = 9 )) # inlet manifold press ref if ( \"Ambient Pressure Relative\" in self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Mode\" ] . data ): tmp = ( self . resampled [ \"Inlet.Manifold.Pressure\" ] / self . resampled [ \"Ambient.Pressure\" ] ) else : tmp = self . resampled [ \"Inlet.Manifold.Pressure\" ] / 1000 tmp . name = \"Inlet.Manifold.Pressure.Estimate.Main.Corrected\" tmp . unit = \"ratio\" tmp . convert_units ( \"%\" ) self . resampled . append ( tmp ) self . resampled . name = \"Resampled Data for calcs\" toc = datetime . now () - tic _LOGGER . debug ( \"Firmware calcs in %.3f \" , toc . total_seconds ()) # Set some ranges self . resampled [ \"Engine.Speed\" ] . data_range = [ 0 , 8000 ] self . resampled [ \"Fuel.Lambda Control.Lambda Aim Delayed\" ] . data_range = [ 0.6 , 1.4 , ] self . _needs_calcs = False self . update_scatter_data ()","title":"update_calcd_data"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.FCM1.update_scatter_data","text":"Update scatter data for fitting. Source code in ccg\\controllers\\motec.py 3886 3887 3888 3889 3890 3891 3892 3893 3894 3895 3896 3897 3898 3899 3900 3901 3902 3903 3904 3905 3906 3907 3908 3909 3910 3911 3912 3913 3914 3915 3916 3917 3918 3919 3920 3921 3922 3923 3924 3925 3926 3927 def update_scatter_data ( self ): \"\"\"Update scatter data for fitting.\"\"\" # Build signal list if self . _needs_calcs : self . update_calcd_data () for table in self . table_data : if f \" { table . name } .Corrected\" in self . resampled : tmp = [] for axis in table . axes : tmp . append ( self . resampled [ f \" { axis . name } \" ] . valid ( self . gate ) . resample ( self . resampled . math_tline ) ) tmp . append ( self . resampled [ f \" { table . name } .Corrected\" ] . valid ( self . gate ) . resample ( self . resampled . math_tline ) ) if table . name == \"Engine.Efficiency.Value\" : color = self . resampled [ \"Inlet.Manifold.Temperature\" ] color_unit = \"%\" color_name = \"Primary Contr.\" color_range = [ 0 , 100 ] else : color = None color_name = None color_unit = None color_range = None table . scatter_data = ScatterData ( data = tmp , name = \"Measured\" , color = color , color_unit = color_unit , color_name = color_name , color_range = color_range , ) . clean () else : table . scatter_data = None","title":"update_scatter_data"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.FirmwareModel","text":"Bases: ABC Base class for M1 firmware model. Source code in ccg\\controllers\\motec.py 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 class FirmwareModel ( ABC ): \"\"\"Base class for M1 firmware model.\"\"\" reference_tables = {} fueling_tables = { \"Engine.Efficiency.Value\" : { \"unit\" : \"%\" , \"prec\" : 1 , \"range\" : [ 10 , 200 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine.Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 1 , }, \"Y\" : { \"sig\" : \"Throttle.Position\" , \"unit\" : \"%\" , \"range\" : [ 0 , 100 ], \"prec\" : 1 , }, \"Z\" : { \"sig\" : \"Inlet.Manifold.Pressure\" , \"unit\" : \"kPa\" , \"range\" : [ 0 , np . inf ], \"prec\" : 1 , }, }, } } fueling_params = { \"Engine.Cylinders\" : 8 } def __init__ ( self , m1cfg : str | Path = None , data : str | Path | Frame = None , gate : GateColl | str | Path = None , warning_dialog : Callable = None , ): self . table_data = None self . read_cal ( m1cfg ) self . tabs = ccg . ui . panel . CalDataTabs () self . _needs_calcs = True self . _needs_scatter_update = True self . _data = None self . warning_dialog = warning_dialog if data is None : self . data = None elif isinstance ( data , Frame ): self . data = data else : self . read_data ( data ) if gate is None : self . gate = None elif isinstance ( gate , GateColl ): self . gate = gate else : self . read_gate ( gate ) self . bank_gates = [] self . resampled = None self . slow_sig : str @property def slow_freq ( self ): \"\"\"return freq of slow signal.\"\"\" return round ( 1 / self . data [ self . slow_sig ] . period ) @property @abstractmethod def n_cyl ( self ): \"\"\"Returns num of cyls\"\"\" @property @abstractmethod def n_banks ( self ): \"\"\"Returns n_banks\"\"\" @property def data ( self ): \"\"\"data\"\"\" return self . _data @data . setter def data ( self , value : Frame ): \"\"\"data setter\"\"\" self . _needs_calcs = True self . _needs_scatter_update = True self . _needs_bank_warning = True self . _data = value def read_gate ( self , filename : str | Path ): \"\"\"Read Gate File\"\"\" self . gate = GateCollAND () . from_file ( filename ) self . _needs_calcs = True self . _needs_scatter_update = True self . _needs_bank_warning = True def read_data ( self , filename : str | Path ): \"\"\"Read data file\"\"\" self . data = read_ld ( filename ) # self._needs_calcs set in data.setter def read_cal ( self , m1cfg : str | Path ): \"\"\"Read the calibration data into table_data.\"\"\" if m1cfg is not None : self . table_data = read_m1cgf ( m1cfg , param_names = self . param_names ) self . convert_tables () self . _needs_calcs = True self . _needs_scatter_update = True self . _needs_bank_warning = True @property def fueling_names ( self ): \"\"\"return names of fueling tables\"\"\" param_names = [] for param in self . fueling_tables : if \"#\" in param : param_names . extend ( param . replace ( \"#\" , str ( i + 1 )) for i in range ( self . n_cyl ) ) else : param_names . append ( param ) return param_names @property def param_names ( self ): \"\"\"Return the names of the parameters\"\"\" param_names = self . fueling_names for param in self . fueling_params : if \"#\" in param : param_names . extend ( param . replace ( \"#\" , str ( i + 1 )) for i in range ( self . n_cyl ) ) else : param_names . append ( param ) for param in self . reference_tables : if \"#\" in param : param_names . extend ( param . replace ( \"#\" , str ( i + 1 )) for i in range ( self . n_cyl ) ) else : param_names . append ( param ) return param_names def convert_tables ( self ): \"\"\"Convert tables using configurations in self.fueling_tables.\"\"\" for name , config in dict ( self . fueling_tables , ** self . reference_tables ) . items (): if \"#\" in name : names = [ name . replace ( \"#\" , str ( i )) for i in range ( 1 , self . n_cyl + 1 )] else : names = [ name ] for name in names : self . table_data [ name ] . convert_units ( config [ \"unit\" ]) self . table_data [ name ] . precision = config [ \"prec\" ] self . table_data [ name ] . data_range = config [ \"range\" ] if \"axes\" in config : for axes , ax_cfg in config [ \"axes\" ] . items (): if axes in self . table_data [ name ] . axes : self . table_data [ name ] . axes [ axes ] . convert_units ( ax_cfg [ \"unit\" ] ) self . table_data [ name ] . axes [ axes ] . precision = ax_cfg [ \"prec\" ] self . table_data [ name ] . axes [ axes ] . data_range = ax_cfg [ \"range\" ] self . table_data [ name ] . axes [ axes ] . name = ax_cfg [ \"sig\" ] # to avoid ctrl-z back to old units self . table_data [ name ] . _archive [ \"prev\" ] = [] self . table_data [ name ] . snapshot ( \"orig\" ) def build_tabs ( self ): \"\"\"build tabs widget\"\"\" if self . table_data : tmp = [] for name in self . fueling_names : cdata = ccg . ui . panel . CalData ( self . table_data [ name ]) self . tabs . tabs [ name ] = cdata if len ( name ) > 25 : # name = re.sub(\"[aeiou]\", \"\", name) name = \"...\" + name [ - 25 :] tmp . append (( name , cdata . widget )) self . tabs . widget [:] = tmp [:] else : self . tabs . tabs = ccg . ui . panel . CalDataTabs () . tabs self . tabs . widget [:] = ccg . ui . panel . CalDataTabs () . widget [:] return self . tabs @abstractmethod def update_calcd_data ( self ): \"\"\"Update calcs for fitting/plotting.\"\"\" @abstractmethod def update_scatter_data ( self ): \"\"\"Update scatter data for fitting/plotting.\"\"\"","title":"FirmwareModel"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.FirmwareModel.data","text":"data","title":"data"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.FirmwareModel.fueling_names","text":"return names of fueling tables","title":"fueling_names"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.FirmwareModel.n_banks","text":"Returns n_banks","title":"n_banks"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.FirmwareModel.n_cyl","text":"Returns num of cyls","title":"n_cyl"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.FirmwareModel.param_names","text":"Return the names of the parameters","title":"param_names"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.FirmwareModel.slow_freq","text":"return freq of slow signal.","title":"slow_freq"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.FirmwareModel.build_tabs","text":"build tabs widget Source code in ccg\\controllers\\motec.py 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 def build_tabs ( self ): \"\"\"build tabs widget\"\"\" if self . table_data : tmp = [] for name in self . fueling_names : cdata = ccg . ui . panel . CalData ( self . table_data [ name ]) self . tabs . tabs [ name ] = cdata if len ( name ) > 25 : # name = re.sub(\"[aeiou]\", \"\", name) name = \"...\" + name [ - 25 :] tmp . append (( name , cdata . widget )) self . tabs . widget [:] = tmp [:] else : self . tabs . tabs = ccg . ui . panel . CalDataTabs () . tabs self . tabs . widget [:] = ccg . ui . panel . CalDataTabs () . widget [:] return self . tabs","title":"build_tabs"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.FirmwareModel.convert_tables","text":"Convert tables using configurations in self.fueling_tables. Source code in ccg\\controllers\\motec.py 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 def convert_tables ( self ): \"\"\"Convert tables using configurations in self.fueling_tables.\"\"\" for name , config in dict ( self . fueling_tables , ** self . reference_tables ) . items (): if \"#\" in name : names = [ name . replace ( \"#\" , str ( i )) for i in range ( 1 , self . n_cyl + 1 )] else : names = [ name ] for name in names : self . table_data [ name ] . convert_units ( config [ \"unit\" ]) self . table_data [ name ] . precision = config [ \"prec\" ] self . table_data [ name ] . data_range = config [ \"range\" ] if \"axes\" in config : for axes , ax_cfg in config [ \"axes\" ] . items (): if axes in self . table_data [ name ] . axes : self . table_data [ name ] . axes [ axes ] . convert_units ( ax_cfg [ \"unit\" ] ) self . table_data [ name ] . axes [ axes ] . precision = ax_cfg [ \"prec\" ] self . table_data [ name ] . axes [ axes ] . data_range = ax_cfg [ \"range\" ] self . table_data [ name ] . axes [ axes ] . name = ax_cfg [ \"sig\" ] # to avoid ctrl-z back to old units self . table_data [ name ] . _archive [ \"prev\" ] = [] self . table_data [ name ] . snapshot ( \"orig\" )","title":"convert_tables"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.FirmwareModel.read_cal","text":"Read the calibration data into table_data. Source code in ccg\\controllers\\motec.py 880 881 882 883 884 885 886 887 def read_cal ( self , m1cfg : str | Path ): \"\"\"Read the calibration data into table_data.\"\"\" if m1cfg is not None : self . table_data = read_m1cgf ( m1cfg , param_names = self . param_names ) self . convert_tables () self . _needs_calcs = True self . _needs_scatter_update = True self . _needs_bank_warning = True","title":"read_cal"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.FirmwareModel.read_data","text":"Read data file Source code in ccg\\controllers\\motec.py 875 876 877 def read_data ( self , filename : str | Path ): \"\"\"Read data file\"\"\" self . data = read_ld ( filename )","title":"read_data"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.FirmwareModel.read_gate","text":"Read Gate File Source code in ccg\\controllers\\motec.py 868 869 870 871 872 873 def read_gate ( self , filename : str | Path ): \"\"\"Read Gate File\"\"\" self . gate = GateCollAND () . from_file ( filename ) self . _needs_calcs = True self . _needs_scatter_update = True self . _needs_bank_warning = True","title":"read_gate"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.FirmwareModel.update_calcd_data","text":"Update calcs for fitting/plotting. Source code in ccg\\controllers\\motec.py 967 968 969 @abstractmethod def update_calcd_data ( self ): \"\"\"Update calcs for fitting/plotting.\"\"\"","title":"update_calcd_data"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.FirmwareModel.update_scatter_data","text":"Update scatter data for fitting/plotting. Source code in ccg\\controllers\\motec.py 971 972 973 @abstractmethod def update_scatter_data ( self ): \"\"\"Update scatter data for fitting/plotting.\"\"\"","title":"update_scatter_data"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.LOORRS","text":"Bases: FirmwareModel M1 Firmware model for LOORRS_Pro2_Pro4 01.02.0006, March 2019 Source code in ccg\\controllers\\motec.py 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622 1623 1624 1625 1626 1627 1628 1629 1630 1631 1632 1633 1634 1635 1636 1637 1638 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 1649 1650 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664 1665 1666 1667 1668 1669 1670 1671 1672 1673 1674 1675 1676 1677 1678 1679 1680 1681 1682 1683 1684 1685 1686 1687 1688 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699 1700 1701 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711 1712 1713 1714 1715 1716 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741 1742 1743 1744 1745 1746 1747 1748 1749 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 1767 1768 1769 1770 1771 1772 1773 1774 1775 1776 1777 1778 1779 1780 1781 1782 1783 1784 1785 1786 1787 1788 1789 1790 1791 1792 1793 1794 1795 1796 1797 1798 1799 1800 1801 1802 1803 1804 1805 1806 1807 1808 1809 1810 1811 1812 1813 1814 1815 1816 1817 1818 1819 1820 1821 1822 1823 1824 1825 1826 1827 1828 1829 1830 1831 1832 1833 1834 1835 1836 1837 1838 1839 1840 1841 1842 1843 1844 1845 1846 1847 1848 1849 1850 1851 1852 1853 1854 1855 1856 1857 1858 1859 1860 1861 1862 1863 1864 1865 1866 1867 1868 1869 1870 1871 1872 1873 1874 1875 1876 1877 1878 1879 1880 1881 1882 1883 1884 1885 1886 1887 1888 1889 1890 1891 1892 1893 1894 1895 1896 1897 1898 1899 1900 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 2025 2026 2027 2028 2029 2030 2031 2032 2033 2034 2035 2036 2037 2038 2039 2040 2041 2042 2043 2044 2045 2046 2047 2048 2049 2050 2051 2052 2053 2054 2055 2056 2057 2058 2059 2060 2061 2062 2063 2064 2065 2066 2067 2068 2069 2070 2071 2072 2073 2074 2075 2076 2077 2078 2079 2080 2081 2082 2083 2084 2085 2086 2087 2088 2089 2090 2091 2092 2093 2094 2095 2096 2097 2098 2099 2100 2101 2102 2103 2104 2105 2106 2107 2108 2109 2110 2111 2112 2113 2114 2115 2116 2117 2118 2119 2120 2121 2122 2123 2124 2125 2126 2127 2128 2129 2130 2131 2132 2133 2134 2135 2136 2137 2138 2139 2140 2141 2142 2143 2144 2145 2146 2147 2148 2149 2150 2151 2152 2153 2154 2155 2156 2157 2158 2159 2160 2161 2162 2163 2164 2165 2166 2167 2168 2169 2170 2171 2172 2173 2174 2175 2176 2177 2178 2179 2180 2181 2182 2183 2184 2185 2186 2187 2188 2189 2190 2191 2192 2193 2194 2195 2196 2197 2198 2199 2200 2201 2202 2203 2204 2205 2206 2207 2208 2209 2210 2211 2212 2213 2214 2215 2216 2217 2218 2219 2220 2221 2222 2223 2224 2225 2226 2227 2228 2229 2230 2231 2232 2233 2234 2235 2236 2237 2238 2239 2240 2241 2242 2243 2244 2245 2246 2247 2248 2249 2250 2251 2252 2253 2254 2255 2256 2257 2258 2259 2260 2261 2262 2263 2264 2265 2266 2267 2268 2269 class LOORRS ( FirmwareModel ): \"\"\"M1 Firmware model for LOORRS_Pro2_Pro4 01.02.0006, March 2019\"\"\" reference_tables = { \"Fuel.Mixture Aim.Main\" : { \"unit\" : \"LA\" , \"prec\" : 2 , \"range\" : [ 0.01 , 5 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine.Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"Engine.Load.Normalised\" , \"unit\" : \"%\" , \"range\" : [ np . NINF , np . inf ], \"prec\" : 1 , }, \"Z\" : { \"sig\" : \"Driver.Fuel.Mixture Aim.Main.Switch\" , \"unit\" : \"\" , \"range\" : [ \"A\" , \"B\" ], \"prec\" : 0 , }, }, }, \"Fuel.Timing.Primary.Main\" : { \"unit\" : \"dBTDC\" , \"prec\" : 1 , \"range\" : [ 0 , 1440 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine.Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"Inlet.Manifold.Pressure\" , \"unit\" : \"kPa\" , \"range\" : [ 0 , np . inf ], \"prec\" : 1 , }, \"Z\" : { \"sig\" : \"Engine.Load.Normalised\" , \"unit\" : \"%\" , \"range\" : [ np . NINF , np . inf ], \"prec\" : 1 , }, }, }, } fueling_tables = { \"Engine.Efficiency.Value\" : { \"unit\" : \"%\" , \"prec\" : 1 , \"range\" : [ 10 , 200 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine.Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"Throttle.Position\" , \"unit\" : \"%\" , \"range\" : [ 0 , 100 ], \"prec\" : 1 , }, \"Z\" : { \"sig\" : \"Inlet.Manifold.Pressure\" , \"unit\" : \"kPa\" , \"range\" : [ 0 , np . inf ], \"prec\" : 1 , }, }, }, \"Fuel.Cylinder #.Trim\" : { \"unit\" : \"%Trim\" , \"prec\" : 1 , \"range\" : [ - 100 , 50 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine.Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"Inlet.Manifold.Pressure\" , \"unit\" : \"kPa\" , \"range\" : [ 0 , np . inf ], \"prec\" : 1 , }, \"Z\" : { \"sig\" : \"Engine.Load.Normalised\" , \"unit\" : \"%\" , \"range\" : [ np . NINF , np . inf ], \"prec\" : 1 , }, }, }, \"Fuel.Cylinder #.Primary.Trim\" : { \"unit\" : \"%Trim\" , \"prec\" : 1 , \"range\" : [ - 100 , 200 ], \"axes\" : { \"X\" : { \"sig\" : \"Engine.Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 0 , }, \"Y\" : { \"sig\" : \"Engine.Load.Normalised\" , \"unit\" : \"%\" , \"range\" : [ np . NINF , np . inf ], \"prec\" : 1 , }, }, }, \"Inlet.Manifold.Pressure.Estimate.Main\" : { \"unit\" : \"%\" , \"prec\" : 1 , \"range\" : [ 0 , np . inf ], \"axes\" : { \"X\" : { \"sig\" : \"Throttle.Position\" , \"unit\" : \"%\" , \"range\" : [ 0 , 100 ], \"prec\" : 1 , }, \"Y\" : { \"sig\" : \"Engine.Speed\" , \"unit\" : \"rpm\" , \"range\" : [ 0 , 30000 ], \"prec\" : 0 , }, \"Z\" : { \"sig\" : \"Ambient.Pressure\" , \"unit\" : \"kPa\" , \"range\" : [ 5 , 110 ], \"prec\" : 1 , }, }, }, \"Fuel.Volume.Trim.Overall\" : { \"unit\" : \"%Trim\" , \"prec\" : 1 , \"range\" : [ - 99.9 , np . inf ], }, \"Coolant.Temperature.Fuel Volume Compensation\" : { \"unit\" : \"%Trim\" , \"prec\" : 1 , \"range\" : [ - 50 , 50 ], \"axes\" : { \"X\" : { \"sig\" : \"Coolant.Temperature\" , \"unit\" : \"F\" , \"range\" : [ - 58 , 482 ], \"prec\" : 1 , }, }, }, } fueling_params = { \"Fuel.Efficiency.Mode\" : { 0 : \"Manifold Air Density\" , 1 : \"Ambient Air Density\" , 2 : \"Airbox Air Density\" , }, \"Inlet.Manifold.Pressure.Mode\" : { 0 : \"Automatic\" , 1 : \"Estimate\" , 2 : \"Sensor\" , }, \"Engine.Cylinders\" : 8 , \"Engine.Cylinder #.Bank\" : 1 , \"Engine.Load.Normalised.Mode\" : { 0 : \"Normal\" , 1 : \"Inlet Manifold Pressure\" , 2 : \"Throttle PositioLambda.Indiv.Bank 2.AvgLambda.Indiv.Bank 2.Avgn\" , }, \"Inlet.Manifold.Pressure.Estimate.Mode\" : { 0 : \"Ambient Pressure Relative\" , 1 : \"100kPa Relative\" , }, \"Fuel.Volume.Trim.Overall\" : 0 , \"Ambient.Pressure.Default.Value\" : 101.3 , } # TODO: complete calcd_sigs = [ \"Fueling.Error.Bank 1\" , \"Fueling.Error.Bank 2\" , \"Fueling.Error.Total\" , \"Engine.Efficiency.Value.Corrected\" , \"Lambda.Indiv.Bank 1.Avg\" , \"Lambda.Indiv.Bank 2.Avg\" , \"Cylinder.Trim.Avg\" , ] def __init__ ( self , m1cfg : str | Path = None , data : str | Path | Frame = None , gate : GateColl | str | Path = None , warning_dialog : Callable = None , ): super () . __init__ ( m1cfg = m1cfg , data = data , gate = gate , warning_dialog = warning_dialog , ) self . slow_sig = \"Engine.Speed\" self . use_tailpipes = [ False ] * self . n_banks @property def n_cyl ( self ): if self . table_data and \"Engine.Cylinders\" in self . table_data : return int ( self . table_data [ \"Engine.Cylinders\" ] . data ) return 8 @property def n_banks ( self ): if self . table_data : return int ( max ( self . table_data [ f \"Engine.Cylinder { i } .Bank\" ] . data for i in range ( 1 , self . n_cyl + 1 ) ) ) return 2 # @profile def check_substitute_sigs ( self ): \"\"\"Try to substitute for some common missing sigs.\"\"\" msgs = [] if self . table_data and self . data : try : mode = self . table_data [ \"Engine.Load.Normalised.Mode\" ] . data if mode == \"Normal\" : # Value = # p * # Engine.Efficiency * # Fuel Vapour Correction * # (Engine.Displacement / Engine.Cylinders) * // Displacement of one cylinder # (1 / (Constants.rAir * (Engine.Charge.Temperature + 273.15))); // Ideal gas law # when (Normalised.Mode) # { # is (Normal) # { # local ideal = # Ambient.Pressure.Standard * # 1.0 * # 1.0 * # (Engine.Displacement / Engine.Cylinders) * // Displacement of one cylinder # (1 / (Constants.rAir * (Constants.standardTemperature + 273.15))); // Ideal gas law # Normalised = Value / ideal; raise NotImplementedError elif mode == \"Inlet.Manifold.Pressure\" : sig = Sig ( name = \"Engine.Load.Normalised\" , data = self . data [ \"Inlet.Manifold.Pressure\" ] / ccg . util . convert_units ( 101.325 , \"kPa\" , self . data [ \"Inlet.Manifold.Pressure\" ] . unit , ), tline = self . data [ \"Inlet.Manifold.Pressure\" ] . tline , unit = \"ratio\" , ) elif mode == \"Throttle Position\" : sig = Sig ( name = \"Engine.Load.Normalised\" , data = self . data [ \"Throttle.Position\" ], ) sig . convert_units ( \"%\" ) if \"Engine.Load.Normalised\" not in self . data : self . data . append ( sig ) msgs . append ( \"`Engine.Load.Normalized` was not logged and has been calculated from input signals.\" ) elif sig . period < self . data [ \"Engine.Load.Normalised\" ] . period : self . data . remove ( \"Engine.Load.Normalised\" ) self . data . append ( sig ) msgs . append ( \"`Engine.Load.Normalized` was logged slowly and has been calculated from input signals.\" ) except KeyError : pass try : if \"Fuel.Volume.Trim\" not in self . data : sig = self . table_data [ \"Fuel.Volume.Trim.Overall\" ][ self . data ] sig . name = \"Fuel.Volume.Trim\" self . data . append ( sig ) msgs . append ( \"`Fuel.Volume.Trim` was not logged and has been calculated from the loaded calibration. ** Ensure that this matches the calibration that generated the data **\" ) except KeyError : pass for i in range ( 1 , self . n_cyl + 1 ): try : name = f \"Fuel.Cylinder { i } .Trim\" if name not in self . data : sig = self . table_data [ name ][ self . data ] self . data . append ( sig ) msgs . append ( f \"` { name } ` was not logged and has been calculated from the loaded calibration. ** Ensure that this matches the calibration that generated the data **\" ) except KeyError : pass try : name = f \"Fuel.Cylinder { i } .Primary.Trim\" if name not in self . data : sig = self . table_data [ name ][ self . data ] self . data . append ( sig ) msgs . append ( f \"` { name } ` was not logged and has been calculated from the loaded calibration. ** Ensure that this matches the calibration that generated the data **\" ) except KeyError : pass try : if \"Coolant.Temperature.Fuel Volume Compensation\" not in self . data : sig = Sig ( self . data [ \"Fuel.Volume.Compensation\" ]) sig . name = \"Coolant.Temperature.Fuel Volume Compensation\" self . data . append ( sig ) msgs . append ( \"`Coolant.Temperature.Fuel Volume Compensation` was not logged and has been substituted with `Fuel.Volume.Compensation`. ** Ensure that no other volume compensation was active. **\" ) except KeyError : pass if msgs : msgs = [ \"## Substituted Signals \\n \" , * msgs ] return msgs @profile def check_sigs ( self ): \"\"\"Check that required input sigs are present.\"\"\" if self . table_data and self . data : msgs = self . check_substitute_sigs () required_sigs = set ( [ \"Fuel.Mixture Aim\" , \"Engine.Efficiency\" , \"Fuel.Volume.Trim\" , \"Fuel.Volume.Compensation\" , \"Coolant.Temperature.Fuel Volume Compensation\" , ] ) for table in self . fueling_tables : for axis in self . table_data [ table . replace ( \"#\" , \"1\" )] . axes : required_sigs . add ( axis . name ) for i in range ( 1 , self . n_cyl + 1 ): required_sigs . add ( f \"Fuel.Cylinder { i } .Trim\" ) required_sigs . add ( f \"Fuel.Cylinder { i } .Primary.Trim\" ) required_sigs . add ( f \"Exhaust.Lambda.Cylinder { i } \" ) for i in range ( 1 , self . n_banks + 1 ): required_sigs . add ( f \"Exhaust.Lambda.Bank { i } \" ) required_sigs . add ( f \"Fuel.Closed Loop.Control.Bank { i } .Trim\" ) if ( \"Ambient Pressure Relative\" in self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Mode\" ] . data ): required_sigs . add ( \"Ambient.Pressure\" ) ok_slow = [ \"Ambient.Pressure\" , \"Fuel.Mixture Aim\" , \"Fuel.Volume.Trim\" , \"Fuel.Volume.Compensation\" , \"Inlet.Manifold.Pressure.Estimate\" , \"Coolant.Temperature.Fuel Volume Compensation\" , \"Coolant.Temperature\" , ] extras = [ \"Inlet.Manifold.Pressure.Estimate\" , \"Inlet.Air.Temperature\" , \"Vehicle.Speed\" , \"Ignition.Cut\" , \"Ignition.Timing\" , \"Idle.State\" , \"Fuel.Volume.Transient\" , \"Fuel.Volume.Trim\" , \"Fuel.Volume.Compensation\" , \"Fuel.Timing.Primary\" , \"Fuel.Temperature\" , \"Fuel.Pressure\" , \"Fuel.Injector.Primary.Duty.Cycle\" , \"Fuel.Film.Primary\" , \"Fuel.Cut\" , \"Engine.Load\" , \"Coolant.Pressure\" , \"Engine.Charge.Temperature\" , \"Engine.Oil.Temperature\" , \"Engine.Oil.Pressure\" , \"ECU.Batter.Voltage\" , ] required_sigs = list ( required_sigs ) missing = [] for sig in required_sigs : if sig not in self . data : missing . append ( sig ) for sig in self . gate . sigs : if sig not in self . data and sig not in self . calcd_sigs : missing . append ( sig ) if missing : missing . sort () # msg = \"<br>\".join(missing) if self . warning_dialog : msgs . extend ([ \" \\n ## Missing Required Signals \\n \" , * missing ]) self . warning_dialog ( title = \"# Missing Signals\" , msg = \"<br>\" . join ( msgs ) ) return False raise ValueError ( f \"Missing Required Signals \\n { missing } \" ) for sig in required_sigs : if sig not in ok_slow : self . slow_sig = sig break for sig in required_sigs : if ( sig not in ok_slow and self . data [ sig ] . period > self . data [ self . slow_sig ] . period ): self . slow_sig = sig for sig in self . gate . sigs : if sig not in self . calcd_sigs and sig not in required_sigs : required_sigs . append ( sig ) tline = self . data [ self . slow_sig ] . tline self . resampled = self . data [ required_sigs ] . resample ( tline ) self . resampled . name = \"Resampled Data for Calc's\" self . data . math_tline = tline self . resampled . math_tline = tline for sig in extras : try : self . resampled . append ( self . data [ sig ] . resample ( tline )) except KeyError : pass if self . slow_freq < 50 : msgs . extend ( [ \" \\n ## Slow Signal \\n \" , f \"Calculation rate limited to { self . slow_freq } Hz by ` { self . slow_sig } `\" , ] ) if msgs : self . warning_dialog ( title = \"# Missing Signals\" , msg = \"<br>\" . join ( msgs )) return True else : return False @profile def update_calcd_data ( self ): \"\"\"Update calculations for fitting/plotting.\"\"\" if self . _needs_calcs : tic = datetime . now () if self . check_sigs (): if self . table_data : acc = 0 n = 0 for cyl in range ( 1 , 1 + self . n_cyl ): tmp = self . resampled [ f \"Fuel.Cylinder { cyl } .Trim\" ] . as_unit ( \"ratio\" ) * self . resampled [ f \"Fuel.Cylinder { cyl } .Primary.Trim\" ] . as_unit ( \"ratio\" ) tmp . unit = \"ratio\" tmp . name = f \"Fuel.Cylinder { cyl } .Trim.Total\" self . resampled . append ( tmp ) acc = acc + tmp n += 1 acc = acc / n acc . name = \"Cylinder.Trim.Avg\" acc . unit = \"ratio\" self . resampled . append ( acc ) for bank in range ( 1 , self . n_banks + 1 ): tmp = 0 n = 0 for cyl in range ( 1 , 1 + self . n_cyl ): if ( self . table_data [ f \"Engine.Cylinder { cyl } .Bank\" ] . data == bank ): n += 1 tmp = ( tmp + self . resampled [ f \"Exhaust.Lambda.Cylinder { cyl } \" ] ) tmp = tmp / n tmp . name = f \"Lambda.Indiv.Bank { bank } .Avg\" tmp . unit = \"LA\" tmp . data_range = [ 0.6 , 1.4 ] self . resampled . append ( tmp ) tmp = 0 n = 0 for cyl in range ( 1 , 1 + self . n_cyl ): if ( self . table_data [ f \"Engine.Cylinder { cyl } .Bank\" ] . data == bank ): n += 1 tmp = tmp + self . resampled [ f \"Fuel.Cylinder { cyl } .Trim\" ] . as_unit ( \"ratio\" ) * self . resampled [ f \"Fuel.Cylinder { cyl } .Primary.Trim\" ] . as_unit ( \"ratio\" ) tmp = tmp / n tmp . name = f \"Cylinder.Trim.Bank { bank } .Avg\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) self . resampled [ f \"Exhaust.Lambda.Bank { bank } \" ] . data_range = [ 0.6 , 1.4 , ] tmp = self . table_data [ \"Coolant.Temperature.Fuel Volume Compensation\" ][ self . resampled ] . as_unit ( \"ratio\" ) / self . resampled [ \"Fuel.Volume.Compensation\" ] . as_unit ( \"ratio\" ) tmp . name = \"Volume.Comp.Delta\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ \"Fuel.Closed Loop.Control.Bank 1.Trim\" ] . as_unit ( \"ratio\" ) * self . resampled [ \"Fuel.Volume.Trim\" ] . as_unit ( \"ratio\" ) / self . resampled [ \"Volume.Comp.Delta\" ] . as_unit ( \"ratio\" ) * self . resampled [ \"Cylinder.Trim.Bank 1.Avg\" ] * self . resampled [ \"Exhaust.Lambda.Bank 1\" ] / self . resampled [ \"Fuel.Mixture Aim\" ] ) # TODO: Fix for only 1 bank tmp . name = \"Fueling.Error.Bank 1\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ \"Fuel.Closed Loop.Control.Bank 2.Trim\" ] . as_unit ( \"ratio\" ) * self . resampled [ \"Fuel.Volume.Trim\" ] . as_unit ( \"ratio\" ) / self . resampled [ \"Volume.Comp.Delta\" ] . as_unit ( \"ratio\" ) * self . resampled [ \"Cylinder.Trim.Bank 2.Avg\" ] * self . resampled [ \"Exhaust.Lambda.Bank 2\" ] / self . resampled [ \"Fuel.Mixture Aim\" ] ) tmp . name = \"Fueling.Error.Bank 2\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ \"Fueling.Error.Bank 1\" ] + self . resampled [ \"Fueling.Error.Bank 2\" ] ) / 2 tmp . name = \"Fueling.Error.Total\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = self . resampled [ \"Fueling.Error.Total\" ] * ( self . resampled [ \"Engine.Efficiency\" ] ) tmp . name = \"Engine.Efficiency.Value.Corrected\" tmp . unit = \"%\" self . resampled . append ( tmp ) self . resampled . append ( Sig ( self . resampled [ \"Engine.Efficiency\" ], name = \"Engine.Efficiency.Value\" , ) ) # copy with name to match table for cyl in range ( 1 , 1 + self . n_cyl ): bank = int ( self . table_data [ f \"Engine.Cylinder { cyl } .Bank\" ] . data ) tmp = ( self . resampled [ f \"Exhaust.Lambda.Cylinder { cyl } \" ] / self . resampled [ f \"Lambda.Indiv.Bank { bank } .Avg\" ] ) tmp . name = f \"Cyl { cyl } .Lam.Error\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ f \"Fuel.Cylinder { cyl } .Trim.Total\" ] / self . resampled [ f \"Cylinder.Trim.Bank { bank } .Avg\" ] ) tmp . name = f \"Fuel.Cylinder { cyl } .Trim.Bank Normalised\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ f \"Fuel.Cylinder { cyl } .Trim.Total\" ] / self . resampled [ \"Cylinder.Trim.Avg\" ] ) tmp . name = f \"Fuel.Cylinder { cyl } .Trim.Normalised\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ f \"Fuel.Cylinder { cyl } .Trim.Bank Normalised\" ] * self . resampled [ f \"Cyl { cyl } .Lam.Error\" ] * ( self . resampled [ f \"Fueling.Error.Bank { bank } \" ] / self . resampled [ \"Fueling.Error.Total\" ] ) ) tmp . name = f \"Fuel.Cylinder { cyl } .Trim.Corrected\" tmp . unit = \"ratio\" tmp . convert_units ( \"%Trim\" ) self . resampled . append ( tmp ) # Calc cyl trims from tailpipe data incase indiv missing tmp = self . resampled [ f \"Fuel.Cylinder { cyl } .Trim.Normalised\" ] * ( self . resampled [ f \"Fueling.Error.Bank { bank } \" ] / self . resampled [ \"Fueling.Error.Total\" ] ) tmp . name = f \"Fuel.Cylinder { cyl } .Trim.Corrected.Tailpipe\" tmp . unit = \"ratio\" tmp . convert_units ( \"%Trim\" ) self . resampled . append ( tmp ) self . resampled [ f \"Exhaust.Lambda.Cylinder { cyl } \" ] . data_range = [ 0.6 , 1.4 , ] self . resampled . append ( self . resampled [ \"Engine.Speed\" ] . dot ( n_win = 17 )) self . resampled . append ( self . resampled [ \"Throttle.Position\" ] . dot ( n_win = 7 ) ) # inlet manifold press ref try : if ( \"Ambient Pressure Relative\" in self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Mode\" ] . data ): tmp = ( self . resampled [ \"Inlet.Manifold.Pressure\" ] / self . resampled [ \"Ambient.Pressure\" ] ) else : tmp = self . resampled [ \"Inlet.Manifold.Pressure\" ] / 100 tmp . name = \"Inlet.Manifold.Pressure.Estimate.Main.Corrected\" tmp . unit = \"ratio\" tmp . convert_units ( \"%\" ) self . resampled . append ( tmp ) if ( \"Ambient Pressure Relative\" in self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Mode\" ] . data ): tmp = ( self . resampled [ \"Inlet.Manifold.Pressure.Estimate\" ] / self . resampled [ \"Ambient.Pressure\" ] ) else : tmp = ( self . resampled [ \"Inlet.Manifold.Pressure.Estimate\" ] / 100 ) tmp . name = \"Inlet.Manifold.Pressure.Estimate.Main\" tmp . unit = \"ratio\" tmp . convert_units ( \"%\" ) self . resampled . append ( tmp ) except KeyError : pass # Coolant temp comps tmp = ( self . resampled [ \"Engine.Efficiency.Value.Corrected\" ] . as_unit ( \"ratio\" ) / self . table_data [ \"Engine.Efficiency.Value\" ][ self . resampled ] . as_unit ( \"ratio\" ) * self . resampled [ \"Coolant.Temperature.Fuel Volume Compensation\" ] . as_unit ( \"ratio\" ) * self . resampled [ \"Volume.Comp.Delta\" ] . as_unit ( \"ratio\" ) ) tmp . name = \"Coolant.Temperature.Fuel Volume Compensation.Corrected\" tmp . unit = \"ratio\" tmp . convert_units ( \"%Trim\" ) self . resampled . append ( tmp ) toc = datetime . now () - tic _LOGGER . debug ( \"Firmware calcs in %.3f \" , toc . total_seconds ()) # Set some ranges self . resampled [ \"Engine.Speed\" ] . data_range = [ 0 , 8800 ] self . resampled [ \"Fuel.Mixture Aim\" ] . data_range = [ 0.6 , 1.4 ] # Add calc'd signals to data frame for general plot self . data . append ( self . resampled ) self . _needs_calcs = False if not self . _needs_calcs : self . update_scatter_data () # Update options for scatter plots opts = [ \"Relative Density\" , * self . resampled . sigs . keys ()] for tab in self . tabs : tab . color_sig . options = opts @profile def update_scatter_data ( self ): \"\"\"Update scatter data for fitting.\"\"\" if self . _needs_scatter_update : # Build signal list bank_gate_tables = [ \"Fuel.Cylinder #.Trim\" ] remove_digits = str . maketrans ( \"0123456789\" , \"##########\" ) msg = [] self . use_tailpipes = [ False ] * self . n_banks if self . _needs_calcs : self . update_calcd_data () for table in self . table_data : if f \" { table . name } .Corrected\" in self . resampled . sigs : tmp : list [ Sig ] = [] ranges = [] if table . name . translate ( remove_digits ) in bank_gate_tables : cyl = \"\" . join ( filter ( lambda x : x . isdigit (), table . name )) bank_ind = ( self . table_data [ f \"Engine.Cylinder { cyl } .Bank\" ] . data [ 0 ] - 1 ) if self . tabs [ table . name ] . additional_gate : gate = GateCollAND ( [ self . bank_gates [ bank_ind ], self . tabs [ table . name ] . additional_gate , ] ) else : gate = self . bank_gates [ bank_ind ] tmp_sig = ( self . resampled [ f \" { table . name } .Corrected\" ] . valid ( gate ) . resample ( self . resampled . math_tline ) ) if ( tmp_sig . data . size - np . count_nonzero ( np . isnan ( tmp_sig . data )) < 1 ): msg . append ( f \" \\n ## Individual Cylinder Lambda signals out of limits on bank { bank_ind + 1 } . \\n Bank trim from tailpipe sensor only.\" ) self . use_tailpipes [ bank_ind ] = True if self . tabs [ table . name ] . additional_gate : gate = GateCollAND ( [ self . gate , self . tabs [ table . name ] . additional_gate ] ) else : gate = self . gate tmp_sig = ( self . resampled [ f \" { table . name } .Corrected.Tailpipe\" ] . valid ( gate ) . resample ( self . resampled . math_tline ) ) self . resampled . remove ( f \" { table . name } .Corrected\" ) self . resampled . append ( Sig ( self . resampled [ f \" { table . name } .Corrected.Tailpipe\" ], name = f \" { table . name } .Corrected\" , ) ) for axis in table . axes : tmp . append ( self . resampled [ f \" { axis . name } \" ] . valid ( gate ) . as_unit ( axis . unit ) . resample ( self . resampled . math_tline ) ) ranges . append ([ axis . min , axis . max ]) tmp . append ( tmp_sig ) ranges . append ([ table . min , table . max ]) else : if self . tabs [ table . name ] . additional_gate : gate = GateCollAND ( [ self . gate , self . tabs [ table . name ] . additional_gate ] ) else : gate = self . gate for axis in table . axes : tmp . append ( self . resampled [ f \" { axis . name } \" ] . valid ( gate ) . as_unit ( axis . unit ) . resample ( self . resampled . math_tline ) ) ranges . append ([ axis . min , axis . max ]) tmp_sig = ( self . resampled [ f \" { table . name } .Corrected\" ] . valid ( gate ) . resample ( self . resampled . math_tline ) ) if \"Coolant.Temperature.Fuel Volume Compensation\" in table . name : try : # Need to adjust offset to center at normal op temp op_temp = self . tabs [ table . name ] . op_temp . value ind = table . axes [ 0 ] . bins ( op_temp )[ 0 ] diff = table . axes [ 0 ] . diff [ ind ] zero_inds = np . logical_and ( np . greater ( tmp [ - 1 ] . data , op_temp - diff / 2 ), np . less ( tmp [ - 1 ] . data , op_temp + diff / 2 ), ) zero_val = np . mean ( tmp_sig . data [ zero_inds ]) if np . isnan ( zero_val ): zero_val = 0 tmp_sig -= zero_val except AttributeError : pass tmp . append ( tmp_sig ) ranges . append ([ table . min , table . max ]) color_data = None color_name = None color_unit = None color_range = None if self . tabs [ table . name ] . color_sig . value : name = self . tabs [ table . name ] . color_sig . value [ 0 ] if \"Relative Density\" in name : color_name = name n_bins = [ 70 ] * len ( tmp ) n_bins [ - 1 ] *= 2 bins = [] for vals , intv , n_bin in zip ( tmp , ranges , n_bins ): bins . append ( np . linspace ( np . minimum ( vals . min , intv [ 0 ]), np . maximum ( vals . max , intv [ 1 ]), n_bin , ) ) color_data = scatter_density ( ScatterData ( tmp ), n_bins = bins ) elif name in self . resampled : color_data = ( self . resampled [ name ] . valid ( gate ) . resample ( self . resampled . math_tline ) . data ) color_name = name color_unit = self . resampled [ name ] . unit color_range = self . resampled [ name ] . data_range table . scatter_data = ScatterData ( data = tmp , name = \"Corrected\" , color = color_data , color_unit = color_unit , color_name = color_name , color_range = color_range , ) . clean () # Add logged data trace if table . name in self . resampled : tmp [ - 1 ] = ( self . resampled [ table . name ] . valid ( gate ) . resample ( self . resampled . math_tline ) ) table . scatter_data . append ( ScatterData ( data = tmp , name = \"Logged\" ) . clean () ) else : table . scatter_data = None self . _needs_scatter_update = False if msg and self . _needs_bank_warning : msg = list ( set ( msg )) self . warning_dialog ( title = \"# Fit Data Warning\" , msg = \"<br>\" . join ( msg )) self . _needs_bank_warning = ( # pylint: disable=attribute-defined-outside-init False ) def normalize_cyl_trims ( self ): \"\"\"Normalizes cyl trims if bp's match.\"\"\" cyl_trim_min = self . fueling_tables [ \"Fuel.Cylinder #.Trim\" ][ \"range\" ][ 0 ] cyl_trim_max = self . fueling_tables [ \"Fuel.Cylinder #.Trim\" ][ \"range\" ][ 1 ] cyl_trim_unit = self . fueling_tables [ \"Fuel.Cylinder #.Trim\" ][ \"unit\" ] prim_trim_unit = self . fueling_tables [ \"Fuel.Cylinder #.Primary.Trim\" ][ \"unit\" ] if self . check_axes (): avg = np . zeros ( self . table_data [ \"Fuel.Cylinder 1.Trim\" ] . data . shape ) n = 0 for cyl in range ( 1 , self . n_cyl + 1 ): avg += self . table_data [ f \"Fuel.Cylinder { cyl } .Trim\" ] . data n += 1 avg = ccg . util . convert_units ( avg / n , cyl_trim_unit , \"ratio\" ) axes_names_equal = True for cyl in range ( 1 , self . n_cyl + 1 ): cyl_trim = ( self . table_data [ f \"Fuel.Cylinder { cyl } .Trim\" ] . as_unit ( \"ratio\" ) . data / avg ) cyl_trim = ccg . util . convert_units ( cyl_trim , \"ratio\" , cyl_trim_unit ) if np . any ( cyl_trim > cyl_trim_max ): prim_trim = ( np . maximum ( cyl_trim - cyl_trim_max , 0 ) / cyl_trim_max + 1 ) prim_trim = ccg . util . convert_units ( prim_trim , \"ratio\" , prim_trim_unit ) for i , axis in enumerate ( self . table_data [ f \"Fuel.Cylinder { cyl } .Trim\" ] . axes ): axes_names_equal = ( axes_names_equal and self . table_data [ f \"Fuel.Cylinder { cyl } .Primary.Trim\" ] . axes [ i ] . name == axis . name ) if axes_names_equal : self . table_data [ f \"Fuel.Cylinder { cyl } .Primary.Trim\" ] . axes = ( self . table_data [ f \"Fuel.Cylinder { cyl } .Trim\" ] . axes ) self . table_data [ f \"Fuel.Cylinder { cyl } .Primary.Trim\" ] . data = ( prim_trim ) else : self . table_data [ f \"Fuel.Cylinder { cyl } .Primary.Trim\" ] . data *= 0 self . table_data [ f \"Fuel.Cylinder { cyl } .Trim\" ] . data = np . clip ( cyl_trim , cyl_trim_min , cyl_trim_max ) if not axes_names_equal : self . warning_dialog ( title = \"# Primary Trim Issue\" , msg = \"`Fuel.Cylinder #.Primary.Trim` required, but axes conflict. \\n Set `Fuel.Cylinder #.Primary.Trim` axes to match `Fuel.Cylinder #.Trim` in M1 Tune before exporting config.\" , ) else : raise ValueError ( \"Cyl trim axes dont match, cant normalize\" ) def check_axes ( self ): \"\"\"Check if cyl trim axes match\"\"\" for i in range ( 2 , self . n_cyl + 1 ): for axis , axis1 in zip ( self . table_data [ f \"Fuel.Cylinder { i } .Trim\" ] . axes , self . table_data [ \"Fuel.Cylinder 1.Trim\" ] . axes , ): if axis1 != axis : return False return True @profile def build_delta_summary ( self ): \"\"\"Builds tables to review fit.\"\"\" if self . table_data : input_tables = Tbls () input_tables . append ( self . table_data [ \"Engine.Efficiency.Value\" ]) cyl_trim_unit = self . fueling_tables [ \"Fuel.Cylinder #.Trim\" ][ \"unit\" ] for cyl in range ( 1 , self . n_cyl + 1 ): # Convert indiv tables to base axes name = f \"Fuel.Cylinder { cyl } .Trim\" axes = input_tables [ \"Engine.Efficiency.Value\" ] . axes tmp = self . convert_table_to_axes ( self . table_data [ name ], axes ) tmp . name = name input_tables . append ( tmp ) name = f \"Fuel.Cylinder { cyl } .Primary.Trim\" axes = input_tables [ \"Engine.Efficiency.Value\" ] . axes tmp = self . convert_table_to_axes ( self . table_data [ name ], axes ) tmp . name = name input_tables . append ( tmp ) result_tables = Tbls () tmp = Tbl ( input_tables [ \"Engine.Efficiency.Value\" ]) tmp . data *= 0 tmp . name = \"Overall\" tmp . unit = \"ratio\" tmp . snapshot ( \"orig\" ) result_tables . append ( tmp ) for bank in range ( 1 , self . n_banks + 1 ): avg = Tbl ( input_tables [ \"Engine.Efficiency.Value\" ]) avg . data *= 0 avg . name = f \"Bank { bank } .Trim.Avg\" avg . unit = \"ratio\" avg . snapshot ( \"orig\" ) n = 0 for cyl in range ( 1 , self . n_cyl + 1 ): indiv = f \"Fuel.Cylinder { cyl } .Trim\" indiv_prim = f \"Fuel.Cylinder { cyl } .Primary.Trim\" tmp = ( input_tables [ \"Engine.Efficiency.Value\" ] . orig . as_unit ( \"ratio\" ) * input_tables [ indiv ] . orig . as_unit ( \"ratio\" ) * input_tables [ indiv_prim ] . orig . as_unit ( \"ratio\" ) * self . table_data [ \"Fuel.Volume.Trim.Overall\" ] . orig . as_unit ( \"ratio\" ) . data ) tmp . name = f \"Individual { cyl } \" tmp . unit = \"ratio\" tmp . snapshot ( \"orig\" ) tmp . data = ( input_tables [ \"Engine.Efficiency.Value\" ] . as_unit ( \"ratio\" ) * input_tables [ indiv ] . as_unit ( \"ratio\" ) * input_tables [ indiv_prim ] . as_unit ( \"ratio\" ) * self . table_data [ \"Fuel.Volume.Trim.Overall\" ] . as_unit ( \"ratio\" ) . data ) . data result_tables . append ( tmp ) if self . table_data [ f \"Engine.Cylinder { cyl } .Bank\" ] . data [ 0 ] == bank : avg . _archive [ \"orig\" ][ - 1 ] += input_tables [ indiv ] . orig . as_unit ( \"ratio\" ) * input_tables [ indiv_prim ] . orig . as_unit ( \"ratio\" ) avg += input_tables [ indiv ] . as_unit ( \"ratio\" ) * input_tables [ indiv_prim ] . as_unit ( \"ratio\" ) n += 1 result_tables [ \"Overall\" ] . _archive [ \"orig\" ][ - 1 ] += tmp . orig result_tables [ \"Overall\" ] += tmp avg . _archive [ \"orig\" ][ - 1 ] /= n avg /= n result_tables . append ( avg ) result_tables [ \"Overall\" ] . _archive [ \"orig\" ][ - 1 ] /= self . n_cyl result_tables [ \"Overall\" ] /= self . n_cyl # FINALLY res = [ ccg . ui . panel . pn . Spacer ( height = 0 ), ccg . ui . panel . pn . pane . Markdown ( \"\"\"# Overall Fueling Delta This accounts for deltas in the `Engine.Efficiency.Value` table, the mean of the `Fuel.Cylinder #.Trim` and `Fuel.Cylinder #.Primary.Trim` tables, and the `Fuel.Volume.Trim.Overall`.\"\"\" , align = \"start\" , ), ] table = result_tables [ \"Overall\" ] axes_data = table . axes prec_args = { \"axis_names\" : [ f \" { axis . name } [ { axis . unit } ]\" for axis in axes_data ], \"axis_breakpoints\" : [ axis . data . tolist () for axis in axes_data ], \"axis_precisions\" : [ axis . precision for axis in axes_data ], \"data_precision\" : table . precision , \"locked\" : table . locked . T . tolist (), } res . append ( ccg . ui . panel . CalDataTbl ( name = \"Overall Fueling Delta %\" , table_name = \"Overall Fueling Delta [%]\" , data = table . delta_perc . T . tolist (), editable = False , colorscale = \"RdBu\" , colorscale_center = 0 , align = \"center\" , ** prec_args , ) ) res . append ( ccg . ui . panel . pn . pane . Markdown ( \"\"\"# Bank Average Cyl Trims Includes both `Trim` and `Primary.Trim`.\"\"\" , align = \"start\" , ) ) for bank in range ( 1 , self . n_banks + 1 ): name = f \"Bank { bank } .Trim.Avg\" table = result_tables [ name ] . as_unit ( cyl_trim_unit ) axes_data = table . axes prec_args = { \"axis_names\" : [ f \" { axis . name } [ { axis . unit } ]\" for axis in axes_data ], \"axis_breakpoints\" : [ axis . data . tolist () for axis in axes_data ], \"axis_precisions\" : [ axis . precision for axis in axes_data ], \"data_precision\" : table . precision , \"locked\" : table . locked . T . tolist (), } res . append ( ccg . ui . panel . CalDataTbl ( name = name , table_name = f \" { name } [ { cyl_trim_unit } ]\" , data = table . data . T . tolist (), editable = False , colorscale = \"RdBu\" , colorscale_center = 0 , align = \"center\" , ** prec_args , ) ) res . append ( ccg . ui . panel . pn . pane . Markdown ( \"\"\"# Individual Cylinder Fueling Deltas These accounts for deltas in the `Engine.Efficiency.Value` table, the the `Fuel.Cylinder #.Trim` and `Fuel.Cylinder #.Primary.Trim` tables, and the `Fuel.Volume.Trim.Overall`.\"\"\" , align = \"start\" , ) ) for cyl in range ( 1 , self . n_cyl + 1 ): name = f \"Individual { cyl } \" table = result_tables [ name ] axes_data = table . axes prec_args = { \"axis_names\" : [ f \" { axis . name } [ { axis . unit } ]\" for axis in axes_data ], \"axis_breakpoints\" : [ axis . data . tolist () for axis in axes_data ], \"axis_precisions\" : [ axis . precision for axis in axes_data ], \"data_precision\" : table . precision , \"locked\" : table . locked . T . tolist (), } res . append ( ccg . ui . panel . CalDataTbl ( name = f \" { name } Fueling Delta %\" , table_name = f \" { name } Fueling Delta [%]\" , data = table . delta_perc . T . tolist (), editable = False , colorscale = \"RdBu\" , colorscale_center = 0 , align = \"center\" , ** prec_args , ) ) return res def convert_table_to_axes ( self , table : Tbl , target : Axes ): \"\"\"Convert a table to fit the target axes if possible.\"\"\" res = Tbl ( name = \"result\" , axes = target , unit = table . unit ) if target . n_dim > 2 : raise NotImplementedError if target . n_dim < table . n_dim : raise NotImplementedError if table . n_dim == 0 : res . data = np . ones ( target . shape ) * table . orig . data res . snapshot ( \"orig\" ) res . data = np . ones ( target . shape ) * table . data return res # Leave in target units, convert table before interpolating. target_grid = target . grid interp_grid = target . grid units = [ \"\" ] * table . n_dim for j , axis in enumerate ( target ): found = False for i , t_axis in enumerate ( table . axes ): if axis . name == t_axis . name : interp_grid [ i ] = target_grid [ j ] units [ i ] = axis . unit found = True break if not found : # Check for possible calc if axis . name == \"Inlet.Manifold.Pressure\" : if \"Engine.Load.Normalised\" in table . axes : i = table . axes . index ( \"Engine.Load.Normalised\" ) # Calc engine load normalized mode = self . table_data [ \"Engine.Load.Normalised.Mode\" ] . data if mode == \"Normal\" : raise NotImplementedError elif mode == \"Inlet Manifold Pressure\" : tmp = Axis ( axis ) tmp . data = axis . data / ccg . util . convert_units ( 101.325 , \"kPa\" , axis . unit , ) interp_grid [ i ] = target_grid [ j ] units [ i ] = \"ratio\" elif mode == \"Throttle Position\" : eng_speed_ind = target . index ( \"Engine.Speed\" ) imap_ind = target . index ( \"Inlet.Manifold.Pressure\" ) interp_grid [ i ] = self . tps_from_map ( eng_speed = target_grid [ eng_speed_ind ], imap = target_grid [ imap_ind ], ) units [ i ] = \"%\" for unit , axis in zip ( units , table . axes ): axis . convert_units ( unit ) interp_vals = np . array ([ x . flatten () for x in interp_grid ]) . T res . data = table . orig . interp ( interp_vals ) . reshape ( target . shape , order = \"f\" ) res . snapshot ( \"orig\" ) res . data = table . interp ( interp_vals ) . reshape ( target . shape , order = \"f\" ) # res.plot() return res def tps_from_map ( self , eng_speed : npt . NDArray , imap : npt . NDArray ): \"\"\"Estimate Throttle.Position from manifold air pressure.\"\"\" n = 100 tps_map = Tbl ( self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Main\" ]) tps_map . name = \"TPS Estimate\" tps_map . interp_on_axis_change = True tps_map . data *= 0 tps_map . f_orig = 0 tps_map . f_smooth = [ 0.001 , 0.001 ] map_unit = self . fueling_tables [ \"Engine.Efficiency.Value\" ][ \"axes\" ][ \"Z\" ][ \"unit\" ] tps_unit = tps_map . axes [ \"Throttle.Position\" ] . unit tps = np . linspace ( tps_map . axes [ \"Throttle.Position\" ] . data . min (), tps_map . axes [ \"Throttle.Position\" ] . data . max (), n , ) eng_spd = np . linspace ( tps_map . axes [ \"Engine.Speed\" ] . data . min (), tps_map . axes [ \"Engine.Speed\" ] . data . max (), n , ) bps = [ x . flatten () for x in np . meshgrid ( tps , eng_spd )] maps = ( self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Main\" ] . as_unit ( \"ratio\" ) . interp ( np . array ( bps ) . T ) * self . table_data [ \"Ambient.Pressure.Default.Value\" ] . as_unit ( map_unit ) . data ) map_bps = np . linspace ( 10 , 101 , 40 , ) tps_map . axes [ \"Throttle.Position\" ] . data = map_bps tps_map . axes [ \"Throttle.Position\" ] . name = \"Inlet.Manifold.Pressure\" tps_map . axes [ \"Inlet.Manifold.Pressure\" ] . unit = map_unit tps_map . unit = tps_unit new_grid = [ maps , bps [ 1 ], bps [ 0 ]] tps_map . scatter_data = ScatterData ( new_grid ) tps_map . fit () # tps_map.plot() interps = np . array ([ imap , eng_speed ]) . T return np . clip ( tps_map . interp ( interps ), 0 , 100 )","title":"LOORRS"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.LOORRS.build_delta_summary","text":"Builds tables to review fit. Source code in ccg\\controllers\\motec.py 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 2025 2026 2027 2028 2029 2030 2031 2032 2033 2034 2035 2036 2037 2038 2039 2040 2041 2042 2043 2044 2045 2046 2047 2048 2049 2050 2051 2052 2053 2054 2055 2056 2057 2058 2059 2060 2061 2062 2063 2064 2065 2066 2067 2068 2069 2070 2071 2072 2073 2074 2075 2076 2077 2078 2079 2080 2081 2082 2083 2084 2085 2086 2087 2088 2089 2090 2091 2092 2093 2094 2095 2096 2097 2098 2099 2100 2101 2102 2103 2104 2105 2106 2107 2108 2109 2110 2111 2112 2113 2114 2115 2116 2117 2118 2119 2120 2121 2122 2123 2124 2125 2126 2127 2128 2129 2130 2131 2132 2133 2134 2135 2136 2137 2138 2139 2140 2141 2142 2143 2144 2145 2146 2147 2148 2149 2150 2151 2152 2153 2154 @profile def build_delta_summary ( self ): \"\"\"Builds tables to review fit.\"\"\" if self . table_data : input_tables = Tbls () input_tables . append ( self . table_data [ \"Engine.Efficiency.Value\" ]) cyl_trim_unit = self . fueling_tables [ \"Fuel.Cylinder #.Trim\" ][ \"unit\" ] for cyl in range ( 1 , self . n_cyl + 1 ): # Convert indiv tables to base axes name = f \"Fuel.Cylinder { cyl } .Trim\" axes = input_tables [ \"Engine.Efficiency.Value\" ] . axes tmp = self . convert_table_to_axes ( self . table_data [ name ], axes ) tmp . name = name input_tables . append ( tmp ) name = f \"Fuel.Cylinder { cyl } .Primary.Trim\" axes = input_tables [ \"Engine.Efficiency.Value\" ] . axes tmp = self . convert_table_to_axes ( self . table_data [ name ], axes ) tmp . name = name input_tables . append ( tmp ) result_tables = Tbls () tmp = Tbl ( input_tables [ \"Engine.Efficiency.Value\" ]) tmp . data *= 0 tmp . name = \"Overall\" tmp . unit = \"ratio\" tmp . snapshot ( \"orig\" ) result_tables . append ( tmp ) for bank in range ( 1 , self . n_banks + 1 ): avg = Tbl ( input_tables [ \"Engine.Efficiency.Value\" ]) avg . data *= 0 avg . name = f \"Bank { bank } .Trim.Avg\" avg . unit = \"ratio\" avg . snapshot ( \"orig\" ) n = 0 for cyl in range ( 1 , self . n_cyl + 1 ): indiv = f \"Fuel.Cylinder { cyl } .Trim\" indiv_prim = f \"Fuel.Cylinder { cyl } .Primary.Trim\" tmp = ( input_tables [ \"Engine.Efficiency.Value\" ] . orig . as_unit ( \"ratio\" ) * input_tables [ indiv ] . orig . as_unit ( \"ratio\" ) * input_tables [ indiv_prim ] . orig . as_unit ( \"ratio\" ) * self . table_data [ \"Fuel.Volume.Trim.Overall\" ] . orig . as_unit ( \"ratio\" ) . data ) tmp . name = f \"Individual { cyl } \" tmp . unit = \"ratio\" tmp . snapshot ( \"orig\" ) tmp . data = ( input_tables [ \"Engine.Efficiency.Value\" ] . as_unit ( \"ratio\" ) * input_tables [ indiv ] . as_unit ( \"ratio\" ) * input_tables [ indiv_prim ] . as_unit ( \"ratio\" ) * self . table_data [ \"Fuel.Volume.Trim.Overall\" ] . as_unit ( \"ratio\" ) . data ) . data result_tables . append ( tmp ) if self . table_data [ f \"Engine.Cylinder { cyl } .Bank\" ] . data [ 0 ] == bank : avg . _archive [ \"orig\" ][ - 1 ] += input_tables [ indiv ] . orig . as_unit ( \"ratio\" ) * input_tables [ indiv_prim ] . orig . as_unit ( \"ratio\" ) avg += input_tables [ indiv ] . as_unit ( \"ratio\" ) * input_tables [ indiv_prim ] . as_unit ( \"ratio\" ) n += 1 result_tables [ \"Overall\" ] . _archive [ \"orig\" ][ - 1 ] += tmp . orig result_tables [ \"Overall\" ] += tmp avg . _archive [ \"orig\" ][ - 1 ] /= n avg /= n result_tables . append ( avg ) result_tables [ \"Overall\" ] . _archive [ \"orig\" ][ - 1 ] /= self . n_cyl result_tables [ \"Overall\" ] /= self . n_cyl # FINALLY res = [ ccg . ui . panel . pn . Spacer ( height = 0 ), ccg . ui . panel . pn . pane . Markdown ( \"\"\"# Overall Fueling Delta This accounts for deltas in the `Engine.Efficiency.Value` table, the mean of the `Fuel.Cylinder #.Trim` and `Fuel.Cylinder #.Primary.Trim` tables, and the `Fuel.Volume.Trim.Overall`.\"\"\" , align = \"start\" , ), ] table = result_tables [ \"Overall\" ] axes_data = table . axes prec_args = { \"axis_names\" : [ f \" { axis . name } [ { axis . unit } ]\" for axis in axes_data ], \"axis_breakpoints\" : [ axis . data . tolist () for axis in axes_data ], \"axis_precisions\" : [ axis . precision for axis in axes_data ], \"data_precision\" : table . precision , \"locked\" : table . locked . T . tolist (), } res . append ( ccg . ui . panel . CalDataTbl ( name = \"Overall Fueling Delta %\" , table_name = \"Overall Fueling Delta [%]\" , data = table . delta_perc . T . tolist (), editable = False , colorscale = \"RdBu\" , colorscale_center = 0 , align = \"center\" , ** prec_args , ) ) res . append ( ccg . ui . panel . pn . pane . Markdown ( \"\"\"# Bank Average Cyl Trims Includes both `Trim` and `Primary.Trim`.\"\"\" , align = \"start\" , ) ) for bank in range ( 1 , self . n_banks + 1 ): name = f \"Bank { bank } .Trim.Avg\" table = result_tables [ name ] . as_unit ( cyl_trim_unit ) axes_data = table . axes prec_args = { \"axis_names\" : [ f \" { axis . name } [ { axis . unit } ]\" for axis in axes_data ], \"axis_breakpoints\" : [ axis . data . tolist () for axis in axes_data ], \"axis_precisions\" : [ axis . precision for axis in axes_data ], \"data_precision\" : table . precision , \"locked\" : table . locked . T . tolist (), } res . append ( ccg . ui . panel . CalDataTbl ( name = name , table_name = f \" { name } [ { cyl_trim_unit } ]\" , data = table . data . T . tolist (), editable = False , colorscale = \"RdBu\" , colorscale_center = 0 , align = \"center\" , ** prec_args , ) ) res . append ( ccg . ui . panel . pn . pane . Markdown ( \"\"\"# Individual Cylinder Fueling Deltas These accounts for deltas in the `Engine.Efficiency.Value` table, the the `Fuel.Cylinder #.Trim` and `Fuel.Cylinder #.Primary.Trim` tables, and the `Fuel.Volume.Trim.Overall`.\"\"\" , align = \"start\" , ) ) for cyl in range ( 1 , self . n_cyl + 1 ): name = f \"Individual { cyl } \" table = result_tables [ name ] axes_data = table . axes prec_args = { \"axis_names\" : [ f \" { axis . name } [ { axis . unit } ]\" for axis in axes_data ], \"axis_breakpoints\" : [ axis . data . tolist () for axis in axes_data ], \"axis_precisions\" : [ axis . precision for axis in axes_data ], \"data_precision\" : table . precision , \"locked\" : table . locked . T . tolist (), } res . append ( ccg . ui . panel . CalDataTbl ( name = f \" { name } Fueling Delta %\" , table_name = f \" { name } Fueling Delta [%]\" , data = table . delta_perc . T . tolist (), editable = False , colorscale = \"RdBu\" , colorscale_center = 0 , align = \"center\" , ** prec_args , ) ) return res","title":"build_delta_summary"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.LOORRS.check_axes","text":"Check if cyl trim axes match Source code in ccg\\controllers\\motec.py 1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978 def check_axes ( self ): \"\"\"Check if cyl trim axes match\"\"\" for i in range ( 2 , self . n_cyl + 1 ): for axis , axis1 in zip ( self . table_data [ f \"Fuel.Cylinder { i } .Trim\" ] . axes , self . table_data [ \"Fuel.Cylinder 1.Trim\" ] . axes , ): if axis1 != axis : return False return True","title":"check_axes"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.LOORRS.check_sigs","text":"Check that required input sigs are present. Source code in ccg\\controllers\\motec.py 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 @profile def check_sigs ( self ): \"\"\"Check that required input sigs are present.\"\"\" if self . table_data and self . data : msgs = self . check_substitute_sigs () required_sigs = set ( [ \"Fuel.Mixture Aim\" , \"Engine.Efficiency\" , \"Fuel.Volume.Trim\" , \"Fuel.Volume.Compensation\" , \"Coolant.Temperature.Fuel Volume Compensation\" , ] ) for table in self . fueling_tables : for axis in self . table_data [ table . replace ( \"#\" , \"1\" )] . axes : required_sigs . add ( axis . name ) for i in range ( 1 , self . n_cyl + 1 ): required_sigs . add ( f \"Fuel.Cylinder { i } .Trim\" ) required_sigs . add ( f \"Fuel.Cylinder { i } .Primary.Trim\" ) required_sigs . add ( f \"Exhaust.Lambda.Cylinder { i } \" ) for i in range ( 1 , self . n_banks + 1 ): required_sigs . add ( f \"Exhaust.Lambda.Bank { i } \" ) required_sigs . add ( f \"Fuel.Closed Loop.Control.Bank { i } .Trim\" ) if ( \"Ambient Pressure Relative\" in self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Mode\" ] . data ): required_sigs . add ( \"Ambient.Pressure\" ) ok_slow = [ \"Ambient.Pressure\" , \"Fuel.Mixture Aim\" , \"Fuel.Volume.Trim\" , \"Fuel.Volume.Compensation\" , \"Inlet.Manifold.Pressure.Estimate\" , \"Coolant.Temperature.Fuel Volume Compensation\" , \"Coolant.Temperature\" , ] extras = [ \"Inlet.Manifold.Pressure.Estimate\" , \"Inlet.Air.Temperature\" , \"Vehicle.Speed\" , \"Ignition.Cut\" , \"Ignition.Timing\" , \"Idle.State\" , \"Fuel.Volume.Transient\" , \"Fuel.Volume.Trim\" , \"Fuel.Volume.Compensation\" , \"Fuel.Timing.Primary\" , \"Fuel.Temperature\" , \"Fuel.Pressure\" , \"Fuel.Injector.Primary.Duty.Cycle\" , \"Fuel.Film.Primary\" , \"Fuel.Cut\" , \"Engine.Load\" , \"Coolant.Pressure\" , \"Engine.Charge.Temperature\" , \"Engine.Oil.Temperature\" , \"Engine.Oil.Pressure\" , \"ECU.Batter.Voltage\" , ] required_sigs = list ( required_sigs ) missing = [] for sig in required_sigs : if sig not in self . data : missing . append ( sig ) for sig in self . gate . sigs : if sig not in self . data and sig not in self . calcd_sigs : missing . append ( sig ) if missing : missing . sort () # msg = \"<br>\".join(missing) if self . warning_dialog : msgs . extend ([ \" \\n ## Missing Required Signals \\n \" , * missing ]) self . warning_dialog ( title = \"# Missing Signals\" , msg = \"<br>\" . join ( msgs ) ) return False raise ValueError ( f \"Missing Required Signals \\n { missing } \" ) for sig in required_sigs : if sig not in ok_slow : self . slow_sig = sig break for sig in required_sigs : if ( sig not in ok_slow and self . data [ sig ] . period > self . data [ self . slow_sig ] . period ): self . slow_sig = sig for sig in self . gate . sigs : if sig not in self . calcd_sigs and sig not in required_sigs : required_sigs . append ( sig ) tline = self . data [ self . slow_sig ] . tline self . resampled = self . data [ required_sigs ] . resample ( tline ) self . resampled . name = \"Resampled Data for Calc's\" self . data . math_tline = tline self . resampled . math_tline = tline for sig in extras : try : self . resampled . append ( self . data [ sig ] . resample ( tline )) except KeyError : pass if self . slow_freq < 50 : msgs . extend ( [ \" \\n ## Slow Signal \\n \" , f \"Calculation rate limited to { self . slow_freq } Hz by ` { self . slow_sig } `\" , ] ) if msgs : self . warning_dialog ( title = \"# Missing Signals\" , msg = \"<br>\" . join ( msgs )) return True else : return False","title":"check_sigs"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.LOORRS.check_substitute_sigs","text":"Try to substitute for some common missing sigs. Source code in ccg\\controllers\\motec.py 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 def check_substitute_sigs ( self ): \"\"\"Try to substitute for some common missing sigs.\"\"\" msgs = [] if self . table_data and self . data : try : mode = self . table_data [ \"Engine.Load.Normalised.Mode\" ] . data if mode == \"Normal\" : # Value = # p * # Engine.Efficiency * # Fuel Vapour Correction * # (Engine.Displacement / Engine.Cylinders) * // Displacement of one cylinder # (1 / (Constants.rAir * (Engine.Charge.Temperature + 273.15))); // Ideal gas law # when (Normalised.Mode) # { # is (Normal) # { # local ideal = # Ambient.Pressure.Standard * # 1.0 * # 1.0 * # (Engine.Displacement / Engine.Cylinders) * // Displacement of one cylinder # (1 / (Constants.rAir * (Constants.standardTemperature + 273.15))); // Ideal gas law # Normalised = Value / ideal; raise NotImplementedError elif mode == \"Inlet.Manifold.Pressure\" : sig = Sig ( name = \"Engine.Load.Normalised\" , data = self . data [ \"Inlet.Manifold.Pressure\" ] / ccg . util . convert_units ( 101.325 , \"kPa\" , self . data [ \"Inlet.Manifold.Pressure\" ] . unit , ), tline = self . data [ \"Inlet.Manifold.Pressure\" ] . tline , unit = \"ratio\" , ) elif mode == \"Throttle Position\" : sig = Sig ( name = \"Engine.Load.Normalised\" , data = self . data [ \"Throttle.Position\" ], ) sig . convert_units ( \"%\" ) if \"Engine.Load.Normalised\" not in self . data : self . data . append ( sig ) msgs . append ( \"`Engine.Load.Normalized` was not logged and has been calculated from input signals.\" ) elif sig . period < self . data [ \"Engine.Load.Normalised\" ] . period : self . data . remove ( \"Engine.Load.Normalised\" ) self . data . append ( sig ) msgs . append ( \"`Engine.Load.Normalized` was logged slowly and has been calculated from input signals.\" ) except KeyError : pass try : if \"Fuel.Volume.Trim\" not in self . data : sig = self . table_data [ \"Fuel.Volume.Trim.Overall\" ][ self . data ] sig . name = \"Fuel.Volume.Trim\" self . data . append ( sig ) msgs . append ( \"`Fuel.Volume.Trim` was not logged and has been calculated from the loaded calibration. ** Ensure that this matches the calibration that generated the data **\" ) except KeyError : pass for i in range ( 1 , self . n_cyl + 1 ): try : name = f \"Fuel.Cylinder { i } .Trim\" if name not in self . data : sig = self . table_data [ name ][ self . data ] self . data . append ( sig ) msgs . append ( f \"` { name } ` was not logged and has been calculated from the loaded calibration. ** Ensure that this matches the calibration that generated the data **\" ) except KeyError : pass try : name = f \"Fuel.Cylinder { i } .Primary.Trim\" if name not in self . data : sig = self . table_data [ name ][ self . data ] self . data . append ( sig ) msgs . append ( f \"` { name } ` was not logged and has been calculated from the loaded calibration. ** Ensure that this matches the calibration that generated the data **\" ) except KeyError : pass try : if \"Coolant.Temperature.Fuel Volume Compensation\" not in self . data : sig = Sig ( self . data [ \"Fuel.Volume.Compensation\" ]) sig . name = \"Coolant.Temperature.Fuel Volume Compensation\" self . data . append ( sig ) msgs . append ( \"`Coolant.Temperature.Fuel Volume Compensation` was not logged and has been substituted with `Fuel.Volume.Compensation`. ** Ensure that no other volume compensation was active. **\" ) except KeyError : pass if msgs : msgs = [ \"## Substituted Signals \\n \" , * msgs ] return msgs","title":"check_substitute_sigs"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.LOORRS.convert_table_to_axes","text":"Convert a table to fit the target axes if possible. Source code in ccg\\controllers\\motec.py 2156 2157 2158 2159 2160 2161 2162 2163 2164 2165 2166 2167 2168 2169 2170 2171 2172 2173 2174 2175 2176 2177 2178 2179 2180 2181 2182 2183 2184 2185 2186 2187 2188 2189 2190 2191 2192 2193 2194 2195 2196 2197 2198 2199 2200 2201 2202 2203 2204 2205 2206 2207 2208 2209 2210 2211 2212 2213 2214 2215 2216 2217 2218 2219 2220 def convert_table_to_axes ( self , table : Tbl , target : Axes ): \"\"\"Convert a table to fit the target axes if possible.\"\"\" res = Tbl ( name = \"result\" , axes = target , unit = table . unit ) if target . n_dim > 2 : raise NotImplementedError if target . n_dim < table . n_dim : raise NotImplementedError if table . n_dim == 0 : res . data = np . ones ( target . shape ) * table . orig . data res . snapshot ( \"orig\" ) res . data = np . ones ( target . shape ) * table . data return res # Leave in target units, convert table before interpolating. target_grid = target . grid interp_grid = target . grid units = [ \"\" ] * table . n_dim for j , axis in enumerate ( target ): found = False for i , t_axis in enumerate ( table . axes ): if axis . name == t_axis . name : interp_grid [ i ] = target_grid [ j ] units [ i ] = axis . unit found = True break if not found : # Check for possible calc if axis . name == \"Inlet.Manifold.Pressure\" : if \"Engine.Load.Normalised\" in table . axes : i = table . axes . index ( \"Engine.Load.Normalised\" ) # Calc engine load normalized mode = self . table_data [ \"Engine.Load.Normalised.Mode\" ] . data if mode == \"Normal\" : raise NotImplementedError elif mode == \"Inlet Manifold Pressure\" : tmp = Axis ( axis ) tmp . data = axis . data / ccg . util . convert_units ( 101.325 , \"kPa\" , axis . unit , ) interp_grid [ i ] = target_grid [ j ] units [ i ] = \"ratio\" elif mode == \"Throttle Position\" : eng_speed_ind = target . index ( \"Engine.Speed\" ) imap_ind = target . index ( \"Inlet.Manifold.Pressure\" ) interp_grid [ i ] = self . tps_from_map ( eng_speed = target_grid [ eng_speed_ind ], imap = target_grid [ imap_ind ], ) units [ i ] = \"%\" for unit , axis in zip ( units , table . axes ): axis . convert_units ( unit ) interp_vals = np . array ([ x . flatten () for x in interp_grid ]) . T res . data = table . orig . interp ( interp_vals ) . reshape ( target . shape , order = \"f\" ) res . snapshot ( \"orig\" ) res . data = table . interp ( interp_vals ) . reshape ( target . shape , order = \"f\" ) # res.plot() return res","title":"convert_table_to_axes"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.LOORRS.normalize_cyl_trims","text":"Normalizes cyl trims if bp's match. Source code in ccg\\controllers\\motec.py 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 1961 1962 1963 1964 1965 1966 def normalize_cyl_trims ( self ): \"\"\"Normalizes cyl trims if bp's match.\"\"\" cyl_trim_min = self . fueling_tables [ \"Fuel.Cylinder #.Trim\" ][ \"range\" ][ 0 ] cyl_trim_max = self . fueling_tables [ \"Fuel.Cylinder #.Trim\" ][ \"range\" ][ 1 ] cyl_trim_unit = self . fueling_tables [ \"Fuel.Cylinder #.Trim\" ][ \"unit\" ] prim_trim_unit = self . fueling_tables [ \"Fuel.Cylinder #.Primary.Trim\" ][ \"unit\" ] if self . check_axes (): avg = np . zeros ( self . table_data [ \"Fuel.Cylinder 1.Trim\" ] . data . shape ) n = 0 for cyl in range ( 1 , self . n_cyl + 1 ): avg += self . table_data [ f \"Fuel.Cylinder { cyl } .Trim\" ] . data n += 1 avg = ccg . util . convert_units ( avg / n , cyl_trim_unit , \"ratio\" ) axes_names_equal = True for cyl in range ( 1 , self . n_cyl + 1 ): cyl_trim = ( self . table_data [ f \"Fuel.Cylinder { cyl } .Trim\" ] . as_unit ( \"ratio\" ) . data / avg ) cyl_trim = ccg . util . convert_units ( cyl_trim , \"ratio\" , cyl_trim_unit ) if np . any ( cyl_trim > cyl_trim_max ): prim_trim = ( np . maximum ( cyl_trim - cyl_trim_max , 0 ) / cyl_trim_max + 1 ) prim_trim = ccg . util . convert_units ( prim_trim , \"ratio\" , prim_trim_unit ) for i , axis in enumerate ( self . table_data [ f \"Fuel.Cylinder { cyl } .Trim\" ] . axes ): axes_names_equal = ( axes_names_equal and self . table_data [ f \"Fuel.Cylinder { cyl } .Primary.Trim\" ] . axes [ i ] . name == axis . name ) if axes_names_equal : self . table_data [ f \"Fuel.Cylinder { cyl } .Primary.Trim\" ] . axes = ( self . table_data [ f \"Fuel.Cylinder { cyl } .Trim\" ] . axes ) self . table_data [ f \"Fuel.Cylinder { cyl } .Primary.Trim\" ] . data = ( prim_trim ) else : self . table_data [ f \"Fuel.Cylinder { cyl } .Primary.Trim\" ] . data *= 0 self . table_data [ f \"Fuel.Cylinder { cyl } .Trim\" ] . data = np . clip ( cyl_trim , cyl_trim_min , cyl_trim_max ) if not axes_names_equal : self . warning_dialog ( title = \"# Primary Trim Issue\" , msg = \"`Fuel.Cylinder #.Primary.Trim` required, but axes conflict. \\n Set `Fuel.Cylinder #.Primary.Trim` axes to match `Fuel.Cylinder #.Trim` in M1 Tune before exporting config.\" , ) else : raise ValueError ( \"Cyl trim axes dont match, cant normalize\" )","title":"normalize_cyl_trims"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.LOORRS.tps_from_map","text":"Estimate Throttle.Position from manifold air pressure. Source code in ccg\\controllers\\motec.py 2222 2223 2224 2225 2226 2227 2228 2229 2230 2231 2232 2233 2234 2235 2236 2237 2238 2239 2240 2241 2242 2243 2244 2245 2246 2247 2248 2249 2250 2251 2252 2253 2254 2255 2256 2257 2258 2259 2260 2261 2262 2263 2264 2265 2266 2267 2268 2269 def tps_from_map ( self , eng_speed : npt . NDArray , imap : npt . NDArray ): \"\"\"Estimate Throttle.Position from manifold air pressure.\"\"\" n = 100 tps_map = Tbl ( self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Main\" ]) tps_map . name = \"TPS Estimate\" tps_map . interp_on_axis_change = True tps_map . data *= 0 tps_map . f_orig = 0 tps_map . f_smooth = [ 0.001 , 0.001 ] map_unit = self . fueling_tables [ \"Engine.Efficiency.Value\" ][ \"axes\" ][ \"Z\" ][ \"unit\" ] tps_unit = tps_map . axes [ \"Throttle.Position\" ] . unit tps = np . linspace ( tps_map . axes [ \"Throttle.Position\" ] . data . min (), tps_map . axes [ \"Throttle.Position\" ] . data . max (), n , ) eng_spd = np . linspace ( tps_map . axes [ \"Engine.Speed\" ] . data . min (), tps_map . axes [ \"Engine.Speed\" ] . data . max (), n , ) bps = [ x . flatten () for x in np . meshgrid ( tps , eng_spd )] maps = ( self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Main\" ] . as_unit ( \"ratio\" ) . interp ( np . array ( bps ) . T ) * self . table_data [ \"Ambient.Pressure.Default.Value\" ] . as_unit ( map_unit ) . data ) map_bps = np . linspace ( 10 , 101 , 40 , ) tps_map . axes [ \"Throttle.Position\" ] . data = map_bps tps_map . axes [ \"Throttle.Position\" ] . name = \"Inlet.Manifold.Pressure\" tps_map . axes [ \"Inlet.Manifold.Pressure\" ] . unit = map_unit tps_map . unit = tps_unit new_grid = [ maps , bps [ 1 ], bps [ 0 ]] tps_map . scatter_data = ScatterData ( new_grid ) tps_map . fit () # tps_map.plot() interps = np . array ([ imap , eng_speed ]) . T return np . clip ( tps_map . interp ( interps ), 0 , 100 )","title":"tps_from_map"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.LOORRS.update_calcd_data","text":"Update calculations for fitting/plotting. Source code in ccg\\controllers\\motec.py 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622 1623 1624 1625 1626 1627 1628 1629 1630 1631 1632 1633 1634 1635 1636 1637 1638 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 1649 1650 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664 1665 1666 1667 1668 1669 1670 1671 1672 1673 1674 1675 1676 1677 1678 1679 1680 1681 1682 1683 1684 1685 1686 1687 1688 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699 1700 1701 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711 1712 1713 1714 1715 1716 1717 1718 1719 1720 @profile def update_calcd_data ( self ): \"\"\"Update calculations for fitting/plotting.\"\"\" if self . _needs_calcs : tic = datetime . now () if self . check_sigs (): if self . table_data : acc = 0 n = 0 for cyl in range ( 1 , 1 + self . n_cyl ): tmp = self . resampled [ f \"Fuel.Cylinder { cyl } .Trim\" ] . as_unit ( \"ratio\" ) * self . resampled [ f \"Fuel.Cylinder { cyl } .Primary.Trim\" ] . as_unit ( \"ratio\" ) tmp . unit = \"ratio\" tmp . name = f \"Fuel.Cylinder { cyl } .Trim.Total\" self . resampled . append ( tmp ) acc = acc + tmp n += 1 acc = acc / n acc . name = \"Cylinder.Trim.Avg\" acc . unit = \"ratio\" self . resampled . append ( acc ) for bank in range ( 1 , self . n_banks + 1 ): tmp = 0 n = 0 for cyl in range ( 1 , 1 + self . n_cyl ): if ( self . table_data [ f \"Engine.Cylinder { cyl } .Bank\" ] . data == bank ): n += 1 tmp = ( tmp + self . resampled [ f \"Exhaust.Lambda.Cylinder { cyl } \" ] ) tmp = tmp / n tmp . name = f \"Lambda.Indiv.Bank { bank } .Avg\" tmp . unit = \"LA\" tmp . data_range = [ 0.6 , 1.4 ] self . resampled . append ( tmp ) tmp = 0 n = 0 for cyl in range ( 1 , 1 + self . n_cyl ): if ( self . table_data [ f \"Engine.Cylinder { cyl } .Bank\" ] . data == bank ): n += 1 tmp = tmp + self . resampled [ f \"Fuel.Cylinder { cyl } .Trim\" ] . as_unit ( \"ratio\" ) * self . resampled [ f \"Fuel.Cylinder { cyl } .Primary.Trim\" ] . as_unit ( \"ratio\" ) tmp = tmp / n tmp . name = f \"Cylinder.Trim.Bank { bank } .Avg\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) self . resampled [ f \"Exhaust.Lambda.Bank { bank } \" ] . data_range = [ 0.6 , 1.4 , ] tmp = self . table_data [ \"Coolant.Temperature.Fuel Volume Compensation\" ][ self . resampled ] . as_unit ( \"ratio\" ) / self . resampled [ \"Fuel.Volume.Compensation\" ] . as_unit ( \"ratio\" ) tmp . name = \"Volume.Comp.Delta\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ \"Fuel.Closed Loop.Control.Bank 1.Trim\" ] . as_unit ( \"ratio\" ) * self . resampled [ \"Fuel.Volume.Trim\" ] . as_unit ( \"ratio\" ) / self . resampled [ \"Volume.Comp.Delta\" ] . as_unit ( \"ratio\" ) * self . resampled [ \"Cylinder.Trim.Bank 1.Avg\" ] * self . resampled [ \"Exhaust.Lambda.Bank 1\" ] / self . resampled [ \"Fuel.Mixture Aim\" ] ) # TODO: Fix for only 1 bank tmp . name = \"Fueling.Error.Bank 1\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ \"Fuel.Closed Loop.Control.Bank 2.Trim\" ] . as_unit ( \"ratio\" ) * self . resampled [ \"Fuel.Volume.Trim\" ] . as_unit ( \"ratio\" ) / self . resampled [ \"Volume.Comp.Delta\" ] . as_unit ( \"ratio\" ) * self . resampled [ \"Cylinder.Trim.Bank 2.Avg\" ] * self . resampled [ \"Exhaust.Lambda.Bank 2\" ] / self . resampled [ \"Fuel.Mixture Aim\" ] ) tmp . name = \"Fueling.Error.Bank 2\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ \"Fueling.Error.Bank 1\" ] + self . resampled [ \"Fueling.Error.Bank 2\" ] ) / 2 tmp . name = \"Fueling.Error.Total\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = self . resampled [ \"Fueling.Error.Total\" ] * ( self . resampled [ \"Engine.Efficiency\" ] ) tmp . name = \"Engine.Efficiency.Value.Corrected\" tmp . unit = \"%\" self . resampled . append ( tmp ) self . resampled . append ( Sig ( self . resampled [ \"Engine.Efficiency\" ], name = \"Engine.Efficiency.Value\" , ) ) # copy with name to match table for cyl in range ( 1 , 1 + self . n_cyl ): bank = int ( self . table_data [ f \"Engine.Cylinder { cyl } .Bank\" ] . data ) tmp = ( self . resampled [ f \"Exhaust.Lambda.Cylinder { cyl } \" ] / self . resampled [ f \"Lambda.Indiv.Bank { bank } .Avg\" ] ) tmp . name = f \"Cyl { cyl } .Lam.Error\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ f \"Fuel.Cylinder { cyl } .Trim.Total\" ] / self . resampled [ f \"Cylinder.Trim.Bank { bank } .Avg\" ] ) tmp . name = f \"Fuel.Cylinder { cyl } .Trim.Bank Normalised\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ f \"Fuel.Cylinder { cyl } .Trim.Total\" ] / self . resampled [ \"Cylinder.Trim.Avg\" ] ) tmp . name = f \"Fuel.Cylinder { cyl } .Trim.Normalised\" tmp . unit = \"ratio\" self . resampled . append ( tmp ) tmp = ( self . resampled [ f \"Fuel.Cylinder { cyl } .Trim.Bank Normalised\" ] * self . resampled [ f \"Cyl { cyl } .Lam.Error\" ] * ( self . resampled [ f \"Fueling.Error.Bank { bank } \" ] / self . resampled [ \"Fueling.Error.Total\" ] ) ) tmp . name = f \"Fuel.Cylinder { cyl } .Trim.Corrected\" tmp . unit = \"ratio\" tmp . convert_units ( \"%Trim\" ) self . resampled . append ( tmp ) # Calc cyl trims from tailpipe data incase indiv missing tmp = self . resampled [ f \"Fuel.Cylinder { cyl } .Trim.Normalised\" ] * ( self . resampled [ f \"Fueling.Error.Bank { bank } \" ] / self . resampled [ \"Fueling.Error.Total\" ] ) tmp . name = f \"Fuel.Cylinder { cyl } .Trim.Corrected.Tailpipe\" tmp . unit = \"ratio\" tmp . convert_units ( \"%Trim\" ) self . resampled . append ( tmp ) self . resampled [ f \"Exhaust.Lambda.Cylinder { cyl } \" ] . data_range = [ 0.6 , 1.4 , ] self . resampled . append ( self . resampled [ \"Engine.Speed\" ] . dot ( n_win = 17 )) self . resampled . append ( self . resampled [ \"Throttle.Position\" ] . dot ( n_win = 7 ) ) # inlet manifold press ref try : if ( \"Ambient Pressure Relative\" in self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Mode\" ] . data ): tmp = ( self . resampled [ \"Inlet.Manifold.Pressure\" ] / self . resampled [ \"Ambient.Pressure\" ] ) else : tmp = self . resampled [ \"Inlet.Manifold.Pressure\" ] / 100 tmp . name = \"Inlet.Manifold.Pressure.Estimate.Main.Corrected\" tmp . unit = \"ratio\" tmp . convert_units ( \"%\" ) self . resampled . append ( tmp ) if ( \"Ambient Pressure Relative\" in self . table_data [ \"Inlet.Manifold.Pressure.Estimate.Mode\" ] . data ): tmp = ( self . resampled [ \"Inlet.Manifold.Pressure.Estimate\" ] / self . resampled [ \"Ambient.Pressure\" ] ) else : tmp = ( self . resampled [ \"Inlet.Manifold.Pressure.Estimate\" ] / 100 ) tmp . name = \"Inlet.Manifold.Pressure.Estimate.Main\" tmp . unit = \"ratio\" tmp . convert_units ( \"%\" ) self . resampled . append ( tmp ) except KeyError : pass # Coolant temp comps tmp = ( self . resampled [ \"Engine.Efficiency.Value.Corrected\" ] . as_unit ( \"ratio\" ) / self . table_data [ \"Engine.Efficiency.Value\" ][ self . resampled ] . as_unit ( \"ratio\" ) * self . resampled [ \"Coolant.Temperature.Fuel Volume Compensation\" ] . as_unit ( \"ratio\" ) * self . resampled [ \"Volume.Comp.Delta\" ] . as_unit ( \"ratio\" ) ) tmp . name = \"Coolant.Temperature.Fuel Volume Compensation.Corrected\" tmp . unit = \"ratio\" tmp . convert_units ( \"%Trim\" ) self . resampled . append ( tmp ) toc = datetime . now () - tic _LOGGER . debug ( \"Firmware calcs in %.3f \" , toc . total_seconds ()) # Set some ranges self . resampled [ \"Engine.Speed\" ] . data_range = [ 0 , 8800 ] self . resampled [ \"Fuel.Mixture Aim\" ] . data_range = [ 0.6 , 1.4 ] # Add calc'd signals to data frame for general plot self . data . append ( self . resampled ) self . _needs_calcs = False if not self . _needs_calcs : self . update_scatter_data () # Update options for scatter plots opts = [ \"Relative Density\" , * self . resampled . sigs . keys ()] for tab in self . tabs : tab . color_sig . options = opts","title":"update_calcd_data"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.LOORRS.update_scatter_data","text":"Update scatter data for fitting. Source code in ccg\\controllers\\motec.py 1722 1723 1724 1725 1726 1727 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741 1742 1743 1744 1745 1746 1747 1748 1749 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 1767 1768 1769 1770 1771 1772 1773 1774 1775 1776 1777 1778 1779 1780 1781 1782 1783 1784 1785 1786 1787 1788 1789 1790 1791 1792 1793 1794 1795 1796 1797 1798 1799 1800 1801 1802 1803 1804 1805 1806 1807 1808 1809 1810 1811 1812 1813 1814 1815 1816 1817 1818 1819 1820 1821 1822 1823 1824 1825 1826 1827 1828 1829 1830 1831 1832 1833 1834 1835 1836 1837 1838 1839 1840 1841 1842 1843 1844 1845 1846 1847 1848 1849 1850 1851 1852 1853 1854 1855 1856 1857 1858 1859 1860 1861 1862 1863 1864 1865 1866 1867 1868 1869 1870 1871 1872 1873 1874 1875 1876 1877 1878 1879 1880 1881 1882 1883 1884 1885 1886 1887 1888 1889 1890 1891 1892 1893 1894 1895 1896 1897 1898 1899 1900 1901 @profile def update_scatter_data ( self ): \"\"\"Update scatter data for fitting.\"\"\" if self . _needs_scatter_update : # Build signal list bank_gate_tables = [ \"Fuel.Cylinder #.Trim\" ] remove_digits = str . maketrans ( \"0123456789\" , \"##########\" ) msg = [] self . use_tailpipes = [ False ] * self . n_banks if self . _needs_calcs : self . update_calcd_data () for table in self . table_data : if f \" { table . name } .Corrected\" in self . resampled . sigs : tmp : list [ Sig ] = [] ranges = [] if table . name . translate ( remove_digits ) in bank_gate_tables : cyl = \"\" . join ( filter ( lambda x : x . isdigit (), table . name )) bank_ind = ( self . table_data [ f \"Engine.Cylinder { cyl } .Bank\" ] . data [ 0 ] - 1 ) if self . tabs [ table . name ] . additional_gate : gate = GateCollAND ( [ self . bank_gates [ bank_ind ], self . tabs [ table . name ] . additional_gate , ] ) else : gate = self . bank_gates [ bank_ind ] tmp_sig = ( self . resampled [ f \" { table . name } .Corrected\" ] . valid ( gate ) . resample ( self . resampled . math_tline ) ) if ( tmp_sig . data . size - np . count_nonzero ( np . isnan ( tmp_sig . data )) < 1 ): msg . append ( f \" \\n ## Individual Cylinder Lambda signals out of limits on bank { bank_ind + 1 } . \\n Bank trim from tailpipe sensor only.\" ) self . use_tailpipes [ bank_ind ] = True if self . tabs [ table . name ] . additional_gate : gate = GateCollAND ( [ self . gate , self . tabs [ table . name ] . additional_gate ] ) else : gate = self . gate tmp_sig = ( self . resampled [ f \" { table . name } .Corrected.Tailpipe\" ] . valid ( gate ) . resample ( self . resampled . math_tline ) ) self . resampled . remove ( f \" { table . name } .Corrected\" ) self . resampled . append ( Sig ( self . resampled [ f \" { table . name } .Corrected.Tailpipe\" ], name = f \" { table . name } .Corrected\" , ) ) for axis in table . axes : tmp . append ( self . resampled [ f \" { axis . name } \" ] . valid ( gate ) . as_unit ( axis . unit ) . resample ( self . resampled . math_tline ) ) ranges . append ([ axis . min , axis . max ]) tmp . append ( tmp_sig ) ranges . append ([ table . min , table . max ]) else : if self . tabs [ table . name ] . additional_gate : gate = GateCollAND ( [ self . gate , self . tabs [ table . name ] . additional_gate ] ) else : gate = self . gate for axis in table . axes : tmp . append ( self . resampled [ f \" { axis . name } \" ] . valid ( gate ) . as_unit ( axis . unit ) . resample ( self . resampled . math_tline ) ) ranges . append ([ axis . min , axis . max ]) tmp_sig = ( self . resampled [ f \" { table . name } .Corrected\" ] . valid ( gate ) . resample ( self . resampled . math_tline ) ) if \"Coolant.Temperature.Fuel Volume Compensation\" in table . name : try : # Need to adjust offset to center at normal op temp op_temp = self . tabs [ table . name ] . op_temp . value ind = table . axes [ 0 ] . bins ( op_temp )[ 0 ] diff = table . axes [ 0 ] . diff [ ind ] zero_inds = np . logical_and ( np . greater ( tmp [ - 1 ] . data , op_temp - diff / 2 ), np . less ( tmp [ - 1 ] . data , op_temp + diff / 2 ), ) zero_val = np . mean ( tmp_sig . data [ zero_inds ]) if np . isnan ( zero_val ): zero_val = 0 tmp_sig -= zero_val except AttributeError : pass tmp . append ( tmp_sig ) ranges . append ([ table . min , table . max ]) color_data = None color_name = None color_unit = None color_range = None if self . tabs [ table . name ] . color_sig . value : name = self . tabs [ table . name ] . color_sig . value [ 0 ] if \"Relative Density\" in name : color_name = name n_bins = [ 70 ] * len ( tmp ) n_bins [ - 1 ] *= 2 bins = [] for vals , intv , n_bin in zip ( tmp , ranges , n_bins ): bins . append ( np . linspace ( np . minimum ( vals . min , intv [ 0 ]), np . maximum ( vals . max , intv [ 1 ]), n_bin , ) ) color_data = scatter_density ( ScatterData ( tmp ), n_bins = bins ) elif name in self . resampled : color_data = ( self . resampled [ name ] . valid ( gate ) . resample ( self . resampled . math_tline ) . data ) color_name = name color_unit = self . resampled [ name ] . unit color_range = self . resampled [ name ] . data_range table . scatter_data = ScatterData ( data = tmp , name = \"Corrected\" , color = color_data , color_unit = color_unit , color_name = color_name , color_range = color_range , ) . clean () # Add logged data trace if table . name in self . resampled : tmp [ - 1 ] = ( self . resampled [ table . name ] . valid ( gate ) . resample ( self . resampled . math_tline ) ) table . scatter_data . append ( ScatterData ( data = tmp , name = \"Logged\" ) . clean () ) else : table . scatter_data = None self . _needs_scatter_update = False if msg and self . _needs_bank_warning : msg = list ( set ( msg )) self . warning_dialog ( title = \"# Fit Data Warning\" , msg = \"<br>\" . join ( msg )) self . _needs_bank_warning = ( # pylint: disable=attribute-defined-outside-init False )","title":"update_scatter_data"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.device_data_reader","text":"Reads the device data from file. Source code in ccg\\controllers\\motec.py 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 def device_data_reader ( file : BufferedReader , _event_loc : int , device_loc : int , sig : Sig = None ) -> Sig : \"\"\"Reads the device data from file.\"\"\" if sig is None : sig = Sig () dev_size = _event_loc - device_loc dev_format = str ( dev_size ) + \"s\" file . seek ( device_loc ) dev_raw = struct . unpack ( dev_format , file . read ( dev_size )) dets = [ 0 , 0 , 1 , 0 , 0 , 14 , dev_size ] # Starting dets dev_data = parse_device_data ( {}, dev_raw [ 0 ], DEVICE_FORMAT , struct . calcsize ( DEVICE_FORMAT ), dets ) if \"lastKey\" in dev_data : del dev_data [ \"lastKey\" ] # we can elim this for key , val in dev_data . items (): setattr ( sig , key , val ) return sig","title":"device_data_reader"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.parse_device_data","text":"Recursive parsing function for device details dev: device info dictionary data: data to parse in bytes frmDet: section details format szDet: size of details dets: section details looks for keyword 'Mo' Source code in ccg\\controllers\\motec.py 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 def parse_device_data ( dev : dict , data : bytes , det_format : int , det_size : int , dets : list ) -> dict : \"\"\"Recursive parsing function for device details dev: device info dictionary data: data to parse in bytes frmDet: section details format szDet: size of details dets: section details looks for keyword 'Mo' \"\"\" i = 0 t = 0 while i < len ( data ) - 1 : i_new = data . find ( b \"Mo\" , i ) if ( i_new < i - 1 ): # no Mo in remainder of data... not sure why its missing the escape seq if ( t > 10 ): # If t is greater than 10, then last try was a false alarm, so Mo is missing i = i_new t = 0 else : t = 999 i = len ( data ) else : i = i_new if i >= 0 : t = data [ i + 2 ] # If t is >10, then this likely isnt a real keyword else : t = 0 if t < 10 : if i == - 1 : # no Mo in this section, so its probably a key or value if ( dets [ - 2 ] == 8 ): # This is a #. seems to be 5 bytes, often 0x02 followed by 4B of # keyfrm = \"<BI\" debugger = \"5s\" elif dets [ - 2 ] == 0 : # String keyfrm = str ( dets [ - 1 ]) + \"s\" debugger = keyfrm elif dets [ - 2 ] == 7 and dets [ - 1 ] == 16 : # Datetime? keyfrm = \"<HHHHHHHH\" debugger = \"16s\" else : # Dont decode the more unusual types return dev key_size = struct . calcsize ( keyfrm ) key_name = struct . unpack ( keyfrm , data [ 0 : key_size ]) t = struct . unpack ( debugger , data [ 0 : key_size ]) if ( dets [ - 2 ] == 8 ): # This is a #. seems to be 5 bytes, often 0x02 followed by 4B of # key_name = key_name [ 1 ] # /(10**keyName[0]) elif dets [ - 2 ] == 0 : # String key_name = ccg . util . byte2str ( key_name [ 0 ]) elif dets [ - 2 ] == 7 and dets [ - 1 ] == 16 : # Datetime? tz = timezone ( - timedelta ( hours = key_name [ 2 ])) key_name = datetime ( key_name [ 0 ], key_name [ 1 ], key_name [ 3 ], key_name [ 4 ], key_name [ 5 ], key_name [ 6 ], key_name [ 7 ] * 1000 , tz , ) if \"lastKey\" in dev : # Then this is a value in lastKey if ( dev [ \"lastKey\" ] in dev ): # If its already in the dev dict then it has _multiple entries if isinstance ( dev [ dev [ \"lastKey\" ]], list ): # If its already a list, append new entry dev [ dev [ \"lastKey\" ]] . append ( key_name ) else : # then this is the second entry, make it into a list dev [ dev [ \"lastKey\" ]] = [ dev [ dev [ \"lastKey\" ]], key_name ] else : dev [ dev [ \"lastKey\" ]] = key_name else : # Then this is a keyName dev [ \"lastKey\" ] = key_name return dev elif i == len ( data ) - 1 : # no Mo in this section return dev i += 2 # length of Mo keyword dets = list ( struct . unpack ( det_format , data [ i : i + det_size ])) i += det_size if dets [ 0 ] < 10 : # this is probably real if dets [ - 2 ] == 10 : # Escape from this level if \"lastKey\" in dev : del dev [ \"lastKey\" ] dev = parse_device_data ( dev , data [ i : i + dets [ - 1 ]], det_format , det_size , dets ) i += dets [ - 1 ] else : i += 1 return dev","title":"parse_device_data"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.parse_value","text":"Convert string to appropriate data type. Source code in ccg\\controllers\\motec.py 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 def parse_value ( text : str , d_type : str ): \"\"\"Convert string to appropriate data type.\"\"\" if d_type in [ DTYPES_TABLE [ \"enum\" ], DTYPES_TABLE [ \"f32\" ]]: try : return float ( text . strip ()) except ValueError as err : if \"-1.#INF\" in text : return np . NINF if \"INF\" in text : return np . Inf raise ValueError from err if d_type in [ DTYPES_TABLE [ \"u32\" ]]: return int ( text . strip (), 0 ) if d_type in [ DTYPES_TABLE [ \"str\" ]]: return text . strip () if d_type in [ DTYPES_TABLE [ \"s32\" ]]: return int ( text . strip ()) raise TypeError ( f \" { d_type } not understood.\" )","title":"parse_value"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.read_ld","text":"Read and parse .ld file. Source code in ccg\\controllers\\motec.py 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 def read_ld ( filenames : str | tuple [ str ] | list [ str ]) -> Frame : \"\"\"Read and parse .ld file.\"\"\" if not ( isinstance ( filenames , list ) or isinstance ( filenames , tuple )): filenames = ( filenames ,) tstart = 0 data = Frame () frame_name = \"\" for filename in filenames : fname = Path ( filename ) with open ( fname , \"rb\" ) as file : frame_name += fname . name + \", \" # Read header data header = seg_reader ( file , 0 , HEADER_FORMAT , HEADER_NAMES , Sig ( name = \"header_data\" ), ) header . tline = TLine ([ tstart ]) # datetime.strptime( # # pylint: disable= no-member # f\"{header.date} {header.time}\", # \"%d/%m/%Y %H:%M:%S\", # ) # # pylint:enable=no-member # .astimezone().astimezone(timezone.utc) # ) # assumes local setting for TZ, then converts to UTC for db header . dev_ver = ( header . dev_ver / 100 # pylint: disable= no-member ) # Dev version seems to have 2 decimals header . filename = filename header . import_time = datetime . now () . astimezone () . astimezone ( timezone . utc ) data . append ( header , append_existing_signals = True ) data . append ( seg_reader ( file , data . header_data . file_event_loc , EVENT_FORMAT , EVENT_NAMES , Sig ( name = \"event_data\" , tline = header . tline ), ), append_existing_signals = True , ) data . append ( seg_reader ( file , data . event_data . file_venue_loc , VENUE_FORMAT , VENUE_NAMES , Sig ( name = \"venue_data\" , tline = header . tline ), ), append_existing_signals = True , ) data . append ( seg_reader ( file , data . venue_data . file_vehicle_loc , VEHICLE_FORMAT , VEHICLE_NAMES , Sig ( name = \"vehicle_data\" , tline = header . tline ), ), append_existing_signals = True , ) data . append ( device_data_reader ( file , data . header_data . file_event_loc , data . header_data . file_dev_loc , Sig ( name = \"device_data\" , tline = header . tline ), ), append_existing_signals = True , ) sigs = sig_reader ( file = file , strt_loc = data . header_data . file_sig_loc , device = data . header_data . dev , start_time = tstart , ) data . append ( sigs , append_existing_signals = True , interweave_tlines = True ) tstart = sigs . tend + 1.0 data . name = frame_name return data","title":"read_ld"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.read_m1cgf","text":"Read .m1cfg xml file to Params. If param_names is not None, only those parameters will be imported. Source code in ccg\\controllers\\motec.py 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 def read_m1cgf ( filename : str | Path , param_names : list [ str ] = None ): \"\"\"Read .m1cfg xml file to Params. If param_names is not None, only those parameters will be imported.\"\"\" tic = datetime . now () if not isinstance ( filename , Path ): filename = Path ( filename ) xml = ET . parse ( filename ) . getroot () pars = [] if param_names is not None : n_par_rem = len ( param_names ) else : n_par_rem = - 1 for table in xml . iter ( \"Table\" ): if param_names is None or table . get ( \"Name\" ) in param_names : n_par_rem -= 1 axes_data = [] axes_units = [] axes_names = [] inds = [] n_axis = - 1 inds = [ 1 , 1 , 1 ] for elem in table . findall ( \"./\" ): d_type = DTYPES_TABLE [ elem [ 0 ] . get ( \"Type\" )] unit = elem [ 0 ] . get ( \"Unit\" ) values = [] for cell in elem . iter ( \"Cell\" ): values . append ( parse_value ( cell . text , d_type )) shp = cell . get ( \"Site\" ) data = np . atleast_1d ( np . array ( values , dtype = d_type )) if elem . tag != \"Body\" : # Axis # Motec data doesnt need to use all available bps axis_ind = [ \"X\" , \"Y\" , \"Z\" ] . index ( elem . tag ) n_axis += 1 diff = data [ 1 :] - data [: - 1 ] ind = np . where ( np . logical_or ( np . append ( False , diff [ 1 :] * diff [: - 1 ] < 0 ), diff == 0 ) )[ 0 ] if np . any ( diff != 0 ): if ind . size > 0 : inds [ axis_ind ] = ind [ 0 ] + 1 data = data [: ind [ 0 ] + 1 ] else : inds [ axis_ind ] = data . size axes_data . append ( data ) axes_units . append ( unit ) axes_names . append ( elem . tag ) else : inds [ axis_ind ] = 1 _LOGGER . debug ( \" %s axis dropped from %s \" , elem . tag , table . get ( \"Name\" ) ) flip_axis = [ False ] * len ( axes_data ) for i , axis in enumerate ( axes_data ): if not ccg . util . monotonic_increasing ( axis ): # motec data can be reversed, but must be monoton flip_axis [ i ] = True axes_data [ i ] = axis [:: - 1 ] axes = Axes ( axes_data = [ Axis ( data = data , unit = unit , name = name ) for data , unit , name in zip ( axes_data , axes_units , axes_names ) ], ) # need to reshape, then trim to active bps, then flip if needed. shp = [ int ( x ) for x in shp . split ( \",\" )] motec_shape = tuple ( x + 1 for x in shp ) max_dim = max ( i if x else 0 for i , x in enumerate ( shp )) + 1 shp = tuple ( x + 1 for x in shp [: max_dim ]) data : npt . NDArray = data . reshape ( shp , order = \"f\" ) # since ij indexing data = np . atleast_1d ( np . squeeze ( data [ np . ix_ ( * [ range ( i ) for i in inds [: max_dim ]])]) ) for i , flip in enumerate ( flip_axis ): if flip : data = np . flip ( data , axis = i ) par = Tbl ( name = table . get ( \"Name\" ), data = data , axes = axes , unit = unit ) par . motec_shape = motec_shape pars . append ( par ) if n_par_rem == 0 : break # Escape early for parameter in xml . iter ( \"Parameter\" ): if param_names is None or parameter . get ( \"Name\" ) in param_names : n_par_rem -= 1 name = parameter . get ( \"Name\" ) for cell in parameter . iter ( \"Cell\" ): tmp = cell . get ( \"Type\" ) tmp = \"str\" if tmp == \"enum\" else tmp d_type = DTYPES_TABLE [ tmp ] unit = cell . get ( \"Unit\" ) data = np . atleast_1d ( np . array ( parse_value ( cell . text , d_type ), dtype = d_type ) ) par = Tbl ( name = name , data = data , unit = unit ) par . motec_shape = ( 0 ,) pars . append ( par ) if n_par_rem == 0 : break # Escape early res = Tbls ( pars , name = filename . name ) toc = datetime . now () - tic _LOGGER . debug ( \"read %s in %.3f \" , res . name , toc . total_seconds ()) return res","title":"read_m1cgf"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.seg_reader","text":"Read segment from binary file. Parameters: file ( BufferedReader ) \u2013 open file to read segment from. strt_location \u2013 starting location to read from. format \u2013 format string to unpack data with. format_names ( list [ str ] ) \u2013 attribute names corresponding to format. Names starting with '_' will be ignored. data ( Sig , default: None ) \u2013 optional CCGSig to put data into. Returns: CCGSig with unpacked data. \u2013 Source code in ccg\\controllers\\motec.py 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 def seg_reader ( file : BufferedReader , strt_loc : int , unpk_format : str , format_names : list [ str ], data : Sig = None , ) -> Sig : \"\"\"Read segment from binary file. Parameters ---------- file open file to read segment from. strt_location starting location to read from. format format string to unpack data with. format_names attribute names corresponding to format. Names starting with '_' will be ignored. data optional CCGSig to put data into. Returns ------- CCGSig with unpacked data. \"\"\" if data is None : data = Sig () file . seek ( strt_loc ) for i , field in enumerate ( struct . unpack ( unpk_format , file . read ( struct . calcsize ( unpk_format ))) ): if not format_names [ i ] . startswith ( \"__\" ): if isinstance ( field , bytes ): field = ccg . util . byte2str ( field ) setattr ( data , format_names [ i ], field ) return data","title":"seg_reader"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.sig_reader","text":"Read signal data from file. Source code in ccg\\controllers\\motec.py 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 def sig_reader ( file : BufferedReader , strt_loc : int , device : str , file_time : datetime = None , start_time : float | datetime = None , ) -> Frame : \"\"\"Read signal data from file.\"\"\" _next_loc = strt_loc frm_sz = struct . calcsize ( SIG_FORMAT ) data = Frame () tstart = None # pylint: disable=no-member while _next_loc : sig = seg_reader ( file , _next_loc , SIG_FORMAT , SIG_NAMES ) if sig . _nsamples > 0 : # Why did the layout change with m1??? if device != \"M1\" : sig . short_name = sig . unit sig . unit = sig . __unk1 # sig.name = ccg.util.clean_name(sig.short_name) sig . name = sig . short_name # Check for longer than std frame full_len = sig . _next_loc - _next_loc if full_len > frm_sz : # import the remaining sig header region # i dont really know what this region is yet, import as bytes ext_len = full_len - frm_sz file . seek ( _next_loc + frm_sz ) ext = file . read ( ext_len ) # Check for long name t_ind = ext . rfind ( b \" \\x00 \" , 0 , - 1 ) t_len = ext [ max ( t_ind , 1 ) - 1 ] if t_len > 32 and t_len < ext_len - t_ind : sig . long_name = ccg . util . byte2str ( ext [ t_ind + 1 : - 1 ]) # sig.name = ccg.util.clean_name(sig.long_name) sig . name = sig . long_name # Read the data file . seek ( sig . _data_loc ) if sig . _data_type == 7 : if sig . _data_type2 == 4 : d_type = np . float32 elif sig . _data_type2 == 2 : d_type = np . float16 else : raise TypeError ( f \"Unexpected data type \\n _sig: % { sig . short_name } \" ) elif sig . _data_type in [ 0 , 3 , 4 , 5 , 6 , 8 ]: if sig . _data_type2 == 4 : d_type = np . int32 elif sig . _data_type2 == 2 : d_type = np . int16 elif sig . _data_type2 == 8 : d_type = np . int64 else : raise TypeError ( f \"Unexpected data type \\n _sig: { sig . short_name } \" ) else : raise TypeError ( f \"Unexpected data type \\n _sig: { sig . short_name } \" ) sig . data = np . fromfile ( file , count = sig . _nsamples , dtype = d_type ) # Choose an efficient data type in case of _ndec>0 if d_type in [ np . int16 , np . int32 ] and sig . _ndec > 0 : d_type = np . float32 elif d_type in [ np . int64 ] and sig . _ndec > 0 : d_type = np . float64 # Scaling for .ld without float type, tries to preserve data type # check if req'd if not ( sig . _denom == 1 and sig . _zero_off == 0 and sig . _multi == 1 and sig . _ndec == 0 ): sig . data = d_type ( ((( sig . data / sig . _denom ) - sig . _zero_off ) * sig . _multi ) * 10 **- sig . _ndec ) if file_time is not None : # No start time info in the file. There is download time, so we can make a bad guess that # it was downloaded immediately. # only calc this once, since different rate signals have a tiny bit different end time. tstart = file_time . timestamp () - sig . nsamples * sig . _freq else : tstart = 0 if start_time is not None : tstart = start_time sig . tline = TLine ( tstart = tstart , nsamples = sig . nsamples , period = 1 / sig . _freq ) data . append ( sig ) _next_loc = sig . _next_loc return data","title":"sig_reader"},{"location":"reference/ccg/controllers/motec/#ccg.controllers.motec.write_m1cfg","text":"Write .m1cfg xml of params. First converts back to units in orig archive. This works well for Params imported with read_m1cfg. Use param_names to export a subset or params. Source code in ccg\\controllers\\motec.py 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 def write_m1cfg ( filename : str | Path , params : Tbls , param_names : list [ str ] = None ): \"\"\"Write .m1cfg xml of params. First converts back to units in `orig` archive. This works well for Params imported with read_m1cfg. Use param_names to export a subset or params.\"\"\" # convert units back # First make a copy to avoid changing base tmp = [] for par in params : tmppar = Tbl ( par ) if hasattr ( par , \"mark\" ): tmppar . mark = par . mark tmp . append ( tmppar ) tmp_params = Tbls ( tmp ) for par , orig in zip ( tmp_params , params ): orig_par = orig . _archive [ \"orig\" ][ 0 ] par . convert_units ( orig_par . unit ) for i in range ( par . n_dim ): par . axes [ i ] . convert_units ( orig_par . axes [ i ] . unit ) par . axes [ i ] . name = orig_par . axes [ i ] . name xml = ET . Element ( \"Configuration\" , attrib = { \"Locale\" : \"English_United States.1252\" , \"DefaultLocale\" : \"C\" }, ) grp = ET . SubElement ( xml , \"Group\" , attrib = { \"Name\" : \"\" }) for param in tmp_params : if param_names is not None and param . name in param_names : if param . motec_shape != ( 0 ,): tbl = ET . SubElement ( grp , \"Table\" , attrib = { \"Name\" : param . name }) expand = [] shp = [ 1 , 1 , 1 ] for i , axis in enumerate ( param . axes ): ax_el = ET . SubElement ( tbl , axis . name ) cells = ET . SubElement ( ax_el , \"Cells\" , attrib = { \"Type\" : MOTEC_TYPE [ axis . data . dtype . str ], \"Unit\" : axis . unit , }, ) ind = [ \"X\" , \"Y\" , \"Z\" ] . index ( axis . name ) if ind > i : expand . append ( i ) shp [ ind ] = axis . n_bps for j , value in enumerate ( axis . data ): site = [ 0 ] * 3 site [ ind ] = j attrib = { \"Site\" : str ( site )[ 1 : - 1 ] . replace ( \" \" , \"\" )} if hasattr ( axis , \"mark\" ): if axis . mark [ j ]: attrib . update ({ \"State\" : \"4\" }) cell = ET . SubElement ( cells , \"Cell\" , attrib = attrib , ) cell . text = str ( value ) for j in range ( 2 - ind ): expand . append ( j + ind + 1 ) bdy = ET . SubElement ( tbl , \"Body\" ) cells = ET . SubElement ( bdy , \"Cells\" , attrib = { \"Type\" : MOTEC_TYPE [ param . dtype . str ], \"Unit\" : param . unit }, ) # shp = param.axes.shape + (1,) * (3 - param.n_dim) # to make 3d full = np . zeros ( param . motec_shape , dtype = param . dtype ) full_mark = np . zeros ( param . motec_shape , dtype = np . bool_ ) if np . any ( expand ): tmp_data = np . expand_dims ( param . data , tuple ( expand )) if hasattr ( param , \"mark\" ): tmp_mark = np . expand_dims ( param . mark , tuple ( expand )) else : tmp_data = param . data if hasattr ( param , \"mark\" ): tmp_mark = param . mark full [ np . ix_ ( * [ range ( i ) for i in shp ])] = tmp_data it = np . nditer ( full , flags = [ \"multi_index\" ], order = \"F\" ) if hasattr ( param , \"mark\" ): full_mark [ np . ix_ ( * [ range ( i ) for i in shp ])] = tmp_mark mark_it = np . nditer ( full_mark , flags = [ \"multi_index\" ], order = \"F\" ) for val , mark in zip ( it , mark_it ): attrib = { \"Site\" : str ( it . multi_index )[ 1 : - 1 ] . replace ( \" \" , \"\" )} if mark : attrib . update ({ \"State\" : \"4\" }) cell = ET . SubElement ( cells , \"Cell\" , attrib = attrib , ) cell . text = str ( val ) else : # Param param_elem = ET . SubElement ( grp , \"Parameter\" , attrib = { \"Name\" : param . name } ) attrib = { \"Type\" : MOTEC_TYPE [ param . data . dtype . str ], } if param . unit is not None : attrib . update ({ \"Unit\" : param . unit }) cell = ET . SubElement ( param_elem , \"Cell\" , attrib = attrib , ) cell . text = str ( param . data [ 0 ]) tree = ET . ElementTree ( xml ) ET . indent ( tree ) filename = Path ( filename ) . with_suffix ( \".m1cfg\" ) tree . write ( filename , xml_declaration = True , encoding = \"ascii\" )","title":"write_m1cfg"},{"location":"reference/ccg/data/","text":"","title":"data"},{"location":"reference/ccg/data/alloc_data/","text":"AllocData Data class for pre-allocating npt.NDArray. Attributes: data ( NDArray ) \u2013 Data dtype ( DTypeLike ) \u2013 Data Type alloc ( tuple [ int ] ) \u2013 Allocated size Source code in ccg\\data\\alloc_data.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 class AllocData : \"\"\" Data class for pre-allocating npt.NDArray. Attributes ------- data: npt.NDArray Data dtype: npt.DTypeLike Data Type alloc: tuple[int] Allocated size \"\"\" __slots__ = \"data\" , \"_shape\" , \"dtype\" , \"_n\" , \"alloc\" , \"_nsamples\" @profile def __init__ ( self , data : npt . NDArray | AllocData | None = None , shape : tuple | None = None , dtype : npt . DTypeLike | None = None , ): self . data : npt . NDArray | None = None self . _shape : tuple | None = None self . _n : int | None = None if shape is None : if data is None : shape = NSAMPLES_DEFAULT else : shape = data . shape if dtype is None : if data is None : dtype = np . dtype ( \"float64\" ) else : dtype = data . dtype self . dtype = dtype if isinstance ( data , AllocData ): self . data = data . data . copy () self . _shape = data . _shape self . _nsamples = data . _nsamples self . alloc = data . alloc else : if data is not None : self . replace ( data ) else : self . reallocate ( shape , dtype ) @profile def reallocate ( self , shape : tuple | list , dtype : npt . DTypeLike , allow_dtype_change = False ) -> None : \"\"\"Allocate or reallocate self.data. Shape and dtype are for the intended data.\"\"\" if len ( shape ) > 1 : new_shape = tuple ( max ( int ( x * F_OVER_ALLOC ), NSAMPLES_MIN ) for x in shape ) if self . _shape is None or not ccg . util . iscompat ( self . data . dtype , dtype ): if ( not allow_dtype_change and self . data is not None and not ccg . util . iscompat ( self . data . dtype , dtype ) ): raise TypeError ( \"Data type change not allowed. Use `allow_dtype_change=True` argument.\" ) self . data = np . zeros ( new_shape , dtype = dtype ) self . dtype = dtype self . alloc = new_shape self . _shape = ( 0 ,) * len ( new_shape ) self . _nsamples = 0 else : for x , y in zip ( shape , self . alloc ): if x > y : self . data . resize ( new_shape , refcheck = False ) # Whats the refcheck do????? self . alloc = new_shape break else : # 1d - This is getting messy for speed :( new_shape = ( int ( max ( shape [ 0 ] * F_OVER_ALLOC , NSAMPLES_MIN )),) if self . _shape is None : if ( not allow_dtype_change and self . data is not None and not ccg . util . iscompat ( self . data . dtype , dtype ) ): raise TypeError ( \"Data type change not allowed. Use `allow_dtype_change=True` argument.\" ) self . data = np . empty ( new_shape , dtype = dtype ) self . dtype = dtype self . alloc = new_shape self . _shape = ( 0 ,) self . _nsamples = 0 else : if shape [ 0 ] > self . alloc [ 0 ]: if ccg . util . iscompat ( self . data . dtype , dtype ): self . data . resize ( new_shape , refcheck = False ) # Whats the refcheck do????? self . alloc = new_shape elif not allow_dtype_change : raise TypeError ( \"Data type change not allowed. Use `allow_dtype_change=True` argument.\" ) else : self . data = np . zeros ( new_shape , dtype = dtype ) self . dtype = dtype self . alloc = new_shape self . _shape = ( 0 ,) self . _nsamples = 0 @profile def append ( self , data : npt . NDArray | AllocData ): \"\"\"Append data to self.\"\"\" # Check if data will fit # TODO: handle expading dims if len ( self . _shape ) > 1 : new_shape = tuple ( x + y for x , y in zip ( self . shape , data . shape )) ind = tuple ( slice ( x , x + y ) for x , y in zip ( self . shape , data . shape )) ind2 = tuple ( slice ( 0 , x ) for x in data . shape ) else : new_shape = ( self . shape [ 0 ] + data . shape [ 0 ],) ind = slice ( self . shape [ 0 ], self . shape [ 0 ] + data . shape [ 0 ]) ind2 = slice ( 0 , data . shape [ 0 ]) self . reallocate ( new_shape , dtype = data . dtype ) if isinstance ( data , AllocData ): self . data [ ind ] = data . data [ ind2 ] else : self . data [ ind ] = data self . _shape = new_shape self . _nsamples = math . prod ( new_shape ) return self @profile def replace ( self , data : npt . NDArray | AllocData ): \"\"\" Replace data without re-allocating if data fits and is the same type. \"\"\" if isinstance ( data , AllocData ): self . data = data . data . copy () self . alloc = data . alloc self . shape = data . shape else : # Check if data will fit # TODO: handle expading dims new_shape = data . shape if self . dtype != data . dtype : # start over self . data = None self . _shape = None self . alloc = None self . reallocate ( new_shape , data . dtype , allow_dtype_change = True ) self . data [ tuple ( slice ( 0 , end ) for end in data . shape )] = data self . _shape = new_shape self . _nsamples = math . prod ( new_shape ) def tobytes ( self ) -> bytes : \"\"\"Returns bytes representation of data\"\"\" return self . data [ np . indices ( self . shape )] . tobytes () @property def shape ( self ) -> tuple : \"\"\"Shape of data\"\"\" return self . _shape @shape . setter @profile def shape ( self , value : tuple ): \"\"\"shape setter\"\"\" self . _shape = value if value is not None : self . _nsamples = math . prod ( value ) else : self . _nsamples = 0 @profile def __getitem__ ( self , index = None ) -> npt . NDArray : \"\"\"Getter function.\"\"\" if self . _shape is None : return self . data [ 0 : 0 ] if index is None : return self . data [ np . indices ( self . shape )] if isinstance ( index , slice ): # assume 1d if index . start is not None and index . start < 0 : start = self . shape [ 0 ] - ( index . start + 1 ) else : start = index . start if index . stop is None : stop = self . shape [ 0 ] elif index . stop < 0 : stop = self . shape - ( index . stop + 1 ) else : stop = index . stop return self . data [ start : stop : index . step ] if isinstance ( index , tuple ): # TODO: This is a problem when compiled. Maybe need to limit to 1d? new_index : list [ slice ] = [] for i , dim in enumerate ( index ): if isinstance ( dim , slice ): if dim . start is not None and dim . start < 0 : start = self . shape [ i ] - ( dim . start + 1 ) else : start = dim . start if dim . stop is None : stop = self . shape [ i ] elif dim . stop < 0 : stop = self . shape - ( dim . stop + 1 ) else : stop = dim . stop dim = slice ( start , stop , dim . step ) new_index . append ( dim ) return self . data [ tuple ( new_index )] elif isinstance ( index , int ): if index < 0 : index = self . nsamples - ( index + 2 ) return self . data [ index ] else : raise NotImplementedError ( f \"getitem not defined for type { type ( index ) } \" ) def __setitem__ ( self , index : tuple [ slice | list | int | npt . NDArray ] | slice , value : list | npt . NDArray , ): \"\"\"Set item func\"\"\" # Check for nested list, if so easier to make it array first try : if isinstance ( value [ 0 ], list ): value = np . array ( value ) except IndexError : pass if isinstance ( value , np . ndarray ): shape = value . shape dtype = value . dtype else : shape = ( len ( value ),) dtype = np . dtype ( type ( value [ 0 ])) # Convert index into alloc shape new_index = [] new_shape = [] for i , dim in enumerate ( index ): if isinstance ( dim , slice ): if dim . start is not None and dim . start < 0 : start = self . shape [ i ] - ( dim . start + 1 ) else : start = dim . start if dim . stop is None : stop = shape [ i ] elif dim . stop < 0 : stop = self . shape - ( dim . stop + 1 ) else : stop = dim . stop dim = slice ( start , stop , dim . step ) dim_shape = stop elif isinstance ( dim , int ): dim_shape = dim + 1 elif isinstance ( dim , list ): dim_shape = max ( dim ) + 1 elif isinstance ( dim , np . ndarray ): if not dim . size : return # empty assignment dim_shape = dim . max () + 1 else : raise NotImplementedError ( f \"index of { type ( dim ) } not implemented.\" ) new_shape . append ( max ( self . shape [ i ], dim_shape )) new_index . append ( dim ) self . reallocate ( shape = new_shape , dtype = dtype , allow_dtype_change = False ) self . data [ tuple ( new_index )] = value self . shape = tuple ( new_shape ) def __iter__ ( self ): self . _n = 0 return self def __next__ ( self ): if self . _n < self . nsamples : res = self . __getitem__ ( np . unravel_index ( self . _n , shape = self . shape )) self . _n += 1 return res raise StopIteration @property def appx_bytes ( self ) -> int : \"\"\"Approximate size of obj in bytes.\"\"\" sz1 = self . nsamples * self . data . itemsize # sz2 = self.data.nbytes return sz1 @property def nsamples ( self ) -> int : \"\"\"Number of samples.\"\"\" return self . _nsamples appx_bytes : int property Approximate size of obj in bytes. nsamples : int property Number of samples. shape : tuple property writable Shape of data __getitem__ ( index = None ) Getter function. Source code in ccg\\data\\alloc_data.py 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 @profile def __getitem__ ( self , index = None ) -> npt . NDArray : \"\"\"Getter function.\"\"\" if self . _shape is None : return self . data [ 0 : 0 ] if index is None : return self . data [ np . indices ( self . shape )] if isinstance ( index , slice ): # assume 1d if index . start is not None and index . start < 0 : start = self . shape [ 0 ] - ( index . start + 1 ) else : start = index . start if index . stop is None : stop = self . shape [ 0 ] elif index . stop < 0 : stop = self . shape - ( index . stop + 1 ) else : stop = index . stop return self . data [ start : stop : index . step ] if isinstance ( index , tuple ): # TODO: This is a problem when compiled. Maybe need to limit to 1d? new_index : list [ slice ] = [] for i , dim in enumerate ( index ): if isinstance ( dim , slice ): if dim . start is not None and dim . start < 0 : start = self . shape [ i ] - ( dim . start + 1 ) else : start = dim . start if dim . stop is None : stop = self . shape [ i ] elif dim . stop < 0 : stop = self . shape - ( dim . stop + 1 ) else : stop = dim . stop dim = slice ( start , stop , dim . step ) new_index . append ( dim ) return self . data [ tuple ( new_index )] elif isinstance ( index , int ): if index < 0 : index = self . nsamples - ( index + 2 ) return self . data [ index ] else : raise NotImplementedError ( f \"getitem not defined for type { type ( index ) } \" ) __setitem__ ( index , value ) Set item func Source code in ccg\\data\\alloc_data.py 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 def __setitem__ ( self , index : tuple [ slice | list | int | npt . NDArray ] | slice , value : list | npt . NDArray , ): \"\"\"Set item func\"\"\" # Check for nested list, if so easier to make it array first try : if isinstance ( value [ 0 ], list ): value = np . array ( value ) except IndexError : pass if isinstance ( value , np . ndarray ): shape = value . shape dtype = value . dtype else : shape = ( len ( value ),) dtype = np . dtype ( type ( value [ 0 ])) # Convert index into alloc shape new_index = [] new_shape = [] for i , dim in enumerate ( index ): if isinstance ( dim , slice ): if dim . start is not None and dim . start < 0 : start = self . shape [ i ] - ( dim . start + 1 ) else : start = dim . start if dim . stop is None : stop = shape [ i ] elif dim . stop < 0 : stop = self . shape - ( dim . stop + 1 ) else : stop = dim . stop dim = slice ( start , stop , dim . step ) dim_shape = stop elif isinstance ( dim , int ): dim_shape = dim + 1 elif isinstance ( dim , list ): dim_shape = max ( dim ) + 1 elif isinstance ( dim , np . ndarray ): if not dim . size : return # empty assignment dim_shape = dim . max () + 1 else : raise NotImplementedError ( f \"index of { type ( dim ) } not implemented.\" ) new_shape . append ( max ( self . shape [ i ], dim_shape )) new_index . append ( dim ) self . reallocate ( shape = new_shape , dtype = dtype , allow_dtype_change = False ) self . data [ tuple ( new_index )] = value self . shape = tuple ( new_shape ) append ( data ) Append data to self. Source code in ccg\\data\\alloc_data.py 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 @profile def append ( self , data : npt . NDArray | AllocData ): \"\"\"Append data to self.\"\"\" # Check if data will fit # TODO: handle expading dims if len ( self . _shape ) > 1 : new_shape = tuple ( x + y for x , y in zip ( self . shape , data . shape )) ind = tuple ( slice ( x , x + y ) for x , y in zip ( self . shape , data . shape )) ind2 = tuple ( slice ( 0 , x ) for x in data . shape ) else : new_shape = ( self . shape [ 0 ] + data . shape [ 0 ],) ind = slice ( self . shape [ 0 ], self . shape [ 0 ] + data . shape [ 0 ]) ind2 = slice ( 0 , data . shape [ 0 ]) self . reallocate ( new_shape , dtype = data . dtype ) if isinstance ( data , AllocData ): self . data [ ind ] = data . data [ ind2 ] else : self . data [ ind ] = data self . _shape = new_shape self . _nsamples = math . prod ( new_shape ) return self reallocate ( shape , dtype , allow_dtype_change = False ) Allocate or reallocate self.data. Shape and dtype are for the intended data. Source code in ccg\\data\\alloc_data.py 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 @profile def reallocate ( self , shape : tuple | list , dtype : npt . DTypeLike , allow_dtype_change = False ) -> None : \"\"\"Allocate or reallocate self.data. Shape and dtype are for the intended data.\"\"\" if len ( shape ) > 1 : new_shape = tuple ( max ( int ( x * F_OVER_ALLOC ), NSAMPLES_MIN ) for x in shape ) if self . _shape is None or not ccg . util . iscompat ( self . data . dtype , dtype ): if ( not allow_dtype_change and self . data is not None and not ccg . util . iscompat ( self . data . dtype , dtype ) ): raise TypeError ( \"Data type change not allowed. Use `allow_dtype_change=True` argument.\" ) self . data = np . zeros ( new_shape , dtype = dtype ) self . dtype = dtype self . alloc = new_shape self . _shape = ( 0 ,) * len ( new_shape ) self . _nsamples = 0 else : for x , y in zip ( shape , self . alloc ): if x > y : self . data . resize ( new_shape , refcheck = False ) # Whats the refcheck do????? self . alloc = new_shape break else : # 1d - This is getting messy for speed :( new_shape = ( int ( max ( shape [ 0 ] * F_OVER_ALLOC , NSAMPLES_MIN )),) if self . _shape is None : if ( not allow_dtype_change and self . data is not None and not ccg . util . iscompat ( self . data . dtype , dtype ) ): raise TypeError ( \"Data type change not allowed. Use `allow_dtype_change=True` argument.\" ) self . data = np . empty ( new_shape , dtype = dtype ) self . dtype = dtype self . alloc = new_shape self . _shape = ( 0 ,) self . _nsamples = 0 else : if shape [ 0 ] > self . alloc [ 0 ]: if ccg . util . iscompat ( self . data . dtype , dtype ): self . data . resize ( new_shape , refcheck = False ) # Whats the refcheck do????? self . alloc = new_shape elif not allow_dtype_change : raise TypeError ( \"Data type change not allowed. Use `allow_dtype_change=True` argument.\" ) else : self . data = np . zeros ( new_shape , dtype = dtype ) self . dtype = dtype self . alloc = new_shape self . _shape = ( 0 ,) self . _nsamples = 0 replace ( data ) Replace data without re-allocating if data fits and is the same type. Source code in ccg\\data\\alloc_data.py 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 @profile def replace ( self , data : npt . NDArray | AllocData ): \"\"\" Replace data without re-allocating if data fits and is the same type. \"\"\" if isinstance ( data , AllocData ): self . data = data . data . copy () self . alloc = data . alloc self . shape = data . shape else : # Check if data will fit # TODO: handle expading dims new_shape = data . shape if self . dtype != data . dtype : # start over self . data = None self . _shape = None self . alloc = None self . reallocate ( new_shape , data . dtype , allow_dtype_change = True ) self . data [ tuple ( slice ( 0 , end ) for end in data . shape )] = data self . _shape = new_shape self . _nsamples = math . prod ( new_shape ) tobytes () Returns bytes representation of data Source code in ccg\\data\\alloc_data.py 184 185 186 def tobytes ( self ) -> bytes : \"\"\"Returns bytes representation of data\"\"\" return self . data [ np . indices ( self . shape )] . tobytes ()","title":"alloc_data"},{"location":"reference/ccg/data/alloc_data/#ccg.data.alloc_data.AllocData","text":"Data class for pre-allocating npt.NDArray. Attributes: data ( NDArray ) \u2013 Data dtype ( DTypeLike ) \u2013 Data Type alloc ( tuple [ int ] ) \u2013 Allocated size Source code in ccg\\data\\alloc_data.py 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 class AllocData : \"\"\" Data class for pre-allocating npt.NDArray. Attributes ------- data: npt.NDArray Data dtype: npt.DTypeLike Data Type alloc: tuple[int] Allocated size \"\"\" __slots__ = \"data\" , \"_shape\" , \"dtype\" , \"_n\" , \"alloc\" , \"_nsamples\" @profile def __init__ ( self , data : npt . NDArray | AllocData | None = None , shape : tuple | None = None , dtype : npt . DTypeLike | None = None , ): self . data : npt . NDArray | None = None self . _shape : tuple | None = None self . _n : int | None = None if shape is None : if data is None : shape = NSAMPLES_DEFAULT else : shape = data . shape if dtype is None : if data is None : dtype = np . dtype ( \"float64\" ) else : dtype = data . dtype self . dtype = dtype if isinstance ( data , AllocData ): self . data = data . data . copy () self . _shape = data . _shape self . _nsamples = data . _nsamples self . alloc = data . alloc else : if data is not None : self . replace ( data ) else : self . reallocate ( shape , dtype ) @profile def reallocate ( self , shape : tuple | list , dtype : npt . DTypeLike , allow_dtype_change = False ) -> None : \"\"\"Allocate or reallocate self.data. Shape and dtype are for the intended data.\"\"\" if len ( shape ) > 1 : new_shape = tuple ( max ( int ( x * F_OVER_ALLOC ), NSAMPLES_MIN ) for x in shape ) if self . _shape is None or not ccg . util . iscompat ( self . data . dtype , dtype ): if ( not allow_dtype_change and self . data is not None and not ccg . util . iscompat ( self . data . dtype , dtype ) ): raise TypeError ( \"Data type change not allowed. Use `allow_dtype_change=True` argument.\" ) self . data = np . zeros ( new_shape , dtype = dtype ) self . dtype = dtype self . alloc = new_shape self . _shape = ( 0 ,) * len ( new_shape ) self . _nsamples = 0 else : for x , y in zip ( shape , self . alloc ): if x > y : self . data . resize ( new_shape , refcheck = False ) # Whats the refcheck do????? self . alloc = new_shape break else : # 1d - This is getting messy for speed :( new_shape = ( int ( max ( shape [ 0 ] * F_OVER_ALLOC , NSAMPLES_MIN )),) if self . _shape is None : if ( not allow_dtype_change and self . data is not None and not ccg . util . iscompat ( self . data . dtype , dtype ) ): raise TypeError ( \"Data type change not allowed. Use `allow_dtype_change=True` argument.\" ) self . data = np . empty ( new_shape , dtype = dtype ) self . dtype = dtype self . alloc = new_shape self . _shape = ( 0 ,) self . _nsamples = 0 else : if shape [ 0 ] > self . alloc [ 0 ]: if ccg . util . iscompat ( self . data . dtype , dtype ): self . data . resize ( new_shape , refcheck = False ) # Whats the refcheck do????? self . alloc = new_shape elif not allow_dtype_change : raise TypeError ( \"Data type change not allowed. Use `allow_dtype_change=True` argument.\" ) else : self . data = np . zeros ( new_shape , dtype = dtype ) self . dtype = dtype self . alloc = new_shape self . _shape = ( 0 ,) self . _nsamples = 0 @profile def append ( self , data : npt . NDArray | AllocData ): \"\"\"Append data to self.\"\"\" # Check if data will fit # TODO: handle expading dims if len ( self . _shape ) > 1 : new_shape = tuple ( x + y for x , y in zip ( self . shape , data . shape )) ind = tuple ( slice ( x , x + y ) for x , y in zip ( self . shape , data . shape )) ind2 = tuple ( slice ( 0 , x ) for x in data . shape ) else : new_shape = ( self . shape [ 0 ] + data . shape [ 0 ],) ind = slice ( self . shape [ 0 ], self . shape [ 0 ] + data . shape [ 0 ]) ind2 = slice ( 0 , data . shape [ 0 ]) self . reallocate ( new_shape , dtype = data . dtype ) if isinstance ( data , AllocData ): self . data [ ind ] = data . data [ ind2 ] else : self . data [ ind ] = data self . _shape = new_shape self . _nsamples = math . prod ( new_shape ) return self @profile def replace ( self , data : npt . NDArray | AllocData ): \"\"\" Replace data without re-allocating if data fits and is the same type. \"\"\" if isinstance ( data , AllocData ): self . data = data . data . copy () self . alloc = data . alloc self . shape = data . shape else : # Check if data will fit # TODO: handle expading dims new_shape = data . shape if self . dtype != data . dtype : # start over self . data = None self . _shape = None self . alloc = None self . reallocate ( new_shape , data . dtype , allow_dtype_change = True ) self . data [ tuple ( slice ( 0 , end ) for end in data . shape )] = data self . _shape = new_shape self . _nsamples = math . prod ( new_shape ) def tobytes ( self ) -> bytes : \"\"\"Returns bytes representation of data\"\"\" return self . data [ np . indices ( self . shape )] . tobytes () @property def shape ( self ) -> tuple : \"\"\"Shape of data\"\"\" return self . _shape @shape . setter @profile def shape ( self , value : tuple ): \"\"\"shape setter\"\"\" self . _shape = value if value is not None : self . _nsamples = math . prod ( value ) else : self . _nsamples = 0 @profile def __getitem__ ( self , index = None ) -> npt . NDArray : \"\"\"Getter function.\"\"\" if self . _shape is None : return self . data [ 0 : 0 ] if index is None : return self . data [ np . indices ( self . shape )] if isinstance ( index , slice ): # assume 1d if index . start is not None and index . start < 0 : start = self . shape [ 0 ] - ( index . start + 1 ) else : start = index . start if index . stop is None : stop = self . shape [ 0 ] elif index . stop < 0 : stop = self . shape - ( index . stop + 1 ) else : stop = index . stop return self . data [ start : stop : index . step ] if isinstance ( index , tuple ): # TODO: This is a problem when compiled. Maybe need to limit to 1d? new_index : list [ slice ] = [] for i , dim in enumerate ( index ): if isinstance ( dim , slice ): if dim . start is not None and dim . start < 0 : start = self . shape [ i ] - ( dim . start + 1 ) else : start = dim . start if dim . stop is None : stop = self . shape [ i ] elif dim . stop < 0 : stop = self . shape - ( dim . stop + 1 ) else : stop = dim . stop dim = slice ( start , stop , dim . step ) new_index . append ( dim ) return self . data [ tuple ( new_index )] elif isinstance ( index , int ): if index < 0 : index = self . nsamples - ( index + 2 ) return self . data [ index ] else : raise NotImplementedError ( f \"getitem not defined for type { type ( index ) } \" ) def __setitem__ ( self , index : tuple [ slice | list | int | npt . NDArray ] | slice , value : list | npt . NDArray , ): \"\"\"Set item func\"\"\" # Check for nested list, if so easier to make it array first try : if isinstance ( value [ 0 ], list ): value = np . array ( value ) except IndexError : pass if isinstance ( value , np . ndarray ): shape = value . shape dtype = value . dtype else : shape = ( len ( value ),) dtype = np . dtype ( type ( value [ 0 ])) # Convert index into alloc shape new_index = [] new_shape = [] for i , dim in enumerate ( index ): if isinstance ( dim , slice ): if dim . start is not None and dim . start < 0 : start = self . shape [ i ] - ( dim . start + 1 ) else : start = dim . start if dim . stop is None : stop = shape [ i ] elif dim . stop < 0 : stop = self . shape - ( dim . stop + 1 ) else : stop = dim . stop dim = slice ( start , stop , dim . step ) dim_shape = stop elif isinstance ( dim , int ): dim_shape = dim + 1 elif isinstance ( dim , list ): dim_shape = max ( dim ) + 1 elif isinstance ( dim , np . ndarray ): if not dim . size : return # empty assignment dim_shape = dim . max () + 1 else : raise NotImplementedError ( f \"index of { type ( dim ) } not implemented.\" ) new_shape . append ( max ( self . shape [ i ], dim_shape )) new_index . append ( dim ) self . reallocate ( shape = new_shape , dtype = dtype , allow_dtype_change = False ) self . data [ tuple ( new_index )] = value self . shape = tuple ( new_shape ) def __iter__ ( self ): self . _n = 0 return self def __next__ ( self ): if self . _n < self . nsamples : res = self . __getitem__ ( np . unravel_index ( self . _n , shape = self . shape )) self . _n += 1 return res raise StopIteration @property def appx_bytes ( self ) -> int : \"\"\"Approximate size of obj in bytes.\"\"\" sz1 = self . nsamples * self . data . itemsize # sz2 = self.data.nbytes return sz1 @property def nsamples ( self ) -> int : \"\"\"Number of samples.\"\"\" return self . _nsamples","title":"AllocData"},{"location":"reference/ccg/data/alloc_data/#ccg.data.alloc_data.AllocData.appx_bytes","text":"Approximate size of obj in bytes.","title":"appx_bytes"},{"location":"reference/ccg/data/alloc_data/#ccg.data.alloc_data.AllocData.nsamples","text":"Number of samples.","title":"nsamples"},{"location":"reference/ccg/data/alloc_data/#ccg.data.alloc_data.AllocData.shape","text":"Shape of data","title":"shape"},{"location":"reference/ccg/data/alloc_data/#ccg.data.alloc_data.AllocData.__getitem__","text":"Getter function. Source code in ccg\\data\\alloc_data.py 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 @profile def __getitem__ ( self , index = None ) -> npt . NDArray : \"\"\"Getter function.\"\"\" if self . _shape is None : return self . data [ 0 : 0 ] if index is None : return self . data [ np . indices ( self . shape )] if isinstance ( index , slice ): # assume 1d if index . start is not None and index . start < 0 : start = self . shape [ 0 ] - ( index . start + 1 ) else : start = index . start if index . stop is None : stop = self . shape [ 0 ] elif index . stop < 0 : stop = self . shape - ( index . stop + 1 ) else : stop = index . stop return self . data [ start : stop : index . step ] if isinstance ( index , tuple ): # TODO: This is a problem when compiled. Maybe need to limit to 1d? new_index : list [ slice ] = [] for i , dim in enumerate ( index ): if isinstance ( dim , slice ): if dim . start is not None and dim . start < 0 : start = self . shape [ i ] - ( dim . start + 1 ) else : start = dim . start if dim . stop is None : stop = self . shape [ i ] elif dim . stop < 0 : stop = self . shape - ( dim . stop + 1 ) else : stop = dim . stop dim = slice ( start , stop , dim . step ) new_index . append ( dim ) return self . data [ tuple ( new_index )] elif isinstance ( index , int ): if index < 0 : index = self . nsamples - ( index + 2 ) return self . data [ index ] else : raise NotImplementedError ( f \"getitem not defined for type { type ( index ) } \" )","title":"__getitem__"},{"location":"reference/ccg/data/alloc_data/#ccg.data.alloc_data.AllocData.__setitem__","text":"Set item func Source code in ccg\\data\\alloc_data.py 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 def __setitem__ ( self , index : tuple [ slice | list | int | npt . NDArray ] | slice , value : list | npt . NDArray , ): \"\"\"Set item func\"\"\" # Check for nested list, if so easier to make it array first try : if isinstance ( value [ 0 ], list ): value = np . array ( value ) except IndexError : pass if isinstance ( value , np . ndarray ): shape = value . shape dtype = value . dtype else : shape = ( len ( value ),) dtype = np . dtype ( type ( value [ 0 ])) # Convert index into alloc shape new_index = [] new_shape = [] for i , dim in enumerate ( index ): if isinstance ( dim , slice ): if dim . start is not None and dim . start < 0 : start = self . shape [ i ] - ( dim . start + 1 ) else : start = dim . start if dim . stop is None : stop = shape [ i ] elif dim . stop < 0 : stop = self . shape - ( dim . stop + 1 ) else : stop = dim . stop dim = slice ( start , stop , dim . step ) dim_shape = stop elif isinstance ( dim , int ): dim_shape = dim + 1 elif isinstance ( dim , list ): dim_shape = max ( dim ) + 1 elif isinstance ( dim , np . ndarray ): if not dim . size : return # empty assignment dim_shape = dim . max () + 1 else : raise NotImplementedError ( f \"index of { type ( dim ) } not implemented.\" ) new_shape . append ( max ( self . shape [ i ], dim_shape )) new_index . append ( dim ) self . reallocate ( shape = new_shape , dtype = dtype , allow_dtype_change = False ) self . data [ tuple ( new_index )] = value self . shape = tuple ( new_shape )","title":"__setitem__"},{"location":"reference/ccg/data/alloc_data/#ccg.data.alloc_data.AllocData.append","text":"Append data to self. Source code in ccg\\data\\alloc_data.py 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 @profile def append ( self , data : npt . NDArray | AllocData ): \"\"\"Append data to self.\"\"\" # Check if data will fit # TODO: handle expading dims if len ( self . _shape ) > 1 : new_shape = tuple ( x + y for x , y in zip ( self . shape , data . shape )) ind = tuple ( slice ( x , x + y ) for x , y in zip ( self . shape , data . shape )) ind2 = tuple ( slice ( 0 , x ) for x in data . shape ) else : new_shape = ( self . shape [ 0 ] + data . shape [ 0 ],) ind = slice ( self . shape [ 0 ], self . shape [ 0 ] + data . shape [ 0 ]) ind2 = slice ( 0 , data . shape [ 0 ]) self . reallocate ( new_shape , dtype = data . dtype ) if isinstance ( data , AllocData ): self . data [ ind ] = data . data [ ind2 ] else : self . data [ ind ] = data self . _shape = new_shape self . _nsamples = math . prod ( new_shape ) return self","title":"append"},{"location":"reference/ccg/data/alloc_data/#ccg.data.alloc_data.AllocData.reallocate","text":"Allocate or reallocate self.data. Shape and dtype are for the intended data. Source code in ccg\\data\\alloc_data.py 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 @profile def reallocate ( self , shape : tuple | list , dtype : npt . DTypeLike , allow_dtype_change = False ) -> None : \"\"\"Allocate or reallocate self.data. Shape and dtype are for the intended data.\"\"\" if len ( shape ) > 1 : new_shape = tuple ( max ( int ( x * F_OVER_ALLOC ), NSAMPLES_MIN ) for x in shape ) if self . _shape is None or not ccg . util . iscompat ( self . data . dtype , dtype ): if ( not allow_dtype_change and self . data is not None and not ccg . util . iscompat ( self . data . dtype , dtype ) ): raise TypeError ( \"Data type change not allowed. Use `allow_dtype_change=True` argument.\" ) self . data = np . zeros ( new_shape , dtype = dtype ) self . dtype = dtype self . alloc = new_shape self . _shape = ( 0 ,) * len ( new_shape ) self . _nsamples = 0 else : for x , y in zip ( shape , self . alloc ): if x > y : self . data . resize ( new_shape , refcheck = False ) # Whats the refcheck do????? self . alloc = new_shape break else : # 1d - This is getting messy for speed :( new_shape = ( int ( max ( shape [ 0 ] * F_OVER_ALLOC , NSAMPLES_MIN )),) if self . _shape is None : if ( not allow_dtype_change and self . data is not None and not ccg . util . iscompat ( self . data . dtype , dtype ) ): raise TypeError ( \"Data type change not allowed. Use `allow_dtype_change=True` argument.\" ) self . data = np . empty ( new_shape , dtype = dtype ) self . dtype = dtype self . alloc = new_shape self . _shape = ( 0 ,) self . _nsamples = 0 else : if shape [ 0 ] > self . alloc [ 0 ]: if ccg . util . iscompat ( self . data . dtype , dtype ): self . data . resize ( new_shape , refcheck = False ) # Whats the refcheck do????? self . alloc = new_shape elif not allow_dtype_change : raise TypeError ( \"Data type change not allowed. Use `allow_dtype_change=True` argument.\" ) else : self . data = np . zeros ( new_shape , dtype = dtype ) self . dtype = dtype self . alloc = new_shape self . _shape = ( 0 ,) self . _nsamples = 0","title":"reallocate"},{"location":"reference/ccg/data/alloc_data/#ccg.data.alloc_data.AllocData.replace","text":"Replace data without re-allocating if data fits and is the same type. Source code in ccg\\data\\alloc_data.py 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 @profile def replace ( self , data : npt . NDArray | AllocData ): \"\"\" Replace data without re-allocating if data fits and is the same type. \"\"\" if isinstance ( data , AllocData ): self . data = data . data . copy () self . alloc = data . alloc self . shape = data . shape else : # Check if data will fit # TODO: handle expading dims new_shape = data . shape if self . dtype != data . dtype : # start over self . data = None self . _shape = None self . alloc = None self . reallocate ( new_shape , data . dtype , allow_dtype_change = True ) self . data [ tuple ( slice ( 0 , end ) for end in data . shape )] = data self . _shape = new_shape self . _nsamples = math . prod ( new_shape )","title":"replace"},{"location":"reference/ccg/data/alloc_data/#ccg.data.alloc_data.AllocData.tobytes","text":"Returns bytes representation of data Source code in ccg\\data\\alloc_data.py 184 185 186 def tobytes ( self ) -> bytes : \"\"\"Returns bytes representation of data\"\"\" return self . data [ np . indices ( self . shape )] . tobytes ()","title":"tobytes"},{"location":"reference/ccg/data/gating/","text":"GateColl Bases: ABC Baseclass for gate collections. Source code in ccg\\data\\gating.py 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 class GateColl ( ABC ): \"\"\"Baseclass for gate collections.\"\"\" _func = np . logical_or def __init__ ( self , conditions : list [ GateCond | GateColl ] = None ): if not isinstance ( conditions , list ): conditions = [ conditions ] self . conds = conditions def valid ( self , frameorsig : Frame | Sig , tline : TLine ): \"\"\"Calculate validity for collection. Returns bool array.\"\"\" res = self . validate ( frameorsig , tline ) . data return res @profile def validate ( self , frameorsig : Frame | Sig , tline : TLine | None = None ): \"\"\"Calculate validity for collection. returns sig\"\"\" tmp_frame = Frame () n = 0 for cond in self . conds : n += 1 sig = cond . validate ( frameorsig , tline ) if not sig . name . endswith ( f \"_ { n } \" ): sig . name = sig . name + \"_\" + str ( n ) tmp_frame . append ( sig ) if tline is None : tline = self . get_combined_tline ( tmp_frame ) res = np . ones (( tline . nsamples ,), dtype = np . bool_ ) for sig in tmp_frame : res = self . _func ( res , sig . interp ( tline ) . data ) sig = Sig ( data = res , name = \"valid\" , tline = tline , interp_method = ccg . util . InterpMethod . ZOH , ) return sig def get_combined_tline ( self , frameorsig : Frame | Sig ): \"\"\"Get a combined tline for gate collection.\"\"\" comb_tline = np . empty ( shape = ( 0 )) if isinstance ( frameorsig , Frame ): for tmp_tline in frameorsig . tlines : comb_tline = np . concatenate (( comb_tline , tmp_tline . unix )) comb_tline = np . unique ( comb_tline ) comb_tline . sort () tline = TLine ( comb_tline ) else : tline = frameorsig . tline return tline @property def sigs ( self ): \"\"\"return list of sigs used in gatecoll.\"\"\" sigs = [] for sig in self . conds : sigs . append ( sig . signame ) return list ( set ( sigs )) def edges ( self , frameorsig : Frame | Sig , tline : TLine = None ) -> tuple [ npt . NDArray , npt . NDArray ]: \"\"\"Returns tuple of tline values at rising and falling edges of validity trace.\"\"\" valid = self . validate ( frameorsig , tline ) # Only want the array, not the tuple of indices rising = np . where ( valid [ 1 :] > valid [: - 1 ])[ 0 ] + 1 falling = np . where ( valid [ 1 :] < valid [: - 1 ])[ 0 ] + 1 if valid [ 0 ]: rising = np . insert ( rising , 0 , 0 ) if valid [ - 1 ] and valid [ - 2 ]: falling = np . append ( falling , valid . tline . nsamples - 1 ) assert rising . shape == falling . shape return valid . tline [ rising ], valid . tline [ falling ] def to_file ( self , filename : str | Path ): \"\"\"Store gate collection definition to config file.\"\"\" coll = gatecoll_to_dict ( self ) if not isinstance ( filename , Path ): filename = Path ( filename ) with open ( filename . with_suffix ( \".gate_cfg.json\" ), \"w\" , encoding = \"utf8\" ) as file : json . dump ( coll , file , indent = 4 ) return filename def from_file ( self , filename : str | Path | bytes ): \"\"\"Read gate collection from file. Returns a new coll.\"\"\" coll = gatecoll_from_file ( filename ) return coll def build_plot ( self , frameorsig : Frame | Sig , tline : TLine = None , def_plot : Plot = None ) -> Plot : \"\"\"Plot a gate collection validity.\"\"\" from ccg.ui.plot import build_gate_plot return build_gate_plot ( self , frameorsig , tline , def_plot = def_plot ) def append ( self , cond : GateColl | GateCond ): \"\"\"Append condition to collection\"\"\" self . conds . append ( cond ) def __iter__ ( self ): \"\"\"iter\"\"\" return iter ( self . conds ) def __repr__ ( self ) -> str : return json . dumps ( gatecoll_to_dict ( self )) sigs property return list of sigs used in gatecoll. __iter__ () iter Source code in ccg\\data\\gating.py 280 281 282 def __iter__ ( self ): \"\"\"iter\"\"\" return iter ( self . conds ) append ( cond ) Append condition to collection Source code in ccg\\data\\gating.py 276 277 278 def append ( self , cond : GateColl | GateCond ): \"\"\"Append condition to collection\"\"\" self . conds . append ( cond ) build_plot ( frameorsig , tline = None , def_plot = None ) Plot a gate collection validity. Source code in ccg\\data\\gating.py 268 269 270 271 272 273 274 def build_plot ( self , frameorsig : Frame | Sig , tline : TLine = None , def_plot : Plot = None ) -> Plot : \"\"\"Plot a gate collection validity.\"\"\" from ccg.ui.plot import build_gate_plot return build_gate_plot ( self , frameorsig , tline , def_plot = def_plot ) edges ( frameorsig , tline = None ) Returns tuple of tline values at rising and falling edges of validity trace. Source code in ccg\\data\\gating.py 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 def edges ( self , frameorsig : Frame | Sig , tline : TLine = None ) -> tuple [ npt . NDArray , npt . NDArray ]: \"\"\"Returns tuple of tline values at rising and falling edges of validity trace.\"\"\" valid = self . validate ( frameorsig , tline ) # Only want the array, not the tuple of indices rising = np . where ( valid [ 1 :] > valid [: - 1 ])[ 0 ] + 1 falling = np . where ( valid [ 1 :] < valid [: - 1 ])[ 0 ] + 1 if valid [ 0 ]: rising = np . insert ( rising , 0 , 0 ) if valid [ - 1 ] and valid [ - 2 ]: falling = np . append ( falling , valid . tline . nsamples - 1 ) assert rising . shape == falling . shape return valid . tline [ rising ], valid . tline [ falling ] from_file ( filename ) Read gate collection from file. Returns a new coll. Source code in ccg\\data\\gating.py 263 264 265 266 def from_file ( self , filename : str | Path | bytes ): \"\"\"Read gate collection from file. Returns a new coll.\"\"\" coll = gatecoll_from_file ( filename ) return coll get_combined_tline ( frameorsig ) Get a combined tline for gate collection. Source code in ccg\\data\\gating.py 213 214 215 216 217 218 219 220 221 222 223 224 225 def get_combined_tline ( self , frameorsig : Frame | Sig ): \"\"\"Get a combined tline for gate collection.\"\"\" comb_tline = np . empty ( shape = ( 0 )) if isinstance ( frameorsig , Frame ): for tmp_tline in frameorsig . tlines : comb_tline = np . concatenate (( comb_tline , tmp_tline . unix )) comb_tline = np . unique ( comb_tline ) comb_tline . sort () tline = TLine ( comb_tline ) else : tline = frameorsig . tline return tline to_file ( filename ) Store gate collection definition to config file. Source code in ccg\\data\\gating.py 254 255 256 257 258 259 260 261 def to_file ( self , filename : str | Path ): \"\"\"Store gate collection definition to config file.\"\"\" coll = gatecoll_to_dict ( self ) if not isinstance ( filename , Path ): filename = Path ( filename ) with open ( filename . with_suffix ( \".gate_cfg.json\" ), \"w\" , encoding = \"utf8\" ) as file : json . dump ( coll , file , indent = 4 ) return filename valid ( frameorsig , tline ) Calculate validity for collection. Returns bool array. Source code in ccg\\data\\gating.py 181 182 183 184 def valid ( self , frameorsig : Frame | Sig , tline : TLine ): \"\"\"Calculate validity for collection. Returns bool array.\"\"\" res = self . validate ( frameorsig , tline ) . data return res validate ( frameorsig , tline = None ) Calculate validity for collection. returns sig Source code in ccg\\data\\gating.py 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 @profile def validate ( self , frameorsig : Frame | Sig , tline : TLine | None = None ): \"\"\"Calculate validity for collection. returns sig\"\"\" tmp_frame = Frame () n = 0 for cond in self . conds : n += 1 sig = cond . validate ( frameorsig , tline ) if not sig . name . endswith ( f \"_ { n } \" ): sig . name = sig . name + \"_\" + str ( n ) tmp_frame . append ( sig ) if tline is None : tline = self . get_combined_tline ( tmp_frame ) res = np . ones (( tline . nsamples ,), dtype = np . bool_ ) for sig in tmp_frame : res = self . _func ( res , sig . interp ( tline ) . data ) sig = Sig ( data = res , name = \"valid\" , tline = tline , interp_method = ccg . util . InterpMethod . ZOH , ) return sig GateCollAND Bases: GateColl Collection of GateCond and'd together. Source code in ccg\\data\\gating.py 288 289 290 291 class GateCollAND ( GateColl ): \"\"\"Collection of GateCond and'd together.\"\"\" _func = np . logical_and GateCollOR Bases: GateColl Collection of GateCond or'd together. Source code in ccg\\data\\gating.py 294 295 296 297 class GateCollOR ( GateColl ): \"\"\"Collection of GateCond or'd together.\"\"\" _func = np . logical_or GateCond Gating condition for validating data in signals or frames. Source code in ccg\\data\\gating.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 class GateCond : \"\"\"Gating condition for validating data in signals or frames.\"\"\" def __init__ ( self , signame : str , min_limit : npt . NBitBase | None = None , max_limit : npt . NBitBase | None = None , enable_delay : float | None = None , disable_delay : float | None = None , unit : str | None = None , ): # Assign defaults if min_limit is None : min_limit = np . NINF if max_limit is None : max_limit = np . inf if enable_delay is None : enable_delay = 0 if disable_delay is None : disable_delay = 0 self . signame = signame self . min_limit = min_limit self . max_limit = max_limit self . enable_delay = enable_delay self . disable_delay = disable_delay self . unit = unit self . last_res = None self . _archive : dict [ int , dict [ int , Sig ]] = {} def valid ( self , frameorsig : Frame | Sig , tline : TLine ) -> npt . NDArray [ np . bool_ ]: \"\"\"Returns boolean array on tline with results of gate condition.\"\"\" res = self . validate ( frameorsig , tline ) return res . interp ( tline . unix ) . data # Interp with ZOH to resample @profile def validate ( self , frameorsig : Frame | Sig , tline : TLine = None , interp_gaps = False ): \"\"\"Calculate validity and return Sig of results.\"\"\" # tic = datetime.now() if isinstance ( frameorsig , Sig ): frameorsig = Frame ( frameorsig ) # Make it a frame for simplicity try : sig = frameorsig [ self . signame ] if tline is None : tline = sig . tline except KeyError as err : raise ValueError ( f \" { self . signame } not in frame: { frameorsig . name } \" ) from err sig_idn = sig . calc_idn () tline_idn = tline . idn if sig_idn in self . _archive : if tline_idn in self . _archive [ sig_idn ]: res = self . _archive [ sig_idn ][ tline_idn ] return res # TODO: Add better handling of different timelines. for now just resample if sig . tline . idn != tline_idn : sig = sig . resample ( tline , interp_gaps = interp_gaps ) _LOGGER . debug ( \"Resampled %s for gating condition on different TLine.\" , self . signame ) inlimit = np . ones (( tline . nsamples ,), np . bool_ ) if self . min_limit is not None : min_limit = ccg . util . convert_units ( self . min_limit , self . unit , sig . unit ) inlimit = np . logical_and ( inlimit , sig . data >= min_limit ) if self . max_limit is not None : max_limit = ccg . util . convert_units ( self . max_limit , self . unit , sig . unit ) inlimit = np . logical_and ( inlimit , sig . data <= max_limit ) rising = np . where ( inlimit [: - 1 ] < inlimit [ 1 :])[ 0 ] + 1 falling = np . where ( inlimit [: - 1 ] > inlimit [ 1 :])[ 0 ] + 1 ten = [] if inlimit [ 0 ]: rising = np . insert ( rising , 0 , 0 ) tdis = [ tline . unix [ 0 ] - 0.00001 ] # to make sure we get a rising edge at 0 else : falling = np . insert ( falling , 0 , 0 ) tdis = [ tline . unix [ 0 ]] if inlimit [ - 1 ]: falling = np . append ( falling , tline . nsamples - 1 ) nrising = len ( rising ) if nrising : if rising [ 0 ] > falling [ 0 ]: falling = np . delete ( falling , 0 ) i = 0 while i < nrising : if ( tline . unix [ rising [ i ]] + self . enable_delay < tline . unix [ falling [ i ]] - self . disable_delay ): ten . append ( tline . unix [ rising [ i ]] + self . enable_delay ) while ( i < nrising - 1 and tline . unix [ falling [ i ]] - self . disable_delay > tline . unix [ rising [ i + 1 ]] + self . enable_delay ): i += 1 tdis . append ( tline . unix [ falling [ i ]] - self . disable_delay ) i += 1 valid = np . ones ( len ( ten )) valid = np . append ( valid , np . zeros ( len ( tdis ))) new_tline = TLine ( np . append ( ten , tdis )) else : valid = np . array ([ 0 , 0 ]) new_tline = TLine ( np . append ( tline [ 0 ], tline [ - 1 ])) res = Sig ( data = valid , tline = new_tline , name = f \" { sig . name } _valid\" , unit = \"valid\" , connect_gaps = True , interp_method = ccg . util . InterpMethod . ZOH , ) res . sort_tline () ccg . util . merge_dict ( self . _archive , { sig_idn : { tline_idn : res }}) # toc = datetime.now() - tic # _LOGGER.debug(\"validate in %.3f\", toc.total_seconds()) return res def build_plot ( self , frameorsig : Frame | Sig , tline : TLine ) -> Plot : \"\"\"Plot a gate condition validity.\"\"\" from ccg.ui.plot import build_gate_plot return build_gate_plot ( self , frameorsig , tline ) def __repr__ ( self ) -> str : res = { \"signame\" : self . signame , \"min_limit\" : self . min_limit , \"max_limit\" : self . max_limit , \"enable_delay\" : self . enable_delay , \"disable_delay\" : self . disable_delay , \"unit\" : self . unit , } return json . dumps ( res ) build_plot ( frameorsig , tline ) Plot a gate condition validity. Source code in ccg\\data\\gating.py 153 154 155 156 157 def build_plot ( self , frameorsig : Frame | Sig , tline : TLine ) -> Plot : \"\"\"Plot a gate condition validity.\"\"\" from ccg.ui.plot import build_gate_plot return build_gate_plot ( self , frameorsig , tline ) valid ( frameorsig , tline ) Returns boolean array on tline with results of gate condition. Source code in ccg\\data\\gating.py 56 57 58 59 60 def valid ( self , frameorsig : Frame | Sig , tline : TLine ) -> npt . NDArray [ np . bool_ ]: \"\"\"Returns boolean array on tline with results of gate condition.\"\"\" res = self . validate ( frameorsig , tline ) return res . interp ( tline . unix ) . data # Interp with ZOH to resample validate ( frameorsig , tline = None , interp_gaps = False ) Calculate validity and return Sig of results. Source code in ccg\\data\\gating.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 @profile def validate ( self , frameorsig : Frame | Sig , tline : TLine = None , interp_gaps = False ): \"\"\"Calculate validity and return Sig of results.\"\"\" # tic = datetime.now() if isinstance ( frameorsig , Sig ): frameorsig = Frame ( frameorsig ) # Make it a frame for simplicity try : sig = frameorsig [ self . signame ] if tline is None : tline = sig . tline except KeyError as err : raise ValueError ( f \" { self . signame } not in frame: { frameorsig . name } \" ) from err sig_idn = sig . calc_idn () tline_idn = tline . idn if sig_idn in self . _archive : if tline_idn in self . _archive [ sig_idn ]: res = self . _archive [ sig_idn ][ tline_idn ] return res # TODO: Add better handling of different timelines. for now just resample if sig . tline . idn != tline_idn : sig = sig . resample ( tline , interp_gaps = interp_gaps ) _LOGGER . debug ( \"Resampled %s for gating condition on different TLine.\" , self . signame ) inlimit = np . ones (( tline . nsamples ,), np . bool_ ) if self . min_limit is not None : min_limit = ccg . util . convert_units ( self . min_limit , self . unit , sig . unit ) inlimit = np . logical_and ( inlimit , sig . data >= min_limit ) if self . max_limit is not None : max_limit = ccg . util . convert_units ( self . max_limit , self . unit , sig . unit ) inlimit = np . logical_and ( inlimit , sig . data <= max_limit ) rising = np . where ( inlimit [: - 1 ] < inlimit [ 1 :])[ 0 ] + 1 falling = np . where ( inlimit [: - 1 ] > inlimit [ 1 :])[ 0 ] + 1 ten = [] if inlimit [ 0 ]: rising = np . insert ( rising , 0 , 0 ) tdis = [ tline . unix [ 0 ] - 0.00001 ] # to make sure we get a rising edge at 0 else : falling = np . insert ( falling , 0 , 0 ) tdis = [ tline . unix [ 0 ]] if inlimit [ - 1 ]: falling = np . append ( falling , tline . nsamples - 1 ) nrising = len ( rising ) if nrising : if rising [ 0 ] > falling [ 0 ]: falling = np . delete ( falling , 0 ) i = 0 while i < nrising : if ( tline . unix [ rising [ i ]] + self . enable_delay < tline . unix [ falling [ i ]] - self . disable_delay ): ten . append ( tline . unix [ rising [ i ]] + self . enable_delay ) while ( i < nrising - 1 and tline . unix [ falling [ i ]] - self . disable_delay > tline . unix [ rising [ i + 1 ]] + self . enable_delay ): i += 1 tdis . append ( tline . unix [ falling [ i ]] - self . disable_delay ) i += 1 valid = np . ones ( len ( ten )) valid = np . append ( valid , np . zeros ( len ( tdis ))) new_tline = TLine ( np . append ( ten , tdis )) else : valid = np . array ([ 0 , 0 ]) new_tline = TLine ( np . append ( tline [ 0 ], tline [ - 1 ])) res = Sig ( data = valid , tline = new_tline , name = f \" { sig . name } _valid\" , unit = \"valid\" , connect_gaps = True , interp_method = ccg . util . InterpMethod . ZOH , ) res . sort_tline () ccg . util . merge_dict ( self . _archive , { sig_idn : { tline_idn : res }}) # toc = datetime.now() - tic # _LOGGER.debug(\"validate in %.3f\", toc.total_seconds()) return res gatecoll_from_dict ( data ) Gate condition collection from dict. Source code in ccg\\data\\gating.py 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 def gatecoll_from_dict ( data : dict ) -> GateCollAND | GateCollOR : \"\"\"Gate condition collection from dict.\"\"\" conds = [] if len ( data ) != 1 or ( \"AND\" not in data and \"OR\" not in data ): raise ValueError ( \"Invalid config document\" ) for key , vals in data . items (): if key == \"AND\" : coll = GateCollAND elif key == \"OR\" : coll = GateCollOR else : raise NotImplementedError ( f \"Gate Collection not implemented for: { key } \" ) for val in vals : if \"AND\" in val or \"OR\" in val : conds . append ( gatecoll_from_dict ( val )) else : conds . append ( GateCond ( ** val )) res = coll ( conds ) return res gatecoll_from_file ( filename ) Read gate collection from config file. Source code in ccg\\data\\gating.py 300 301 302 303 304 305 306 307 308 309 310 311 def gatecoll_from_file ( filename : str | Path | bytes ): \"\"\"Read gate collection from config file.\"\"\" if filename and str ( filename ) != \".\" : if isinstance ( filename , bytes ): data = json . loads ( filename ) else : with open ( filename , \"r\" , encoding = \"utf8\" ) as file : data = json . load ( file ) res = gatecoll_from_dict ( data ) return res else : raise OSError ( f \"Invalid filename: { filename } for gate collection import.\" ) gatecoll_to_dict ( coll ) Recursive gate condition collection to dict. Source code in ccg\\data\\gating.py 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 def gatecoll_to_dict ( coll : GateColl ) -> dict : \"\"\"Recursive gate condition collection to dict.\"\"\" if not isinstance ( coll , GateColl ): raise TypeError ( \"Must be a GateColl\" ) tmp = [] for cond in coll . conds : if isinstance ( cond , GateCond ): cond_def = { \"signame\" : cond . signame , \"min_limit\" : cond . min_limit , \"max_limit\" : cond . max_limit , \"enable_delay\" : cond . enable_delay , \"disable_delay\" : cond . disable_delay , \"unit\" : cond . unit , } tmp . append ( cond_def ) elif isinstance ( cond , GateColl ): tmp . append ( gatecoll_to_dict ( cond )) if isinstance ( coll , GateCollAND ): res = { \"AND\" : tmp } elif isinstance ( coll , GateCollOR ): res = { \"OR\" : tmp } return res","title":"gating"},{"location":"reference/ccg/data/gating/#ccg.data.gating.GateColl","text":"Bases: ABC Baseclass for gate collections. Source code in ccg\\data\\gating.py 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 class GateColl ( ABC ): \"\"\"Baseclass for gate collections.\"\"\" _func = np . logical_or def __init__ ( self , conditions : list [ GateCond | GateColl ] = None ): if not isinstance ( conditions , list ): conditions = [ conditions ] self . conds = conditions def valid ( self , frameorsig : Frame | Sig , tline : TLine ): \"\"\"Calculate validity for collection. Returns bool array.\"\"\" res = self . validate ( frameorsig , tline ) . data return res @profile def validate ( self , frameorsig : Frame | Sig , tline : TLine | None = None ): \"\"\"Calculate validity for collection. returns sig\"\"\" tmp_frame = Frame () n = 0 for cond in self . conds : n += 1 sig = cond . validate ( frameorsig , tline ) if not sig . name . endswith ( f \"_ { n } \" ): sig . name = sig . name + \"_\" + str ( n ) tmp_frame . append ( sig ) if tline is None : tline = self . get_combined_tline ( tmp_frame ) res = np . ones (( tline . nsamples ,), dtype = np . bool_ ) for sig in tmp_frame : res = self . _func ( res , sig . interp ( tline ) . data ) sig = Sig ( data = res , name = \"valid\" , tline = tline , interp_method = ccg . util . InterpMethod . ZOH , ) return sig def get_combined_tline ( self , frameorsig : Frame | Sig ): \"\"\"Get a combined tline for gate collection.\"\"\" comb_tline = np . empty ( shape = ( 0 )) if isinstance ( frameorsig , Frame ): for tmp_tline in frameorsig . tlines : comb_tline = np . concatenate (( comb_tline , tmp_tline . unix )) comb_tline = np . unique ( comb_tline ) comb_tline . sort () tline = TLine ( comb_tline ) else : tline = frameorsig . tline return tline @property def sigs ( self ): \"\"\"return list of sigs used in gatecoll.\"\"\" sigs = [] for sig in self . conds : sigs . append ( sig . signame ) return list ( set ( sigs )) def edges ( self , frameorsig : Frame | Sig , tline : TLine = None ) -> tuple [ npt . NDArray , npt . NDArray ]: \"\"\"Returns tuple of tline values at rising and falling edges of validity trace.\"\"\" valid = self . validate ( frameorsig , tline ) # Only want the array, not the tuple of indices rising = np . where ( valid [ 1 :] > valid [: - 1 ])[ 0 ] + 1 falling = np . where ( valid [ 1 :] < valid [: - 1 ])[ 0 ] + 1 if valid [ 0 ]: rising = np . insert ( rising , 0 , 0 ) if valid [ - 1 ] and valid [ - 2 ]: falling = np . append ( falling , valid . tline . nsamples - 1 ) assert rising . shape == falling . shape return valid . tline [ rising ], valid . tline [ falling ] def to_file ( self , filename : str | Path ): \"\"\"Store gate collection definition to config file.\"\"\" coll = gatecoll_to_dict ( self ) if not isinstance ( filename , Path ): filename = Path ( filename ) with open ( filename . with_suffix ( \".gate_cfg.json\" ), \"w\" , encoding = \"utf8\" ) as file : json . dump ( coll , file , indent = 4 ) return filename def from_file ( self , filename : str | Path | bytes ): \"\"\"Read gate collection from file. Returns a new coll.\"\"\" coll = gatecoll_from_file ( filename ) return coll def build_plot ( self , frameorsig : Frame | Sig , tline : TLine = None , def_plot : Plot = None ) -> Plot : \"\"\"Plot a gate collection validity.\"\"\" from ccg.ui.plot import build_gate_plot return build_gate_plot ( self , frameorsig , tline , def_plot = def_plot ) def append ( self , cond : GateColl | GateCond ): \"\"\"Append condition to collection\"\"\" self . conds . append ( cond ) def __iter__ ( self ): \"\"\"iter\"\"\" return iter ( self . conds ) def __repr__ ( self ) -> str : return json . dumps ( gatecoll_to_dict ( self ))","title":"GateColl"},{"location":"reference/ccg/data/gating/#ccg.data.gating.GateColl.sigs","text":"return list of sigs used in gatecoll.","title":"sigs"},{"location":"reference/ccg/data/gating/#ccg.data.gating.GateColl.__iter__","text":"iter Source code in ccg\\data\\gating.py 280 281 282 def __iter__ ( self ): \"\"\"iter\"\"\" return iter ( self . conds )","title":"__iter__"},{"location":"reference/ccg/data/gating/#ccg.data.gating.GateColl.append","text":"Append condition to collection Source code in ccg\\data\\gating.py 276 277 278 def append ( self , cond : GateColl | GateCond ): \"\"\"Append condition to collection\"\"\" self . conds . append ( cond )","title":"append"},{"location":"reference/ccg/data/gating/#ccg.data.gating.GateColl.build_plot","text":"Plot a gate collection validity. Source code in ccg\\data\\gating.py 268 269 270 271 272 273 274 def build_plot ( self , frameorsig : Frame | Sig , tline : TLine = None , def_plot : Plot = None ) -> Plot : \"\"\"Plot a gate collection validity.\"\"\" from ccg.ui.plot import build_gate_plot return build_gate_plot ( self , frameorsig , tline , def_plot = def_plot )","title":"build_plot"},{"location":"reference/ccg/data/gating/#ccg.data.gating.GateColl.edges","text":"Returns tuple of tline values at rising and falling edges of validity trace. Source code in ccg\\data\\gating.py 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 def edges ( self , frameorsig : Frame | Sig , tline : TLine = None ) -> tuple [ npt . NDArray , npt . NDArray ]: \"\"\"Returns tuple of tline values at rising and falling edges of validity trace.\"\"\" valid = self . validate ( frameorsig , tline ) # Only want the array, not the tuple of indices rising = np . where ( valid [ 1 :] > valid [: - 1 ])[ 0 ] + 1 falling = np . where ( valid [ 1 :] < valid [: - 1 ])[ 0 ] + 1 if valid [ 0 ]: rising = np . insert ( rising , 0 , 0 ) if valid [ - 1 ] and valid [ - 2 ]: falling = np . append ( falling , valid . tline . nsamples - 1 ) assert rising . shape == falling . shape return valid . tline [ rising ], valid . tline [ falling ]","title":"edges"},{"location":"reference/ccg/data/gating/#ccg.data.gating.GateColl.from_file","text":"Read gate collection from file. Returns a new coll. Source code in ccg\\data\\gating.py 263 264 265 266 def from_file ( self , filename : str | Path | bytes ): \"\"\"Read gate collection from file. Returns a new coll.\"\"\" coll = gatecoll_from_file ( filename ) return coll","title":"from_file"},{"location":"reference/ccg/data/gating/#ccg.data.gating.GateColl.get_combined_tline","text":"Get a combined tline for gate collection. Source code in ccg\\data\\gating.py 213 214 215 216 217 218 219 220 221 222 223 224 225 def get_combined_tline ( self , frameorsig : Frame | Sig ): \"\"\"Get a combined tline for gate collection.\"\"\" comb_tline = np . empty ( shape = ( 0 )) if isinstance ( frameorsig , Frame ): for tmp_tline in frameorsig . tlines : comb_tline = np . concatenate (( comb_tline , tmp_tline . unix )) comb_tline = np . unique ( comb_tline ) comb_tline . sort () tline = TLine ( comb_tline ) else : tline = frameorsig . tline return tline","title":"get_combined_tline"},{"location":"reference/ccg/data/gating/#ccg.data.gating.GateColl.to_file","text":"Store gate collection definition to config file. Source code in ccg\\data\\gating.py 254 255 256 257 258 259 260 261 def to_file ( self , filename : str | Path ): \"\"\"Store gate collection definition to config file.\"\"\" coll = gatecoll_to_dict ( self ) if not isinstance ( filename , Path ): filename = Path ( filename ) with open ( filename . with_suffix ( \".gate_cfg.json\" ), \"w\" , encoding = \"utf8\" ) as file : json . dump ( coll , file , indent = 4 ) return filename","title":"to_file"},{"location":"reference/ccg/data/gating/#ccg.data.gating.GateColl.valid","text":"Calculate validity for collection. Returns bool array. Source code in ccg\\data\\gating.py 181 182 183 184 def valid ( self , frameorsig : Frame | Sig , tline : TLine ): \"\"\"Calculate validity for collection. Returns bool array.\"\"\" res = self . validate ( frameorsig , tline ) . data return res","title":"valid"},{"location":"reference/ccg/data/gating/#ccg.data.gating.GateColl.validate","text":"Calculate validity for collection. returns sig Source code in ccg\\data\\gating.py 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 @profile def validate ( self , frameorsig : Frame | Sig , tline : TLine | None = None ): \"\"\"Calculate validity for collection. returns sig\"\"\" tmp_frame = Frame () n = 0 for cond in self . conds : n += 1 sig = cond . validate ( frameorsig , tline ) if not sig . name . endswith ( f \"_ { n } \" ): sig . name = sig . name + \"_\" + str ( n ) tmp_frame . append ( sig ) if tline is None : tline = self . get_combined_tline ( tmp_frame ) res = np . ones (( tline . nsamples ,), dtype = np . bool_ ) for sig in tmp_frame : res = self . _func ( res , sig . interp ( tline ) . data ) sig = Sig ( data = res , name = \"valid\" , tline = tline , interp_method = ccg . util . InterpMethod . ZOH , ) return sig","title":"validate"},{"location":"reference/ccg/data/gating/#ccg.data.gating.GateCollAND","text":"Bases: GateColl Collection of GateCond and'd together. Source code in ccg\\data\\gating.py 288 289 290 291 class GateCollAND ( GateColl ): \"\"\"Collection of GateCond and'd together.\"\"\" _func = np . logical_and","title":"GateCollAND"},{"location":"reference/ccg/data/gating/#ccg.data.gating.GateCollOR","text":"Bases: GateColl Collection of GateCond or'd together. Source code in ccg\\data\\gating.py 294 295 296 297 class GateCollOR ( GateColl ): \"\"\"Collection of GateCond or'd together.\"\"\" _func = np . logical_or","title":"GateCollOR"},{"location":"reference/ccg/data/gating/#ccg.data.gating.GateCond","text":"Gating condition for validating data in signals or frames. Source code in ccg\\data\\gating.py 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 class GateCond : \"\"\"Gating condition for validating data in signals or frames.\"\"\" def __init__ ( self , signame : str , min_limit : npt . NBitBase | None = None , max_limit : npt . NBitBase | None = None , enable_delay : float | None = None , disable_delay : float | None = None , unit : str | None = None , ): # Assign defaults if min_limit is None : min_limit = np . NINF if max_limit is None : max_limit = np . inf if enable_delay is None : enable_delay = 0 if disable_delay is None : disable_delay = 0 self . signame = signame self . min_limit = min_limit self . max_limit = max_limit self . enable_delay = enable_delay self . disable_delay = disable_delay self . unit = unit self . last_res = None self . _archive : dict [ int , dict [ int , Sig ]] = {} def valid ( self , frameorsig : Frame | Sig , tline : TLine ) -> npt . NDArray [ np . bool_ ]: \"\"\"Returns boolean array on tline with results of gate condition.\"\"\" res = self . validate ( frameorsig , tline ) return res . interp ( tline . unix ) . data # Interp with ZOH to resample @profile def validate ( self , frameorsig : Frame | Sig , tline : TLine = None , interp_gaps = False ): \"\"\"Calculate validity and return Sig of results.\"\"\" # tic = datetime.now() if isinstance ( frameorsig , Sig ): frameorsig = Frame ( frameorsig ) # Make it a frame for simplicity try : sig = frameorsig [ self . signame ] if tline is None : tline = sig . tline except KeyError as err : raise ValueError ( f \" { self . signame } not in frame: { frameorsig . name } \" ) from err sig_idn = sig . calc_idn () tline_idn = tline . idn if sig_idn in self . _archive : if tline_idn in self . _archive [ sig_idn ]: res = self . _archive [ sig_idn ][ tline_idn ] return res # TODO: Add better handling of different timelines. for now just resample if sig . tline . idn != tline_idn : sig = sig . resample ( tline , interp_gaps = interp_gaps ) _LOGGER . debug ( \"Resampled %s for gating condition on different TLine.\" , self . signame ) inlimit = np . ones (( tline . nsamples ,), np . bool_ ) if self . min_limit is not None : min_limit = ccg . util . convert_units ( self . min_limit , self . unit , sig . unit ) inlimit = np . logical_and ( inlimit , sig . data >= min_limit ) if self . max_limit is not None : max_limit = ccg . util . convert_units ( self . max_limit , self . unit , sig . unit ) inlimit = np . logical_and ( inlimit , sig . data <= max_limit ) rising = np . where ( inlimit [: - 1 ] < inlimit [ 1 :])[ 0 ] + 1 falling = np . where ( inlimit [: - 1 ] > inlimit [ 1 :])[ 0 ] + 1 ten = [] if inlimit [ 0 ]: rising = np . insert ( rising , 0 , 0 ) tdis = [ tline . unix [ 0 ] - 0.00001 ] # to make sure we get a rising edge at 0 else : falling = np . insert ( falling , 0 , 0 ) tdis = [ tline . unix [ 0 ]] if inlimit [ - 1 ]: falling = np . append ( falling , tline . nsamples - 1 ) nrising = len ( rising ) if nrising : if rising [ 0 ] > falling [ 0 ]: falling = np . delete ( falling , 0 ) i = 0 while i < nrising : if ( tline . unix [ rising [ i ]] + self . enable_delay < tline . unix [ falling [ i ]] - self . disable_delay ): ten . append ( tline . unix [ rising [ i ]] + self . enable_delay ) while ( i < nrising - 1 and tline . unix [ falling [ i ]] - self . disable_delay > tline . unix [ rising [ i + 1 ]] + self . enable_delay ): i += 1 tdis . append ( tline . unix [ falling [ i ]] - self . disable_delay ) i += 1 valid = np . ones ( len ( ten )) valid = np . append ( valid , np . zeros ( len ( tdis ))) new_tline = TLine ( np . append ( ten , tdis )) else : valid = np . array ([ 0 , 0 ]) new_tline = TLine ( np . append ( tline [ 0 ], tline [ - 1 ])) res = Sig ( data = valid , tline = new_tline , name = f \" { sig . name } _valid\" , unit = \"valid\" , connect_gaps = True , interp_method = ccg . util . InterpMethod . ZOH , ) res . sort_tline () ccg . util . merge_dict ( self . _archive , { sig_idn : { tline_idn : res }}) # toc = datetime.now() - tic # _LOGGER.debug(\"validate in %.3f\", toc.total_seconds()) return res def build_plot ( self , frameorsig : Frame | Sig , tline : TLine ) -> Plot : \"\"\"Plot a gate condition validity.\"\"\" from ccg.ui.plot import build_gate_plot return build_gate_plot ( self , frameorsig , tline ) def __repr__ ( self ) -> str : res = { \"signame\" : self . signame , \"min_limit\" : self . min_limit , \"max_limit\" : self . max_limit , \"enable_delay\" : self . enable_delay , \"disable_delay\" : self . disable_delay , \"unit\" : self . unit , } return json . dumps ( res )","title":"GateCond"},{"location":"reference/ccg/data/gating/#ccg.data.gating.GateCond.build_plot","text":"Plot a gate condition validity. Source code in ccg\\data\\gating.py 153 154 155 156 157 def build_plot ( self , frameorsig : Frame | Sig , tline : TLine ) -> Plot : \"\"\"Plot a gate condition validity.\"\"\" from ccg.ui.plot import build_gate_plot return build_gate_plot ( self , frameorsig , tline )","title":"build_plot"},{"location":"reference/ccg/data/gating/#ccg.data.gating.GateCond.valid","text":"Returns boolean array on tline with results of gate condition. Source code in ccg\\data\\gating.py 56 57 58 59 60 def valid ( self , frameorsig : Frame | Sig , tline : TLine ) -> npt . NDArray [ np . bool_ ]: \"\"\"Returns boolean array on tline with results of gate condition.\"\"\" res = self . validate ( frameorsig , tline ) return res . interp ( tline . unix ) . data # Interp with ZOH to resample","title":"valid"},{"location":"reference/ccg/data/gating/#ccg.data.gating.GateCond.validate","text":"Calculate validity and return Sig of results. Source code in ccg\\data\\gating.py 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 @profile def validate ( self , frameorsig : Frame | Sig , tline : TLine = None , interp_gaps = False ): \"\"\"Calculate validity and return Sig of results.\"\"\" # tic = datetime.now() if isinstance ( frameorsig , Sig ): frameorsig = Frame ( frameorsig ) # Make it a frame for simplicity try : sig = frameorsig [ self . signame ] if tline is None : tline = sig . tline except KeyError as err : raise ValueError ( f \" { self . signame } not in frame: { frameorsig . name } \" ) from err sig_idn = sig . calc_idn () tline_idn = tline . idn if sig_idn in self . _archive : if tline_idn in self . _archive [ sig_idn ]: res = self . _archive [ sig_idn ][ tline_idn ] return res # TODO: Add better handling of different timelines. for now just resample if sig . tline . idn != tline_idn : sig = sig . resample ( tline , interp_gaps = interp_gaps ) _LOGGER . debug ( \"Resampled %s for gating condition on different TLine.\" , self . signame ) inlimit = np . ones (( tline . nsamples ,), np . bool_ ) if self . min_limit is not None : min_limit = ccg . util . convert_units ( self . min_limit , self . unit , sig . unit ) inlimit = np . logical_and ( inlimit , sig . data >= min_limit ) if self . max_limit is not None : max_limit = ccg . util . convert_units ( self . max_limit , self . unit , sig . unit ) inlimit = np . logical_and ( inlimit , sig . data <= max_limit ) rising = np . where ( inlimit [: - 1 ] < inlimit [ 1 :])[ 0 ] + 1 falling = np . where ( inlimit [: - 1 ] > inlimit [ 1 :])[ 0 ] + 1 ten = [] if inlimit [ 0 ]: rising = np . insert ( rising , 0 , 0 ) tdis = [ tline . unix [ 0 ] - 0.00001 ] # to make sure we get a rising edge at 0 else : falling = np . insert ( falling , 0 , 0 ) tdis = [ tline . unix [ 0 ]] if inlimit [ - 1 ]: falling = np . append ( falling , tline . nsamples - 1 ) nrising = len ( rising ) if nrising : if rising [ 0 ] > falling [ 0 ]: falling = np . delete ( falling , 0 ) i = 0 while i < nrising : if ( tline . unix [ rising [ i ]] + self . enable_delay < tline . unix [ falling [ i ]] - self . disable_delay ): ten . append ( tline . unix [ rising [ i ]] + self . enable_delay ) while ( i < nrising - 1 and tline . unix [ falling [ i ]] - self . disable_delay > tline . unix [ rising [ i + 1 ]] + self . enable_delay ): i += 1 tdis . append ( tline . unix [ falling [ i ]] - self . disable_delay ) i += 1 valid = np . ones ( len ( ten )) valid = np . append ( valid , np . zeros ( len ( tdis ))) new_tline = TLine ( np . append ( ten , tdis )) else : valid = np . array ([ 0 , 0 ]) new_tline = TLine ( np . append ( tline [ 0 ], tline [ - 1 ])) res = Sig ( data = valid , tline = new_tline , name = f \" { sig . name } _valid\" , unit = \"valid\" , connect_gaps = True , interp_method = ccg . util . InterpMethod . ZOH , ) res . sort_tline () ccg . util . merge_dict ( self . _archive , { sig_idn : { tline_idn : res }}) # toc = datetime.now() - tic # _LOGGER.debug(\"validate in %.3f\", toc.total_seconds()) return res","title":"validate"},{"location":"reference/ccg/data/gating/#ccg.data.gating.gatecoll_from_dict","text":"Gate condition collection from dict. Source code in ccg\\data\\gating.py 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 def gatecoll_from_dict ( data : dict ) -> GateCollAND | GateCollOR : \"\"\"Gate condition collection from dict.\"\"\" conds = [] if len ( data ) != 1 or ( \"AND\" not in data and \"OR\" not in data ): raise ValueError ( \"Invalid config document\" ) for key , vals in data . items (): if key == \"AND\" : coll = GateCollAND elif key == \"OR\" : coll = GateCollOR else : raise NotImplementedError ( f \"Gate Collection not implemented for: { key } \" ) for val in vals : if \"AND\" in val or \"OR\" in val : conds . append ( gatecoll_from_dict ( val )) else : conds . append ( GateCond ( ** val )) res = coll ( conds ) return res","title":"gatecoll_from_dict"},{"location":"reference/ccg/data/gating/#ccg.data.gating.gatecoll_from_file","text":"Read gate collection from config file. Source code in ccg\\data\\gating.py 300 301 302 303 304 305 306 307 308 309 310 311 def gatecoll_from_file ( filename : str | Path | bytes ): \"\"\"Read gate collection from config file.\"\"\" if filename and str ( filename ) != \".\" : if isinstance ( filename , bytes ): data = json . loads ( filename ) else : with open ( filename , \"r\" , encoding = \"utf8\" ) as file : data = json . load ( file ) res = gatecoll_from_dict ( data ) return res else : raise OSError ( f \"Invalid filename: { filename } for gate collection import.\" )","title":"gatecoll_from_file"},{"location":"reference/ccg/data/gating/#ccg.data.gating.gatecoll_to_dict","text":"Recursive gate condition collection to dict. Source code in ccg\\data\\gating.py 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 def gatecoll_to_dict ( coll : GateColl ) -> dict : \"\"\"Recursive gate condition collection to dict.\"\"\" if not isinstance ( coll , GateColl ): raise TypeError ( \"Must be a GateColl\" ) tmp = [] for cond in coll . conds : if isinstance ( cond , GateCond ): cond_def = { \"signame\" : cond . signame , \"min_limit\" : cond . min_limit , \"max_limit\" : cond . max_limit , \"enable_delay\" : cond . enable_delay , \"disable_delay\" : cond . disable_delay , \"unit\" : cond . unit , } tmp . append ( cond_def ) elif isinstance ( cond , GateColl ): tmp . append ( gatecoll_to_dict ( cond )) if isinstance ( coll , GateCollAND ): res = { \"AND\" : tmp } elif isinstance ( coll , GateCollOR ): res = { \"OR\" : tmp } return res","title":"gatecoll_to_dict"},{"location":"reference/ccg/data/tbldata/","text":"CCG Table data module. Axes CCG Parameter Axis collection. Source code in ccg\\data\\tbldata.py 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 class Axes : \"\"\"CCG Parameter Axis collection.\"\"\" def __init__ ( self , axes_data : list [ Axis ] | Axis | list [ dict ] | Axes = None , parent : Tbl = None , interpolate_on_change : bool = None , ): self . interpolate_on_change = None self . axes : list [ Axis ] = [] self . append ( axes_data ) self . parent = parent # needs to be set after axes to avoid int on chng if interpolate_on_change is not None : self . interpolate_on_change = interpolate_on_change # Default to true if self . interpolate_on_change is None : self . interpolate_on_change = True def append ( self , axis : list [ Axis ] | Axis | list [ dict ] | Axes ): \"\"\"Append axis to Axes. Will not interp.\"\"\" tmp_int = self . interpolate_on_change self . interpolate_on_change = False if isinstance ( axis , Axis ): axis = [ axis ] elif isinstance ( axis , Axes ): self . interpolate_on_change = axis . interpolate_on_change axis = axis . axes if axis is not None : # make copies of each axis, also asign parent new_axes = [ ( Axis ( ** tmp_axis , parent = self ) if isinstance ( tmp_axis , dict ) else Axis ( tmp_axis , parent = self ) ) for tmp_axis in axis ] # Ensure axes have names for i , axs in enumerate ( new_axes ): if axs . name is None : new_axes [ i ] . name = f \"axis_ { i } \" self . axes . extend ( new_axes ) self . interpolate_on_change = tmp_int @property def shape ( self ) -> tuple : \"\"\"Shape of axes bps\"\"\" if self . axes : shp = tuple ( x . n_bps for x in self . axes ) else : shp = ( 1 ,) return shp @property def table_shape ( self ) -> tuple : \"\"\"Shape of the expected data table. first axis is in cols (to match ecu standards), second in rows, beyond that they are stacked rows.\"\"\" if self . axes : shp = [ 1 , self . axes [ 0 ] . n_bps ] if self . n_dim > 1 : for axis in self . axes [ 1 :]: shp [ 0 ] = shp [ 0 ] * axis . n_bps else : shp = ( 0 ,) return tuple ( shp ) @property def grid ( self ): \"\"\"Return a meshgrid of the axis bps.\"\"\" bps = [] for axis in self . axes : bps . append ( axis . data ) mesh = np . meshgrid ( * bps ) res = [] for col in mesh : res . append ( col . flatten ()) return res @property def n_dim ( self ) -> int : \"\"\"Number of Dimensions.\"\"\" return len ( self . axes ) @property def n_bps ( self ) -> int : \"\"\"Number of breakpoints.\"\"\" n_bps = 1 for axis in self . axes : n_bps *= axis . n_bps return n_bps def __iter__ ( self ): \"\"\"Iterate over Axes.\"\"\" return iter ( self . axes ) def to_dict ( self ) -> dict : \"\"\"to dictionary.\"\"\" res = [] for axis in self . axes : res . append ( axis . to_dict ()) return res def __repr__ ( self ) -> str : \"\"\"repr\"\"\" return f \"Axes( { json . dumps ( self . to_dict ()) } )\" def __getattr__ ( self , key : str ) -> Axis : if key . startswith ( \"_\" ): raise AttributeError # Probably dont want to let it return _** for axis in self . axes : if axis . name == key : return axis def __getitem__ ( self , key ) -> Axis | list [ Axis ]: if isinstance ( key , str ): for axis in self . axes : if axis . name == key : return axis elif isinstance ( key , int ): return self . axes [ key ] elif isinstance ( key , slice ): return self . axes [ key ] else : raise NotImplementedError ( f \"Get item not implemented for type: { type ( key ) } \" ) def __setitem__ ( self , key : str | int , value : Axis ): \"\"\"Handle interpolation if needed.\"\"\" if self . interpolate_on_change and self . parent is not None : tmp_axes = copy . deepcopy ( self . axes ) # TODO: Check for circ ref when includes parent if isinstance ( key , str ): for i , axis in enumerate ( tmp_axes ): if axis . name == key : tmp_axes [ i ] = value break elif isinstance ( key , int ): tmp_axes [ key ] = value else : raise NotImplementedError ( f \"Set item not implemented for type: { type ( key ) } \" ) new_data = self . parent . interp ( Axes ( tmp_axes ), extrapolate = True ) self . parent . data = new_data , True # To allow shape change # Snapshot happens here, so axes should be updated after. value . parent = self if isinstance ( key , str ): for i , axis in enumerate ( self . axes ): if axis . name == key : self . axes [ i ] = value elif isinstance ( key , int ): self . axes [ key ] = value def __json__ ( self ): \"\"\"make serializable\"\"\" return self . to_dict () def __eq__ ( self , other : Axes ): \"\"\"equal\"\"\" res = ( self . table_shape == other . table_shape and self . interpolate_on_change == other . interpolate_on_change ) if res : for axis , other_axis in zip ( self . axes , other . axes ): if res : res = res and axis == other_axis else : break return res def __contains__ ( self , key ): \"\"\"Check if key is an axis name in axes\"\"\" names = [] for axis in self . axes : names . append ( axis . name ) return key in names def index ( self , key : str ): \"\"\"return axis index by name\"\"\" for i , axis in enumerate ( self . axes ): if axis . name == key : return i return False grid property Return a meshgrid of the axis bps. n_bps : int property Number of breakpoints. n_dim : int property Number of Dimensions. shape : tuple property Shape of axes bps table_shape : tuple property Shape of the expected data table. first axis is in cols (to match ecu standards), second in rows, beyond that they are stacked rows. __contains__ ( key ) Check if key is an axis name in axes Source code in ccg\\data\\tbldata.py 402 403 404 405 406 407 def __contains__ ( self , key ): \"\"\"Check if key is an axis name in axes\"\"\" names = [] for axis in self . axes : names . append ( axis . name ) return key in names __eq__ ( other ) equal Source code in ccg\\data\\tbldata.py 388 389 390 391 392 393 394 395 396 397 398 399 400 def __eq__ ( self , other : Axes ): \"\"\"equal\"\"\" res = ( self . table_shape == other . table_shape and self . interpolate_on_change == other . interpolate_on_change ) if res : for axis , other_axis in zip ( self . axes , other . axes ): if res : res = res and axis == other_axis else : break return res __iter__ () Iterate over Axes. Source code in ccg\\data\\tbldata.py 315 316 317 def __iter__ ( self ): \"\"\"Iterate over Axes.\"\"\" return iter ( self . axes ) __json__ () make serializable Source code in ccg\\data\\tbldata.py 384 385 386 def __json__ ( self ): \"\"\"make serializable\"\"\" return self . to_dict () __repr__ () repr Source code in ccg\\data\\tbldata.py 326 327 328 def __repr__ ( self ) -> str : \"\"\"repr\"\"\" return f \"Axes( { json . dumps ( self . to_dict ()) } )\" __setitem__ ( key , value ) Handle interpolation if needed. Source code in ccg\\data\\tbldata.py 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 def __setitem__ ( self , key : str | int , value : Axis ): \"\"\"Handle interpolation if needed.\"\"\" if self . interpolate_on_change and self . parent is not None : tmp_axes = copy . deepcopy ( self . axes ) # TODO: Check for circ ref when includes parent if isinstance ( key , str ): for i , axis in enumerate ( tmp_axes ): if axis . name == key : tmp_axes [ i ] = value break elif isinstance ( key , int ): tmp_axes [ key ] = value else : raise NotImplementedError ( f \"Set item not implemented for type: { type ( key ) } \" ) new_data = self . parent . interp ( Axes ( tmp_axes ), extrapolate = True ) self . parent . data = new_data , True # To allow shape change # Snapshot happens here, so axes should be updated after. value . parent = self if isinstance ( key , str ): for i , axis in enumerate ( self . axes ): if axis . name == key : self . axes [ i ] = value elif isinstance ( key , int ): self . axes [ key ] = value append ( axis ) Append axis to Axes. Will not interp. Source code in ccg\\data\\tbldata.py 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 def append ( self , axis : list [ Axis ] | Axis | list [ dict ] | Axes ): \"\"\"Append axis to Axes. Will not interp.\"\"\" tmp_int = self . interpolate_on_change self . interpolate_on_change = False if isinstance ( axis , Axis ): axis = [ axis ] elif isinstance ( axis , Axes ): self . interpolate_on_change = axis . interpolate_on_change axis = axis . axes if axis is not None : # make copies of each axis, also asign parent new_axes = [ ( Axis ( ** tmp_axis , parent = self ) if isinstance ( tmp_axis , dict ) else Axis ( tmp_axis , parent = self ) ) for tmp_axis in axis ] # Ensure axes have names for i , axs in enumerate ( new_axes ): if axs . name is None : new_axes [ i ] . name = f \"axis_ { i } \" self . axes . extend ( new_axes ) self . interpolate_on_change = tmp_int index ( key ) return axis index by name Source code in ccg\\data\\tbldata.py 409 410 411 412 413 414 def index ( self , key : str ): \"\"\"return axis index by name\"\"\" for i , axis in enumerate ( self . axes ): if axis . name == key : return i return False to_dict () to dictionary. Source code in ccg\\data\\tbldata.py 319 320 321 322 323 324 def to_dict ( self ) -> dict : \"\"\"to dictionary.\"\"\" res = [] for axis in self . axes : res . append ( axis . to_dict ()) return res Axis CCG Parameter axis. Source code in ccg\\data\\tbldata.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 class Axis : \"\"\"CCG Parameter axis.\"\"\" def __init__ ( self , data : npt . NDArray | list | Axis = None , name : str = None , unit : str = None , data_range : list = None , precision : int = None , interp_method : ccg . util . InterpMethod = \"\" , parent : Axes = None , ): self . _prec = None self . _data : npt . NDArray | None = None if isinstance ( data , Axis ): self . name = data . name self . unit = data . unit self . interp_method = data . interp_method self . parent = data . parent self . data_range = data . data_range self . _prec = data . _prec data = data . data . copy () if name is not None : self . name = name if unit is not None : self . unit = unit if interp_method is not None : self . interp_method = ccg . util . InterpMethod ( interp_method ) if parent is not None : self . parent = parent if data_range is not None : self . data_range = data_range if precision is not None : self . precision = precision else : self . name = name self . unit = unit self . interp_method = ccg . util . InterpMethod ( interp_method ) self . parent = parent self . data_range = data_range self . precision = precision if isinstance ( data , list ): data = np . array ( data ) self . data = data @property def data ( self ): \"\"\"data.\"\"\" if self . _data is not None : return self . _data else : raise ValueError @data . setter def data ( self , value : npt . NDArray ): if len ( value . shape ) > 1 : raise ValueError ( f \"Axis { self . name } must have at most 1 dimension\" ) if len ( value ) > 0 and not ccg . util . monotonic_increasing ( value ): raise ValueError ( f \"Axis { self . name } must be monotonic increasing.\" ) if self . _data is not None and self . parent is not None : tmp_axis = Axis ( self ) tmp_axis . _data = value self . parent [ self . name ] = tmp_axis # replace with tmp axis to trigger interp if applicable else : self . _data = value @property def precision ( self ): \"\"\"Return the number of decimals.\"\"\" if self . _prec is None : prec = calc_prec ( self . data ) else : prec = self . _prec return prec @precision . setter def precision ( self , value ): \"\"\"Set prec\"\"\" self . _prec = value @property def diff ( self ) -> npt . NDArray [ np . float_ ]: \"\"\"difference.\"\"\" if len ( self . data ) > 0 : return self . data [ 1 :] - self . data [: - 1 ] return np . atleast_1d ( 0 ) @property def is_monotonic_increasing ( self ) -> bool : \"\"\"Check if axis is monotonic.\"\"\" return ccg . util . monotonic_increasing ( self . data ) @property def n_bps ( self ) -> int : \"\"\"Number of breakpoints.\"\"\" return len ( self ) @property def min ( self ): \"\"\"min bp\"\"\" return self . data [ 0 ] @property def max ( self ): \"\"\"max bp\"\"\" return self . data [ - 1 ] def convert_units ( self , unit : str ): \"\"\"Convert units.\"\"\" self . _data = ccg . util . convert_units ( self . data , self . unit , unit ) # Set _data to avoid triggering conversion. self . unit = unit def as_unit ( self , unit : str ): \"\"\"Return copy converted to unit.\"\"\" res = Axis ( self ) res . data = ccg . util . convert_units ( self . data , self . unit , unit ) res . unit = unit return res def bins ( self , values : npt . NDArray | float , extrap : bool = True ): \"\"\"Return bin and interpolation factor of values.\"\"\" bins = np . clip ( np . digitize ( values , self . data ) - 1 , 0 , self . n_bps - 2 ) intf : npt . NDArray | float = ( values - self . data [ bins ]) / self . diff [ bins ] if not extrap : intf = np . clip ( intf , 0 , 1 ) return bins , intf def __len__ ( self ) -> int : \"\"\"Length.\"\"\" return len ( self . data ) def to_dict ( self ) -> dict : \"\"\"to dictionary.\"\"\" res = { \"name\" : self . name , \"data\" : self . data . tolist (), \"unit\" : self . unit , \"interp_method\" : self . interp_method , \"data_range\" : self . data_range , \"precision\" : self . precision , } return res def __repr__ ( self ) -> str : \"\"\"repr\"\"\" return f \"Axis( { json . dumps ( self . to_dict ()) } )\" def __getitem__ ( self , index ): return self . data [ index ] def __setitem__ ( self , index , value ): \"\"\"Triggers interp in parent axes if applicable.\"\"\" if self . _data is not None and self . parent is not None : tmp_axis = Axis ( self ) tmp_axis . _data [ index ] = value self . parent [ self . name ] = tmp_axis # replace with tmp axis to trigger interp if applicable else : self . _data [ index ] = value def __json__ ( self ): \"\"\"make serializable\"\"\" return self . to_dict () def __eq__ ( self , other : Axis ) -> bool : \"\"\"equality\"\"\" res = ( self . name == other . name and self . unit == other . unit and self . interp_method == other . interp_method and self . data_range == other . data_range and self . precision == other . precision and np . all ( self . data == other . data ) ) return res data property writable data. diff : npt . NDArray [ np . float_ ] property difference. is_monotonic_increasing : bool property Check if axis is monotonic. max property max bp min property min bp n_bps : int property Number of breakpoints. precision property writable Return the number of decimals. __eq__ ( other ) equality Source code in ccg\\data\\tbldata.py 201 202 203 204 205 206 207 208 209 210 211 def __eq__ ( self , other : Axis ) -> bool : \"\"\"equality\"\"\" res = ( self . name == other . name and self . unit == other . unit and self . interp_method == other . interp_method and self . data_range == other . data_range and self . precision == other . precision and np . all ( self . data == other . data ) ) return res __json__ () make serializable Source code in ccg\\data\\tbldata.py 197 198 199 def __json__ ( self ): \"\"\"make serializable\"\"\" return self . to_dict () __len__ () Length. Source code in ccg\\data\\tbldata.py 164 165 166 def __len__ ( self ) -> int : \"\"\"Length.\"\"\" return len ( self . data ) __repr__ () repr Source code in ccg\\data\\tbldata.py 180 181 182 def __repr__ ( self ) -> str : \"\"\"repr\"\"\" return f \"Axis( { json . dumps ( self . to_dict ()) } )\" __setitem__ ( index , value ) Triggers interp in parent axes if applicable. Source code in ccg\\data\\tbldata.py 187 188 189 190 191 192 193 194 195 def __setitem__ ( self , index , value ): \"\"\"Triggers interp in parent axes if applicable.\"\"\" if self . _data is not None and self . parent is not None : tmp_axis = Axis ( self ) tmp_axis . _data [ index ] = value self . parent [ self . name ] = tmp_axis # replace with tmp axis to trigger interp if applicable else : self . _data [ index ] = value as_unit ( unit ) Return copy converted to unit. Source code in ccg\\data\\tbldata.py 149 150 151 152 153 154 def as_unit ( self , unit : str ): \"\"\"Return copy converted to unit.\"\"\" res = Axis ( self ) res . data = ccg . util . convert_units ( self . data , self . unit , unit ) res . unit = unit return res bins ( values , extrap = True ) Return bin and interpolation factor of values. Source code in ccg\\data\\tbldata.py 156 157 158 159 160 161 162 def bins ( self , values : npt . NDArray | float , extrap : bool = True ): \"\"\"Return bin and interpolation factor of values.\"\"\" bins = np . clip ( np . digitize ( values , self . data ) - 1 , 0 , self . n_bps - 2 ) intf : npt . NDArray | float = ( values - self . data [ bins ]) / self . diff [ bins ] if not extrap : intf = np . clip ( intf , 0 , 1 ) return bins , intf convert_units ( unit ) Convert units. Source code in ccg\\data\\tbldata.py 143 144 145 146 147 def convert_units ( self , unit : str ): \"\"\"Convert units.\"\"\" self . _data = ccg . util . convert_units ( self . data , self . unit , unit ) # Set _data to avoid triggering conversion. self . unit = unit to_dict () to dictionary. Source code in ccg\\data\\tbldata.py 168 169 170 171 172 173 174 175 176 177 178 def to_dict ( self ) -> dict : \"\"\"to dictionary.\"\"\" res = { \"name\" : self . name , \"data\" : self . data . tolist (), \"unit\" : self . unit , \"interp_method\" : self . interp_method , \"data_range\" : self . data_range , \"precision\" : self . precision , } return res ScatterData Class for storing scatter data to plot with a parameter. Source code in ccg\\data\\tbldata.py 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 class ScatterData : \"\"\"Class for storing scatter data to plot with a parameter.\"\"\" def __init__ ( self , data : list [ npt . NDArray | Sig ], name : str = None , color : npt . NDArray = None , weight : npt . NDArray | float = None , color_name : str = None , color_unit : str = None , color_range : list [ float ] = None , time : npt . NDArray = None , ): self . _color_prec = None self . _weight = None self . _color_range = None if isinstance ( data [ 0 ], np . ndarray ): self . data = data elif isinstance ( data [ 0 ], Sig ): self . data = [ x . data for x in data ] elif isinstance ( data [ 0 ], list ): tmp = [] for lst in data : tmp . append ( np . array ( lst )) self . data = tmp else : raise NotImplementedError ( f \"data of type { type ( data [ 0 ]) } not implemented\" ) if name is None : name = \"Measured\" self . name = name if isinstance ( color , Sig ): self . color = color . data else : if isinstance ( color , list ): color = np . array ( color ) self . color = color self . color_label = color_name self . color_range = color_range if color_unit is None : self . color_unit = \"\" else : self . color_unit = color_unit self . weight = weight self . time = time @property def ndim ( self ): return len ( self . data ) - 1 @property def weight ( self ): \"\"\"Weight\"\"\" return self . _weight @weight . setter def weight ( self , value : npt . NDArray [ np . floating ] | float | None ): \"\"\"Check length and make array if float.\"\"\" if value is None : value = np . ones ( self . data [ 0 ] . data . shape , dtype = np . float64 ) elif isinstance ( value , float ): value = np . ones ( self . data [ 0 ] . data . shape ) * value elif isinstance ( value , list ): value = np . array ( value ) if value . shape != self . data [ 0 ] . data . shape : raise ValueError ( f \"weight of shape: { value . shape } , not compatible with: { self . data [ 0 ] . data . shape } \" ) self . _weight = value @property def color_range ( self ): \"\"\"Return Color Range\"\"\" if self . _color_range is None : if self . color is None : return None if self . color . size > 1 : if self . color_unit == \"ratio\" : return ccg . util . centered_range ( self . color , 1 ) return np . nanpercentile ( self . color , [ 2 , 98 ]) . tolist () else : return None return self . _color_range @color_range . setter def color_range ( self , value : list ): \"\"\"color range setter\"\"\" self . _color_range = value @property def color_precision ( self ): \"\"\"Return the number of decimals.\"\"\" if self . _color_prec is None : if self . color is not None : prec = calc_prec ( self . color ) else : prec = 0 else : prec = self . _color_prec return prec @color_precision . setter def color_precision ( self , value ): \"\"\"Set prec\"\"\" self . _color_prec = value def color_from_density ( self ): self . color = scatter_density ( self ) self . color_label = \"Relative Density\" self . color_unit = \"[]\" self . color_range = None def clean ( self , sort = False ): \"\"\"remove any nan's\"\"\" inds_to_remove = np . logical_or ( np . any ( np . isnan ( self . data ), axis = 0 ), np . isnan ( self . weight ), ) if self . color is not None : inds_to_remove = np . logical_or ( inds_to_remove , np . isnan ( self . color )) self . color = self . color [ ~ inds_to_remove ] self . data : list [ npt . NDArray ] = [ x [ ~ inds_to_remove ] for x in self . data ] self . weight = self . weight [ ~ inds_to_remove ] if sort and self . color is not None and len ( self . color ) > 0 : inds = np . argsort ( self . color ) self . color = self . color [ inds ] self . weight = self . weight [ inds ] new_data = [] for arr in self . data : new_data . append ( arr [ inds ]) self . data = new_data return self def to_dict ( self ): \"\"\"to dict\"\"\" res = { \"name\" : self . name , \"data\" : [ d . tolist () for d in self . data ], \"color\" : ( self . color . tolist () if isinstance ( self . color , np . ndarray ) else self . color ), \"color_name\" : self . color_label , \"color_unit\" : self . color_unit , \"color_range\" : self . color_range , \"weight\" : ( self . weight . tolist () if isinstance ( self . weight , np . ndarray ) else self . weight ), } return res def __json__ ( self ): \"\"\"to json\"\"\" return self . to_dict () def __repr__ ( self ): \"\"\"repr\"\"\" return f \"ScatterData(** { json . dumps ( self ) } )\" color_precision property writable Return the number of decimals. color_range property writable Return Color Range weight property writable Weight __json__ () to json Source code in ccg\\data\\tbldata.py 576 577 578 def __json__ ( self ): \"\"\"to json\"\"\" return self . to_dict () __repr__ () repr Source code in ccg\\data\\tbldata.py 580 581 582 def __repr__ ( self ): \"\"\"repr\"\"\" return f \"ScatterData(** { json . dumps ( self ) } )\" clean ( sort = False ) remove any nan's Source code in ccg\\data\\tbldata.py 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 def clean ( self , sort = False ): \"\"\"remove any nan's\"\"\" inds_to_remove = np . logical_or ( np . any ( np . isnan ( self . data ), axis = 0 ), np . isnan ( self . weight ), ) if self . color is not None : inds_to_remove = np . logical_or ( inds_to_remove , np . isnan ( self . color )) self . color = self . color [ ~ inds_to_remove ] self . data : list [ npt . NDArray ] = [ x [ ~ inds_to_remove ] for x in self . data ] self . weight = self . weight [ ~ inds_to_remove ] if sort and self . color is not None and len ( self . color ) > 0 : inds = np . argsort ( self . color ) self . color = self . color [ inds ] self . weight = self . weight [ inds ] new_data = [] for arr in self . data : new_data . append ( arr [ inds ]) self . data = new_data return self to_dict () to dict Source code in ccg\\data\\tbldata.py 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 def to_dict ( self ): \"\"\"to dict\"\"\" res = { \"name\" : self . name , \"data\" : [ d . tolist () for d in self . data ], \"color\" : ( self . color . tolist () if isinstance ( self . color , np . ndarray ) else self . color ), \"color_name\" : self . color_label , \"color_unit\" : self . color_unit , \"color_range\" : self . color_range , \"weight\" : ( self . weight . tolist () if isinstance ( self . weight , np . ndarray ) else self . weight ), } return res Tbl CCG Parameter. Source code in ccg\\data\\tbldata.py 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 class Tbl : \"\"\"CCG Parameter.\"\"\" def __init__ ( self , data : npt . NDArray | Tbl | list = None , axes : Axes | list = None , name : str = None , unit : str = None , data_range : list = None , precision : int = None , interp_on_axis_change : bool = True , archive : dict = None , scatter_data : ScatterData | list [ ScatterData ] = None , f_smooth : list [ float ] = None , f_orig : float = None , locked : npt . NDArray | list = None , periodic : list [ bool ] = None , ): self . _prec = None self . _archive : dict [ str , list [ Tbl ]] = {} self . _f_smooth = None self . _locked = None self . _axes = None self . _periodic = None self . _motec_shape = None self . count = None if isinstance ( data , Tbl ): if data . data is not None : self . _data = data . data . copy () else : self . _data = None self . _axes = Axes ( data . axes , parent = self ) self . name = data . name self . unit = data . unit self . data_range = data . data_range self . _prec = data . _prec self . interp_on_axis_change = data . interp_on_axis_change self . scatter_data = copy . deepcopy ( data . scatter_data ) self . _f_smooth = data . _f_smooth self . f_orig = data . f_orig self . _locked = data . _locked self . _periodic = data . _periodic self . _motec_shape = data . _motec_shape self . _scatter_data = [] if axes is not None : self . _axes = Axes ( axes , parent = self ) if name is not None : self . name = name if unit is not None : self . unit = unit if data_range is not None : self . data_range = data . data_range if precision is not None : self . precision = precision if interp_on_axis_change is not None : self . interp_on_axis_change = interp_on_axis_change if scatter_data is not None : self . scatter_data = scatter_data if f_smooth is not None : self . f_smooth = f_smooth if f_orig is not None : self . f_orig = f_orig if locked is not None : self . locked = locked if periodic is not None : self . periodic = periodic else : if isinstance ( data , list ): data = np . atleast_1d ( data ) new_axes = Axes ( axes , parent = self ) self . check_shape ( data , new_axes , name ) self . _data = data self . _axes = new_axes if self . count is None : self . count = np . zeros ( self . shape , dtype = np . float_ ) self . name = name self . unit = unit self . data_range = data_range self . precision = precision self . interp_on_axis_change = interp_on_axis_change self . scatter_data = scatter_data self . f_smooth = f_smooth self . locked = locked self . periodic = periodic if f_orig is None : f_orig = 0.1 self . f_orig = f_orig self . snapshot ( \"orig\" ) if archive is not None : # check if its dict of dicts for key , arch in archive . items (): if isinstance ( arch [ 0 ], dict ): arch = [ Tbl ( ** x ) for x in arch ] self . _archive [ key ] = arch self . created = datetime . datetime . now () @property def interp_on_axis_change ( self ): \"\"\"Interpolate on axis change\"\"\" return self . axes . interpolate_on_change @interp_on_axis_change . setter def interp_on_axis_change ( self , value ): \"Setter\" self . axes . interpolate_on_change = value def check_shape ( self , data : npt . NDArray , axes : Axes , name : str = None ): \"\"\"Check that shape is compatible, else raise ValueError.\"\"\" if data is not None and axes is not None and data . shape != axes . shape : raise ValueError ( f \"Data for { name } is incompatible shape: { data . shape } , expected: { axes . shape } \" ) @property def scatter_data ( self ) -> list [ ScatterData ]: \"\"\"Scatter data\"\"\" return self . _scatter_data @scatter_data . setter def scatter_data ( self , value : ScatterData | list [ ScatterData ]): \"\"\"setter\"\"\" if not isinstance ( value , list ): if isinstance ( value , dict ): value = ScatterData ( ** value ) value = [ value ] else : tmp = [] for sc in value : if isinstance ( sc , dict ): tmp . append ( ScatterData ( ** sc )) elif isinstance ( sc , ScatterData ) or sc is None : tmp . append ( sc ) else : raise NotImplementedError value = tmp self . _scatter_data = value # TODO: Why is this a list?? def snapshot ( self , name : str = None ): \"\"\"Archive current value.\"\"\" if name is None : name = \"prev\" if name not in self . _archive : self . _archive [ name ] = [] if not self . _archive [ name ] or self . _archive [ name ][ - 1 ] != self : self . _archive [ name ] . append ( Tbl ( self )) # to make a copy def convert_units ( self , unit : str ): \"\"\"Convert units in place.\"\"\" self . data = ccg . util . convert_units ( self . data , self . unit , unit ) self . unit = unit def as_unit ( self , unit : str ): \"\"\"Return copy converted to unit.\"\"\" res = Tbl ( self ) res . data = ccg . util . convert_units ( self . data , self . unit , unit ) res . unit = unit return res @property def data ( self ): \"\"\"Return the table data.\"\"\" return self . _data @data . setter def data ( self , value : npt . NDArray | tuple [ npt . NDArray , bool ]): \"\"\"Set the data, store a snapshot first.\"\"\" if isinstance ( value , tuple ): allow_shape_change = value [ 1 ] value = value [ 0 ] else : allow_shape_change = False if not allow_shape_change : self . check_shape ( value , self . axes , self . name ) if self . _data is not None : self . snapshot () self . _data = np . atleast_1d ( value ) . astype ( self . data . dtype ) else : self . _data = np . atleast_1d ( value ) if self . count is None : self . count = np . zeros ( self . shape , dtype = np . float_ ) @property def delta ( self ) -> npt . NDArray : \"\"\"Delta to original table.\"\"\" orig = ccg . util . convert_units ( self . orig . interp ( self . axes , extrapolate = False ), self . orig . unit , self . unit ) return self . data - orig @property def delta_perc ( self ) -> npt . NDArray [ np . floating ]: \"\"\"Percent delta to original table.\"\"\" # Check units have no offset _ , off , quant = ccg . util . find_unit ( self . unit ) if off != 0 : to_unit = list ( ccg . util . UNIT_CONV [ quant ] . keys ())[ 0 ] else : to_unit = self . unit data = ccg . util . convert_units ( self . data , self . unit , to_unit ) orig = ccg . util . convert_units ( self . orig . interp ( self . axes , extrapolate = False ), self . orig . unit , to_unit ) # if np.any(orig == 0): # orig[orig == 0] = 0.01 # Avoid div/0 res = ( data / orig ) - 1 if np . any ( np . isnan ( res )) or np . any ( np . isinf ( res )): res [ np . isnan ( res )] = 0 # set any nan to 0 res [ np . isinf ( res )] = np . sign ( res [ np . isinf ( res )]) * 1 res = ccg . util . convert_units ( res , \"ratio\" , \"%\" ) return res @property def f_smooth ( self ): \"\"\"Return f_smooth\"\"\" if self . _f_smooth is not None : return self . _f_smooth raise ValueError @f_smooth . setter def f_smooth ( self , value : list [ float ] | float ): \"\"\"set f_smooth\"\"\" if value is None : self . _f_smooth = [ 0.1 ] * self . n_dim elif isinstance ( value , float ): self . _f_smooth = [ value ] * self . n_dim elif len ( value ) != self . n_dim : raise ValueError ( f \"f_smooth len: { len ( value ) } must be scalar or length of { self . n_dim } \" ) else : self . _f_smooth = value @property def precision ( self ): \"\"\"Return the number of decimals.\"\"\" if self . _prec is None : if self . data is not None : prec = calc_prec ( self . data ) else : prec = 0 else : prec = self . _prec return prec @precision . setter def precision ( self , value ): \"\"\"Set prec\"\"\" self . _prec = value @property def locked ( self ): \"\"\"locked\"\"\" if self . _locked is not None : return self . _locked else : raise ValueError @locked . setter def locked ( self , value : npt . NDArray [ np . bool_ ] | bool | list [ bool ]): \"\"\"Set locked\"\"\" if isinstance ( value , list ): value = np . array ( value ) if self . data is not None : if isinstance ( value , bool ): value = np . ones ( self . data . shape , dtype = np . bool_ ) * value elif value is None : value = np . zeros ( self . data . shape , dtype = np . bool_ ) else : if value . shape != self . data . shape : raise ValueError ( f \"locked shape of { value . shape } is incompatible with { self . data . shape } \" ) self . _locked = value @property def periodic ( self ): \"\"\"Return periodic constraints.\"\"\" return self . _periodic @periodic . setter def periodic ( self , value : bool | list [ bool ]): \"\"\"Set periodic constraints\"\"\" if isinstance ( value , bool ): value = [ value ] * self . n_dim if value is None : value = [ False ] * self . n_dim if len ( value ) != self . n_dim : raise ValueError ( f \"periodic constraints of len: { len ( value ) } is incompatible with n_dim: { self . n_dim } \" ) self . _periodic = value @property def axes ( self ) -> Axes : \"\"\"returns the axes.\"\"\" return self . _axes @axes . setter def axes ( self , value : Axes ): \"\"\"set the axes, interpolate if `self.interp_on_axis_change=True`\"\"\" if self . axes is not None and value . shape != self . axes . shape : raise ValueError ( f \"Unexpected Axes shape for { self . name } of: { value . shape } . Expected: { self . axes . shape } \" ) if self . interp_on_axis_change : # interpolate new_data = self . interp ( value , extrapolate = True ) self . _axes = value self . data = new_data # snapshot happens in here. else : # interpret if self . axes is not None : self . snapshot () self . _axes = value self . _axes . parent = self @property def shape ( self ): \"\"\"shape\"\"\" return self . axes . shape @property def dtype ( self ): \"\"\"dtype\"\"\" return self . data . dtype @property def motec_shape ( self ): \"\"\"shape of base motec table\"\"\" if self . _motec_shape : return self . _motec_shape return self . shape + ( 1 ,) * ( 3 - max ( self . n_dim , 1 )) # to make 3d @motec_shape . setter def motec_shape ( self , value : tuple ): \"\"\"motec_shape_setter\"\"\" self . _motec_shape = value @property def orig ( self ): \"\"\"Return copy of original param.\"\"\" return Tbl ( self . _archive [ \"orig\" ][ - 1 ], name = \"orig\" ) @property def min ( self ): \"\"\"min value\"\"\" return self . data . min () @property def max ( self ): \"\"\"max value\"\"\" return self . data . max () def data_color ( self , colorscale = \"Turbo\" , light_font = \"#e5e5e5\" , dark_font = \"#434343\" ): \"\"\"Get colors for table, makes use of plotly colorscales.\"\"\" import plotly.colors as pc scale = pc . get_colorscale ( colorscale ) pts = ( self . data - self . data . min ()) / ( self . data . max () - self . data . min ()) colors = pc . sample_colorscale ( scale , pts . flatten () . tolist ()) font_colors = ccg . util . max_contrast ( colors , light_font , dark_font ) colors = np . array ( colors ) . reshape ( self . shape ) font_colors = np . array ( font_colors ) . reshape ( self . shape ) return colors , font_colors def prev ( self ) -> Tbl : \"\"\"Return previous state of this param.\"\"\" if \"prev\" in self . _archive : return self . _archive [ \"prev\" ][ - 1 ] return self def undo ( self , nsteps : int = None ) -> None : \"\"\"Restore prev state of data and axes by nsteps. -1 is oldest undo.\"\"\" if \"prev\" in self . _archive and len ( self . _archive [ \"prev\" ]) > 0 : if nsteps is None : prev = self . _archive [ \"prev\" ] . pop ( - 1 ) elif nsteps == - 1 : prev = self . _archive [ \"prev\" ][ 0 ] self . _archive [ \"prev\" ] = [] # clear prev else : prev = self . _archive [ \"prev\" ][ - 1 * nsteps ] del self . _archive [ \"prev\" ][ - 1 * nsteps :] prev . axes . parent = self # since axes parent ref is lost in archive. self . _axes = prev . axes self . _data : npt . NDArray = prev . data def clear_archive ( self ): \"\"\"Clear archive.\"\"\" self . _archive = None def interp ( self , new_bps : Axes | npt . NDArray | Frame | Sig , extrapolate : bool = False ): \"\"\"Return data interpolated at new_bps. Parameters ---------- new_bps If new_bps is an ndarray it must be nsamples x nd, and the result will be nsamples, If new_bps is an Axes, it must have the same number of dimensions as the param. If new_bps is a Frame, it looks for signals matching axis names. extrapolate saturate to bounds if False Returns ------- interpolated data, size of nsamples, if new_bps is ndarray or size of axes if new_bps is axes. \"\"\" if self . n_dim == 0 : return self . data # Interpolation doesnt make sense for 0d if np . any ([ x . interp_method != ccg . util . InterpMethod . LINEAR for x in self . axes ]): raise NotImplementedError ( \"Only linear interp is implemented\" ) if isinstance ( new_bps , Axes ): if new_bps . n_dim < self . n_dim : raise ValueError ( f \"new_bps has { new_bps . n_dim } dimensions. Expected >= { self . n_dim } .\" ) tmp = [] for i , axis in enumerate ( new_bps ): if i < self . n_dim : tmp . append ( axis . data ) points = np . meshgrid ( * tmp , indexing = \"ij\" ) # *bps to unpack bps points = np . array ([ point . flatten () for point in points ]) . T elif isinstance ( new_bps , Frame ): # TODO: Add fix for different timelines tline1 = new_bps [ self . axes [ 0 ] . name ] . tline points = new_bps [ self . axes [ 0 ] . name ] . data [:, np . newaxis ] for i in range ( 1 , self . n_dim ): if new_bps [ self . axes [ i ] . name ] . tline != tline1 : raise ValueError ( f \" { self . axes [ 0 ] . name } and { self . axes [ i ] . name } have different tlines, cannot interp { self . name } \" ) points = np . append ( points , new_bps [ self . axes [ i ] . name ] . data [:, np . newaxis ], axis = 1 ) else : if new_bps . shape [ 1 ] != self . n_dim : raise ValueError ( f \"new_bps has { new_bps . shape [ 1 ] } dimensions. Expected { self . n_dim } .\" ) points = new_bps bps = [] for axis in self . axes : bps . append ( axis . data ) new_data = ccg . util . linearinterp ( bps = bps , data = self . data , points = points , extrapolate = extrapolate ) if isinstance ( new_bps , Axes ): new_data = new_data . reshape ( tuple ( x . n_bps for x in new_bps )) if isinstance ( new_bps , Frame | Sig ): new_data = Sig ( data = new_data , tline = tline1 , name = self . name , unit = self . unit ) return new_data def plot ( self ) -> Plot : \"\"\"Generate plot\"\"\" from ccg.ui.plot import Plot plot = Plot ( self ) plot . plot () return plot def fit ( self , saturate = False ): \"\"\"Fit param if scatter data is present.\"\"\" if self . scatter_data [ 0 ] is None : raise ValueError ( f \"Scatter data is missing to fit { self . name } \" ) tmp = fit ( self , data = self . scatter_data [ 0 ]) if saturate and self . data_range : tmp = np . clip ( tmp , self . data_range [ 0 ], self . data_range [ 1 ]) self . data = tmp @property def n_dim ( self ) -> int : \"\"\"Number of Dimensions.\"\"\" return self . axes . n_dim @property def grid ( self ): \"\"\"Axes BPs grid.\"\"\" return self . axes . grid def to_dict ( self , include_archive : bool = True , include_scatter : bool = True ) -> dict : \"\"\"To dict\"\"\" res = { \"name\" : self . name , \"unit\" : self . unit , \"axes\" : self . axes . to_dict (), \"data\" : self . data . tolist (), \"data_range\" : self . data_range , \"precision\" : self . precision , \"interp_on_axis_change\" : self . interp_on_axis_change , \"locked\" : self . locked . tolist (), } if include_archive and \"_archive\" in self . __dict__ : res [ \"archive\" ] = {} for key , val in self . _archive . items (): res [ \"archive\" ][ key ] = [ par . to_dict () for par in val ] if include_scatter and \"_scatter_data\" in self . __dict__ : res [ \"scatter_data\" ] = [ sd . to_dict () if sd is not None else None for sd in self . scatter_data ] return res def to_file ( self , filename : str | Path , include_archive : bool = False , include_scatter : bool = False , ): \"\"\"Save to file\"\"\" filename = Path ( filename ) if filename . suffixes [ - 2 :] != [ \".tbl\" , \".json\" ]: filename = filename . with_suffix ( \".tbl.json\" ) with open ( filename , \"w\" , encoding = \"utf8\" ) as f : f . write ( json . dumps ( self . to_dict ( include_archive = include_archive , include_scatter = include_scatter , ), indent = 4 , ) ) return filename async def to_file_async ( self , filename : str | Path , include_archive : bool = False , include_scatter : bool = False , ): \"\"\"Save to file asynchronously\"\"\" filename = Path ( filename ) if filename . suffixes [ - 2 :] != [ \".tbl\" , \".json\" ]: filename = filename . with_suffix ( \".tbl.json\" ) async with aiofiles . open ( filename , \"w\" , encoding = \"utf8\" ) as f : await f . write ( json . dumps ( self . to_dict ( include_archive = include_archive , include_scatter = include_scatter , ), indent = 4 , ) ) return filename @classmethod async def from_file_async ( cls , filename : str | Path ): \"\"\" Asynchronously load Tbl from file. Parameters ---------- filename : str | Path The name of the file from which to load the data. If the file extension is not \".tbl.json\", it will be added. Returns ------- cls An instance of Tbl, initialized with the data loaded from the file. Notes ----- This method is asynchronous and should be awaited. \"\"\" filename = Path ( filename ) if filename . suffixes [ - 2 :] != [ \".tbl\" , \".json\" ]: filename = filename . with_suffix ( \".tbl.json\" ) async with aiofiles . open ( filename , \"r\" , encoding = \"utf8\" ) as f : data = await f . read () tbl_dict = json . loads ( data ) return cls ( ** tbl_dict ) @classmethod def from_file ( cls , filename : str | Path ): \"\"\" Synchronously load Tbl from file. Parameters ---------- filename : str | Path The name of the file from which to load the data. If the file extension is not \".tbl.json\", it will be added. Returns ------- cls An instance of Tbl, initialized with the data loaded from the file. \"\"\" filename = Path ( filename ) if filename . suffixes [ - 2 :] != [ \".tbl\" , \".json\" ]: filename = filename . with_suffix ( \".tbl.json\" ) with open ( filename , \"r\" , encoding = \"utf8\" ) as f : data = f . read () tbl_dict = json . loads ( data ) return cls ( ** tbl_dict ) def __add__ ( self , other ): \"\"\"add, interpolate other if its a Param. returns new Param.\"\"\" res = Tbl ( name = \"_result\" , data = self ) if isinstance ( other , Tbl ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] + %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . interp ( self . axes , extrapolate = True ) res . data = self . data + other return res def __sub__ ( self , other ): \"\"\"subtract, interpolate other if its a Param. returns new Param.\"\"\" res = Tbl ( name = \"_result\" , data = self ) if isinstance ( other , Tbl ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] - %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . interp ( self . axes , extrapolate = True ) res . data = self . data - other return res def __iadd__ ( self , other ): \"\"\"add, interpolate other if its a Param. in place.\"\"\" if isinstance ( other , Tbl ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] + %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . interp ( self . axes , extrapolate = True ) self . data = self . data + other return self def __isub__ ( self , other ): \"\"\"subtract, interpolate other if its a Param. in place.\"\"\" if isinstance ( other , Tbl ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] - %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . interp ( self . axes , extrapolate = True ) self . data = self . data - other return self def __radd__ ( self , other ): \"\"\"add, resamples to parent.math_tline if exists. returns new Param.\"\"\" return self . __add__ ( other ) def __rsub__ ( self , other ): \"\"\"subtract, interpolate other if its a Param. returns new Param.\"\"\" res = Tbl ( name = \"_result\" , data = self ) if isinstance ( other , Tbl ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] - %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . interp ( self . axes , extrapolate = True ) res . data = other - self . data return res def __mul__ ( self , other ): \"\"\"multiply(elementwise), interpolate other if its a Param. returns new Param.\"\"\" res = Tbl ( name = \"_result\" , data = self ) if isinstance ( other , Tbl ): if self . unit and self . unit == other . unit : unit = self . unit + \"**2\" elif other . unit is None : unit = self . unit else : unit = self . unit + \"*\" + other . unit other = other . interp ( self . axes , extrapolate = True ) else : unit = self . unit res . unit = unit res . data = self . data * other return res def __truediv__ ( self , other ): \"\"\"divide(elementwise), resamples to parent.math_tline if exists. returns Param.\"\"\" res = Tbl ( name = \"_result\" , data = self ) if isinstance ( other , Tbl ): if self . unit == other . unit : unit = None elif other . unit is None : unit = self . unit else : unit = self . unit + \"/\" + other . unit other = other . interp ( self . axes , extrapolate = True ) else : unit = self . unit res . unit = unit res . data = self . data / other return res def __imul__ ( self , other ): \"\"\"multiply(elementwise), interpolate other if its a Param. returns new Param.\"\"\" if isinstance ( other , Tbl ): if self . unit and self . unit == other . unit : unit = self . unit + \"**2\" elif other . unit is None : unit = self . unit else : unit = self . unit + \"*\" + other . unit other = other . interp ( self . axes , extrapolate = True ) else : unit = self . unit self . unit = unit self . data *= other return self def __itruediv__ ( self , other ): \"\"\"divide(elementwise), resamples to parent.math_tline if exists. returns Param.\"\"\" if isinstance ( other , Tbl ): if self . unit == other . unit : unit = None elif other . unit is None : unit = self . unit else : unit = self . unit + \"/\" + other . unit other = other . interp ( self . axes , extrapolate = True ) else : unit = self . unit self . unit = unit self . data /= other return self def __pow__ ( self , other ): \"\"\"power, resamples to parent.math_tline if exists. returns Param.\"\"\" res = Tbl ( name = \"_result\" , data = self ) unit = self . unit + \"**n\" if isinstance ( other , Tbl ): other = other . interp ( self . axes , extrapolate = True ) elif len ( other ) == 1 : unit = self . unit + \"**\" + str ( other ) res . unit = unit res . data = self . data ** other return res def __abs__ ( self ): \"\"\"abs\"\"\" res = Tbl ( self , name = f \"abs( { self . name } )\" ) res . data = np . abs ( self . data ) return res def __neg__ ( self ): \"\"\"neg\"\"\" res = Tbl ( self , name = f \"neg( { self . name } )\" ) res . data = self . data * - 1 return res def __eq__ ( self , other : Tbl ) -> bool : \"\"\"Returns True if basics match.\"\"\" res = ( isinstance ( other , Tbl ) and self . name == other . name and self . unit == other . unit and self . axes == other . axes and np . all ( self . data == other . data ) and self . precision == other . precision and self . interp_on_axis_change == other . interp_on_axis_change ) return res def __repr__ ( self ) -> str : \"\"\"repr\"\"\" return f \"Tbl( { json . dumps ( self . to_dict ()) } )\" def __getitem__ ( self , index : list [ list ] | Axes | npt . NDArray | str | Frame ): if isinstance ( index , list ): if not isinstance ( index [ 0 ], list ): index = [ index ] if len ( index [ 0 ]) == self . n_dim : new_bps = np . array ( index ) else : raise ValueError ( f \"Index must be nsamples x { self . n_dim } \" ) elif isinstance ( index , Axes | np . ndarray ): new_bps = index elif isinstance ( index , str ): if index in self . __dict__ : return self . __dict__ [ index ] else : try : return getattr ( self , index ) except KeyError as err : raise KeyError ( f \" { index } not in { self . name } \" ) from err elif isinstance ( index , tuple ): if isinstance ( index [ 0 ], list ): new_bps = np . array ( list ( index )) else : new_bps = np . array ([ list ( index )]) elif isinstance ( index , Frame ): # If a frame is passed in, calculate interpolated values on the math_tline or fastest of inputs. if self . n_dim == 0 : # find a tline if index . math_tline is not None : tline = index . math_tline else : try : tline = index . tline except ValueError : pass tline = index . tlines . get_fastest () data = self . data [ 0 ] # To let sig __init__ expand to tline else : if index . math_tline is None : # Find tline, fastest of axes tline = index [ self . axes [ 0 ] . name ] . tline for axis in self . axes : if index [ axis . name ] . tline . period < tline . period : tline = index [ axis . name ] . tline else : tline = index . math_tline new_bps = np . empty (( tline . nsamples , self . n_dim )) for i , axis in enumerate ( self . axes ): new_bps [:, i ] = ( index [ axis . name ] . as_unit ( axis . unit ) . resample ( tline ) . data ) data = self . interp ( new_bps ) res = Sig ( name = self . name , unit = self . unit , data = data , tline = tline ) return res else : raise NotImplementedError ( f \"Getitem not implemented for type: { type ( index ) } \" ) return self . interp ( new_bps ) def __json__ ( self ): \"\"\"make serializable\"\"\" return self . to_dict () axes : Axes property writable returns the axes. data property writable Return the table data. delta : npt . NDArray property Delta to original table. delta_perc : npt . NDArray [ np . floating ] property Percent delta to original table. dtype property dtype f_smooth property writable Return f_smooth grid property Axes BPs grid. interp_on_axis_change property writable Interpolate on axis change locked property writable locked max property max value min property min value motec_shape property writable shape of base motec table n_dim : int property Number of Dimensions. orig property Return copy of original param. periodic property writable Return periodic constraints. precision property writable Return the number of decimals. scatter_data : list [ ScatterData ] property writable Scatter data shape property shape __abs__ () abs Source code in ccg\\data\\tbldata.py 1377 1378 1379 1380 1381 def __abs__ ( self ): \"\"\"abs\"\"\" res = Tbl ( self , name = f \"abs( { self . name } )\" ) res . data = np . abs ( self . data ) return res __add__ ( other ) add, interpolate other if its a Param. returns new Param. Source code in ccg\\data\\tbldata.py 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 def __add__ ( self , other ): \"\"\"add, interpolate other if its a Param. returns new Param.\"\"\" res = Tbl ( name = \"_result\" , data = self ) if isinstance ( other , Tbl ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] + %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . interp ( self . axes , extrapolate = True ) res . data = self . data + other return res __eq__ ( other ) Returns True if basics match. Source code in ccg\\data\\tbldata.py 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 def __eq__ ( self , other : Tbl ) -> bool : \"\"\"Returns True if basics match.\"\"\" res = ( isinstance ( other , Tbl ) and self . name == other . name and self . unit == other . unit and self . axes == other . axes and np . all ( self . data == other . data ) and self . precision == other . precision and self . interp_on_axis_change == other . interp_on_axis_change ) return res __iadd__ ( other ) add, interpolate other if its a Param. in place. Source code in ccg\\data\\tbldata.py 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 def __iadd__ ( self , other ): \"\"\"add, interpolate other if its a Param. in place.\"\"\" if isinstance ( other , Tbl ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] + %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . interp ( self . axes , extrapolate = True ) self . data = self . data + other return self __imul__ ( other ) multiply(elementwise), interpolate other if its a Param. returns new Param. Source code in ccg\\data\\tbldata.py 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 def __imul__ ( self , other ): \"\"\"multiply(elementwise), interpolate other if its a Param. returns new Param.\"\"\" if isinstance ( other , Tbl ): if self . unit and self . unit == other . unit : unit = self . unit + \"**2\" elif other . unit is None : unit = self . unit else : unit = self . unit + \"*\" + other . unit other = other . interp ( self . axes , extrapolate = True ) else : unit = self . unit self . unit = unit self . data *= other return self __isub__ ( other ) subtract, interpolate other if its a Param. in place. Source code in ccg\\data\\tbldata.py 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 def __isub__ ( self , other ): \"\"\"subtract, interpolate other if its a Param. in place.\"\"\" if isinstance ( other , Tbl ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] - %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . interp ( self . axes , extrapolate = True ) self . data = self . data - other return self __itruediv__ ( other ) divide(elementwise), resamples to parent.math_tline if exists. returns Param. Source code in ccg\\data\\tbldata.py 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 def __itruediv__ ( self , other ): \"\"\"divide(elementwise), resamples to parent.math_tline if exists. returns Param.\"\"\" if isinstance ( other , Tbl ): if self . unit == other . unit : unit = None elif other . unit is None : unit = self . unit else : unit = self . unit + \"/\" + other . unit other = other . interp ( self . axes , extrapolate = True ) else : unit = self . unit self . unit = unit self . data /= other return self __json__ () make serializable Source code in ccg\\data\\tbldata.py 1468 1469 1470 def __json__ ( self ): \"\"\"make serializable\"\"\" return self . to_dict () __mul__ ( other ) multiply(elementwise), interpolate other if its a Param. returns new Param. Source code in ccg\\data\\tbldata.py 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 def __mul__ ( self , other ): \"\"\"multiply(elementwise), interpolate other if its a Param. returns new Param.\"\"\" res = Tbl ( name = \"_result\" , data = self ) if isinstance ( other , Tbl ): if self . unit and self . unit == other . unit : unit = self . unit + \"**2\" elif other . unit is None : unit = self . unit else : unit = self . unit + \"*\" + other . unit other = other . interp ( self . axes , extrapolate = True ) else : unit = self . unit res . unit = unit res . data = self . data * other return res __neg__ () neg Source code in ccg\\data\\tbldata.py 1383 1384 1385 1386 1387 def __neg__ ( self ): \"\"\"neg\"\"\" res = Tbl ( self , name = f \"neg( { self . name } )\" ) res . data = self . data * - 1 return res __pow__ ( other ) power, resamples to parent.math_tline if exists. returns Param. Source code in ccg\\data\\tbldata.py 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 def __pow__ ( self , other ): \"\"\"power, resamples to parent.math_tline if exists. returns Param.\"\"\" res = Tbl ( name = \"_result\" , data = self ) unit = self . unit + \"**n\" if isinstance ( other , Tbl ): other = other . interp ( self . axes , extrapolate = True ) elif len ( other ) == 1 : unit = self . unit + \"**\" + str ( other ) res . unit = unit res . data = self . data ** other return res __radd__ ( other ) add, resamples to parent.math_tline if exists. returns new Param. Source code in ccg\\data\\tbldata.py 1276 1277 1278 def __radd__ ( self , other ): \"\"\"add, resamples to parent.math_tline if exists. returns new Param.\"\"\" return self . __add__ ( other ) __repr__ () repr Source code in ccg\\data\\tbldata.py 1402 1403 1404 def __repr__ ( self ) -> str : \"\"\"repr\"\"\" return f \"Tbl( { json . dumps ( self . to_dict ()) } )\" __rsub__ ( other ) subtract, interpolate other if its a Param. returns new Param. Source code in ccg\\data\\tbldata.py 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 def __rsub__ ( self , other ): \"\"\"subtract, interpolate other if its a Param. returns new Param.\"\"\" res = Tbl ( name = \"_result\" , data = self ) if isinstance ( other , Tbl ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] - %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . interp ( self . axes , extrapolate = True ) res . data = other - self . data return res __sub__ ( other ) subtract, interpolate other if its a Param. returns new Param. Source code in ccg\\data\\tbldata.py 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 def __sub__ ( self , other ): \"\"\"subtract, interpolate other if its a Param. returns new Param.\"\"\" res = Tbl ( name = \"_result\" , data = self ) if isinstance ( other , Tbl ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] - %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . interp ( self . axes , extrapolate = True ) res . data = self . data - other return res __truediv__ ( other ) divide(elementwise), resamples to parent.math_tline if exists. returns Param. Source code in ccg\\data\\tbldata.py 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 def __truediv__ ( self , other ): \"\"\"divide(elementwise), resamples to parent.math_tline if exists. returns Param.\"\"\" res = Tbl ( name = \"_result\" , data = self ) if isinstance ( other , Tbl ): if self . unit == other . unit : unit = None elif other . unit is None : unit = self . unit else : unit = self . unit + \"/\" + other . unit other = other . interp ( self . axes , extrapolate = True ) else : unit = self . unit res . unit = unit res . data = self . data / other return res as_unit ( unit ) Return copy converted to unit. Source code in ccg\\data\\tbldata.py 745 746 747 748 749 750 def as_unit ( self , unit : str ): \"\"\"Return copy converted to unit.\"\"\" res = Tbl ( self ) res . data = ccg . util . convert_units ( self . data , self . unit , unit ) res . unit = unit return res check_shape ( data , axes , name = None ) Check that shape is compatible, else raise ValueError. Source code in ccg\\data\\tbldata.py 697 698 699 700 701 702 def check_shape ( self , data : npt . NDArray , axes : Axes , name : str = None ): \"\"\"Check that shape is compatible, else raise ValueError.\"\"\" if data is not None and axes is not None and data . shape != axes . shape : raise ValueError ( f \"Data for { name } is incompatible shape: { data . shape } , expected: { axes . shape } \" ) clear_archive () Clear archive. Source code in ccg\\data\\tbldata.py 987 988 989 def clear_archive ( self ): \"\"\"Clear archive.\"\"\" self . _archive = None convert_units ( unit ) Convert units in place. Source code in ccg\\data\\tbldata.py 740 741 742 743 def convert_units ( self , unit : str ): \"\"\"Convert units in place.\"\"\" self . data = ccg . util . convert_units ( self . data , self . unit , unit ) self . unit = unit data_color ( colorscale = 'Turbo' , light_font = '#e5e5e5' , dark_font = '#434343' ) Get colors for table, makes use of plotly colorscales. Source code in ccg\\data\\tbldata.py 953 954 955 956 957 958 959 960 961 962 963 def data_color ( self , colorscale = \"Turbo\" , light_font = \"#e5e5e5\" , dark_font = \"#434343\" ): \"\"\"Get colors for table, makes use of plotly colorscales.\"\"\" import plotly.colors as pc scale = pc . get_colorscale ( colorscale ) pts = ( self . data - self . data . min ()) / ( self . data . max () - self . data . min ()) colors = pc . sample_colorscale ( scale , pts . flatten () . tolist ()) font_colors = ccg . util . max_contrast ( colors , light_font , dark_font ) colors = np . array ( colors ) . reshape ( self . shape ) font_colors = np . array ( font_colors ) . reshape ( self . shape ) return colors , font_colors fit ( saturate = False ) Fit param if scatter data is present. Source code in ccg\\data\\tbldata.py 1067 1068 1069 1070 1071 1072 1073 1074 def fit ( self , saturate = False ): \"\"\"Fit param if scatter data is present.\"\"\" if self . scatter_data [ 0 ] is None : raise ValueError ( f \"Scatter data is missing to fit { self . name } \" ) tmp = fit ( self , data = self . scatter_data [ 0 ]) if saturate and self . data_range : tmp = np . clip ( tmp , self . data_range [ 0 ], self . data_range [ 1 ]) self . data = tmp from_file ( filename ) classmethod Synchronously load Tbl from file. Parameters: filename ( str | Path ) \u2013 The name of the file from which to load the data. If the file extension is not \".tbl.json\", it will be added. Returns: cls \u2013 An instance of Tbl, initialized with the data loaded from the file. Source code in ccg\\data\\tbldata.py 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 @classmethod def from_file ( cls , filename : str | Path ): \"\"\" Synchronously load Tbl from file. Parameters ---------- filename : str | Path The name of the file from which to load the data. If the file extension is not \".tbl.json\", it will be added. Returns ------- cls An instance of Tbl, initialized with the data loaded from the file. \"\"\" filename = Path ( filename ) if filename . suffixes [ - 2 :] != [ \".tbl\" , \".json\" ]: filename = filename . with_suffix ( \".tbl.json\" ) with open ( filename , \"r\" , encoding = \"utf8\" ) as f : data = f . read () tbl_dict = json . loads ( data ) return cls ( ** tbl_dict ) from_file_async ( filename ) async classmethod Asynchronously load Tbl from file. Parameters: filename ( str | Path ) \u2013 The name of the file from which to load the data. If the file extension is not \".tbl.json\", it will be added. Returns: cls \u2013 An instance of Tbl, initialized with the data loaded from the file. Notes This method is asynchronous and should be awaited. Source code in ccg\\data\\tbldata.py 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 @classmethod async def from_file_async ( cls , filename : str | Path ): \"\"\" Asynchronously load Tbl from file. Parameters ---------- filename : str | Path The name of the file from which to load the data. If the file extension is not \".tbl.json\", it will be added. Returns ------- cls An instance of Tbl, initialized with the data loaded from the file. Notes ----- This method is asynchronous and should be awaited. \"\"\" filename = Path ( filename ) if filename . suffixes [ - 2 :] != [ \".tbl\" , \".json\" ]: filename = filename . with_suffix ( \".tbl.json\" ) async with aiofiles . open ( filename , \"r\" , encoding = \"utf8\" ) as f : data = await f . read () tbl_dict = json . loads ( data ) return cls ( ** tbl_dict ) interp ( new_bps , extrapolate = False ) Return data interpolated at new_bps. Parameters: new_bps ( Axes | NDArray | Frame | Sig ) \u2013 If new_bps is an ndarray it must be nsamples x nd, and the result will be nsamples, If new_bps is an Axes, it must have the same number of dimensions as the param. If new_bps is a Frame, it looks for signals matching axis names. extrapolate ( bool , default: False ) \u2013 saturate to bounds if False Returns: interpolated data, size of nsamples, if new_bps is ndarray or size of axes if new_bps is axes. \u2013 Source code in ccg\\data\\tbldata.py 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 def interp ( self , new_bps : Axes | npt . NDArray | Frame | Sig , extrapolate : bool = False ): \"\"\"Return data interpolated at new_bps. Parameters ---------- new_bps If new_bps is an ndarray it must be nsamples x nd, and the result will be nsamples, If new_bps is an Axes, it must have the same number of dimensions as the param. If new_bps is a Frame, it looks for signals matching axis names. extrapolate saturate to bounds if False Returns ------- interpolated data, size of nsamples, if new_bps is ndarray or size of axes if new_bps is axes. \"\"\" if self . n_dim == 0 : return self . data # Interpolation doesnt make sense for 0d if np . any ([ x . interp_method != ccg . util . InterpMethod . LINEAR for x in self . axes ]): raise NotImplementedError ( \"Only linear interp is implemented\" ) if isinstance ( new_bps , Axes ): if new_bps . n_dim < self . n_dim : raise ValueError ( f \"new_bps has { new_bps . n_dim } dimensions. Expected >= { self . n_dim } .\" ) tmp = [] for i , axis in enumerate ( new_bps ): if i < self . n_dim : tmp . append ( axis . data ) points = np . meshgrid ( * tmp , indexing = \"ij\" ) # *bps to unpack bps points = np . array ([ point . flatten () for point in points ]) . T elif isinstance ( new_bps , Frame ): # TODO: Add fix for different timelines tline1 = new_bps [ self . axes [ 0 ] . name ] . tline points = new_bps [ self . axes [ 0 ] . name ] . data [:, np . newaxis ] for i in range ( 1 , self . n_dim ): if new_bps [ self . axes [ i ] . name ] . tline != tline1 : raise ValueError ( f \" { self . axes [ 0 ] . name } and { self . axes [ i ] . name } have different tlines, cannot interp { self . name } \" ) points = np . append ( points , new_bps [ self . axes [ i ] . name ] . data [:, np . newaxis ], axis = 1 ) else : if new_bps . shape [ 1 ] != self . n_dim : raise ValueError ( f \"new_bps has { new_bps . shape [ 1 ] } dimensions. Expected { self . n_dim } .\" ) points = new_bps bps = [] for axis in self . axes : bps . append ( axis . data ) new_data = ccg . util . linearinterp ( bps = bps , data = self . data , points = points , extrapolate = extrapolate ) if isinstance ( new_bps , Axes ): new_data = new_data . reshape ( tuple ( x . n_bps for x in new_bps )) if isinstance ( new_bps , Frame | Sig ): new_data = Sig ( data = new_data , tline = tline1 , name = self . name , unit = self . unit ) return new_data plot () Generate plot Source code in ccg\\data\\tbldata.py 1059 1060 1061 1062 1063 1064 1065 def plot ( self ) -> Plot : \"\"\"Generate plot\"\"\" from ccg.ui.plot import Plot plot = Plot ( self ) plot . plot () return plot prev () Return previous state of this param. Source code in ccg\\data\\tbldata.py 965 966 967 968 969 def prev ( self ) -> Tbl : \"\"\"Return previous state of this param.\"\"\" if \"prev\" in self . _archive : return self . _archive [ \"prev\" ][ - 1 ] return self snapshot ( name = None ) Archive current value. Source code in ccg\\data\\tbldata.py 730 731 732 733 734 735 736 737 738 def snapshot ( self , name : str = None ): \"\"\"Archive current value.\"\"\" if name is None : name = \"prev\" if name not in self . _archive : self . _archive [ name ] = [] if not self . _archive [ name ] or self . _archive [ name ][ - 1 ] != self : self . _archive [ name ] . append ( Tbl ( self )) # to make a copy to_dict ( include_archive = True , include_scatter = True ) To dict Source code in ccg\\data\\tbldata.py 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 def to_dict ( self , include_archive : bool = True , include_scatter : bool = True ) -> dict : \"\"\"To dict\"\"\" res = { \"name\" : self . name , \"unit\" : self . unit , \"axes\" : self . axes . to_dict (), \"data\" : self . data . tolist (), \"data_range\" : self . data_range , \"precision\" : self . precision , \"interp_on_axis_change\" : self . interp_on_axis_change , \"locked\" : self . locked . tolist (), } if include_archive and \"_archive\" in self . __dict__ : res [ \"archive\" ] = {} for key , val in self . _archive . items (): res [ \"archive\" ][ key ] = [ par . to_dict () for par in val ] if include_scatter and \"_scatter_data\" in self . __dict__ : res [ \"scatter_data\" ] = [ sd . to_dict () if sd is not None else None for sd in self . scatter_data ] return res to_file ( filename , include_archive = False , include_scatter = False ) Save to file Source code in ccg\\data\\tbldata.py 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 def to_file ( self , filename : str | Path , include_archive : bool = False , include_scatter : bool = False , ): \"\"\"Save to file\"\"\" filename = Path ( filename ) if filename . suffixes [ - 2 :] != [ \".tbl\" , \".json\" ]: filename = filename . with_suffix ( \".tbl.json\" ) with open ( filename , \"w\" , encoding = \"utf8\" ) as f : f . write ( json . dumps ( self . to_dict ( include_archive = include_archive , include_scatter = include_scatter , ), indent = 4 , ) ) return filename to_file_async ( filename , include_archive = False , include_scatter = False ) async Save to file asynchronously Source code in ccg\\data\\tbldata.py 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 async def to_file_async ( self , filename : str | Path , include_archive : bool = False , include_scatter : bool = False , ): \"\"\"Save to file asynchronously\"\"\" filename = Path ( filename ) if filename . suffixes [ - 2 :] != [ \".tbl\" , \".json\" ]: filename = filename . with_suffix ( \".tbl.json\" ) async with aiofiles . open ( filename , \"w\" , encoding = \"utf8\" ) as f : await f . write ( json . dumps ( self . to_dict ( include_archive = include_archive , include_scatter = include_scatter , ), indent = 4 , ) ) return filename undo ( nsteps = None ) Restore prev state of data and axes by nsteps. -1 is oldest undo. Source code in ccg\\data\\tbldata.py 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 def undo ( self , nsteps : int = None ) -> None : \"\"\"Restore prev state of data and axes by nsteps. -1 is oldest undo.\"\"\" if \"prev\" in self . _archive and len ( self . _archive [ \"prev\" ]) > 0 : if nsteps is None : prev = self . _archive [ \"prev\" ] . pop ( - 1 ) elif nsteps == - 1 : prev = self . _archive [ \"prev\" ][ 0 ] self . _archive [ \"prev\" ] = [] # clear prev else : prev = self . _archive [ \"prev\" ][ - 1 * nsteps ] del self . _archive [ \"prev\" ][ - 1 * nsteps :] prev . axes . parent = self # since axes parent ref is lost in archive. self . _axes = prev . axes self . _data : npt . NDArray = prev . data Tbls Collection of Param. Source code in ccg\\data\\tbldata.py 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622 1623 1624 1625 1626 1627 1628 1629 1630 1631 1632 1633 1634 1635 1636 1637 1638 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 1649 1650 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664 1665 1666 1667 1668 1669 1670 1671 1672 1673 1674 class Tbls : \"\"\"Collection of Param.\"\"\" def __init__ ( self , params : Tbls | Tbl | list [ Tbl | dict ] | None = None , name : str | None = None , ): self . name = None self . tbls : dict [ str , Tbl ] = {} if isinstance ( params , Tbl ): params = [ params ] elif isinstance ( params , Tbls ): self . name = params . name params = list ( params . tbls . values ()) if isinstance ( params , list ): self . append ( params ) if name is not None : self . name = name def append ( self , params : list [ Tbl ] | Tbls | Tbl | list [ dict ]) -> Self : \"\"\"append params to self. Keeps ref.\"\"\" if isinstance ( params , Tbl ): params = [ params ] for param in params : self . tbls [ param [ \"name\" ]] = param if isinstance ( param , Tbl ) else Tbl ( ** param ) return self def to_dict ( self , include_archive : bool = True , include_scatter : bool = True ) -> dict : \"\"\"to dict\"\"\" res = { \"name\" : self . name , \"params\" : {}} for key , tbl in self . tbls . items (): res [ \"params\" ][ key ] = tbl . to_dict ( include_archive = include_archive , include_scatter = include_scatter ) return res def to_file ( self , filename : str | Path , include_archive : bool = False , include_scatter : bool = False , ): \"\"\"Save to file\"\"\" filename = Path ( filename ) if filename . suffixes [ - 2 :] != [ \".tbls\" , \".json\" ]: filename = filename . with_suffix ( \".tbls.json\" ) with open ( filename , \"w\" , encoding = \"utf8\" ) as f : f . write ( json . dumps ( self . to_dict ( include_archive = include_archive , include_scatter = include_scatter ), indent = 4 , ) ) return filename async def to_file_async ( self , filename : str | Path , include_archive : bool = False , include_scatter : bool = False , ): \"\"\"Asynchronously save to file Parameters ---------- filename : str | Path The path of the file to write to. include_archive : bool, optional Whether to include archive data, by default False include_scatter : bool, optional Whether to include scatter data, by default False Returns ------- Path The path to the file that was written. \"\"\" filename = Path ( filename ) if filename . suffixes [ - 2 :] != [ \".tbls\" , \".json\" ]: filename = filename . with_suffix ( \".tbls.json\" ) async with aiofiles . open ( filename , \"w\" , encoding = \"utf8\" ) as f : await f . write ( json . dumps ( self . to_dict ( include_archive = include_archive , include_scatter = include_scatter ), indent = 4 , ) ) return filename @classmethod def from_file ( cls , filename : str | Path , filedata : bytes | None = None ) -> \"Tbls\" : \"\"\"Read Tbls from file. Parameters ---------- filename : str | Path The path to the file to read from. filedata : bytes | None, optional The file data, if already loaded, by default None Returns ------- Tbls The Tbls instance with tbl's loaded from file. \"\"\" filename = Path ( filename ) if filename . suffixes [ - 2 :] != [ \".tbls\" , \".json\" ]: filename = filename . with_suffix ( \".tbls.json\" ) if filedata is None : with open ( filename , \"r\" , encoding = \"utf8\" ) as f : pars = json . loads ( f . read ()) else : pars = json . loads ( filedata ) tbls = cls () tbls . name = pars [ \"name\" ] for key , par in pars [ \"params\" ] . items (): tbls . append ( Tbl ( ** par )) return tbls @classmethod async def from_file_async ( cls , filename : str | Path ) -> Self : \"\"\"Async tbls from file Parameters ---------- filename : str | Path path Returns ------- Tbls Tbls with tbl's from file \"\"\" filename = Path ( filename ) if filename . suffixes [ - 2 :] != [ \".Tbls\" , \".json\" ]: filename = filename . with_suffix ( \".Tbls.json\" ) async with aiofiles . open ( filename , \"r\" , encoding = \"utf8\" ) as f : pars = json . loads ( await f . read ()) tbls = cls () tbls . name = pars [ \"name\" ] for key , par in pars [ \"params\" ] . items (): tbls . append ( Tbl ( ** par )) return tbls def __repr__ ( self ): \"\"\"repr\"\"\" return f \"Tbls( { json . dumps ( self . to_dict (), indent = 4 ) } )\" def __getattr__ ( self , key : str ) -> Tbl : if key . startswith ( \"_\" ): raise AttributeError # Probably dont want to let it return _** if key in self . tbls : return self . tbls [ key ] @overload def __getitem__ ( self , key : str ) -> Tbl : pass @overload def __getitem__ ( self , key : list [ str ]) -> Tbls : pass def __getitem__ ( self , key : str | list [ str ]): if isinstance ( key , list ): res = Tbls ( name = self . name ) for item in key : if item in self . tbls : res . append ( self . tbls [ item ]) return res if key in self . tbls : return self . tbls [ key ] raise KeyError ( f \" { key } is not in { self . name } \" ) def __setitem__ ( self , key : str , value : Tbl ): \"\"\"setitem\"\"\" self . tbls [ key ] = value def __json__ ( self ): \"\"\"make serializable\"\"\" return self . to_dict () def __iter__ ( self ): \"\"\"iter\"\"\" return iter ( self . tbls . values ()) __iter__ () iter Source code in ccg\\data\\tbldata.py 1672 1673 1674 def __iter__ ( self ): \"\"\"iter\"\"\" return iter ( self . tbls . values ()) __json__ () make serializable Source code in ccg\\data\\tbldata.py 1668 1669 1670 def __json__ ( self ): \"\"\"make serializable\"\"\" return self . to_dict () __repr__ () repr Source code in ccg\\data\\tbldata.py 1632 1633 1634 def __repr__ ( self ): \"\"\"repr\"\"\" return f \"Tbls( { json . dumps ( self . to_dict (), indent = 4 ) } )\" __setitem__ ( key , value ) setitem Source code in ccg\\data\\tbldata.py 1664 1665 1666 def __setitem__ ( self , key : str , value : Tbl ): \"\"\"setitem\"\"\" self . tbls [ key ] = value append ( params ) append params to self. Keeps ref. Source code in ccg\\data\\tbldata.py 1495 1496 1497 1498 1499 1500 1501 1502 def append ( self , params : list [ Tbl ] | Tbls | Tbl | list [ dict ]) -> Self : \"\"\"append params to self. Keeps ref.\"\"\" if isinstance ( params , Tbl ): params = [ params ] for param in params : self . tbls [ param [ \"name\" ]] = param if isinstance ( param , Tbl ) else Tbl ( ** param ) return self from_file ( filename , filedata = None ) classmethod Read Tbls from file. Parameters: filename ( str | Path ) \u2013 The path to the file to read from. filedata ( bytes | None , default: None ) \u2013 The file data, if already loaded, by default None Returns: Tbls \u2013 The Tbls instance with tbl's loaded from file. Source code in ccg\\data\\tbldata.py 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601 1602 1603 @classmethod def from_file ( cls , filename : str | Path , filedata : bytes | None = None ) -> \"Tbls\" : \"\"\"Read Tbls from file. Parameters ---------- filename : str | Path The path to the file to read from. filedata : bytes | None, optional The file data, if already loaded, by default None Returns ------- Tbls The Tbls instance with tbl's loaded from file. \"\"\" filename = Path ( filename ) if filename . suffixes [ - 2 :] != [ \".tbls\" , \".json\" ]: filename = filename . with_suffix ( \".tbls.json\" ) if filedata is None : with open ( filename , \"r\" , encoding = \"utf8\" ) as f : pars = json . loads ( f . read ()) else : pars = json . loads ( filedata ) tbls = cls () tbls . name = pars [ \"name\" ] for key , par in pars [ \"params\" ] . items (): tbls . append ( Tbl ( ** par )) return tbls from_file_async ( filename ) async classmethod Async tbls from file Parameters: filename ( str | Path ) \u2013 path Returns: Tbls \u2013 Tbls with tbl's from file Source code in ccg\\data\\tbldata.py 1605 1606 1607 1608 1609 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622 1623 1624 1625 1626 1627 1628 1629 1630 @classmethod async def from_file_async ( cls , filename : str | Path ) -> Self : \"\"\"Async tbls from file Parameters ---------- filename : str | Path path Returns ------- Tbls Tbls with tbl's from file \"\"\" filename = Path ( filename ) if filename . suffixes [ - 2 :] != [ \".Tbls\" , \".json\" ]: filename = filename . with_suffix ( \".Tbls.json\" ) async with aiofiles . open ( filename , \"r\" , encoding = \"utf8\" ) as f : pars = json . loads ( await f . read ()) tbls = cls () tbls . name = pars [ \"name\" ] for key , par in pars [ \"params\" ] . items (): tbls . append ( Tbl ( ** par )) return tbls to_dict ( include_archive = True , include_scatter = True ) to dict Source code in ccg\\data\\tbldata.py 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 def to_dict ( self , include_archive : bool = True , include_scatter : bool = True ) -> dict : \"\"\"to dict\"\"\" res = { \"name\" : self . name , \"params\" : {}} for key , tbl in self . tbls . items (): res [ \"params\" ][ key ] = tbl . to_dict ( include_archive = include_archive , include_scatter = include_scatter ) return res to_file ( filename , include_archive = False , include_scatter = False ) Save to file Source code in ccg\\data\\tbldata.py 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 def to_file ( self , filename : str | Path , include_archive : bool = False , include_scatter : bool = False , ): \"\"\"Save to file\"\"\" filename = Path ( filename ) if filename . suffixes [ - 2 :] != [ \".tbls\" , \".json\" ]: filename = filename . with_suffix ( \".tbls.json\" ) with open ( filename , \"w\" , encoding = \"utf8\" ) as f : f . write ( json . dumps ( self . to_dict ( include_archive = include_archive , include_scatter = include_scatter ), indent = 4 , ) ) return filename to_file_async ( filename , include_archive = False , include_scatter = False ) async Asynchronously save to file Parameters: filename ( str | Path ) \u2013 The path of the file to write to. include_archive ( bool , default: False ) \u2013 Whether to include archive data, by default False include_scatter ( bool , default: False ) \u2013 Whether to include scatter data, by default False Returns: Path \u2013 The path to the file that was written. Source code in ccg\\data\\tbldata.py 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 async def to_file_async ( self , filename : str | Path , include_archive : bool = False , include_scatter : bool = False , ): \"\"\"Asynchronously save to file Parameters ---------- filename : str | Path The path of the file to write to. include_archive : bool, optional Whether to include archive data, by default False include_scatter : bool, optional Whether to include scatter data, by default False Returns ------- Path The path to the file that was written. \"\"\" filename = Path ( filename ) if filename . suffixes [ - 2 :] != [ \".tbls\" , \".json\" ]: filename = filename . with_suffix ( \".tbls.json\" ) async with aiofiles . open ( filename , \"w\" , encoding = \"utf8\" ) as f : await f . write ( json . dumps ( self . to_dict ( include_archive = include_archive , include_scatter = include_scatter ), indent = 4 , ) ) return filename calc_prec ( data ) Calc Precision. Source code in ccg\\data\\tbldata.py 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 def calc_prec ( data : npt . NDArray ) -> int : \"\"\"Calc Precision.\"\"\" if len ( data ) < 1 : return 0 span = np . nanmax ( data ) - np . nanmin ( data ) if span > 0 : prec = max ( int ( 3 - np . round ( np . log10 ( span ))), 0 ) else : prec = 0 return prec fit ( par , data ) nd linear interpolation fitting Source code in ccg\\data\\tbldata.py 1677 1678 1679 1680 1681 1682 1683 1684 1685 1686 1687 1688 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699 1700 1701 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711 1712 1713 1714 1715 1716 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741 1742 1743 1744 1745 1746 1747 1748 1749 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 1767 1768 1769 1770 1771 1772 1773 1774 1775 1776 1777 1778 1779 1780 1781 1782 1783 1784 1785 1786 1787 1788 1789 1790 1791 1792 1793 1794 1795 1796 1797 1798 1799 1800 1801 1802 1803 1804 1805 1806 1807 1808 1809 1810 1811 1812 1813 1814 1815 1816 1817 1818 1819 1820 1821 1822 1823 1824 1825 1826 1827 1828 1829 1830 1831 1832 1833 1834 1835 1836 1837 1838 1839 1840 1841 1842 1843 1844 1845 1846 1847 1848 1849 1850 1851 1852 1853 1854 1855 1856 1857 1858 1859 1860 1861 1862 1863 1864 1865 1866 1867 1868 1869 1870 1871 1872 1873 1874 1875 1876 1877 1878 1879 1880 1881 1882 1883 1884 1885 1886 1887 1888 1889 1890 1891 1892 1893 1894 1895 1896 1897 1898 1899 1900 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 def fit ( par : Tbl , data : ScatterData ) -> np . ndarray : \"\"\"nd linear interpolation fitting\"\"\" tic = datetime . datetime . now () n_dim = par . n_dim n_grid = par . axes . n_bps # Clean data, remove any nan data . clean () n_samples = len ( data . data [ 0 ]) inds = [] intfs = [] for axis , values in zip ( par . axes , data . data ): bins , intf = axis . bins ( values , extrap = True ) inds . append ( bins ) intfs . append ( intf ) ind = [] intf = [] rows = np . concatenate ([ np . arange ( n_samples )] * 2 ** n_dim , axis = 0 ) adders = np . array ([ x . flatten () for x in np . meshgrid ( * ([ 0 , 1 ],) * n_dim )]) for i in range ( 2 ** n_dim ): adder = adders [:, i , None ] ind . append ( np . ravel_multi_index ( inds + adder , par . data . shape )) intf . append ( np . prod ([( 1 - x ) * ( 1 - y ) + x * y for x , y in zip ( intfs , adder )], axis = 0 ) ) intf_array = np . concatenate ( intf , axis = 0 ) ind_array = np . concatenate ( ind , axis = 0 ) model_matrix = csr_array ( ( intf_array , ( rows , ind_array )), shape = ( n_samples , n_grid ), ) # Counting # Similar to model matrix, but saturating edges intf_sat = [] intfs_sat = np . maximum ( np . minimum ( intfs , 1 ), 0 ) adders = np . array ([ x . flatten () for x in np . meshgrid ( * ([ 0 , 1 ],) * n_dim )]) for i in range ( 2 ** n_dim ): adder = adders [:, i , None ] intf_sat . append ( np . prod ( [( 1 - x ) * ( 1 - y ) + x * y for x , y in zip ( intfs_sat , adder )], axis = 0 ) ) intf_sat_array = np . concatenate ( intf_sat , axis = 0 ) count_matrix = csr_array ( ( intf_sat_array , ( rows , ind_array )), shape = ( n_samples , n_grid ), dtype = float , ) count : npt . NDArray [ np . floating ] = np . sum ( count_matrix . toarray () * data . weight [:, None ], axis = 0 ) par . count = count . reshape ( par . data . shape ) count_mean : float = np . mean ( count ) # Regulizer, pull fit towards starting point # TODO: Add modifier with normal vectors to weaken spring constant? f_orig_fudge = par . f_orig / ( 10 * ( 1 - par . f_orig ) + par . f_orig ) # edited 8/31/22 to allow 0 f_orig = max ( min ( par . f_orig * f_orig_fudge , 0.99999 ), 0 ) f_orig_weight = np . ones (( n_grid ,)) * ( count_mean / ( 1 - f_orig ) - count_mean ) # removed +1 8/31/22 f_orig_matrix = csr_array ( np . eye ( n_grid )) # Regulizer, Smoothing, thermal diffusion model smooth_fudge = [ 1 / ( 10 * ( 1 - x ) + 1 ) for x in par . f_smooth ] # rss_smooth: float = np.mean([x * y for x, y in zip(par.f_smooth, smooth_fudge)]) rss_smooth : float = np . sqrt ( np . sum ([ z * z for z in [ x * y for x , y in zip ( par . f_smooth , smooth_fudge )]]) ) if rss_smooth > 0 : rel_smooths = [ z / rss_smooth for z in [ x * y for x , y in zip ( par . f_smooth , smooth_fudge )] ] f_smooth = min ( max ( rss_smooth , 0 ), 0.9999999 ) d_bps = [ axis . diff for axis in par . axes ] d_means = [ np . mean ( d , axis = 0 ) for d in d_bps ] inds = [ np . arange ( axis . n_bps ) for axis in par . axes ] smooth_rows = [] smooth_cols = [] smooth_vals = [] for i , ( axis , d_bp , d_mean , rel_smooth ) in enumerate ( zip ( par . axes , d_bps , d_means , rel_smooths ) ): tmp_inds = inds . copy () tmp_inds [ i ] = np . arange ( 1 , axis . n_bps - 1 , 1 ) ind_mesh = np . meshgrid ( * tmp_inds ) delta1 = d_bp [ ind_mesh [ i ] . flatten () - 1 ] / d_mean delta2 = d_bp [ ind_mesh [ i ] . flatten ()] / d_mean rows = np . ravel_multi_index ( ind_mesh , par . data . shape ) . flatten () ind_mesh [ i ] += - 1 smooth_cols . append ( np . ravel_multi_index ( ind_mesh , par . data . shape ) . flatten ()) smooth_rows . append ( rows ) smooth_vals . append ( rel_smooth * ( - 2 / ( delta1 * ( delta1 + delta2 )))) ind_mesh [ i ] += 1 smooth_cols . append ( np . ravel_multi_index ( ind_mesh , par . data . shape ) . flatten ()) smooth_rows . append ( rows ) smooth_vals . append ( rel_smooth * ( 2 / ( delta1 * delta2 ))) ind_mesh [ i ] += 1 smooth_cols . append ( np . ravel_multi_index ( ind_mesh , par . data . shape ) . flatten ()) smooth_rows . append ( rows ) smooth_vals . append ( rel_smooth * ( - 2 / ( delta2 * ( delta1 + delta2 )))) smooth_matrix = csr_array ( ( np . concatenate ( smooth_vals , axis = 0 ), ( np . concatenate ( smooth_rows , axis = 0 ), np . concatenate ( smooth_cols , axis = 0 ), ), ), shape = ( n_grid , n_grid ), dtype = float , ) tmp_model : npt . NDArray [ np . floating ] = ( np . absolute ( model_matrix . toarray ()) . sum ( axis = 0 ) . reshape ( par . data . shape ) ) tmp_smooth : npt . NDArray [ np . floating ] = ( np . absolute ( smooth_matrix . toarray ()) . sum ( axis = 0 ) . reshape ( par . data . shape ) ) n_model = np . linalg . norm ( tmp_model ) n_smooth = np . linalg . norm ( tmp_smooth ) f_smooth_norm : float = (( n_model + f_orig_weight [ 0 ]) / ( n_smooth )) / ( 1 - f_smooth ) - (( n_model + f_orig_weight [ 0 ]) / ( n_smooth )) f_smooth_weight = np . ones (( n_grid ,)) * f_smooth_norm f_smooth_rhs = np . zeros (( n_grid ,)) # append regulizers final_weight : npt . NDArray [ np . floating ] = np . concatenate ( ( data . weight , f_orig_weight , f_smooth_weight ) ) final_weight = np . sqrt ( final_weight / np . mean ( final_weight )) final_matrix = csr_array ( vstack (( model_matrix , f_orig_matrix , smooth_matrix ))) final_rhs = np . concatenate (( data . data [ - 1 ], par . data . flatten (), f_smooth_rhs )) else : final_weight = np . concatenate (( data . weight , f_orig_weight )) final_weight = np . sqrt ( final_weight / np . mean ( final_weight )) final_matrix = csr_array ( vstack (( model_matrix , f_orig_matrix ), format = \"csr\" )) final_rhs = np . concatenate (( data . data [ - 1 ], par . data . flatten ())) # Constraints # locked values c_tol = 1.0e-13 constrained = np . empty (( 0 , par . axes . n_bps ), dtype = np . bool_ ) const_rhs = np . empty (( 0 ,)) if np . any ( par . locked ): constrained = np . diag ( par . locked . flatten ())[ par . locked . flatten (), :] const_rhs = par . data [ par . locked ] . flatten () if np . any ( par . periodic ): for i , periodic in enumerate ( par . periodic ): if periodic : # value tmp_inds = inds . copy () tmp_inds [ i ] = [ 0 ] ind_mesh = np . meshgrid ( * tmp_inds ) flat_inds = np . ravel_multi_index ( ind_mesh , par . data . shape , mode = \"wrap\" ) . flatten () tmp_inds [ i ] = [ - 1 ] ind_mesh = np . meshgrid ( * tmp_inds ) flat_inds = np . vstack ( ( flat_inds , np . ravel_multi_index ( ind_mesh , par . data . shape , mode = \"wrap\" ) . flatten (), ) ) n_const = flat_inds . shape [ 1 ] tmp = np . zeros (( n_const , par . axes . n_bps ), dtype = np . bool_ ) tmp [ range ( n_const ), flat_inds [ 0 , :]] = 1 tmp [ range ( n_const ), flat_inds [ 1 , :]] = - 1 constrained = np . concatenate (( constrained , tmp )) const_rhs = np . concatenate (( const_rhs , np . zeros ( n_const ))) # slope diff_r = par . axes [ i ] . diff [ - 1 ] / par . axes [ i ] . diff [ 0 ] tmp_inds = inds . copy () tmp_inds [ i ] = [ 0 ] ind_mesh = np . meshgrid ( * tmp_inds ) flat_inds = np . ravel_multi_index ( ind_mesh , par . data . shape , mode = \"wrap\" ) . flatten () tmp_inds [ i ] = [ 1 ] ind_mesh = np . meshgrid ( * tmp_inds ) flat_inds = np . vstack ( ( flat_inds , np . ravel_multi_index ( ind_mesh , par . data . shape , mode = \"wrap\" ) . flatten (), ) ) tmp_inds [ i ] = [ - 2 ] ind_mesh = np . meshgrid ( * tmp_inds ) flat_inds = np . vstack ( ( flat_inds , np . ravel_multi_index ( ind_mesh , par . data . shape , mode = \"wrap\" ) . flatten (), ) ) tmp_inds [ i ] = [ - 1 ] ind_mesh = np . meshgrid ( * tmp_inds ) flat_inds = np . vstack ( ( flat_inds , np . ravel_multi_index ( ind_mesh , par . data . shape , mode = \"wrap\" ) . flatten (), ) ) n_const = flat_inds . shape [ 1 ] tmp = np . zeros (( n_const , par . axes . n_bps )) tmp [ range ( n_const ), flat_inds [ 0 , :]] = - diff_r tmp [ range ( n_const ), flat_inds [ 1 , :]] = diff_r tmp [ range ( n_const ), flat_inds [ 2 , :]] = 1.0 tmp [ range ( n_const ), flat_inds [ 3 , :]] = - 1.0 constrained = np . concatenate (( constrained , tmp )) const_rhs = np . concatenate (( const_rhs , np . zeros ( n_const ))) # Solve if np . any ( constrained ): q : npt . NDArray [ np . floating ] r : npt . NDArray [ np . floating ] p : npt . NDArray [ np . int_ ] q , r , p = qr ( constrained , pivoting = True ) # r_diag = np.diag(r) const_rank = np . linalg . matrix_rank ( r ) if const_rank >= par . axes . n_bps : raise ValueError ( \"Over Constrained\" ) if const_rank < constrained . shape [ 0 ]: k = q [:, const_rank :] . T @ const_rhs if np . any ( k > ( c_tol * np . linalg . norm ( const_rhs ))): raise ValueError ( \"Constraint is rank deficient and numerically inconsistent.\" ) qpd = q [:, : const_rank ] . T @ const_rhs subs = p [: const_rank ] est = p [ const_rank :] r1 = r [: const_rank , : const_rank ] r2 = r [: const_rank , const_rank :] a1 : csr_array = final_matrix [:, subs ] qpd = qpd [: const_rank ] rhs_mod = final_rhs - a1 . toarray () @ ( np . linalg . lstsq ( r1 , qpd , rcond = None )[ 0 ]) model_mod : csr_array = final_matrix [:, est ] - a1 @ ( np . linalg . lstsq ( r1 , r2 , rcond = None )[ 0 ] ) res2 = np . linalg . lstsq ( final_weight [:, None ] * model_mod , final_weight * rhs_mod , rcond = None )[ 0 ] res1 = np . linalg . lstsq ( r1 , qpd - r2 @ res2 , rcond = None )[ 0 ] res = np . zeros (( par . axes . n_bps ), dtype = np . floating ) res [ est ] = res2 res [ subs ] = res1 else : # , x0=par.data.flatten() tmp : tuple = linalg . lsqr ( final_weight [:, None ] * final_matrix , final_weight * final_rhs , x0 = par . data . flatten (), ) _LOGGER . debug ( \"niter: %i \" , tmp [ 2 ]) res : npt . NDArray [ np . floating ] = tmp [ 0 ] toc = datetime . datetime . now () - tic _LOGGER . debug ( \"Fitted in %.3f \" , toc . total_seconds ()) return res . reshape ( par . data . shape ) scatter_density ( scatter_data , n_bins = 50 ) Find the density in an nD scatter Source code in ccg\\data\\tbldata.py 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 @ccg . util . profile def scatter_density ( scatter_data : ScatterData , n_bins : int | list [ list ] = 50 ): \"\"\"Find the density in an nD scatter\"\"\" density = np . zeros ( scatter_data . data [ 0 ] . shape ) * np . nan nan_inds = np . any ( np . isnan ( scatter_data . data ), axis = 0 ) sctr = np . array ( scatter_data . clean () . data ) . T # nd hist hist , edges = np . histogramdd ( sctr , bins = n_bins , density = False ) # nd -1 hist if isinstance ( n_bins , list ): n1_bins = n_bins [: - 1 ] else : n1_bins = n_bins hist1 , _ = np . histogramdd ( sctr [ ... , : - 1 ], bins = n1_bins , density = False ) hist1 = np . clip ( hist1 , a_min = np . mean ( hist1 ) / 1 , a_max = None ) tmp = hist / hist1 [ ... , np . newaxis ] tmp [ np . logical_or ( np . isnan ( tmp ), np . isinf ( tmp ))] = 0 bps = [ x [ 1 :] for x in edges ] density [ ~ nan_inds ] = ccg . util . linearinterp ( bps , tmp , sctr ) return density","title":"tbldata"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Axes","text":"CCG Parameter Axis collection. Source code in ccg\\data\\tbldata.py 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 class Axes : \"\"\"CCG Parameter Axis collection.\"\"\" def __init__ ( self , axes_data : list [ Axis ] | Axis | list [ dict ] | Axes = None , parent : Tbl = None , interpolate_on_change : bool = None , ): self . interpolate_on_change = None self . axes : list [ Axis ] = [] self . append ( axes_data ) self . parent = parent # needs to be set after axes to avoid int on chng if interpolate_on_change is not None : self . interpolate_on_change = interpolate_on_change # Default to true if self . interpolate_on_change is None : self . interpolate_on_change = True def append ( self , axis : list [ Axis ] | Axis | list [ dict ] | Axes ): \"\"\"Append axis to Axes. Will not interp.\"\"\" tmp_int = self . interpolate_on_change self . interpolate_on_change = False if isinstance ( axis , Axis ): axis = [ axis ] elif isinstance ( axis , Axes ): self . interpolate_on_change = axis . interpolate_on_change axis = axis . axes if axis is not None : # make copies of each axis, also asign parent new_axes = [ ( Axis ( ** tmp_axis , parent = self ) if isinstance ( tmp_axis , dict ) else Axis ( tmp_axis , parent = self ) ) for tmp_axis in axis ] # Ensure axes have names for i , axs in enumerate ( new_axes ): if axs . name is None : new_axes [ i ] . name = f \"axis_ { i } \" self . axes . extend ( new_axes ) self . interpolate_on_change = tmp_int @property def shape ( self ) -> tuple : \"\"\"Shape of axes bps\"\"\" if self . axes : shp = tuple ( x . n_bps for x in self . axes ) else : shp = ( 1 ,) return shp @property def table_shape ( self ) -> tuple : \"\"\"Shape of the expected data table. first axis is in cols (to match ecu standards), second in rows, beyond that they are stacked rows.\"\"\" if self . axes : shp = [ 1 , self . axes [ 0 ] . n_bps ] if self . n_dim > 1 : for axis in self . axes [ 1 :]: shp [ 0 ] = shp [ 0 ] * axis . n_bps else : shp = ( 0 ,) return tuple ( shp ) @property def grid ( self ): \"\"\"Return a meshgrid of the axis bps.\"\"\" bps = [] for axis in self . axes : bps . append ( axis . data ) mesh = np . meshgrid ( * bps ) res = [] for col in mesh : res . append ( col . flatten ()) return res @property def n_dim ( self ) -> int : \"\"\"Number of Dimensions.\"\"\" return len ( self . axes ) @property def n_bps ( self ) -> int : \"\"\"Number of breakpoints.\"\"\" n_bps = 1 for axis in self . axes : n_bps *= axis . n_bps return n_bps def __iter__ ( self ): \"\"\"Iterate over Axes.\"\"\" return iter ( self . axes ) def to_dict ( self ) -> dict : \"\"\"to dictionary.\"\"\" res = [] for axis in self . axes : res . append ( axis . to_dict ()) return res def __repr__ ( self ) -> str : \"\"\"repr\"\"\" return f \"Axes( { json . dumps ( self . to_dict ()) } )\" def __getattr__ ( self , key : str ) -> Axis : if key . startswith ( \"_\" ): raise AttributeError # Probably dont want to let it return _** for axis in self . axes : if axis . name == key : return axis def __getitem__ ( self , key ) -> Axis | list [ Axis ]: if isinstance ( key , str ): for axis in self . axes : if axis . name == key : return axis elif isinstance ( key , int ): return self . axes [ key ] elif isinstance ( key , slice ): return self . axes [ key ] else : raise NotImplementedError ( f \"Get item not implemented for type: { type ( key ) } \" ) def __setitem__ ( self , key : str | int , value : Axis ): \"\"\"Handle interpolation if needed.\"\"\" if self . interpolate_on_change and self . parent is not None : tmp_axes = copy . deepcopy ( self . axes ) # TODO: Check for circ ref when includes parent if isinstance ( key , str ): for i , axis in enumerate ( tmp_axes ): if axis . name == key : tmp_axes [ i ] = value break elif isinstance ( key , int ): tmp_axes [ key ] = value else : raise NotImplementedError ( f \"Set item not implemented for type: { type ( key ) } \" ) new_data = self . parent . interp ( Axes ( tmp_axes ), extrapolate = True ) self . parent . data = new_data , True # To allow shape change # Snapshot happens here, so axes should be updated after. value . parent = self if isinstance ( key , str ): for i , axis in enumerate ( self . axes ): if axis . name == key : self . axes [ i ] = value elif isinstance ( key , int ): self . axes [ key ] = value def __json__ ( self ): \"\"\"make serializable\"\"\" return self . to_dict () def __eq__ ( self , other : Axes ): \"\"\"equal\"\"\" res = ( self . table_shape == other . table_shape and self . interpolate_on_change == other . interpolate_on_change ) if res : for axis , other_axis in zip ( self . axes , other . axes ): if res : res = res and axis == other_axis else : break return res def __contains__ ( self , key ): \"\"\"Check if key is an axis name in axes\"\"\" names = [] for axis in self . axes : names . append ( axis . name ) return key in names def index ( self , key : str ): \"\"\"return axis index by name\"\"\" for i , axis in enumerate ( self . axes ): if axis . name == key : return i return False","title":"Axes"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Axes.grid","text":"Return a meshgrid of the axis bps.","title":"grid"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Axes.n_bps","text":"Number of breakpoints.","title":"n_bps"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Axes.n_dim","text":"Number of Dimensions.","title":"n_dim"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Axes.shape","text":"Shape of axes bps","title":"shape"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Axes.table_shape","text":"Shape of the expected data table. first axis is in cols (to match ecu standards), second in rows, beyond that they are stacked rows.","title":"table_shape"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Axes.__contains__","text":"Check if key is an axis name in axes Source code in ccg\\data\\tbldata.py 402 403 404 405 406 407 def __contains__ ( self , key ): \"\"\"Check if key is an axis name in axes\"\"\" names = [] for axis in self . axes : names . append ( axis . name ) return key in names","title":"__contains__"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Axes.__eq__","text":"equal Source code in ccg\\data\\tbldata.py 388 389 390 391 392 393 394 395 396 397 398 399 400 def __eq__ ( self , other : Axes ): \"\"\"equal\"\"\" res = ( self . table_shape == other . table_shape and self . interpolate_on_change == other . interpolate_on_change ) if res : for axis , other_axis in zip ( self . axes , other . axes ): if res : res = res and axis == other_axis else : break return res","title":"__eq__"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Axes.__iter__","text":"Iterate over Axes. Source code in ccg\\data\\tbldata.py 315 316 317 def __iter__ ( self ): \"\"\"Iterate over Axes.\"\"\" return iter ( self . axes )","title":"__iter__"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Axes.__json__","text":"make serializable Source code in ccg\\data\\tbldata.py 384 385 386 def __json__ ( self ): \"\"\"make serializable\"\"\" return self . to_dict ()","title":"__json__"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Axes.__repr__","text":"repr Source code in ccg\\data\\tbldata.py 326 327 328 def __repr__ ( self ) -> str : \"\"\"repr\"\"\" return f \"Axes( { json . dumps ( self . to_dict ()) } )\"","title":"__repr__"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Axes.__setitem__","text":"Handle interpolation if needed. Source code in ccg\\data\\tbldata.py 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 def __setitem__ ( self , key : str | int , value : Axis ): \"\"\"Handle interpolation if needed.\"\"\" if self . interpolate_on_change and self . parent is not None : tmp_axes = copy . deepcopy ( self . axes ) # TODO: Check for circ ref when includes parent if isinstance ( key , str ): for i , axis in enumerate ( tmp_axes ): if axis . name == key : tmp_axes [ i ] = value break elif isinstance ( key , int ): tmp_axes [ key ] = value else : raise NotImplementedError ( f \"Set item not implemented for type: { type ( key ) } \" ) new_data = self . parent . interp ( Axes ( tmp_axes ), extrapolate = True ) self . parent . data = new_data , True # To allow shape change # Snapshot happens here, so axes should be updated after. value . parent = self if isinstance ( key , str ): for i , axis in enumerate ( self . axes ): if axis . name == key : self . axes [ i ] = value elif isinstance ( key , int ): self . axes [ key ] = value","title":"__setitem__"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Axes.append","text":"Append axis to Axes. Will not interp. Source code in ccg\\data\\tbldata.py 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 def append ( self , axis : list [ Axis ] | Axis | list [ dict ] | Axes ): \"\"\"Append axis to Axes. Will not interp.\"\"\" tmp_int = self . interpolate_on_change self . interpolate_on_change = False if isinstance ( axis , Axis ): axis = [ axis ] elif isinstance ( axis , Axes ): self . interpolate_on_change = axis . interpolate_on_change axis = axis . axes if axis is not None : # make copies of each axis, also asign parent new_axes = [ ( Axis ( ** tmp_axis , parent = self ) if isinstance ( tmp_axis , dict ) else Axis ( tmp_axis , parent = self ) ) for tmp_axis in axis ] # Ensure axes have names for i , axs in enumerate ( new_axes ): if axs . name is None : new_axes [ i ] . name = f \"axis_ { i } \" self . axes . extend ( new_axes ) self . interpolate_on_change = tmp_int","title":"append"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Axes.index","text":"return axis index by name Source code in ccg\\data\\tbldata.py 409 410 411 412 413 414 def index ( self , key : str ): \"\"\"return axis index by name\"\"\" for i , axis in enumerate ( self . axes ): if axis . name == key : return i return False","title":"index"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Axes.to_dict","text":"to dictionary. Source code in ccg\\data\\tbldata.py 319 320 321 322 323 324 def to_dict ( self ) -> dict : \"\"\"to dictionary.\"\"\" res = [] for axis in self . axes : res . append ( axis . to_dict ()) return res","title":"to_dict"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Axis","text":"CCG Parameter axis. Source code in ccg\\data\\tbldata.py 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 class Axis : \"\"\"CCG Parameter axis.\"\"\" def __init__ ( self , data : npt . NDArray | list | Axis = None , name : str = None , unit : str = None , data_range : list = None , precision : int = None , interp_method : ccg . util . InterpMethod = \"\" , parent : Axes = None , ): self . _prec = None self . _data : npt . NDArray | None = None if isinstance ( data , Axis ): self . name = data . name self . unit = data . unit self . interp_method = data . interp_method self . parent = data . parent self . data_range = data . data_range self . _prec = data . _prec data = data . data . copy () if name is not None : self . name = name if unit is not None : self . unit = unit if interp_method is not None : self . interp_method = ccg . util . InterpMethod ( interp_method ) if parent is not None : self . parent = parent if data_range is not None : self . data_range = data_range if precision is not None : self . precision = precision else : self . name = name self . unit = unit self . interp_method = ccg . util . InterpMethod ( interp_method ) self . parent = parent self . data_range = data_range self . precision = precision if isinstance ( data , list ): data = np . array ( data ) self . data = data @property def data ( self ): \"\"\"data.\"\"\" if self . _data is not None : return self . _data else : raise ValueError @data . setter def data ( self , value : npt . NDArray ): if len ( value . shape ) > 1 : raise ValueError ( f \"Axis { self . name } must have at most 1 dimension\" ) if len ( value ) > 0 and not ccg . util . monotonic_increasing ( value ): raise ValueError ( f \"Axis { self . name } must be monotonic increasing.\" ) if self . _data is not None and self . parent is not None : tmp_axis = Axis ( self ) tmp_axis . _data = value self . parent [ self . name ] = tmp_axis # replace with tmp axis to trigger interp if applicable else : self . _data = value @property def precision ( self ): \"\"\"Return the number of decimals.\"\"\" if self . _prec is None : prec = calc_prec ( self . data ) else : prec = self . _prec return prec @precision . setter def precision ( self , value ): \"\"\"Set prec\"\"\" self . _prec = value @property def diff ( self ) -> npt . NDArray [ np . float_ ]: \"\"\"difference.\"\"\" if len ( self . data ) > 0 : return self . data [ 1 :] - self . data [: - 1 ] return np . atleast_1d ( 0 ) @property def is_monotonic_increasing ( self ) -> bool : \"\"\"Check if axis is monotonic.\"\"\" return ccg . util . monotonic_increasing ( self . data ) @property def n_bps ( self ) -> int : \"\"\"Number of breakpoints.\"\"\" return len ( self ) @property def min ( self ): \"\"\"min bp\"\"\" return self . data [ 0 ] @property def max ( self ): \"\"\"max bp\"\"\" return self . data [ - 1 ] def convert_units ( self , unit : str ): \"\"\"Convert units.\"\"\" self . _data = ccg . util . convert_units ( self . data , self . unit , unit ) # Set _data to avoid triggering conversion. self . unit = unit def as_unit ( self , unit : str ): \"\"\"Return copy converted to unit.\"\"\" res = Axis ( self ) res . data = ccg . util . convert_units ( self . data , self . unit , unit ) res . unit = unit return res def bins ( self , values : npt . NDArray | float , extrap : bool = True ): \"\"\"Return bin and interpolation factor of values.\"\"\" bins = np . clip ( np . digitize ( values , self . data ) - 1 , 0 , self . n_bps - 2 ) intf : npt . NDArray | float = ( values - self . data [ bins ]) / self . diff [ bins ] if not extrap : intf = np . clip ( intf , 0 , 1 ) return bins , intf def __len__ ( self ) -> int : \"\"\"Length.\"\"\" return len ( self . data ) def to_dict ( self ) -> dict : \"\"\"to dictionary.\"\"\" res = { \"name\" : self . name , \"data\" : self . data . tolist (), \"unit\" : self . unit , \"interp_method\" : self . interp_method , \"data_range\" : self . data_range , \"precision\" : self . precision , } return res def __repr__ ( self ) -> str : \"\"\"repr\"\"\" return f \"Axis( { json . dumps ( self . to_dict ()) } )\" def __getitem__ ( self , index ): return self . data [ index ] def __setitem__ ( self , index , value ): \"\"\"Triggers interp in parent axes if applicable.\"\"\" if self . _data is not None and self . parent is not None : tmp_axis = Axis ( self ) tmp_axis . _data [ index ] = value self . parent [ self . name ] = tmp_axis # replace with tmp axis to trigger interp if applicable else : self . _data [ index ] = value def __json__ ( self ): \"\"\"make serializable\"\"\" return self . to_dict () def __eq__ ( self , other : Axis ) -> bool : \"\"\"equality\"\"\" res = ( self . name == other . name and self . unit == other . unit and self . interp_method == other . interp_method and self . data_range == other . data_range and self . precision == other . precision and np . all ( self . data == other . data ) ) return res","title":"Axis"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Axis.data","text":"data.","title":"data"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Axis.diff","text":"difference.","title":"diff"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Axis.is_monotonic_increasing","text":"Check if axis is monotonic.","title":"is_monotonic_increasing"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Axis.max","text":"max bp","title":"max"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Axis.min","text":"min bp","title":"min"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Axis.n_bps","text":"Number of breakpoints.","title":"n_bps"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Axis.precision","text":"Return the number of decimals.","title":"precision"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Axis.__eq__","text":"equality Source code in ccg\\data\\tbldata.py 201 202 203 204 205 206 207 208 209 210 211 def __eq__ ( self , other : Axis ) -> bool : \"\"\"equality\"\"\" res = ( self . name == other . name and self . unit == other . unit and self . interp_method == other . interp_method and self . data_range == other . data_range and self . precision == other . precision and np . all ( self . data == other . data ) ) return res","title":"__eq__"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Axis.__json__","text":"make serializable Source code in ccg\\data\\tbldata.py 197 198 199 def __json__ ( self ): \"\"\"make serializable\"\"\" return self . to_dict ()","title":"__json__"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Axis.__len__","text":"Length. Source code in ccg\\data\\tbldata.py 164 165 166 def __len__ ( self ) -> int : \"\"\"Length.\"\"\" return len ( self . data )","title":"__len__"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Axis.__repr__","text":"repr Source code in ccg\\data\\tbldata.py 180 181 182 def __repr__ ( self ) -> str : \"\"\"repr\"\"\" return f \"Axis( { json . dumps ( self . to_dict ()) } )\"","title":"__repr__"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Axis.__setitem__","text":"Triggers interp in parent axes if applicable. Source code in ccg\\data\\tbldata.py 187 188 189 190 191 192 193 194 195 def __setitem__ ( self , index , value ): \"\"\"Triggers interp in parent axes if applicable.\"\"\" if self . _data is not None and self . parent is not None : tmp_axis = Axis ( self ) tmp_axis . _data [ index ] = value self . parent [ self . name ] = tmp_axis # replace with tmp axis to trigger interp if applicable else : self . _data [ index ] = value","title":"__setitem__"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Axis.as_unit","text":"Return copy converted to unit. Source code in ccg\\data\\tbldata.py 149 150 151 152 153 154 def as_unit ( self , unit : str ): \"\"\"Return copy converted to unit.\"\"\" res = Axis ( self ) res . data = ccg . util . convert_units ( self . data , self . unit , unit ) res . unit = unit return res","title":"as_unit"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Axis.bins","text":"Return bin and interpolation factor of values. Source code in ccg\\data\\tbldata.py 156 157 158 159 160 161 162 def bins ( self , values : npt . NDArray | float , extrap : bool = True ): \"\"\"Return bin and interpolation factor of values.\"\"\" bins = np . clip ( np . digitize ( values , self . data ) - 1 , 0 , self . n_bps - 2 ) intf : npt . NDArray | float = ( values - self . data [ bins ]) / self . diff [ bins ] if not extrap : intf = np . clip ( intf , 0 , 1 ) return bins , intf","title":"bins"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Axis.convert_units","text":"Convert units. Source code in ccg\\data\\tbldata.py 143 144 145 146 147 def convert_units ( self , unit : str ): \"\"\"Convert units.\"\"\" self . _data = ccg . util . convert_units ( self . data , self . unit , unit ) # Set _data to avoid triggering conversion. self . unit = unit","title":"convert_units"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Axis.to_dict","text":"to dictionary. Source code in ccg\\data\\tbldata.py 168 169 170 171 172 173 174 175 176 177 178 def to_dict ( self ) -> dict : \"\"\"to dictionary.\"\"\" res = { \"name\" : self . name , \"data\" : self . data . tolist (), \"unit\" : self . unit , \"interp_method\" : self . interp_method , \"data_range\" : self . data_range , \"precision\" : self . precision , } return res","title":"to_dict"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.ScatterData","text":"Class for storing scatter data to plot with a parameter. Source code in ccg\\data\\tbldata.py 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 class ScatterData : \"\"\"Class for storing scatter data to plot with a parameter.\"\"\" def __init__ ( self , data : list [ npt . NDArray | Sig ], name : str = None , color : npt . NDArray = None , weight : npt . NDArray | float = None , color_name : str = None , color_unit : str = None , color_range : list [ float ] = None , time : npt . NDArray = None , ): self . _color_prec = None self . _weight = None self . _color_range = None if isinstance ( data [ 0 ], np . ndarray ): self . data = data elif isinstance ( data [ 0 ], Sig ): self . data = [ x . data for x in data ] elif isinstance ( data [ 0 ], list ): tmp = [] for lst in data : tmp . append ( np . array ( lst )) self . data = tmp else : raise NotImplementedError ( f \"data of type { type ( data [ 0 ]) } not implemented\" ) if name is None : name = \"Measured\" self . name = name if isinstance ( color , Sig ): self . color = color . data else : if isinstance ( color , list ): color = np . array ( color ) self . color = color self . color_label = color_name self . color_range = color_range if color_unit is None : self . color_unit = \"\" else : self . color_unit = color_unit self . weight = weight self . time = time @property def ndim ( self ): return len ( self . data ) - 1 @property def weight ( self ): \"\"\"Weight\"\"\" return self . _weight @weight . setter def weight ( self , value : npt . NDArray [ np . floating ] | float | None ): \"\"\"Check length and make array if float.\"\"\" if value is None : value = np . ones ( self . data [ 0 ] . data . shape , dtype = np . float64 ) elif isinstance ( value , float ): value = np . ones ( self . data [ 0 ] . data . shape ) * value elif isinstance ( value , list ): value = np . array ( value ) if value . shape != self . data [ 0 ] . data . shape : raise ValueError ( f \"weight of shape: { value . shape } , not compatible with: { self . data [ 0 ] . data . shape } \" ) self . _weight = value @property def color_range ( self ): \"\"\"Return Color Range\"\"\" if self . _color_range is None : if self . color is None : return None if self . color . size > 1 : if self . color_unit == \"ratio\" : return ccg . util . centered_range ( self . color , 1 ) return np . nanpercentile ( self . color , [ 2 , 98 ]) . tolist () else : return None return self . _color_range @color_range . setter def color_range ( self , value : list ): \"\"\"color range setter\"\"\" self . _color_range = value @property def color_precision ( self ): \"\"\"Return the number of decimals.\"\"\" if self . _color_prec is None : if self . color is not None : prec = calc_prec ( self . color ) else : prec = 0 else : prec = self . _color_prec return prec @color_precision . setter def color_precision ( self , value ): \"\"\"Set prec\"\"\" self . _color_prec = value def color_from_density ( self ): self . color = scatter_density ( self ) self . color_label = \"Relative Density\" self . color_unit = \"[]\" self . color_range = None def clean ( self , sort = False ): \"\"\"remove any nan's\"\"\" inds_to_remove = np . logical_or ( np . any ( np . isnan ( self . data ), axis = 0 ), np . isnan ( self . weight ), ) if self . color is not None : inds_to_remove = np . logical_or ( inds_to_remove , np . isnan ( self . color )) self . color = self . color [ ~ inds_to_remove ] self . data : list [ npt . NDArray ] = [ x [ ~ inds_to_remove ] for x in self . data ] self . weight = self . weight [ ~ inds_to_remove ] if sort and self . color is not None and len ( self . color ) > 0 : inds = np . argsort ( self . color ) self . color = self . color [ inds ] self . weight = self . weight [ inds ] new_data = [] for arr in self . data : new_data . append ( arr [ inds ]) self . data = new_data return self def to_dict ( self ): \"\"\"to dict\"\"\" res = { \"name\" : self . name , \"data\" : [ d . tolist () for d in self . data ], \"color\" : ( self . color . tolist () if isinstance ( self . color , np . ndarray ) else self . color ), \"color_name\" : self . color_label , \"color_unit\" : self . color_unit , \"color_range\" : self . color_range , \"weight\" : ( self . weight . tolist () if isinstance ( self . weight , np . ndarray ) else self . weight ), } return res def __json__ ( self ): \"\"\"to json\"\"\" return self . to_dict () def __repr__ ( self ): \"\"\"repr\"\"\" return f \"ScatterData(** { json . dumps ( self ) } )\"","title":"ScatterData"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.ScatterData.color_precision","text":"Return the number of decimals.","title":"color_precision"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.ScatterData.color_range","text":"Return Color Range","title":"color_range"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.ScatterData.weight","text":"Weight","title":"weight"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.ScatterData.__json__","text":"to json Source code in ccg\\data\\tbldata.py 576 577 578 def __json__ ( self ): \"\"\"to json\"\"\" return self . to_dict ()","title":"__json__"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.ScatterData.__repr__","text":"repr Source code in ccg\\data\\tbldata.py 580 581 582 def __repr__ ( self ): \"\"\"repr\"\"\" return f \"ScatterData(** { json . dumps ( self ) } )\"","title":"__repr__"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.ScatterData.clean","text":"remove any nan's Source code in ccg\\data\\tbldata.py 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 def clean ( self , sort = False ): \"\"\"remove any nan's\"\"\" inds_to_remove = np . logical_or ( np . any ( np . isnan ( self . data ), axis = 0 ), np . isnan ( self . weight ), ) if self . color is not None : inds_to_remove = np . logical_or ( inds_to_remove , np . isnan ( self . color )) self . color = self . color [ ~ inds_to_remove ] self . data : list [ npt . NDArray ] = [ x [ ~ inds_to_remove ] for x in self . data ] self . weight = self . weight [ ~ inds_to_remove ] if sort and self . color is not None and len ( self . color ) > 0 : inds = np . argsort ( self . color ) self . color = self . color [ inds ] self . weight = self . weight [ inds ] new_data = [] for arr in self . data : new_data . append ( arr [ inds ]) self . data = new_data return self","title":"clean"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.ScatterData.to_dict","text":"to dict Source code in ccg\\data\\tbldata.py 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 def to_dict ( self ): \"\"\"to dict\"\"\" res = { \"name\" : self . name , \"data\" : [ d . tolist () for d in self . data ], \"color\" : ( self . color . tolist () if isinstance ( self . color , np . ndarray ) else self . color ), \"color_name\" : self . color_label , \"color_unit\" : self . color_unit , \"color_range\" : self . color_range , \"weight\" : ( self . weight . tolist () if isinstance ( self . weight , np . ndarray ) else self . weight ), } return res","title":"to_dict"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl","text":"CCG Parameter. Source code in ccg\\data\\tbldata.py 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 class Tbl : \"\"\"CCG Parameter.\"\"\" def __init__ ( self , data : npt . NDArray | Tbl | list = None , axes : Axes | list = None , name : str = None , unit : str = None , data_range : list = None , precision : int = None , interp_on_axis_change : bool = True , archive : dict = None , scatter_data : ScatterData | list [ ScatterData ] = None , f_smooth : list [ float ] = None , f_orig : float = None , locked : npt . NDArray | list = None , periodic : list [ bool ] = None , ): self . _prec = None self . _archive : dict [ str , list [ Tbl ]] = {} self . _f_smooth = None self . _locked = None self . _axes = None self . _periodic = None self . _motec_shape = None self . count = None if isinstance ( data , Tbl ): if data . data is not None : self . _data = data . data . copy () else : self . _data = None self . _axes = Axes ( data . axes , parent = self ) self . name = data . name self . unit = data . unit self . data_range = data . data_range self . _prec = data . _prec self . interp_on_axis_change = data . interp_on_axis_change self . scatter_data = copy . deepcopy ( data . scatter_data ) self . _f_smooth = data . _f_smooth self . f_orig = data . f_orig self . _locked = data . _locked self . _periodic = data . _periodic self . _motec_shape = data . _motec_shape self . _scatter_data = [] if axes is not None : self . _axes = Axes ( axes , parent = self ) if name is not None : self . name = name if unit is not None : self . unit = unit if data_range is not None : self . data_range = data . data_range if precision is not None : self . precision = precision if interp_on_axis_change is not None : self . interp_on_axis_change = interp_on_axis_change if scatter_data is not None : self . scatter_data = scatter_data if f_smooth is not None : self . f_smooth = f_smooth if f_orig is not None : self . f_orig = f_orig if locked is not None : self . locked = locked if periodic is not None : self . periodic = periodic else : if isinstance ( data , list ): data = np . atleast_1d ( data ) new_axes = Axes ( axes , parent = self ) self . check_shape ( data , new_axes , name ) self . _data = data self . _axes = new_axes if self . count is None : self . count = np . zeros ( self . shape , dtype = np . float_ ) self . name = name self . unit = unit self . data_range = data_range self . precision = precision self . interp_on_axis_change = interp_on_axis_change self . scatter_data = scatter_data self . f_smooth = f_smooth self . locked = locked self . periodic = periodic if f_orig is None : f_orig = 0.1 self . f_orig = f_orig self . snapshot ( \"orig\" ) if archive is not None : # check if its dict of dicts for key , arch in archive . items (): if isinstance ( arch [ 0 ], dict ): arch = [ Tbl ( ** x ) for x in arch ] self . _archive [ key ] = arch self . created = datetime . datetime . now () @property def interp_on_axis_change ( self ): \"\"\"Interpolate on axis change\"\"\" return self . axes . interpolate_on_change @interp_on_axis_change . setter def interp_on_axis_change ( self , value ): \"Setter\" self . axes . interpolate_on_change = value def check_shape ( self , data : npt . NDArray , axes : Axes , name : str = None ): \"\"\"Check that shape is compatible, else raise ValueError.\"\"\" if data is not None and axes is not None and data . shape != axes . shape : raise ValueError ( f \"Data for { name } is incompatible shape: { data . shape } , expected: { axes . shape } \" ) @property def scatter_data ( self ) -> list [ ScatterData ]: \"\"\"Scatter data\"\"\" return self . _scatter_data @scatter_data . setter def scatter_data ( self , value : ScatterData | list [ ScatterData ]): \"\"\"setter\"\"\" if not isinstance ( value , list ): if isinstance ( value , dict ): value = ScatterData ( ** value ) value = [ value ] else : tmp = [] for sc in value : if isinstance ( sc , dict ): tmp . append ( ScatterData ( ** sc )) elif isinstance ( sc , ScatterData ) or sc is None : tmp . append ( sc ) else : raise NotImplementedError value = tmp self . _scatter_data = value # TODO: Why is this a list?? def snapshot ( self , name : str = None ): \"\"\"Archive current value.\"\"\" if name is None : name = \"prev\" if name not in self . _archive : self . _archive [ name ] = [] if not self . _archive [ name ] or self . _archive [ name ][ - 1 ] != self : self . _archive [ name ] . append ( Tbl ( self )) # to make a copy def convert_units ( self , unit : str ): \"\"\"Convert units in place.\"\"\" self . data = ccg . util . convert_units ( self . data , self . unit , unit ) self . unit = unit def as_unit ( self , unit : str ): \"\"\"Return copy converted to unit.\"\"\" res = Tbl ( self ) res . data = ccg . util . convert_units ( self . data , self . unit , unit ) res . unit = unit return res @property def data ( self ): \"\"\"Return the table data.\"\"\" return self . _data @data . setter def data ( self , value : npt . NDArray | tuple [ npt . NDArray , bool ]): \"\"\"Set the data, store a snapshot first.\"\"\" if isinstance ( value , tuple ): allow_shape_change = value [ 1 ] value = value [ 0 ] else : allow_shape_change = False if not allow_shape_change : self . check_shape ( value , self . axes , self . name ) if self . _data is not None : self . snapshot () self . _data = np . atleast_1d ( value ) . astype ( self . data . dtype ) else : self . _data = np . atleast_1d ( value ) if self . count is None : self . count = np . zeros ( self . shape , dtype = np . float_ ) @property def delta ( self ) -> npt . NDArray : \"\"\"Delta to original table.\"\"\" orig = ccg . util . convert_units ( self . orig . interp ( self . axes , extrapolate = False ), self . orig . unit , self . unit ) return self . data - orig @property def delta_perc ( self ) -> npt . NDArray [ np . floating ]: \"\"\"Percent delta to original table.\"\"\" # Check units have no offset _ , off , quant = ccg . util . find_unit ( self . unit ) if off != 0 : to_unit = list ( ccg . util . UNIT_CONV [ quant ] . keys ())[ 0 ] else : to_unit = self . unit data = ccg . util . convert_units ( self . data , self . unit , to_unit ) orig = ccg . util . convert_units ( self . orig . interp ( self . axes , extrapolate = False ), self . orig . unit , to_unit ) # if np.any(orig == 0): # orig[orig == 0] = 0.01 # Avoid div/0 res = ( data / orig ) - 1 if np . any ( np . isnan ( res )) or np . any ( np . isinf ( res )): res [ np . isnan ( res )] = 0 # set any nan to 0 res [ np . isinf ( res )] = np . sign ( res [ np . isinf ( res )]) * 1 res = ccg . util . convert_units ( res , \"ratio\" , \"%\" ) return res @property def f_smooth ( self ): \"\"\"Return f_smooth\"\"\" if self . _f_smooth is not None : return self . _f_smooth raise ValueError @f_smooth . setter def f_smooth ( self , value : list [ float ] | float ): \"\"\"set f_smooth\"\"\" if value is None : self . _f_smooth = [ 0.1 ] * self . n_dim elif isinstance ( value , float ): self . _f_smooth = [ value ] * self . n_dim elif len ( value ) != self . n_dim : raise ValueError ( f \"f_smooth len: { len ( value ) } must be scalar or length of { self . n_dim } \" ) else : self . _f_smooth = value @property def precision ( self ): \"\"\"Return the number of decimals.\"\"\" if self . _prec is None : if self . data is not None : prec = calc_prec ( self . data ) else : prec = 0 else : prec = self . _prec return prec @precision . setter def precision ( self , value ): \"\"\"Set prec\"\"\" self . _prec = value @property def locked ( self ): \"\"\"locked\"\"\" if self . _locked is not None : return self . _locked else : raise ValueError @locked . setter def locked ( self , value : npt . NDArray [ np . bool_ ] | bool | list [ bool ]): \"\"\"Set locked\"\"\" if isinstance ( value , list ): value = np . array ( value ) if self . data is not None : if isinstance ( value , bool ): value = np . ones ( self . data . shape , dtype = np . bool_ ) * value elif value is None : value = np . zeros ( self . data . shape , dtype = np . bool_ ) else : if value . shape != self . data . shape : raise ValueError ( f \"locked shape of { value . shape } is incompatible with { self . data . shape } \" ) self . _locked = value @property def periodic ( self ): \"\"\"Return periodic constraints.\"\"\" return self . _periodic @periodic . setter def periodic ( self , value : bool | list [ bool ]): \"\"\"Set periodic constraints\"\"\" if isinstance ( value , bool ): value = [ value ] * self . n_dim if value is None : value = [ False ] * self . n_dim if len ( value ) != self . n_dim : raise ValueError ( f \"periodic constraints of len: { len ( value ) } is incompatible with n_dim: { self . n_dim } \" ) self . _periodic = value @property def axes ( self ) -> Axes : \"\"\"returns the axes.\"\"\" return self . _axes @axes . setter def axes ( self , value : Axes ): \"\"\"set the axes, interpolate if `self.interp_on_axis_change=True`\"\"\" if self . axes is not None and value . shape != self . axes . shape : raise ValueError ( f \"Unexpected Axes shape for { self . name } of: { value . shape } . Expected: { self . axes . shape } \" ) if self . interp_on_axis_change : # interpolate new_data = self . interp ( value , extrapolate = True ) self . _axes = value self . data = new_data # snapshot happens in here. else : # interpret if self . axes is not None : self . snapshot () self . _axes = value self . _axes . parent = self @property def shape ( self ): \"\"\"shape\"\"\" return self . axes . shape @property def dtype ( self ): \"\"\"dtype\"\"\" return self . data . dtype @property def motec_shape ( self ): \"\"\"shape of base motec table\"\"\" if self . _motec_shape : return self . _motec_shape return self . shape + ( 1 ,) * ( 3 - max ( self . n_dim , 1 )) # to make 3d @motec_shape . setter def motec_shape ( self , value : tuple ): \"\"\"motec_shape_setter\"\"\" self . _motec_shape = value @property def orig ( self ): \"\"\"Return copy of original param.\"\"\" return Tbl ( self . _archive [ \"orig\" ][ - 1 ], name = \"orig\" ) @property def min ( self ): \"\"\"min value\"\"\" return self . data . min () @property def max ( self ): \"\"\"max value\"\"\" return self . data . max () def data_color ( self , colorscale = \"Turbo\" , light_font = \"#e5e5e5\" , dark_font = \"#434343\" ): \"\"\"Get colors for table, makes use of plotly colorscales.\"\"\" import plotly.colors as pc scale = pc . get_colorscale ( colorscale ) pts = ( self . data - self . data . min ()) / ( self . data . max () - self . data . min ()) colors = pc . sample_colorscale ( scale , pts . flatten () . tolist ()) font_colors = ccg . util . max_contrast ( colors , light_font , dark_font ) colors = np . array ( colors ) . reshape ( self . shape ) font_colors = np . array ( font_colors ) . reshape ( self . shape ) return colors , font_colors def prev ( self ) -> Tbl : \"\"\"Return previous state of this param.\"\"\" if \"prev\" in self . _archive : return self . _archive [ \"prev\" ][ - 1 ] return self def undo ( self , nsteps : int = None ) -> None : \"\"\"Restore prev state of data and axes by nsteps. -1 is oldest undo.\"\"\" if \"prev\" in self . _archive and len ( self . _archive [ \"prev\" ]) > 0 : if nsteps is None : prev = self . _archive [ \"prev\" ] . pop ( - 1 ) elif nsteps == - 1 : prev = self . _archive [ \"prev\" ][ 0 ] self . _archive [ \"prev\" ] = [] # clear prev else : prev = self . _archive [ \"prev\" ][ - 1 * nsteps ] del self . _archive [ \"prev\" ][ - 1 * nsteps :] prev . axes . parent = self # since axes parent ref is lost in archive. self . _axes = prev . axes self . _data : npt . NDArray = prev . data def clear_archive ( self ): \"\"\"Clear archive.\"\"\" self . _archive = None def interp ( self , new_bps : Axes | npt . NDArray | Frame | Sig , extrapolate : bool = False ): \"\"\"Return data interpolated at new_bps. Parameters ---------- new_bps If new_bps is an ndarray it must be nsamples x nd, and the result will be nsamples, If new_bps is an Axes, it must have the same number of dimensions as the param. If new_bps is a Frame, it looks for signals matching axis names. extrapolate saturate to bounds if False Returns ------- interpolated data, size of nsamples, if new_bps is ndarray or size of axes if new_bps is axes. \"\"\" if self . n_dim == 0 : return self . data # Interpolation doesnt make sense for 0d if np . any ([ x . interp_method != ccg . util . InterpMethod . LINEAR for x in self . axes ]): raise NotImplementedError ( \"Only linear interp is implemented\" ) if isinstance ( new_bps , Axes ): if new_bps . n_dim < self . n_dim : raise ValueError ( f \"new_bps has { new_bps . n_dim } dimensions. Expected >= { self . n_dim } .\" ) tmp = [] for i , axis in enumerate ( new_bps ): if i < self . n_dim : tmp . append ( axis . data ) points = np . meshgrid ( * tmp , indexing = \"ij\" ) # *bps to unpack bps points = np . array ([ point . flatten () for point in points ]) . T elif isinstance ( new_bps , Frame ): # TODO: Add fix for different timelines tline1 = new_bps [ self . axes [ 0 ] . name ] . tline points = new_bps [ self . axes [ 0 ] . name ] . data [:, np . newaxis ] for i in range ( 1 , self . n_dim ): if new_bps [ self . axes [ i ] . name ] . tline != tline1 : raise ValueError ( f \" { self . axes [ 0 ] . name } and { self . axes [ i ] . name } have different tlines, cannot interp { self . name } \" ) points = np . append ( points , new_bps [ self . axes [ i ] . name ] . data [:, np . newaxis ], axis = 1 ) else : if new_bps . shape [ 1 ] != self . n_dim : raise ValueError ( f \"new_bps has { new_bps . shape [ 1 ] } dimensions. Expected { self . n_dim } .\" ) points = new_bps bps = [] for axis in self . axes : bps . append ( axis . data ) new_data = ccg . util . linearinterp ( bps = bps , data = self . data , points = points , extrapolate = extrapolate ) if isinstance ( new_bps , Axes ): new_data = new_data . reshape ( tuple ( x . n_bps for x in new_bps )) if isinstance ( new_bps , Frame | Sig ): new_data = Sig ( data = new_data , tline = tline1 , name = self . name , unit = self . unit ) return new_data def plot ( self ) -> Plot : \"\"\"Generate plot\"\"\" from ccg.ui.plot import Plot plot = Plot ( self ) plot . plot () return plot def fit ( self , saturate = False ): \"\"\"Fit param if scatter data is present.\"\"\" if self . scatter_data [ 0 ] is None : raise ValueError ( f \"Scatter data is missing to fit { self . name } \" ) tmp = fit ( self , data = self . scatter_data [ 0 ]) if saturate and self . data_range : tmp = np . clip ( tmp , self . data_range [ 0 ], self . data_range [ 1 ]) self . data = tmp @property def n_dim ( self ) -> int : \"\"\"Number of Dimensions.\"\"\" return self . axes . n_dim @property def grid ( self ): \"\"\"Axes BPs grid.\"\"\" return self . axes . grid def to_dict ( self , include_archive : bool = True , include_scatter : bool = True ) -> dict : \"\"\"To dict\"\"\" res = { \"name\" : self . name , \"unit\" : self . unit , \"axes\" : self . axes . to_dict (), \"data\" : self . data . tolist (), \"data_range\" : self . data_range , \"precision\" : self . precision , \"interp_on_axis_change\" : self . interp_on_axis_change , \"locked\" : self . locked . tolist (), } if include_archive and \"_archive\" in self . __dict__ : res [ \"archive\" ] = {} for key , val in self . _archive . items (): res [ \"archive\" ][ key ] = [ par . to_dict () for par in val ] if include_scatter and \"_scatter_data\" in self . __dict__ : res [ \"scatter_data\" ] = [ sd . to_dict () if sd is not None else None for sd in self . scatter_data ] return res def to_file ( self , filename : str | Path , include_archive : bool = False , include_scatter : bool = False , ): \"\"\"Save to file\"\"\" filename = Path ( filename ) if filename . suffixes [ - 2 :] != [ \".tbl\" , \".json\" ]: filename = filename . with_suffix ( \".tbl.json\" ) with open ( filename , \"w\" , encoding = \"utf8\" ) as f : f . write ( json . dumps ( self . to_dict ( include_archive = include_archive , include_scatter = include_scatter , ), indent = 4 , ) ) return filename async def to_file_async ( self , filename : str | Path , include_archive : bool = False , include_scatter : bool = False , ): \"\"\"Save to file asynchronously\"\"\" filename = Path ( filename ) if filename . suffixes [ - 2 :] != [ \".tbl\" , \".json\" ]: filename = filename . with_suffix ( \".tbl.json\" ) async with aiofiles . open ( filename , \"w\" , encoding = \"utf8\" ) as f : await f . write ( json . dumps ( self . to_dict ( include_archive = include_archive , include_scatter = include_scatter , ), indent = 4 , ) ) return filename @classmethod async def from_file_async ( cls , filename : str | Path ): \"\"\" Asynchronously load Tbl from file. Parameters ---------- filename : str | Path The name of the file from which to load the data. If the file extension is not \".tbl.json\", it will be added. Returns ------- cls An instance of Tbl, initialized with the data loaded from the file. Notes ----- This method is asynchronous and should be awaited. \"\"\" filename = Path ( filename ) if filename . suffixes [ - 2 :] != [ \".tbl\" , \".json\" ]: filename = filename . with_suffix ( \".tbl.json\" ) async with aiofiles . open ( filename , \"r\" , encoding = \"utf8\" ) as f : data = await f . read () tbl_dict = json . loads ( data ) return cls ( ** tbl_dict ) @classmethod def from_file ( cls , filename : str | Path ): \"\"\" Synchronously load Tbl from file. Parameters ---------- filename : str | Path The name of the file from which to load the data. If the file extension is not \".tbl.json\", it will be added. Returns ------- cls An instance of Tbl, initialized with the data loaded from the file. \"\"\" filename = Path ( filename ) if filename . suffixes [ - 2 :] != [ \".tbl\" , \".json\" ]: filename = filename . with_suffix ( \".tbl.json\" ) with open ( filename , \"r\" , encoding = \"utf8\" ) as f : data = f . read () tbl_dict = json . loads ( data ) return cls ( ** tbl_dict ) def __add__ ( self , other ): \"\"\"add, interpolate other if its a Param. returns new Param.\"\"\" res = Tbl ( name = \"_result\" , data = self ) if isinstance ( other , Tbl ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] + %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . interp ( self . axes , extrapolate = True ) res . data = self . data + other return res def __sub__ ( self , other ): \"\"\"subtract, interpolate other if its a Param. returns new Param.\"\"\" res = Tbl ( name = \"_result\" , data = self ) if isinstance ( other , Tbl ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] - %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . interp ( self . axes , extrapolate = True ) res . data = self . data - other return res def __iadd__ ( self , other ): \"\"\"add, interpolate other if its a Param. in place.\"\"\" if isinstance ( other , Tbl ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] + %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . interp ( self . axes , extrapolate = True ) self . data = self . data + other return self def __isub__ ( self , other ): \"\"\"subtract, interpolate other if its a Param. in place.\"\"\" if isinstance ( other , Tbl ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] - %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . interp ( self . axes , extrapolate = True ) self . data = self . data - other return self def __radd__ ( self , other ): \"\"\"add, resamples to parent.math_tline if exists. returns new Param.\"\"\" return self . __add__ ( other ) def __rsub__ ( self , other ): \"\"\"subtract, interpolate other if its a Param. returns new Param.\"\"\" res = Tbl ( name = \"_result\" , data = self ) if isinstance ( other , Tbl ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] - %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . interp ( self . axes , extrapolate = True ) res . data = other - self . data return res def __mul__ ( self , other ): \"\"\"multiply(elementwise), interpolate other if its a Param. returns new Param.\"\"\" res = Tbl ( name = \"_result\" , data = self ) if isinstance ( other , Tbl ): if self . unit and self . unit == other . unit : unit = self . unit + \"**2\" elif other . unit is None : unit = self . unit else : unit = self . unit + \"*\" + other . unit other = other . interp ( self . axes , extrapolate = True ) else : unit = self . unit res . unit = unit res . data = self . data * other return res def __truediv__ ( self , other ): \"\"\"divide(elementwise), resamples to parent.math_tline if exists. returns Param.\"\"\" res = Tbl ( name = \"_result\" , data = self ) if isinstance ( other , Tbl ): if self . unit == other . unit : unit = None elif other . unit is None : unit = self . unit else : unit = self . unit + \"/\" + other . unit other = other . interp ( self . axes , extrapolate = True ) else : unit = self . unit res . unit = unit res . data = self . data / other return res def __imul__ ( self , other ): \"\"\"multiply(elementwise), interpolate other if its a Param. returns new Param.\"\"\" if isinstance ( other , Tbl ): if self . unit and self . unit == other . unit : unit = self . unit + \"**2\" elif other . unit is None : unit = self . unit else : unit = self . unit + \"*\" + other . unit other = other . interp ( self . axes , extrapolate = True ) else : unit = self . unit self . unit = unit self . data *= other return self def __itruediv__ ( self , other ): \"\"\"divide(elementwise), resamples to parent.math_tline if exists. returns Param.\"\"\" if isinstance ( other , Tbl ): if self . unit == other . unit : unit = None elif other . unit is None : unit = self . unit else : unit = self . unit + \"/\" + other . unit other = other . interp ( self . axes , extrapolate = True ) else : unit = self . unit self . unit = unit self . data /= other return self def __pow__ ( self , other ): \"\"\"power, resamples to parent.math_tline if exists. returns Param.\"\"\" res = Tbl ( name = \"_result\" , data = self ) unit = self . unit + \"**n\" if isinstance ( other , Tbl ): other = other . interp ( self . axes , extrapolate = True ) elif len ( other ) == 1 : unit = self . unit + \"**\" + str ( other ) res . unit = unit res . data = self . data ** other return res def __abs__ ( self ): \"\"\"abs\"\"\" res = Tbl ( self , name = f \"abs( { self . name } )\" ) res . data = np . abs ( self . data ) return res def __neg__ ( self ): \"\"\"neg\"\"\" res = Tbl ( self , name = f \"neg( { self . name } )\" ) res . data = self . data * - 1 return res def __eq__ ( self , other : Tbl ) -> bool : \"\"\"Returns True if basics match.\"\"\" res = ( isinstance ( other , Tbl ) and self . name == other . name and self . unit == other . unit and self . axes == other . axes and np . all ( self . data == other . data ) and self . precision == other . precision and self . interp_on_axis_change == other . interp_on_axis_change ) return res def __repr__ ( self ) -> str : \"\"\"repr\"\"\" return f \"Tbl( { json . dumps ( self . to_dict ()) } )\" def __getitem__ ( self , index : list [ list ] | Axes | npt . NDArray | str | Frame ): if isinstance ( index , list ): if not isinstance ( index [ 0 ], list ): index = [ index ] if len ( index [ 0 ]) == self . n_dim : new_bps = np . array ( index ) else : raise ValueError ( f \"Index must be nsamples x { self . n_dim } \" ) elif isinstance ( index , Axes | np . ndarray ): new_bps = index elif isinstance ( index , str ): if index in self . __dict__ : return self . __dict__ [ index ] else : try : return getattr ( self , index ) except KeyError as err : raise KeyError ( f \" { index } not in { self . name } \" ) from err elif isinstance ( index , tuple ): if isinstance ( index [ 0 ], list ): new_bps = np . array ( list ( index )) else : new_bps = np . array ([ list ( index )]) elif isinstance ( index , Frame ): # If a frame is passed in, calculate interpolated values on the math_tline or fastest of inputs. if self . n_dim == 0 : # find a tline if index . math_tline is not None : tline = index . math_tline else : try : tline = index . tline except ValueError : pass tline = index . tlines . get_fastest () data = self . data [ 0 ] # To let sig __init__ expand to tline else : if index . math_tline is None : # Find tline, fastest of axes tline = index [ self . axes [ 0 ] . name ] . tline for axis in self . axes : if index [ axis . name ] . tline . period < tline . period : tline = index [ axis . name ] . tline else : tline = index . math_tline new_bps = np . empty (( tline . nsamples , self . n_dim )) for i , axis in enumerate ( self . axes ): new_bps [:, i ] = ( index [ axis . name ] . as_unit ( axis . unit ) . resample ( tline ) . data ) data = self . interp ( new_bps ) res = Sig ( name = self . name , unit = self . unit , data = data , tline = tline ) return res else : raise NotImplementedError ( f \"Getitem not implemented for type: { type ( index ) } \" ) return self . interp ( new_bps ) def __json__ ( self ): \"\"\"make serializable\"\"\" return self . to_dict ()","title":"Tbl"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.axes","text":"returns the axes.","title":"axes"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.data","text":"Return the table data.","title":"data"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.delta","text":"Delta to original table.","title":"delta"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.delta_perc","text":"Percent delta to original table.","title":"delta_perc"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.dtype","text":"dtype","title":"dtype"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.f_smooth","text":"Return f_smooth","title":"f_smooth"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.grid","text":"Axes BPs grid.","title":"grid"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.interp_on_axis_change","text":"Interpolate on axis change","title":"interp_on_axis_change"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.locked","text":"locked","title":"locked"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.max","text":"max value","title":"max"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.min","text":"min value","title":"min"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.motec_shape","text":"shape of base motec table","title":"motec_shape"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.n_dim","text":"Number of Dimensions.","title":"n_dim"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.orig","text":"Return copy of original param.","title":"orig"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.periodic","text":"Return periodic constraints.","title":"periodic"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.precision","text":"Return the number of decimals.","title":"precision"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.scatter_data","text":"Scatter data","title":"scatter_data"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.shape","text":"shape","title":"shape"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.__abs__","text":"abs Source code in ccg\\data\\tbldata.py 1377 1378 1379 1380 1381 def __abs__ ( self ): \"\"\"abs\"\"\" res = Tbl ( self , name = f \"abs( { self . name } )\" ) res . data = np . abs ( self . data ) return res","title":"__abs__"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.__add__","text":"add, interpolate other if its a Param. returns new Param. Source code in ccg\\data\\tbldata.py 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 def __add__ ( self , other ): \"\"\"add, interpolate other if its a Param. returns new Param.\"\"\" res = Tbl ( name = \"_result\" , data = self ) if isinstance ( other , Tbl ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] + %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . interp ( self . axes , extrapolate = True ) res . data = self . data + other return res","title":"__add__"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.__eq__","text":"Returns True if basics match. Source code in ccg\\data\\tbldata.py 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 def __eq__ ( self , other : Tbl ) -> bool : \"\"\"Returns True if basics match.\"\"\" res = ( isinstance ( other , Tbl ) and self . name == other . name and self . unit == other . unit and self . axes == other . axes and np . all ( self . data == other . data ) and self . precision == other . precision and self . interp_on_axis_change == other . interp_on_axis_change ) return res","title":"__eq__"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.__iadd__","text":"add, interpolate other if its a Param. in place. Source code in ccg\\data\\tbldata.py 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 def __iadd__ ( self , other ): \"\"\"add, interpolate other if its a Param. in place.\"\"\" if isinstance ( other , Tbl ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] + %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . interp ( self . axes , extrapolate = True ) self . data = self . data + other return self","title":"__iadd__"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.__imul__","text":"multiply(elementwise), interpolate other if its a Param. returns new Param. Source code in ccg\\data\\tbldata.py 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 def __imul__ ( self , other ): \"\"\"multiply(elementwise), interpolate other if its a Param. returns new Param.\"\"\" if isinstance ( other , Tbl ): if self . unit and self . unit == other . unit : unit = self . unit + \"**2\" elif other . unit is None : unit = self . unit else : unit = self . unit + \"*\" + other . unit other = other . interp ( self . axes , extrapolate = True ) else : unit = self . unit self . unit = unit self . data *= other return self","title":"__imul__"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.__isub__","text":"subtract, interpolate other if its a Param. in place. Source code in ccg\\data\\tbldata.py 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 def __isub__ ( self , other ): \"\"\"subtract, interpolate other if its a Param. in place.\"\"\" if isinstance ( other , Tbl ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] - %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . interp ( self . axes , extrapolate = True ) self . data = self . data - other return self","title":"__isub__"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.__itruediv__","text":"divide(elementwise), resamples to parent.math_tline if exists. returns Param. Source code in ccg\\data\\tbldata.py 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 def __itruediv__ ( self , other ): \"\"\"divide(elementwise), resamples to parent.math_tline if exists. returns Param.\"\"\" if isinstance ( other , Tbl ): if self . unit == other . unit : unit = None elif other . unit is None : unit = self . unit else : unit = self . unit + \"/\" + other . unit other = other . interp ( self . axes , extrapolate = True ) else : unit = self . unit self . unit = unit self . data /= other return self","title":"__itruediv__"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.__json__","text":"make serializable Source code in ccg\\data\\tbldata.py 1468 1469 1470 def __json__ ( self ): \"\"\"make serializable\"\"\" return self . to_dict ()","title":"__json__"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.__mul__","text":"multiply(elementwise), interpolate other if its a Param. returns new Param. Source code in ccg\\data\\tbldata.py 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 def __mul__ ( self , other ): \"\"\"multiply(elementwise), interpolate other if its a Param. returns new Param.\"\"\" res = Tbl ( name = \"_result\" , data = self ) if isinstance ( other , Tbl ): if self . unit and self . unit == other . unit : unit = self . unit + \"**2\" elif other . unit is None : unit = self . unit else : unit = self . unit + \"*\" + other . unit other = other . interp ( self . axes , extrapolate = True ) else : unit = self . unit res . unit = unit res . data = self . data * other return res","title":"__mul__"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.__neg__","text":"neg Source code in ccg\\data\\tbldata.py 1383 1384 1385 1386 1387 def __neg__ ( self ): \"\"\"neg\"\"\" res = Tbl ( self , name = f \"neg( { self . name } )\" ) res . data = self . data * - 1 return res","title":"__neg__"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.__pow__","text":"power, resamples to parent.math_tline if exists. returns Param. Source code in ccg\\data\\tbldata.py 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 def __pow__ ( self , other ): \"\"\"power, resamples to parent.math_tline if exists. returns Param.\"\"\" res = Tbl ( name = \"_result\" , data = self ) unit = self . unit + \"**n\" if isinstance ( other , Tbl ): other = other . interp ( self . axes , extrapolate = True ) elif len ( other ) == 1 : unit = self . unit + \"**\" + str ( other ) res . unit = unit res . data = self . data ** other return res","title":"__pow__"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.__radd__","text":"add, resamples to parent.math_tline if exists. returns new Param. Source code in ccg\\data\\tbldata.py 1276 1277 1278 def __radd__ ( self , other ): \"\"\"add, resamples to parent.math_tline if exists. returns new Param.\"\"\" return self . __add__ ( other )","title":"__radd__"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.__repr__","text":"repr Source code in ccg\\data\\tbldata.py 1402 1403 1404 def __repr__ ( self ) -> str : \"\"\"repr\"\"\" return f \"Tbl( { json . dumps ( self . to_dict ()) } )\"","title":"__repr__"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.__rsub__","text":"subtract, interpolate other if its a Param. returns new Param. Source code in ccg\\data\\tbldata.py 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 def __rsub__ ( self , other ): \"\"\"subtract, interpolate other if its a Param. returns new Param.\"\"\" res = Tbl ( name = \"_result\" , data = self ) if isinstance ( other , Tbl ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] - %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . interp ( self . axes , extrapolate = True ) res . data = other - self . data return res","title":"__rsub__"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.__sub__","text":"subtract, interpolate other if its a Param. returns new Param. Source code in ccg\\data\\tbldata.py 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 def __sub__ ( self , other ): \"\"\"subtract, interpolate other if its a Param. returns new Param.\"\"\" res = Tbl ( name = \"_result\" , data = self ) if isinstance ( other , Tbl ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] - %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . interp ( self . axes , extrapolate = True ) res . data = self . data - other return res","title":"__sub__"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.__truediv__","text":"divide(elementwise), resamples to parent.math_tline if exists. returns Param. Source code in ccg\\data\\tbldata.py 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 def __truediv__ ( self , other ): \"\"\"divide(elementwise), resamples to parent.math_tline if exists. returns Param.\"\"\" res = Tbl ( name = \"_result\" , data = self ) if isinstance ( other , Tbl ): if self . unit == other . unit : unit = None elif other . unit is None : unit = self . unit else : unit = self . unit + \"/\" + other . unit other = other . interp ( self . axes , extrapolate = True ) else : unit = self . unit res . unit = unit res . data = self . data / other return res","title":"__truediv__"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.as_unit","text":"Return copy converted to unit. Source code in ccg\\data\\tbldata.py 745 746 747 748 749 750 def as_unit ( self , unit : str ): \"\"\"Return copy converted to unit.\"\"\" res = Tbl ( self ) res . data = ccg . util . convert_units ( self . data , self . unit , unit ) res . unit = unit return res","title":"as_unit"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.check_shape","text":"Check that shape is compatible, else raise ValueError. Source code in ccg\\data\\tbldata.py 697 698 699 700 701 702 def check_shape ( self , data : npt . NDArray , axes : Axes , name : str = None ): \"\"\"Check that shape is compatible, else raise ValueError.\"\"\" if data is not None and axes is not None and data . shape != axes . shape : raise ValueError ( f \"Data for { name } is incompatible shape: { data . shape } , expected: { axes . shape } \" )","title":"check_shape"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.clear_archive","text":"Clear archive. Source code in ccg\\data\\tbldata.py 987 988 989 def clear_archive ( self ): \"\"\"Clear archive.\"\"\" self . _archive = None","title":"clear_archive"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.convert_units","text":"Convert units in place. Source code in ccg\\data\\tbldata.py 740 741 742 743 def convert_units ( self , unit : str ): \"\"\"Convert units in place.\"\"\" self . data = ccg . util . convert_units ( self . data , self . unit , unit ) self . unit = unit","title":"convert_units"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.data_color","text":"Get colors for table, makes use of plotly colorscales. Source code in ccg\\data\\tbldata.py 953 954 955 956 957 958 959 960 961 962 963 def data_color ( self , colorscale = \"Turbo\" , light_font = \"#e5e5e5\" , dark_font = \"#434343\" ): \"\"\"Get colors for table, makes use of plotly colorscales.\"\"\" import plotly.colors as pc scale = pc . get_colorscale ( colorscale ) pts = ( self . data - self . data . min ()) / ( self . data . max () - self . data . min ()) colors = pc . sample_colorscale ( scale , pts . flatten () . tolist ()) font_colors = ccg . util . max_contrast ( colors , light_font , dark_font ) colors = np . array ( colors ) . reshape ( self . shape ) font_colors = np . array ( font_colors ) . reshape ( self . shape ) return colors , font_colors","title":"data_color"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.fit","text":"Fit param if scatter data is present. Source code in ccg\\data\\tbldata.py 1067 1068 1069 1070 1071 1072 1073 1074 def fit ( self , saturate = False ): \"\"\"Fit param if scatter data is present.\"\"\" if self . scatter_data [ 0 ] is None : raise ValueError ( f \"Scatter data is missing to fit { self . name } \" ) tmp = fit ( self , data = self . scatter_data [ 0 ]) if saturate and self . data_range : tmp = np . clip ( tmp , self . data_range [ 0 ], self . data_range [ 1 ]) self . data = tmp","title":"fit"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.from_file","text":"Synchronously load Tbl from file. Parameters: filename ( str | Path ) \u2013 The name of the file from which to load the data. If the file extension is not \".tbl.json\", it will be added. Returns: cls \u2013 An instance of Tbl, initialized with the data loaded from the file. Source code in ccg\\data\\tbldata.py 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 @classmethod def from_file ( cls , filename : str | Path ): \"\"\" Synchronously load Tbl from file. Parameters ---------- filename : str | Path The name of the file from which to load the data. If the file extension is not \".tbl.json\", it will be added. Returns ------- cls An instance of Tbl, initialized with the data loaded from the file. \"\"\" filename = Path ( filename ) if filename . suffixes [ - 2 :] != [ \".tbl\" , \".json\" ]: filename = filename . with_suffix ( \".tbl.json\" ) with open ( filename , \"r\" , encoding = \"utf8\" ) as f : data = f . read () tbl_dict = json . loads ( data ) return cls ( ** tbl_dict )","title":"from_file"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.from_file_async","text":"Asynchronously load Tbl from file. Parameters: filename ( str | Path ) \u2013 The name of the file from which to load the data. If the file extension is not \".tbl.json\", it will be added. Returns: cls \u2013 An instance of Tbl, initialized with the data loaded from the file. Notes This method is asynchronous and should be awaited. Source code in ccg\\data\\tbldata.py 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 @classmethod async def from_file_async ( cls , filename : str | Path ): \"\"\" Asynchronously load Tbl from file. Parameters ---------- filename : str | Path The name of the file from which to load the data. If the file extension is not \".tbl.json\", it will be added. Returns ------- cls An instance of Tbl, initialized with the data loaded from the file. Notes ----- This method is asynchronous and should be awaited. \"\"\" filename = Path ( filename ) if filename . suffixes [ - 2 :] != [ \".tbl\" , \".json\" ]: filename = filename . with_suffix ( \".tbl.json\" ) async with aiofiles . open ( filename , \"r\" , encoding = \"utf8\" ) as f : data = await f . read () tbl_dict = json . loads ( data ) return cls ( ** tbl_dict )","title":"from_file_async"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.interp","text":"Return data interpolated at new_bps. Parameters: new_bps ( Axes | NDArray | Frame | Sig ) \u2013 If new_bps is an ndarray it must be nsamples x nd, and the result will be nsamples, If new_bps is an Axes, it must have the same number of dimensions as the param. If new_bps is a Frame, it looks for signals matching axis names. extrapolate ( bool , default: False ) \u2013 saturate to bounds if False Returns: interpolated data, size of nsamples, if new_bps is ndarray or size of axes if new_bps is axes. \u2013 Source code in ccg\\data\\tbldata.py 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 def interp ( self , new_bps : Axes | npt . NDArray | Frame | Sig , extrapolate : bool = False ): \"\"\"Return data interpolated at new_bps. Parameters ---------- new_bps If new_bps is an ndarray it must be nsamples x nd, and the result will be nsamples, If new_bps is an Axes, it must have the same number of dimensions as the param. If new_bps is a Frame, it looks for signals matching axis names. extrapolate saturate to bounds if False Returns ------- interpolated data, size of nsamples, if new_bps is ndarray or size of axes if new_bps is axes. \"\"\" if self . n_dim == 0 : return self . data # Interpolation doesnt make sense for 0d if np . any ([ x . interp_method != ccg . util . InterpMethod . LINEAR for x in self . axes ]): raise NotImplementedError ( \"Only linear interp is implemented\" ) if isinstance ( new_bps , Axes ): if new_bps . n_dim < self . n_dim : raise ValueError ( f \"new_bps has { new_bps . n_dim } dimensions. Expected >= { self . n_dim } .\" ) tmp = [] for i , axis in enumerate ( new_bps ): if i < self . n_dim : tmp . append ( axis . data ) points = np . meshgrid ( * tmp , indexing = \"ij\" ) # *bps to unpack bps points = np . array ([ point . flatten () for point in points ]) . T elif isinstance ( new_bps , Frame ): # TODO: Add fix for different timelines tline1 = new_bps [ self . axes [ 0 ] . name ] . tline points = new_bps [ self . axes [ 0 ] . name ] . data [:, np . newaxis ] for i in range ( 1 , self . n_dim ): if new_bps [ self . axes [ i ] . name ] . tline != tline1 : raise ValueError ( f \" { self . axes [ 0 ] . name } and { self . axes [ i ] . name } have different tlines, cannot interp { self . name } \" ) points = np . append ( points , new_bps [ self . axes [ i ] . name ] . data [:, np . newaxis ], axis = 1 ) else : if new_bps . shape [ 1 ] != self . n_dim : raise ValueError ( f \"new_bps has { new_bps . shape [ 1 ] } dimensions. Expected { self . n_dim } .\" ) points = new_bps bps = [] for axis in self . axes : bps . append ( axis . data ) new_data = ccg . util . linearinterp ( bps = bps , data = self . data , points = points , extrapolate = extrapolate ) if isinstance ( new_bps , Axes ): new_data = new_data . reshape ( tuple ( x . n_bps for x in new_bps )) if isinstance ( new_bps , Frame | Sig ): new_data = Sig ( data = new_data , tline = tline1 , name = self . name , unit = self . unit ) return new_data","title":"interp"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.plot","text":"Generate plot Source code in ccg\\data\\tbldata.py 1059 1060 1061 1062 1063 1064 1065 def plot ( self ) -> Plot : \"\"\"Generate plot\"\"\" from ccg.ui.plot import Plot plot = Plot ( self ) plot . plot () return plot","title":"plot"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.prev","text":"Return previous state of this param. Source code in ccg\\data\\tbldata.py 965 966 967 968 969 def prev ( self ) -> Tbl : \"\"\"Return previous state of this param.\"\"\" if \"prev\" in self . _archive : return self . _archive [ \"prev\" ][ - 1 ] return self","title":"prev"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.snapshot","text":"Archive current value. Source code in ccg\\data\\tbldata.py 730 731 732 733 734 735 736 737 738 def snapshot ( self , name : str = None ): \"\"\"Archive current value.\"\"\" if name is None : name = \"prev\" if name not in self . _archive : self . _archive [ name ] = [] if not self . _archive [ name ] or self . _archive [ name ][ - 1 ] != self : self . _archive [ name ] . append ( Tbl ( self )) # to make a copy","title":"snapshot"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.to_dict","text":"To dict Source code in ccg\\data\\tbldata.py 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 def to_dict ( self , include_archive : bool = True , include_scatter : bool = True ) -> dict : \"\"\"To dict\"\"\" res = { \"name\" : self . name , \"unit\" : self . unit , \"axes\" : self . axes . to_dict (), \"data\" : self . data . tolist (), \"data_range\" : self . data_range , \"precision\" : self . precision , \"interp_on_axis_change\" : self . interp_on_axis_change , \"locked\" : self . locked . tolist (), } if include_archive and \"_archive\" in self . __dict__ : res [ \"archive\" ] = {} for key , val in self . _archive . items (): res [ \"archive\" ][ key ] = [ par . to_dict () for par in val ] if include_scatter and \"_scatter_data\" in self . __dict__ : res [ \"scatter_data\" ] = [ sd . to_dict () if sd is not None else None for sd in self . scatter_data ] return res","title":"to_dict"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.to_file","text":"Save to file Source code in ccg\\data\\tbldata.py 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 def to_file ( self , filename : str | Path , include_archive : bool = False , include_scatter : bool = False , ): \"\"\"Save to file\"\"\" filename = Path ( filename ) if filename . suffixes [ - 2 :] != [ \".tbl\" , \".json\" ]: filename = filename . with_suffix ( \".tbl.json\" ) with open ( filename , \"w\" , encoding = \"utf8\" ) as f : f . write ( json . dumps ( self . to_dict ( include_archive = include_archive , include_scatter = include_scatter , ), indent = 4 , ) ) return filename","title":"to_file"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.to_file_async","text":"Save to file asynchronously Source code in ccg\\data\\tbldata.py 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 async def to_file_async ( self , filename : str | Path , include_archive : bool = False , include_scatter : bool = False , ): \"\"\"Save to file asynchronously\"\"\" filename = Path ( filename ) if filename . suffixes [ - 2 :] != [ \".tbl\" , \".json\" ]: filename = filename . with_suffix ( \".tbl.json\" ) async with aiofiles . open ( filename , \"w\" , encoding = \"utf8\" ) as f : await f . write ( json . dumps ( self . to_dict ( include_archive = include_archive , include_scatter = include_scatter , ), indent = 4 , ) ) return filename","title":"to_file_async"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbl.undo","text":"Restore prev state of data and axes by nsteps. -1 is oldest undo. Source code in ccg\\data\\tbldata.py 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 def undo ( self , nsteps : int = None ) -> None : \"\"\"Restore prev state of data and axes by nsteps. -1 is oldest undo.\"\"\" if \"prev\" in self . _archive and len ( self . _archive [ \"prev\" ]) > 0 : if nsteps is None : prev = self . _archive [ \"prev\" ] . pop ( - 1 ) elif nsteps == - 1 : prev = self . _archive [ \"prev\" ][ 0 ] self . _archive [ \"prev\" ] = [] # clear prev else : prev = self . _archive [ \"prev\" ][ - 1 * nsteps ] del self . _archive [ \"prev\" ][ - 1 * nsteps :] prev . axes . parent = self # since axes parent ref is lost in archive. self . _axes = prev . axes self . _data : npt . NDArray = prev . data","title":"undo"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbls","text":"Collection of Param. Source code in ccg\\data\\tbldata.py 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622 1623 1624 1625 1626 1627 1628 1629 1630 1631 1632 1633 1634 1635 1636 1637 1638 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 1649 1650 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664 1665 1666 1667 1668 1669 1670 1671 1672 1673 1674 class Tbls : \"\"\"Collection of Param.\"\"\" def __init__ ( self , params : Tbls | Tbl | list [ Tbl | dict ] | None = None , name : str | None = None , ): self . name = None self . tbls : dict [ str , Tbl ] = {} if isinstance ( params , Tbl ): params = [ params ] elif isinstance ( params , Tbls ): self . name = params . name params = list ( params . tbls . values ()) if isinstance ( params , list ): self . append ( params ) if name is not None : self . name = name def append ( self , params : list [ Tbl ] | Tbls | Tbl | list [ dict ]) -> Self : \"\"\"append params to self. Keeps ref.\"\"\" if isinstance ( params , Tbl ): params = [ params ] for param in params : self . tbls [ param [ \"name\" ]] = param if isinstance ( param , Tbl ) else Tbl ( ** param ) return self def to_dict ( self , include_archive : bool = True , include_scatter : bool = True ) -> dict : \"\"\"to dict\"\"\" res = { \"name\" : self . name , \"params\" : {}} for key , tbl in self . tbls . items (): res [ \"params\" ][ key ] = tbl . to_dict ( include_archive = include_archive , include_scatter = include_scatter ) return res def to_file ( self , filename : str | Path , include_archive : bool = False , include_scatter : bool = False , ): \"\"\"Save to file\"\"\" filename = Path ( filename ) if filename . suffixes [ - 2 :] != [ \".tbls\" , \".json\" ]: filename = filename . with_suffix ( \".tbls.json\" ) with open ( filename , \"w\" , encoding = \"utf8\" ) as f : f . write ( json . dumps ( self . to_dict ( include_archive = include_archive , include_scatter = include_scatter ), indent = 4 , ) ) return filename async def to_file_async ( self , filename : str | Path , include_archive : bool = False , include_scatter : bool = False , ): \"\"\"Asynchronously save to file Parameters ---------- filename : str | Path The path of the file to write to. include_archive : bool, optional Whether to include archive data, by default False include_scatter : bool, optional Whether to include scatter data, by default False Returns ------- Path The path to the file that was written. \"\"\" filename = Path ( filename ) if filename . suffixes [ - 2 :] != [ \".tbls\" , \".json\" ]: filename = filename . with_suffix ( \".tbls.json\" ) async with aiofiles . open ( filename , \"w\" , encoding = \"utf8\" ) as f : await f . write ( json . dumps ( self . to_dict ( include_archive = include_archive , include_scatter = include_scatter ), indent = 4 , ) ) return filename @classmethod def from_file ( cls , filename : str | Path , filedata : bytes | None = None ) -> \"Tbls\" : \"\"\"Read Tbls from file. Parameters ---------- filename : str | Path The path to the file to read from. filedata : bytes | None, optional The file data, if already loaded, by default None Returns ------- Tbls The Tbls instance with tbl's loaded from file. \"\"\" filename = Path ( filename ) if filename . suffixes [ - 2 :] != [ \".tbls\" , \".json\" ]: filename = filename . with_suffix ( \".tbls.json\" ) if filedata is None : with open ( filename , \"r\" , encoding = \"utf8\" ) as f : pars = json . loads ( f . read ()) else : pars = json . loads ( filedata ) tbls = cls () tbls . name = pars [ \"name\" ] for key , par in pars [ \"params\" ] . items (): tbls . append ( Tbl ( ** par )) return tbls @classmethod async def from_file_async ( cls , filename : str | Path ) -> Self : \"\"\"Async tbls from file Parameters ---------- filename : str | Path path Returns ------- Tbls Tbls with tbl's from file \"\"\" filename = Path ( filename ) if filename . suffixes [ - 2 :] != [ \".Tbls\" , \".json\" ]: filename = filename . with_suffix ( \".Tbls.json\" ) async with aiofiles . open ( filename , \"r\" , encoding = \"utf8\" ) as f : pars = json . loads ( await f . read ()) tbls = cls () tbls . name = pars [ \"name\" ] for key , par in pars [ \"params\" ] . items (): tbls . append ( Tbl ( ** par )) return tbls def __repr__ ( self ): \"\"\"repr\"\"\" return f \"Tbls( { json . dumps ( self . to_dict (), indent = 4 ) } )\" def __getattr__ ( self , key : str ) -> Tbl : if key . startswith ( \"_\" ): raise AttributeError # Probably dont want to let it return _** if key in self . tbls : return self . tbls [ key ] @overload def __getitem__ ( self , key : str ) -> Tbl : pass @overload def __getitem__ ( self , key : list [ str ]) -> Tbls : pass def __getitem__ ( self , key : str | list [ str ]): if isinstance ( key , list ): res = Tbls ( name = self . name ) for item in key : if item in self . tbls : res . append ( self . tbls [ item ]) return res if key in self . tbls : return self . tbls [ key ] raise KeyError ( f \" { key } is not in { self . name } \" ) def __setitem__ ( self , key : str , value : Tbl ): \"\"\"setitem\"\"\" self . tbls [ key ] = value def __json__ ( self ): \"\"\"make serializable\"\"\" return self . to_dict () def __iter__ ( self ): \"\"\"iter\"\"\" return iter ( self . tbls . values ())","title":"Tbls"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbls.__iter__","text":"iter Source code in ccg\\data\\tbldata.py 1672 1673 1674 def __iter__ ( self ): \"\"\"iter\"\"\" return iter ( self . tbls . values ())","title":"__iter__"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbls.__json__","text":"make serializable Source code in ccg\\data\\tbldata.py 1668 1669 1670 def __json__ ( self ): \"\"\"make serializable\"\"\" return self . to_dict ()","title":"__json__"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbls.__repr__","text":"repr Source code in ccg\\data\\tbldata.py 1632 1633 1634 def __repr__ ( self ): \"\"\"repr\"\"\" return f \"Tbls( { json . dumps ( self . to_dict (), indent = 4 ) } )\"","title":"__repr__"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbls.__setitem__","text":"setitem Source code in ccg\\data\\tbldata.py 1664 1665 1666 def __setitem__ ( self , key : str , value : Tbl ): \"\"\"setitem\"\"\" self . tbls [ key ] = value","title":"__setitem__"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbls.append","text":"append params to self. Keeps ref. Source code in ccg\\data\\tbldata.py 1495 1496 1497 1498 1499 1500 1501 1502 def append ( self , params : list [ Tbl ] | Tbls | Tbl | list [ dict ]) -> Self : \"\"\"append params to self. Keeps ref.\"\"\" if isinstance ( params , Tbl ): params = [ params ] for param in params : self . tbls [ param [ \"name\" ]] = param if isinstance ( param , Tbl ) else Tbl ( ** param ) return self","title":"append"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbls.from_file","text":"Read Tbls from file. Parameters: filename ( str | Path ) \u2013 The path to the file to read from. filedata ( bytes | None , default: None ) \u2013 The file data, if already loaded, by default None Returns: Tbls \u2013 The Tbls instance with tbl's loaded from file. Source code in ccg\\data\\tbldata.py 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601 1602 1603 @classmethod def from_file ( cls , filename : str | Path , filedata : bytes | None = None ) -> \"Tbls\" : \"\"\"Read Tbls from file. Parameters ---------- filename : str | Path The path to the file to read from. filedata : bytes | None, optional The file data, if already loaded, by default None Returns ------- Tbls The Tbls instance with tbl's loaded from file. \"\"\" filename = Path ( filename ) if filename . suffixes [ - 2 :] != [ \".tbls\" , \".json\" ]: filename = filename . with_suffix ( \".tbls.json\" ) if filedata is None : with open ( filename , \"r\" , encoding = \"utf8\" ) as f : pars = json . loads ( f . read ()) else : pars = json . loads ( filedata ) tbls = cls () tbls . name = pars [ \"name\" ] for key , par in pars [ \"params\" ] . items (): tbls . append ( Tbl ( ** par )) return tbls","title":"from_file"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbls.from_file_async","text":"Async tbls from file Parameters: filename ( str | Path ) \u2013 path Returns: Tbls \u2013 Tbls with tbl's from file Source code in ccg\\data\\tbldata.py 1605 1606 1607 1608 1609 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622 1623 1624 1625 1626 1627 1628 1629 1630 @classmethod async def from_file_async ( cls , filename : str | Path ) -> Self : \"\"\"Async tbls from file Parameters ---------- filename : str | Path path Returns ------- Tbls Tbls with tbl's from file \"\"\" filename = Path ( filename ) if filename . suffixes [ - 2 :] != [ \".Tbls\" , \".json\" ]: filename = filename . with_suffix ( \".Tbls.json\" ) async with aiofiles . open ( filename , \"r\" , encoding = \"utf8\" ) as f : pars = json . loads ( await f . read ()) tbls = cls () tbls . name = pars [ \"name\" ] for key , par in pars [ \"params\" ] . items (): tbls . append ( Tbl ( ** par )) return tbls","title":"from_file_async"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbls.to_dict","text":"to dict Source code in ccg\\data\\tbldata.py 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 def to_dict ( self , include_archive : bool = True , include_scatter : bool = True ) -> dict : \"\"\"to dict\"\"\" res = { \"name\" : self . name , \"params\" : {}} for key , tbl in self . tbls . items (): res [ \"params\" ][ key ] = tbl . to_dict ( include_archive = include_archive , include_scatter = include_scatter ) return res","title":"to_dict"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbls.to_file","text":"Save to file Source code in ccg\\data\\tbldata.py 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 def to_file ( self , filename : str | Path , include_archive : bool = False , include_scatter : bool = False , ): \"\"\"Save to file\"\"\" filename = Path ( filename ) if filename . suffixes [ - 2 :] != [ \".tbls\" , \".json\" ]: filename = filename . with_suffix ( \".tbls.json\" ) with open ( filename , \"w\" , encoding = \"utf8\" ) as f : f . write ( json . dumps ( self . to_dict ( include_archive = include_archive , include_scatter = include_scatter ), indent = 4 , ) ) return filename","title":"to_file"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.Tbls.to_file_async","text":"Asynchronously save to file Parameters: filename ( str | Path ) \u2013 The path of the file to write to. include_archive ( bool , default: False ) \u2013 Whether to include archive data, by default False include_scatter ( bool , default: False ) \u2013 Whether to include scatter data, by default False Returns: Path \u2013 The path to the file that was written. Source code in ccg\\data\\tbldata.py 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 async def to_file_async ( self , filename : str | Path , include_archive : bool = False , include_scatter : bool = False , ): \"\"\"Asynchronously save to file Parameters ---------- filename : str | Path The path of the file to write to. include_archive : bool, optional Whether to include archive data, by default False include_scatter : bool, optional Whether to include scatter data, by default False Returns ------- Path The path to the file that was written. \"\"\" filename = Path ( filename ) if filename . suffixes [ - 2 :] != [ \".tbls\" , \".json\" ]: filename = filename . with_suffix ( \".tbls.json\" ) async with aiofiles . open ( filename , \"w\" , encoding = \"utf8\" ) as f : await f . write ( json . dumps ( self . to_dict ( include_archive = include_archive , include_scatter = include_scatter ), indent = 4 , ) ) return filename","title":"to_file_async"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.calc_prec","text":"Calc Precision. Source code in ccg\\data\\tbldata.py 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 def calc_prec ( data : npt . NDArray ) -> int : \"\"\"Calc Precision.\"\"\" if len ( data ) < 1 : return 0 span = np . nanmax ( data ) - np . nanmin ( data ) if span > 0 : prec = max ( int ( 3 - np . round ( np . log10 ( span ))), 0 ) else : prec = 0 return prec","title":"calc_prec"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.fit","text":"nd linear interpolation fitting Source code in ccg\\data\\tbldata.py 1677 1678 1679 1680 1681 1682 1683 1684 1685 1686 1687 1688 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699 1700 1701 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711 1712 1713 1714 1715 1716 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741 1742 1743 1744 1745 1746 1747 1748 1749 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 1767 1768 1769 1770 1771 1772 1773 1774 1775 1776 1777 1778 1779 1780 1781 1782 1783 1784 1785 1786 1787 1788 1789 1790 1791 1792 1793 1794 1795 1796 1797 1798 1799 1800 1801 1802 1803 1804 1805 1806 1807 1808 1809 1810 1811 1812 1813 1814 1815 1816 1817 1818 1819 1820 1821 1822 1823 1824 1825 1826 1827 1828 1829 1830 1831 1832 1833 1834 1835 1836 1837 1838 1839 1840 1841 1842 1843 1844 1845 1846 1847 1848 1849 1850 1851 1852 1853 1854 1855 1856 1857 1858 1859 1860 1861 1862 1863 1864 1865 1866 1867 1868 1869 1870 1871 1872 1873 1874 1875 1876 1877 1878 1879 1880 1881 1882 1883 1884 1885 1886 1887 1888 1889 1890 1891 1892 1893 1894 1895 1896 1897 1898 1899 1900 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 def fit ( par : Tbl , data : ScatterData ) -> np . ndarray : \"\"\"nd linear interpolation fitting\"\"\" tic = datetime . datetime . now () n_dim = par . n_dim n_grid = par . axes . n_bps # Clean data, remove any nan data . clean () n_samples = len ( data . data [ 0 ]) inds = [] intfs = [] for axis , values in zip ( par . axes , data . data ): bins , intf = axis . bins ( values , extrap = True ) inds . append ( bins ) intfs . append ( intf ) ind = [] intf = [] rows = np . concatenate ([ np . arange ( n_samples )] * 2 ** n_dim , axis = 0 ) adders = np . array ([ x . flatten () for x in np . meshgrid ( * ([ 0 , 1 ],) * n_dim )]) for i in range ( 2 ** n_dim ): adder = adders [:, i , None ] ind . append ( np . ravel_multi_index ( inds + adder , par . data . shape )) intf . append ( np . prod ([( 1 - x ) * ( 1 - y ) + x * y for x , y in zip ( intfs , adder )], axis = 0 ) ) intf_array = np . concatenate ( intf , axis = 0 ) ind_array = np . concatenate ( ind , axis = 0 ) model_matrix = csr_array ( ( intf_array , ( rows , ind_array )), shape = ( n_samples , n_grid ), ) # Counting # Similar to model matrix, but saturating edges intf_sat = [] intfs_sat = np . maximum ( np . minimum ( intfs , 1 ), 0 ) adders = np . array ([ x . flatten () for x in np . meshgrid ( * ([ 0 , 1 ],) * n_dim )]) for i in range ( 2 ** n_dim ): adder = adders [:, i , None ] intf_sat . append ( np . prod ( [( 1 - x ) * ( 1 - y ) + x * y for x , y in zip ( intfs_sat , adder )], axis = 0 ) ) intf_sat_array = np . concatenate ( intf_sat , axis = 0 ) count_matrix = csr_array ( ( intf_sat_array , ( rows , ind_array )), shape = ( n_samples , n_grid ), dtype = float , ) count : npt . NDArray [ np . floating ] = np . sum ( count_matrix . toarray () * data . weight [:, None ], axis = 0 ) par . count = count . reshape ( par . data . shape ) count_mean : float = np . mean ( count ) # Regulizer, pull fit towards starting point # TODO: Add modifier with normal vectors to weaken spring constant? f_orig_fudge = par . f_orig / ( 10 * ( 1 - par . f_orig ) + par . f_orig ) # edited 8/31/22 to allow 0 f_orig = max ( min ( par . f_orig * f_orig_fudge , 0.99999 ), 0 ) f_orig_weight = np . ones (( n_grid ,)) * ( count_mean / ( 1 - f_orig ) - count_mean ) # removed +1 8/31/22 f_orig_matrix = csr_array ( np . eye ( n_grid )) # Regulizer, Smoothing, thermal diffusion model smooth_fudge = [ 1 / ( 10 * ( 1 - x ) + 1 ) for x in par . f_smooth ] # rss_smooth: float = np.mean([x * y for x, y in zip(par.f_smooth, smooth_fudge)]) rss_smooth : float = np . sqrt ( np . sum ([ z * z for z in [ x * y for x , y in zip ( par . f_smooth , smooth_fudge )]]) ) if rss_smooth > 0 : rel_smooths = [ z / rss_smooth for z in [ x * y for x , y in zip ( par . f_smooth , smooth_fudge )] ] f_smooth = min ( max ( rss_smooth , 0 ), 0.9999999 ) d_bps = [ axis . diff for axis in par . axes ] d_means = [ np . mean ( d , axis = 0 ) for d in d_bps ] inds = [ np . arange ( axis . n_bps ) for axis in par . axes ] smooth_rows = [] smooth_cols = [] smooth_vals = [] for i , ( axis , d_bp , d_mean , rel_smooth ) in enumerate ( zip ( par . axes , d_bps , d_means , rel_smooths ) ): tmp_inds = inds . copy () tmp_inds [ i ] = np . arange ( 1 , axis . n_bps - 1 , 1 ) ind_mesh = np . meshgrid ( * tmp_inds ) delta1 = d_bp [ ind_mesh [ i ] . flatten () - 1 ] / d_mean delta2 = d_bp [ ind_mesh [ i ] . flatten ()] / d_mean rows = np . ravel_multi_index ( ind_mesh , par . data . shape ) . flatten () ind_mesh [ i ] += - 1 smooth_cols . append ( np . ravel_multi_index ( ind_mesh , par . data . shape ) . flatten ()) smooth_rows . append ( rows ) smooth_vals . append ( rel_smooth * ( - 2 / ( delta1 * ( delta1 + delta2 )))) ind_mesh [ i ] += 1 smooth_cols . append ( np . ravel_multi_index ( ind_mesh , par . data . shape ) . flatten ()) smooth_rows . append ( rows ) smooth_vals . append ( rel_smooth * ( 2 / ( delta1 * delta2 ))) ind_mesh [ i ] += 1 smooth_cols . append ( np . ravel_multi_index ( ind_mesh , par . data . shape ) . flatten ()) smooth_rows . append ( rows ) smooth_vals . append ( rel_smooth * ( - 2 / ( delta2 * ( delta1 + delta2 )))) smooth_matrix = csr_array ( ( np . concatenate ( smooth_vals , axis = 0 ), ( np . concatenate ( smooth_rows , axis = 0 ), np . concatenate ( smooth_cols , axis = 0 ), ), ), shape = ( n_grid , n_grid ), dtype = float , ) tmp_model : npt . NDArray [ np . floating ] = ( np . absolute ( model_matrix . toarray ()) . sum ( axis = 0 ) . reshape ( par . data . shape ) ) tmp_smooth : npt . NDArray [ np . floating ] = ( np . absolute ( smooth_matrix . toarray ()) . sum ( axis = 0 ) . reshape ( par . data . shape ) ) n_model = np . linalg . norm ( tmp_model ) n_smooth = np . linalg . norm ( tmp_smooth ) f_smooth_norm : float = (( n_model + f_orig_weight [ 0 ]) / ( n_smooth )) / ( 1 - f_smooth ) - (( n_model + f_orig_weight [ 0 ]) / ( n_smooth )) f_smooth_weight = np . ones (( n_grid ,)) * f_smooth_norm f_smooth_rhs = np . zeros (( n_grid ,)) # append regulizers final_weight : npt . NDArray [ np . floating ] = np . concatenate ( ( data . weight , f_orig_weight , f_smooth_weight ) ) final_weight = np . sqrt ( final_weight / np . mean ( final_weight )) final_matrix = csr_array ( vstack (( model_matrix , f_orig_matrix , smooth_matrix ))) final_rhs = np . concatenate (( data . data [ - 1 ], par . data . flatten (), f_smooth_rhs )) else : final_weight = np . concatenate (( data . weight , f_orig_weight )) final_weight = np . sqrt ( final_weight / np . mean ( final_weight )) final_matrix = csr_array ( vstack (( model_matrix , f_orig_matrix ), format = \"csr\" )) final_rhs = np . concatenate (( data . data [ - 1 ], par . data . flatten ())) # Constraints # locked values c_tol = 1.0e-13 constrained = np . empty (( 0 , par . axes . n_bps ), dtype = np . bool_ ) const_rhs = np . empty (( 0 ,)) if np . any ( par . locked ): constrained = np . diag ( par . locked . flatten ())[ par . locked . flatten (), :] const_rhs = par . data [ par . locked ] . flatten () if np . any ( par . periodic ): for i , periodic in enumerate ( par . periodic ): if periodic : # value tmp_inds = inds . copy () tmp_inds [ i ] = [ 0 ] ind_mesh = np . meshgrid ( * tmp_inds ) flat_inds = np . ravel_multi_index ( ind_mesh , par . data . shape , mode = \"wrap\" ) . flatten () tmp_inds [ i ] = [ - 1 ] ind_mesh = np . meshgrid ( * tmp_inds ) flat_inds = np . vstack ( ( flat_inds , np . ravel_multi_index ( ind_mesh , par . data . shape , mode = \"wrap\" ) . flatten (), ) ) n_const = flat_inds . shape [ 1 ] tmp = np . zeros (( n_const , par . axes . n_bps ), dtype = np . bool_ ) tmp [ range ( n_const ), flat_inds [ 0 , :]] = 1 tmp [ range ( n_const ), flat_inds [ 1 , :]] = - 1 constrained = np . concatenate (( constrained , tmp )) const_rhs = np . concatenate (( const_rhs , np . zeros ( n_const ))) # slope diff_r = par . axes [ i ] . diff [ - 1 ] / par . axes [ i ] . diff [ 0 ] tmp_inds = inds . copy () tmp_inds [ i ] = [ 0 ] ind_mesh = np . meshgrid ( * tmp_inds ) flat_inds = np . ravel_multi_index ( ind_mesh , par . data . shape , mode = \"wrap\" ) . flatten () tmp_inds [ i ] = [ 1 ] ind_mesh = np . meshgrid ( * tmp_inds ) flat_inds = np . vstack ( ( flat_inds , np . ravel_multi_index ( ind_mesh , par . data . shape , mode = \"wrap\" ) . flatten (), ) ) tmp_inds [ i ] = [ - 2 ] ind_mesh = np . meshgrid ( * tmp_inds ) flat_inds = np . vstack ( ( flat_inds , np . ravel_multi_index ( ind_mesh , par . data . shape , mode = \"wrap\" ) . flatten (), ) ) tmp_inds [ i ] = [ - 1 ] ind_mesh = np . meshgrid ( * tmp_inds ) flat_inds = np . vstack ( ( flat_inds , np . ravel_multi_index ( ind_mesh , par . data . shape , mode = \"wrap\" ) . flatten (), ) ) n_const = flat_inds . shape [ 1 ] tmp = np . zeros (( n_const , par . axes . n_bps )) tmp [ range ( n_const ), flat_inds [ 0 , :]] = - diff_r tmp [ range ( n_const ), flat_inds [ 1 , :]] = diff_r tmp [ range ( n_const ), flat_inds [ 2 , :]] = 1.0 tmp [ range ( n_const ), flat_inds [ 3 , :]] = - 1.0 constrained = np . concatenate (( constrained , tmp )) const_rhs = np . concatenate (( const_rhs , np . zeros ( n_const ))) # Solve if np . any ( constrained ): q : npt . NDArray [ np . floating ] r : npt . NDArray [ np . floating ] p : npt . NDArray [ np . int_ ] q , r , p = qr ( constrained , pivoting = True ) # r_diag = np.diag(r) const_rank = np . linalg . matrix_rank ( r ) if const_rank >= par . axes . n_bps : raise ValueError ( \"Over Constrained\" ) if const_rank < constrained . shape [ 0 ]: k = q [:, const_rank :] . T @ const_rhs if np . any ( k > ( c_tol * np . linalg . norm ( const_rhs ))): raise ValueError ( \"Constraint is rank deficient and numerically inconsistent.\" ) qpd = q [:, : const_rank ] . T @ const_rhs subs = p [: const_rank ] est = p [ const_rank :] r1 = r [: const_rank , : const_rank ] r2 = r [: const_rank , const_rank :] a1 : csr_array = final_matrix [:, subs ] qpd = qpd [: const_rank ] rhs_mod = final_rhs - a1 . toarray () @ ( np . linalg . lstsq ( r1 , qpd , rcond = None )[ 0 ]) model_mod : csr_array = final_matrix [:, est ] - a1 @ ( np . linalg . lstsq ( r1 , r2 , rcond = None )[ 0 ] ) res2 = np . linalg . lstsq ( final_weight [:, None ] * model_mod , final_weight * rhs_mod , rcond = None )[ 0 ] res1 = np . linalg . lstsq ( r1 , qpd - r2 @ res2 , rcond = None )[ 0 ] res = np . zeros (( par . axes . n_bps ), dtype = np . floating ) res [ est ] = res2 res [ subs ] = res1 else : # , x0=par.data.flatten() tmp : tuple = linalg . lsqr ( final_weight [:, None ] * final_matrix , final_weight * final_rhs , x0 = par . data . flatten (), ) _LOGGER . debug ( \"niter: %i \" , tmp [ 2 ]) res : npt . NDArray [ np . floating ] = tmp [ 0 ] toc = datetime . datetime . now () - tic _LOGGER . debug ( \"Fitted in %.3f \" , toc . total_seconds ()) return res . reshape ( par . data . shape )","title":"fit"},{"location":"reference/ccg/data/tbldata/#ccg.data.tbldata.scatter_density","text":"Find the density in an nD scatter Source code in ccg\\data\\tbldata.py 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 @ccg . util . profile def scatter_density ( scatter_data : ScatterData , n_bins : int | list [ list ] = 50 ): \"\"\"Find the density in an nD scatter\"\"\" density = np . zeros ( scatter_data . data [ 0 ] . shape ) * np . nan nan_inds = np . any ( np . isnan ( scatter_data . data ), axis = 0 ) sctr = np . array ( scatter_data . clean () . data ) . T # nd hist hist , edges = np . histogramdd ( sctr , bins = n_bins , density = False ) # nd -1 hist if isinstance ( n_bins , list ): n1_bins = n_bins [: - 1 ] else : n1_bins = n_bins hist1 , _ = np . histogramdd ( sctr [ ... , : - 1 ], bins = n1_bins , density = False ) hist1 = np . clip ( hist1 , a_min = np . mean ( hist1 ) / 1 , a_max = None ) tmp = hist / hist1 [ ... , np . newaxis ] tmp [ np . logical_or ( np . isnan ( tmp ), np . isinf ( tmp ))] = 0 bps = [ x [ 1 :] for x in edges ] density [ ~ nan_inds ] = ccg . util . linearinterp ( bps , tmp , sctr ) return density","title":"scatter_density"},{"location":"reference/ccg/data/tsdata/","text":"CCG Time Series data module. Frame Collection of Time Series data. Parameters: data ( Sig | list [ Sig ] | None , default: None ) \u2013 TS Data, by default None. References to Sig will be broken. name ( str | None , default: None ) \u2013 Frame name, by default None math_tline ( TLine | None , default: None ) \u2013 TLine for Frame wide math, by default None Attributes: sigs ( dict [ str , Sig ] ) \u2013 dictionary of Sigs tlines ( TLineCollection ) \u2013 Collection of timelines, referenced by Sigs name ( str ) \u2013 Frame Name nsigs ( int ) \u2013 nsamples ( int ) \u2013 tend ( float | None ) \u2013 tstart ( float | None ) \u2013 tline ( TLine | None ) \u2013 Source code in ccg\\data\\tsdata.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 class Frame : \"\"\"Collection of Time Series data. Parameters ---------- data : Sig | list[Sig] | None, optional TS Data, by default None. References to Sig will be broken. name : str | None, optional Frame name, by default None math_tline : TLine | None, optional TLine for Frame wide math, by default None Attributes ------- sigs : dict[str, Sig] dictionary of Sigs tlines: TLineCollection Collection of timelines, referenced by Sigs name: str Frame Name nsigs nsamples tend tstart tline \"\"\" CUTOFF = 0.5 # For difflib compares def __init__ ( self , data : Sig | list [ Sig ] | None = None , name : str | None = None , math_tline : TLine | None = None , ) -> None : self . sigs : dict [ str , Sig ] = {} self . tlines = TLineCollection ( self ) self . name = name sigs = [] self . math_tline = math_tline # if isinstance(data, pd.DataFrame): # tline = TLine(data) # for col in data: # sig = Sig( # data=data[col], # tline=tline, # name=col, # frame=self, # ) # sigs.append(sig) if isinstance ( data , Sig ): sigs . append ( data ) elif isinstance ( data , list ): for sig in data : sigs . append ( sig ) elif data is None : pass else : raise NotImplementedError ( f \"Frame generation from { type ( data ) } is not implemented.\" ) self . append ( sigs ) @property def nsigs ( self ) -> int : \"\"\"Number of Sigs in collection.\"\"\" return len ( self . sigs ) @property def nsamples ( self ) -> int : \"\"\"Cumulative samples (counting unique timelines as well).\"\"\" nsamples = self . tlines . nsamples for _ , sig in self . sigs . items (): nsamples += sig . nsamples return nsamples @property def tend ( self ) -> float | None : \"\"\"Latest end time from TLine collection. Returns ------- float Time in unix. \"\"\" return self . tlines . tend @property def tstart ( self ) -> float | None : \"\"\"Earliest start time from TLine collection. Returns ------- float Time in unix. \"\"\" return self . tlines . tstart @property def tend_iso ( self ) -> npt . NDArray [ np . datetime64 ]: \"\"\"Latest end time from TLine collection. Returns ------- float Time in iso. \"\"\" return self . tlines . tend_iso @property def tstart_iso ( self ): \"\"\"Earliest start time from TLine collection. Returns ------- float Time in iso. \"\"\" return self . tlines . tstart_iso # def calc_idn(self): # \"\"\"Calculate hash for IDN.\"\"\" # tic = datetime.now() # idn = xxhash.xxh3_64(self.sigs).intdigest() # toc = datetime.now() - tic # _LOGGER.debug(\"IDN calc'd for %s in %.3f\", self.name, toc.total_seconds()) # return idn def resample ( self , sample_to : TLine , sigs : str | list [ str ] | None = None , inplace : bool | None = False , prefix : str | None = None , suffix : str | None = None , ** kwargs , ): \"\"\"Resample Frame to a `sample_to` TLine. Parameters ---------- sample_to : TLine TLine to resample to sigs : str | list[str] | None, optional list of sigs to resample, full frame if None, by default None inplace : bool | None, optional if True, will resample signals and append (id prefix or suffix is not None) or replace inplace. By default False prefix : str | None, optional prefix to signame, by default None suffix : str | None, optional suffix to signame, by default None **kwargs Additional arguments passed to `Sig.resample()` Returns ------- Frame Returns Self if inplace, else a new Frame \"\"\" if inplace : res = self else : res = Frame () if sigs is not None : if isinstance ( sigs , str ): sigs = [ sigs ] else : sigs = list ( self . sigs . keys ()) for sig in sigs : newsig = self . sigs [ sig ] . resample ( sample_to , ** kwargs ) if prefix is not None : newsig . name = prefix + newsig . name if suffix is not None : newsig . name = newsig . name + suffix if inplace and prefix is None and suffix is None : res . remove ( sig ) res . append ( newsig ) return res def append ( self , item : Sig | Frame | list [ Sig ], append_existing_signals : bool = False , interweave_tlines : bool = False , ): \"\"\"Append to CCG Frame in place.\"\"\" if isinstance ( item , Frame ): sigs_to_apnd = list ( item . sigs . keys ()) for _ , new_sigs in item . tlines . sigs . items (): for sig in new_sigs : if append_existing_signals and sig in self and sig in sigs_to_apnd : check_overlap ( self [ sig ], item [ sig ], interweave_tlines ) old_idn = self . tlines . idns [ sig ] new_tline = self . tlines [ old_idn ] . append_to_new ( item [ sig ]) if new_tline . is_monotonic_increasing : for old_sig in list ( self . tlines . sigs [ old_idn ]): if old_sig in item : self . tlines . remove ( old_sig ) self [ old_sig ] . tline = new_tline self . tlines . append ( self [ old_sig ]) # for references self [ old_sig ] . _data . append ( item [ old_sig ] . _data ) # get the rest of the attributes if item [ old_sig ] . connect_gaps is not None : self [ old_sig ] . connect_gaps = item [ old_sig ] . connect_gaps if item [ old_sig ] . data_enum is not None : self [ old_sig ] . data_enum = item [ old_sig ] . data_enum if item [ old_sig ] . interp_method is not None : self [ old_sig ] . interp_method = item [ old_sig ] . interp_method if item [ old_sig ] . unit is not None : self [ old_sig ] . unit = item [ old_sig ] . unit # Check for unknown attributes. the new signal value will overide the original. for key , val in item [ old_sig ] . __dict__ . items (): if ( not key . startswith ( \"_\" ) and key not in SIG_ATTRS ): setattr ( self [ old_sig ], key , val ) sigs_to_apnd . remove ( old_sig ) else : raise NotImplementedError ( \"batch appends not implemented for non-monoton\" ) for signame in sigs_to_apnd : sig = item [ signame ] self . _append_sig ( sig , append_existing_signals , interweave_tlines ) elif isinstance ( item , list ): for sig in item : self . _append_sig ( sig , append_existing_signals , interweave_tlines ) else : self . _append_sig ( item , append_existing_signals , interweave_tlines ) @profile def _append_sig ( self , sig : Sig , append_existing_signals : bool = False , interweave_tlines : bool = False , ): \"\"\"Append a signal to Frame.\"\"\" # create a new sig to break references to existing sig_copy = Sig ( sig ) # Check for matching name if sig_copy . name in self . sigs : if append_existing_signals : self . sigs [ sig_copy . name ] . append ( sig_copy , interweave_tlines = interweave_tlines , remove_duplicates = False , ) else : _LOGGER . warning ( \"Sig %s already exists, use append_existing_signals=True.\" , sig . name , ) else : self . tlines . append ( sig_copy ) # sig_copy.tline = tlref # replace with the tline reference # 2/10/24 now in tlines.append() sig_copy . parent = self self . sigs [ sig_copy . name ] = sig_copy def _rename_sig ( self , oldname , newname ): \"\"\" Rename signal references in frame. Use `frm['oldname'].name = newname` to rename signal and update frame references together. \"\"\" self . sigs [ newname ] = self . sigs . pop ( oldname ) self . tlines . idns [ newname ] = self . tlines . idns . pop ( oldname ) ind = self . tlines . sigs [ self . tlines . idns [ newname ]] . index ( oldname ) self . tlines . sigs [ self . tlines . idns [ newname ]][ ind ] = newname def sort ( self , remove_safe_duplicates = False , remove_all_duplicates = False ): \"\"\"Sort signals by timeline for monoton increasing.\"\"\" for _ , sig in self . sigs . items (): sig . sort_tline ( inplace = True , remove_safe_duplicates = remove_safe_duplicates , remove_all_duplicates = remove_all_duplicates , ) # def to_pandas(self) -> pd.DataFrame: # \"\"\"Convert CCGFrame to pd.DataFrame.\"\"\" # serieslist = [] # for sig in self: # serieslist.append(sig.to_pandas()) # pddf = pd.concat(serieslist, join=\"outer\", axis=1) # return pddf def clear ( self ): \"\"\"Clears frame in place.\"\"\" self . sigs : dict [ str , Sig ] = {} self . tlines = TLineCollection ( self ) def clean_names ( self ): \"\"\"Cleans signal names.\"\"\" rename_list = {} for signame , _ in self . sigs . items (): clean_name = ccg . util . clean_name ( signame ) if clean_name != signame : rename_list . update ({ signame : clean_name }) for signame , clean_name in rename_list . items (): _LOGGER . debug ( \" %s renamed to %s \" , signame , clean_name ) self [ signame ] . name = clean_name def remove ( self , signames : str | list [ str ]): \"\"\"Removes sigs from frame.\"\"\" if not isinstance ( signames , list ): signames = [ signames ] for signame in signames : if signame in self : self . tlines . remove ( signame ) self . sigs . pop ( signame , None ) def plot ( self ): \"\"\"Plot data frame.\"\"\" from ccg.ui.plot import Plot plt = Plot ( self ) plt . plot () def valid ( self , gatecoll : GateColl , tline : TLine | None = None ) -> Frame : \"\"\"Returns a new Frame, invalid data replaced with nan. calc'd on `tline` or combined TLine if None Parameters ---------- gatecoll : GateColl Collection of gating conditions tline : TLine | None, optional TLine to calculate validity on, by default None Returns ------- Frame New instance of Frame \"\"\" res = Frame ( name = self . name ) # if tline is None: # tline = self.tlines.get_fastest() valid_sig = gatecoll . validate ( self , tline ) for tmp_tline in self . tlines : if tmp_tline . nsamples > 1 : b_valid = valid_sig . interp ( tmp_tline ) . data for sig in self . tlines . sigs [ tmp_tline . idn ]: newsig = Sig ( self [ sig ]) nan = np . NaN if newsig . data . dtype . kind in [ \"i\" , \"u\" ]: newsig . data = newsig . data . astype ( \"float\" ) elif newsig . data . dtype . kind in [ \"U\" , \"S\" ]: nan = \"\" newsig . data [ ~ b_valid ] = nan res . append ( newsig ) return res @property def tline ( self ) -> TLine | None : \"\"\"If frame has only one tline, return it.\"\"\" if self . tlines . n_tlines == 1 : return list ( self . tlines . tlines . values ())[ 0 ] else : raise ValueError ( f \" { 'frame' if self . name is None else self . name } has more than one tline,\" + f \" { 'frame' if self . name is None else self . name } .tline() invalid.\" ) @profile def from_excel ( self , filename : str | Path , tline_col : int | str = None , signame_row : int = None , signame_regex : str = None , filedata : BytesIO | StringIO | bytes = None , sigunit_row : int = None , sigdata_row : int = None , ) -> Frame : \"\"\"Generate frame from excel file. Parameters ---------- filename tline_col Column to use for an index signame_row Row with names to parse with _regex signame_regex regex string to parse signal names. Use named groups for parameters to pass into Sig instatiation, for example name, units, etc. example here: https://regex101.com/r/bfBrdf/6 filedata string or bytes io. filename will only be used for ext, name, etc. \"\"\" tic = datetime . now () if isinstance ( filename , str ): filename = Path ( filename ) if signame_row is None : signame_row = 0 if tline_col is None : tline_col = 0 if signame_regex is None : signame_regex = r \"(?P<name>^.*?)(?:(?:\\s?\\((?P<unit>(?!.*\\().*)\\))|$)\" # Default regex `signal name (unit)`-> `{'name':'signal name','unit':'unit'` # https://regex101.com/r/bfBrdf/6 regex = re . compile ( signame_regex ) data = self . read_filedata ( filename , filedata ) toc = datetime . now () - tic _LOGGER . debug ( \"read %s in %.3f .\" , filename , toc . total_seconds ()) tic = datetime . now () if isinstance ( signame_row , str ): for i , row in enumerate ( data ): if row [ 0 ] == signame_row : signame_row = i break else : raise ValueError ( f \"Signal Name Row: { signame_row } not found in first column of data file.\" ) signames = data [ signame_row , :] . astype ( \"str\" ) signames = np . char . strip ( signames ) if sigunit_row is not None : sigunits = data [ sigunit_row , :] . astype ( \"str\" ) sig_args = [ { \"name\" : name , \"unit\" : unit } for name , unit in zip ( signames , sigunits ) ] else : sig_args = [ regex . match ( signame ) . groupdict () for signame in signames ] # Check for duplicate names and add _dup existing = [] for sig in sig_args : if sig [ \"name\" ] not in existing : existing . append ( sig [ \"name\" ]) else : existing . append ( sig [ \"name\" ] + \"_dup\" ) sig [ \"name\" ] = sig [ \"name\" ] + \"_dup\" if isinstance ( tline_col , str ): tline_col = np . where ( signames == tline_col ) if tline_col [ 0 ] . size == 0 : raise ValueError ( \"tline_col is not in signames.\" ) else : tline_col = [ tline_col ] if sigdata_row is None : sigdata_row = signame_row + 1 tmp : npt . NDArray = data [ sigdata_row :, tline_col ] . ravel () try : tmp = tmp . astype ( \"float\" ) except ValueError : tmp = tmp . astype ( type ( tmp [ 0 ])) tline = TLine ( tmp ) for i , kwargs in enumerate ( sig_args ): if i != tline_col [ 0 ]: sigtype = type ( data [ sigdata_row , i ]) sigdata = data [ sigdata_row :, i ] . ravel () . astype ( sigtype ) if sigtype is str : try : sigdata = sigdata . astype ( float ) except ValueError : pass new_sig = Sig ( data = sigdata , tline = tline , ** kwargs , ) self . append ( new_sig ) toc = datetime . now () - tic _LOGGER . debug ( \"built frame in %.3f .\" , toc . total_seconds ()) tic = datetime . now () return self @profile def read_filedata ( self , filename : Path , filedata : BytesIO | StringIO | bytes | None = None ): \"\"\"Reads file data for building frame from file\"\"\" ext = filename . suffix if ext in [ \".xlsx\" , \".xlsm\" , \".XLSX\" , \".XLSM\" ]: # Use openpyxl if filedata is None : wb = openpyxl . load_workbook ( filename = filename , read_only = True , data_only = True ) else : wb = openpyxl . load_workbook ( filename = filedata , read_only = True , data_only = True ) ws = wb . active data = ws . values data = np . array ( list ( data )) wb . close () elif ext in [ \".xls\" , \".XLS\" ]: # Use xlrd wb_xls : xlrd . book . Book = xlrd . open_workbook ( filename = filename , file_contents = filedata ) ws = wb_xls . sheet_by_index ( 0 ) # data = np.array(ws._cell_values) data = np . empty ( shape = ( ws . nrows , ws . ncols ), dtype = \"O\" ) for i in range ( ws . ncols ): data [:, i ] = ws . col_values ( i ) elif ext in [ \".csv\" , \".CSV\" ]: if filedata is None : with open ( filename , \"r\" , encoding = \"utf8\" ) as file : csvreader = csv . reader ( file , dialect = \"excel\" ) tmp = list ( csvreader ) max_col = max ( map ( len , tmp )) data = np . array ( [ tmp_row + [ None ] * ( max_col - len ( tmp_row )) for tmp_row in tmp ], dtype = \"O\" , ) else : if isinstance ( filedata , bytes ): csvreader = csv . reader ( io . StringIO ( filedata . decode ( \"utf-8\" ))) else : csvreader = csv . reader ( filedata ) tmp = list ( csvreader ) max_col = max ( map ( len , tmp )) data = np . array ( [ tmp_row + [ None ] * ( max_col - len ( tmp_row )) for tmp_row in tmp ], dtype = \"O\" , ) else : raise NotImplementedError ( f \"Frame from Excel not implemented for ext: { ext } \" ) return data # async def read_filedata_async( # self, filename: Path, filedata: BytesIO | StringIO | bytes = None # ): # \"\"\"Reads file data for building frame from file\"\"\" # ext = filename.suffix # if ext in [\".xlsx\", \".xlsm\", \".XLSX\", \".XLSM\"]: # # Use openpyxl # if filedata is None: # wb = openpyxl.load_workbook( # filename=filename, read_only=True, data_only=True # ) # else: # wb = openpyxl.load_workbook( # filename=filedata, read_only=True, data_only=True # ) # ws = wb.active # data = ws.values # data = np.array(list(data)) # wb.close() # elif ext in [\".xls\", \".XLS\"]: # # Use xlrd # wb_xls: xlrd.book.Book = xlrd.open_workbook( # filename=filename, file_contents=filedata # ) # ws = wb_xls.sheet_by_index(0) # # data = np.array(ws._cell_values) # data = np.empty(shape=(ws.nrows, ws.ncols), dtype=\"O\") # for i in range(ws.ncols): # data[:, i] = ws.col_values(i) # elif ext in [\".csv\", \".CSV\"]: # if filedata is None: # async with aiofiles.open(filename, \"r\", encoding=\"utf8\") as file: # csvreader = aiocsv.AsyncReader(file, dialect=\"excel\") # tmp = await list(csvreader) # max_col = max(map(len, tmp)) # data = np.array( # [ # tmp_row + [None] * (max_col - len(tmp_row)) # for tmp_row in tmp # ], # dtype=\"O\", # ) # else: # if isinstance(filedata, bytes): # csvreader = aiocsv.AsyncReader( # io.StringIO(filedata.decode(\"utf-8\")) # ) # else: # csvreader = aiocsv.AsyncReader(filedata) # tmp = await list(csvreader) # max_col = max(map(len, tmp)) # data = np.array( # [tmp_row + [None] * (max_col - len(tmp_row)) for tmp_row in tmp], # dtype=\"O\", # ) # else: # raise NotImplementedError( # f\"Frame from Excel not implemented for ext: {ext}\" # ) # return data def __getattr__ ( self , signame : str ) -> Sig : \"\"\"Provides dot notation access to Sigs if their names conform to dot notation. Parameters ---------- signame : str Must conform to dot notation (no spaces or special characters, starts with non numeric char, etc.) Returns ------- Sig Reference to Sig in Self \"\"\" if signame . startswith ( \"_\" ): raise AttributeError # Probably dont want to let it return _** return self . __getitem__ ( signame ) @overload def __getitem__ ( self , index : str ) -> Sig : pass @overload def __getitem__ ( self , index : Frame | list [ str ] | slice | set [ str ] | tuple [ str ] ) -> Frame : pass @profile def __getitem__ ( self , index : Frame | list [ str ] | set [ str ] | tuple [ str ] | str | slice ) -> Frame | Sig : \"\"\"Frame item getter. Parameters ---------- index : Frame | list[str] | slice | set[str] | str Frame, list of Sig names, slice of Returns ------- Frame | Sig New instance of Frame if index is Frame, list[str], slice. Reference to the Sig if str is a sig name. Examples -------- >>>TEST_LIST = [1.0, 2.0, 3.0] >>>TEST_ARR = np.array(TEST_LIST) >>>TEST_TIME = [0.0, 1.0, 2.0] >>>TEST_TLINE = TLine(TEST_TIME) >>>TEST_SIG = Sig(data=TEST_ARR, tline=TEST_TLINE, name=\"TestSig\") >>>assert frm[\"TestSig\"] == TEST_SIG # The reference to TEST_SIG was broken when appended to frm >>>assert frm[\"TestSig\"] is frm.sigs[\"TestSig\"] # The reference is preserved to the Sig in frm >>>assert frm[[\"TestSig\", \"TestSig2\"]] is not frm # The reference is broken to frm >>>assert frm[[\"TestSig\", \"TestSig2\"]] == frm >>>slicedfrm = frm[0:1.1] # sliced in time, with no step there is no resample >>>assert slicedfrm.tstart == 0.0 >>>assert slicedfrm.tend == 1.0 >>>assert slicedfrm.TestSig.nsamples == 2 # note 2 samples since no step was defined in slice >>>sliced_w_resample = frm[0:1.1:0.1] # Sliced in time, resamples to slice since step was defined. >>>assert sliced_w_resample.tstart == 0.0 >>>assert sliced_w_resample.tend == 1.0 >>>assert sliced_w_resample.TestSig.nsamples == 11 # note 2 samples since no step was defined in slice \"\"\" res = Frame ( name = self . name ) if isinstance ( index , Frame ): # This should be a boolean frame with indices that should be returned raise NotImplementedError ( \"Get item by boolean index is not implemented.\" ) if isinstance ( index , str ): self . _check_dot ( index ) if index not in self . sigs : index = self . check_for_alt ( index ) return self . sigs [ index ] if isinstance ( index , list | set | tuple ): if not index : # if empty return all sigs index = list ( self . sigs . keys ()) for signame in index : # Check for _dot notation, calculate derivatives if not present self . _check_dot ( signame ) if signame not in self . sigs : signame = self . check_for_alt ( signame ) res . append ( self . sigs [ signame ]) # improve to slice instead of re-build? elif isinstance ( index , slice ): # slicing is in time axis. if isinstance ( index . start , datetime ): ind_start = index . start . timestamp () else : ind_start = index . start if isinstance ( index . stop , datetime ): ind_stop = index . stop . timestamp () else : ind_stop = index . stop if isinstance ( index . step , timedelta ): step = index . step . total_seconds () else : step = index . step if index . step is None : # No step, so dont resample for tline in self . tlines : if index . start is None : start = tline . tstart else : start = ind_start if index . stop is None : # Since python is r-worded, this is a special case. # Need to make sure the last sample is included. stop = tline . tend + 0.000001 else : stop = ind_stop inds = np . logical_and ( tline . unix >= start , tline . unix < stop ) if np . any ( inds ): new_tline = TLine ( tline [ inds ]) for signame in self . tlines . sigs [ tline . idn ]: unks = {} old_sig = self . sigs [ signame ] for key , val in old_sig . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : unks . update ({ key : val }) new_sig = Sig ( data = old_sig . data [ inds ], tline = new_tline , name = old_sig . name , unit = old_sig . unit , interp_method = old_sig . interp_method , connect_gaps = old_sig . connect_gaps , data_enum = old_sig . data_enum , ** unks , ) res . append ( new_sig ) else : # Step was defined so we need to resample for tline in self . tlines : if index . start is None : start = tline . tstart else : start = ind_start if index . stop is None : stop = tline . tend else : stop = ind_stop new_tline = TLine ( tstart = start , tend = stop , period = step ) for signame in self . tlines . sigs [ tline . idn ]: res . append ( self . sigs [ signame ] . resample ( sample_to = new_tline )) else : raise NotImplementedError ( f \"Get item for index of type { type ( index ) } not implemented\" ) return res @profile def check_for_alt ( self , index ): \"\"\"Check for alternate name in case of missing dot notation\"\"\" # alt = difflib.get_close_matches( # index, self.sigs.keys(), n=1, cutoff=self.CUTOFF # ) alt = extractOne ( index , self . sigs . keys ()) if alt : if len ( alt [ 0 ]) != len ( index ): raise KeyError ( f \"' { index } ' is not in frame: { self . name } \" ) deltas_ok = [ x == \".\" or x == \" \" if x != y else True for x , y in zip ( index , alt [ 0 ]) ] if all ( deltas_ok ): index = alt [ 0 ] else : raise KeyError ( f \"' { index } ' is not in frame: { self . name } \" ) else : raise KeyError ( f \"' { index } ' is not in frame: { self . name } \" ) return index def __contains__ ( self , key ): \"\"\"Checks if key is a signame in frame\"\"\" self . _check_dot ( key ) res = key in self . sigs if res : return True else : try : _ = self . check_for_alt ( key ) return True except KeyError : return False def _check_dot ( self , signame : str ): \"\"\"Check if signame is _dot and calc deriv if needed.\"\"\" if signame not in self . sigs : if \"_dot\" in signame : n_dot = signame . count ( \"dot\" ) base_name = signame [ 0 : signame . index ( \"_dot\" )] if base_name not in self . sigs : base_name = self . check_for_alt ( base_name ) if base_name + \"_\" + \"dot\" * n_dot not in self . sigs : new_sig = self [ base_name ] . dot ( n_dot ) self . append ( new_sig ) @profile def subset ( self , index : slice , sigs : list [ str ] = None ): \"\"\"Get a subset of frame. Allows slicing by signals and in timeline.\"\"\" res = Frame ( name = self . name ) if sigs is None or not sigs : sigs = self . sigs . keys () if isinstance ( index . start , datetime ): ind_start = index . start . timestamp () else : ind_start = index . start if isinstance ( index . stop , datetime ): ind_stop = index . stop . timestamp () else : ind_stop = index . stop if isinstance ( index . step , timedelta ): step = index . step . total_seconds () else : step = index . step if index . step is None : # No step, so dont resample for tline in self . tlines : if any ( x in sigs for x in self . tlines . sigs [ tline . idn ]): if index . start is None : start = tline . tstart else : start = ind_start if index . stop is None : # Since python is r-worded, this is a special case. # Need to make sure the last sample is included. stop = tline . tend + 0.000001 else : stop = ind_stop inds = np . logical_and ( tline . unix >= start , tline . unix < stop ) if np . any ( inds ): new_tline = TLine ( tline [ inds ]) for signame in self . tlines . sigs [ tline . idn ]: if signame in sigs : old_sig = self . sigs [ signame ] new_sig = Sig ( old_sig ) new_sig . data = old_sig . data [ inds ] new_sig . tline = new_tline res . append ( new_sig ) else : # Step was defined so we need to resample for tline in self . tlines : if index . start is None : start = tline . tstart else : start = ind_start if index . stop is None : stop = tline . tend else : stop = ind_stop new_tline = TLine ( tstart = start , tend = stop , period = step ) for signame in self . tlines . sigs [ tline . idn ]: if signame in sigs : res . append ( self . sigs [ signame ] . resample ( sample_to = new_tline )) return res def __iter__ ( self ): \"\"\"Iterate.\"\"\" return iter ( self . sigs . values ()) def __repr__ ( self ) -> str : \"\"\"Return repr string.\"\"\" sigs = self . sigs . keys () reprstr = f \" { self . __class__ . __qualname__ } ([ { ', ' . join ( sigs ) } ])\" return reprstr def __eq__ ( self , other : Self ) -> bool : \"\"\"Check equality.\"\"\" if isinstance ( other , self . __class__ ): iseq = self . sigs == other . sigs and self . tlines == other . tlines return iseq return False nsamples : int property Cumulative samples (counting unique timelines as well). nsigs : int property Number of Sigs in collection. tend : float | None property Latest end time from TLine collection. Returns: float \u2013 Time in unix. tend_iso : npt . NDArray [ np . datetime64 ] property Latest end time from TLine collection. Returns: float \u2013 Time in iso. tline : TLine | None property If frame has only one tline, return it. tstart : float | None property Earliest start time from TLine collection. Returns: float \u2013 Time in unix. tstart_iso property Earliest start time from TLine collection. Returns: float \u2013 Time in iso. __contains__ ( key ) Checks if key is a signame in frame Source code in ccg\\data\\tsdata.py 858 859 860 861 862 863 864 865 866 867 868 869 def __contains__ ( self , key ): \"\"\"Checks if key is a signame in frame\"\"\" self . _check_dot ( key ) res = key in self . sigs if res : return True else : try : _ = self . check_for_alt ( key ) return True except KeyError : return False __eq__ ( other ) Check equality. Source code in ccg\\data\\tsdata.py 955 956 957 958 959 960 961 def __eq__ ( self , other : Self ) -> bool : \"\"\"Check equality.\"\"\" if isinstance ( other , self . __class__ ): iseq = self . sigs == other . sigs and self . tlines == other . tlines return iseq return False __getattr__ ( signame ) Provides dot notation access to Sigs if their names conform to dot notation. Parameters: signame ( str ) \u2013 Must conform to dot notation (no spaces or special characters, starts with non numeric char, etc.) Returns: Sig \u2013 Reference to Sig in Self Source code in ccg\\data\\tsdata.py 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 def __getattr__ ( self , signame : str ) -> Sig : \"\"\"Provides dot notation access to Sigs if their names conform to dot notation. Parameters ---------- signame : str Must conform to dot notation (no spaces or special characters, starts with non numeric char, etc.) Returns ------- Sig Reference to Sig in Self \"\"\" if signame . startswith ( \"_\" ): raise AttributeError # Probably dont want to let it return _** return self . __getitem__ ( signame ) __getitem__ ( index ) Frame item getter. Parameters: index ( Frame | list [ str ] | slice | set [ str ] | str ) \u2013 Frame, list of Sig names, slice of Returns: Frame | Sig \u2013 New instance of Frame if index is Frame, list[str], slice. Reference to the Sig if str is a sig name. Examples: >>>TEST_LIST = [1.0, 2.0, 3.0] >>>TEST_ARR = np.array(TEST_LIST) >>>TEST_TIME = [0.0, 1.0, 2.0] >>>TEST_TLINE = TLine(TEST_TIME) >>>TEST_SIG = Sig(data=TEST_ARR, tline=TEST_TLINE, name=\"TestSig\") >>>assert frm[\"TestSig\"] == TEST_SIG # The reference to TEST_SIG was broken when appended to frm >>>assert frm[\"TestSig\"] is frm.sigs[\"TestSig\"] # The reference is preserved to the Sig in frm >>>assert frm[[\"TestSig\", \"TestSig2\"]] is not frm # The reference is broken to frm >>>assert frm[[\"TestSig\", \"TestSig2\"]] == frm >>>slicedfrm = frm[0:1.1] # sliced in time, with no step there is no resample >>>assert slicedfrm.tstart == 0.0 >>>assert slicedfrm.tend == 1.0 >>>assert slicedfrm.TestSig.nsamples == 2 # note 2 samples since no step was defined in slice >>>sliced_w_resample = frm[0:1.1:0.1] # Sliced in time, resamples to slice since step was defined. >>>assert sliced_w_resample.tstart == 0.0 >>>assert sliced_w_resample.tend == 1.0 >>>assert sliced_w_resample.TestSig.nsamples == 11 # note 2 samples since no step was defined in slice Source code in ccg\\data\\tsdata.py 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 @profile def __getitem__ ( self , index : Frame | list [ str ] | set [ str ] | tuple [ str ] | str | slice ) -> Frame | Sig : \"\"\"Frame item getter. Parameters ---------- index : Frame | list[str] | slice | set[str] | str Frame, list of Sig names, slice of Returns ------- Frame | Sig New instance of Frame if index is Frame, list[str], slice. Reference to the Sig if str is a sig name. Examples -------- >>>TEST_LIST = [1.0, 2.0, 3.0] >>>TEST_ARR = np.array(TEST_LIST) >>>TEST_TIME = [0.0, 1.0, 2.0] >>>TEST_TLINE = TLine(TEST_TIME) >>>TEST_SIG = Sig(data=TEST_ARR, tline=TEST_TLINE, name=\"TestSig\") >>>assert frm[\"TestSig\"] == TEST_SIG # The reference to TEST_SIG was broken when appended to frm >>>assert frm[\"TestSig\"] is frm.sigs[\"TestSig\"] # The reference is preserved to the Sig in frm >>>assert frm[[\"TestSig\", \"TestSig2\"]] is not frm # The reference is broken to frm >>>assert frm[[\"TestSig\", \"TestSig2\"]] == frm >>>slicedfrm = frm[0:1.1] # sliced in time, with no step there is no resample >>>assert slicedfrm.tstart == 0.0 >>>assert slicedfrm.tend == 1.0 >>>assert slicedfrm.TestSig.nsamples == 2 # note 2 samples since no step was defined in slice >>>sliced_w_resample = frm[0:1.1:0.1] # Sliced in time, resamples to slice since step was defined. >>>assert sliced_w_resample.tstart == 0.0 >>>assert sliced_w_resample.tend == 1.0 >>>assert sliced_w_resample.TestSig.nsamples == 11 # note 2 samples since no step was defined in slice \"\"\" res = Frame ( name = self . name ) if isinstance ( index , Frame ): # This should be a boolean frame with indices that should be returned raise NotImplementedError ( \"Get item by boolean index is not implemented.\" ) if isinstance ( index , str ): self . _check_dot ( index ) if index not in self . sigs : index = self . check_for_alt ( index ) return self . sigs [ index ] if isinstance ( index , list | set | tuple ): if not index : # if empty return all sigs index = list ( self . sigs . keys ()) for signame in index : # Check for _dot notation, calculate derivatives if not present self . _check_dot ( signame ) if signame not in self . sigs : signame = self . check_for_alt ( signame ) res . append ( self . sigs [ signame ]) # improve to slice instead of re-build? elif isinstance ( index , slice ): # slicing is in time axis. if isinstance ( index . start , datetime ): ind_start = index . start . timestamp () else : ind_start = index . start if isinstance ( index . stop , datetime ): ind_stop = index . stop . timestamp () else : ind_stop = index . stop if isinstance ( index . step , timedelta ): step = index . step . total_seconds () else : step = index . step if index . step is None : # No step, so dont resample for tline in self . tlines : if index . start is None : start = tline . tstart else : start = ind_start if index . stop is None : # Since python is r-worded, this is a special case. # Need to make sure the last sample is included. stop = tline . tend + 0.000001 else : stop = ind_stop inds = np . logical_and ( tline . unix >= start , tline . unix < stop ) if np . any ( inds ): new_tline = TLine ( tline [ inds ]) for signame in self . tlines . sigs [ tline . idn ]: unks = {} old_sig = self . sigs [ signame ] for key , val in old_sig . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : unks . update ({ key : val }) new_sig = Sig ( data = old_sig . data [ inds ], tline = new_tline , name = old_sig . name , unit = old_sig . unit , interp_method = old_sig . interp_method , connect_gaps = old_sig . connect_gaps , data_enum = old_sig . data_enum , ** unks , ) res . append ( new_sig ) else : # Step was defined so we need to resample for tline in self . tlines : if index . start is None : start = tline . tstart else : start = ind_start if index . stop is None : stop = tline . tend else : stop = ind_stop new_tline = TLine ( tstart = start , tend = stop , period = step ) for signame in self . tlines . sigs [ tline . idn ]: res . append ( self . sigs [ signame ] . resample ( sample_to = new_tline )) else : raise NotImplementedError ( f \"Get item for index of type { type ( index ) } not implemented\" ) return res __iter__ () Iterate. Source code in ccg\\data\\tsdata.py 945 946 947 def __iter__ ( self ): \"\"\"Iterate.\"\"\" return iter ( self . sigs . values ()) __repr__ () Return repr string. Source code in ccg\\data\\tsdata.py 949 950 951 952 953 def __repr__ ( self ) -> str : \"\"\"Return repr string.\"\"\" sigs = self . sigs . keys () reprstr = f \" { self . __class__ . __qualname__ } ([ { ', ' . join ( sigs ) } ])\" return reprstr append ( item , append_existing_signals = False , interweave_tlines = False ) Append to CCG Frame in place. Source code in ccg\\data\\tsdata.py 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 def append ( self , item : Sig | Frame | list [ Sig ], append_existing_signals : bool = False , interweave_tlines : bool = False , ): \"\"\"Append to CCG Frame in place.\"\"\" if isinstance ( item , Frame ): sigs_to_apnd = list ( item . sigs . keys ()) for _ , new_sigs in item . tlines . sigs . items (): for sig in new_sigs : if append_existing_signals and sig in self and sig in sigs_to_apnd : check_overlap ( self [ sig ], item [ sig ], interweave_tlines ) old_idn = self . tlines . idns [ sig ] new_tline = self . tlines [ old_idn ] . append_to_new ( item [ sig ]) if new_tline . is_monotonic_increasing : for old_sig in list ( self . tlines . sigs [ old_idn ]): if old_sig in item : self . tlines . remove ( old_sig ) self [ old_sig ] . tline = new_tline self . tlines . append ( self [ old_sig ]) # for references self [ old_sig ] . _data . append ( item [ old_sig ] . _data ) # get the rest of the attributes if item [ old_sig ] . connect_gaps is not None : self [ old_sig ] . connect_gaps = item [ old_sig ] . connect_gaps if item [ old_sig ] . data_enum is not None : self [ old_sig ] . data_enum = item [ old_sig ] . data_enum if item [ old_sig ] . interp_method is not None : self [ old_sig ] . interp_method = item [ old_sig ] . interp_method if item [ old_sig ] . unit is not None : self [ old_sig ] . unit = item [ old_sig ] . unit # Check for unknown attributes. the new signal value will overide the original. for key , val in item [ old_sig ] . __dict__ . items (): if ( not key . startswith ( \"_\" ) and key not in SIG_ATTRS ): setattr ( self [ old_sig ], key , val ) sigs_to_apnd . remove ( old_sig ) else : raise NotImplementedError ( \"batch appends not implemented for non-monoton\" ) for signame in sigs_to_apnd : sig = item [ signame ] self . _append_sig ( sig , append_existing_signals , interweave_tlines ) elif isinstance ( item , list ): for sig in item : self . _append_sig ( sig , append_existing_signals , interweave_tlines ) else : self . _append_sig ( item , append_existing_signals , interweave_tlines ) check_for_alt ( index ) Check for alternate name in case of missing dot notation Source code in ccg\\data\\tsdata.py 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 @profile def check_for_alt ( self , index ): \"\"\"Check for alternate name in case of missing dot notation\"\"\" # alt = difflib.get_close_matches( # index, self.sigs.keys(), n=1, cutoff=self.CUTOFF # ) alt = extractOne ( index , self . sigs . keys ()) if alt : if len ( alt [ 0 ]) != len ( index ): raise KeyError ( f \"' { index } ' is not in frame: { self . name } \" ) deltas_ok = [ x == \".\" or x == \" \" if x != y else True for x , y in zip ( index , alt [ 0 ]) ] if all ( deltas_ok ): index = alt [ 0 ] else : raise KeyError ( f \"' { index } ' is not in frame: { self . name } \" ) else : raise KeyError ( f \"' { index } ' is not in frame: { self . name } \" ) return index clean_names () Cleans signal names. Source code in ccg\\data\\tsdata.py 363 364 365 366 367 368 369 370 371 372 373 def clean_names ( self ): \"\"\"Cleans signal names.\"\"\" rename_list = {} for signame , _ in self . sigs . items (): clean_name = ccg . util . clean_name ( signame ) if clean_name != signame : rename_list . update ({ signame : clean_name }) for signame , clean_name in rename_list . items (): _LOGGER . debug ( \" %s renamed to %s \" , signame , clean_name ) self [ signame ] . name = clean_name clear () Clears frame in place. Source code in ccg\\data\\tsdata.py 358 359 360 361 def clear ( self ): \"\"\"Clears frame in place.\"\"\" self . sigs : dict [ str , Sig ] = {} self . tlines = TLineCollection ( self ) from_excel ( filename , tline_col = None , signame_row = None , signame_regex = None , filedata = None , sigunit_row = None , sigdata_row = None ) Generate frame from excel file. Parameters: filename ( str | Path ) \u2013 tline_col ( int | str , default: None ) \u2013 Column to use for an index signame_row ( int , default: None ) \u2013 Row with names to parse with _regex signame_regex ( str , default: None ) \u2013 regex string to parse signal names. Use named groups for parameters to pass into Sig instatiation, for example name, units, etc. example here: https://regex101.com/r/bfBrdf/6 filedata ( BytesIO | StringIO | bytes , default: None ) \u2013 string or bytes io. filename will only be used for ext, name, etc. Source code in ccg\\data\\tsdata.py 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 @profile def from_excel ( self , filename : str | Path , tline_col : int | str = None , signame_row : int = None , signame_regex : str = None , filedata : BytesIO | StringIO | bytes = None , sigunit_row : int = None , sigdata_row : int = None , ) -> Frame : \"\"\"Generate frame from excel file. Parameters ---------- filename tline_col Column to use for an index signame_row Row with names to parse with _regex signame_regex regex string to parse signal names. Use named groups for parameters to pass into Sig instatiation, for example name, units, etc. example here: https://regex101.com/r/bfBrdf/6 filedata string or bytes io. filename will only be used for ext, name, etc. \"\"\" tic = datetime . now () if isinstance ( filename , str ): filename = Path ( filename ) if signame_row is None : signame_row = 0 if tline_col is None : tline_col = 0 if signame_regex is None : signame_regex = r \"(?P<name>^.*?)(?:(?:\\s?\\((?P<unit>(?!.*\\().*)\\))|$)\" # Default regex `signal name (unit)`-> `{'name':'signal name','unit':'unit'` # https://regex101.com/r/bfBrdf/6 regex = re . compile ( signame_regex ) data = self . read_filedata ( filename , filedata ) toc = datetime . now () - tic _LOGGER . debug ( \"read %s in %.3f .\" , filename , toc . total_seconds ()) tic = datetime . now () if isinstance ( signame_row , str ): for i , row in enumerate ( data ): if row [ 0 ] == signame_row : signame_row = i break else : raise ValueError ( f \"Signal Name Row: { signame_row } not found in first column of data file.\" ) signames = data [ signame_row , :] . astype ( \"str\" ) signames = np . char . strip ( signames ) if sigunit_row is not None : sigunits = data [ sigunit_row , :] . astype ( \"str\" ) sig_args = [ { \"name\" : name , \"unit\" : unit } for name , unit in zip ( signames , sigunits ) ] else : sig_args = [ regex . match ( signame ) . groupdict () for signame in signames ] # Check for duplicate names and add _dup existing = [] for sig in sig_args : if sig [ \"name\" ] not in existing : existing . append ( sig [ \"name\" ]) else : existing . append ( sig [ \"name\" ] + \"_dup\" ) sig [ \"name\" ] = sig [ \"name\" ] + \"_dup\" if isinstance ( tline_col , str ): tline_col = np . where ( signames == tline_col ) if tline_col [ 0 ] . size == 0 : raise ValueError ( \"tline_col is not in signames.\" ) else : tline_col = [ tline_col ] if sigdata_row is None : sigdata_row = signame_row + 1 tmp : npt . NDArray = data [ sigdata_row :, tline_col ] . ravel () try : tmp = tmp . astype ( \"float\" ) except ValueError : tmp = tmp . astype ( type ( tmp [ 0 ])) tline = TLine ( tmp ) for i , kwargs in enumerate ( sig_args ): if i != tline_col [ 0 ]: sigtype = type ( data [ sigdata_row , i ]) sigdata = data [ sigdata_row :, i ] . ravel () . astype ( sigtype ) if sigtype is str : try : sigdata = sigdata . astype ( float ) except ValueError : pass new_sig = Sig ( data = sigdata , tline = tline , ** kwargs , ) self . append ( new_sig ) toc = datetime . now () - tic _LOGGER . debug ( \"built frame in %.3f .\" , toc . total_seconds ()) tic = datetime . now () return self plot () Plot data frame. Source code in ccg\\data\\tsdata.py 384 385 386 387 388 389 def plot ( self ): \"\"\"Plot data frame.\"\"\" from ccg.ui.plot import Plot plt = Plot ( self ) plt . plot () read_filedata ( filename , filedata = None ) Reads file data for building frame from file Source code in ccg\\data\\tsdata.py 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 @profile def read_filedata ( self , filename : Path , filedata : BytesIO | StringIO | bytes | None = None ): \"\"\"Reads file data for building frame from file\"\"\" ext = filename . suffix if ext in [ \".xlsx\" , \".xlsm\" , \".XLSX\" , \".XLSM\" ]: # Use openpyxl if filedata is None : wb = openpyxl . load_workbook ( filename = filename , read_only = True , data_only = True ) else : wb = openpyxl . load_workbook ( filename = filedata , read_only = True , data_only = True ) ws = wb . active data = ws . values data = np . array ( list ( data )) wb . close () elif ext in [ \".xls\" , \".XLS\" ]: # Use xlrd wb_xls : xlrd . book . Book = xlrd . open_workbook ( filename = filename , file_contents = filedata ) ws = wb_xls . sheet_by_index ( 0 ) # data = np.array(ws._cell_values) data = np . empty ( shape = ( ws . nrows , ws . ncols ), dtype = \"O\" ) for i in range ( ws . ncols ): data [:, i ] = ws . col_values ( i ) elif ext in [ \".csv\" , \".CSV\" ]: if filedata is None : with open ( filename , \"r\" , encoding = \"utf8\" ) as file : csvreader = csv . reader ( file , dialect = \"excel\" ) tmp = list ( csvreader ) max_col = max ( map ( len , tmp )) data = np . array ( [ tmp_row + [ None ] * ( max_col - len ( tmp_row )) for tmp_row in tmp ], dtype = \"O\" , ) else : if isinstance ( filedata , bytes ): csvreader = csv . reader ( io . StringIO ( filedata . decode ( \"utf-8\" ))) else : csvreader = csv . reader ( filedata ) tmp = list ( csvreader ) max_col = max ( map ( len , tmp )) data = np . array ( [ tmp_row + [ None ] * ( max_col - len ( tmp_row )) for tmp_row in tmp ], dtype = \"O\" , ) else : raise NotImplementedError ( f \"Frame from Excel not implemented for ext: { ext } \" ) return data remove ( signames ) Removes sigs from frame. Source code in ccg\\data\\tsdata.py 375 376 377 378 379 380 381 382 def remove ( self , signames : str | list [ str ]): \"\"\"Removes sigs from frame.\"\"\" if not isinstance ( signames , list ): signames = [ signames ] for signame in signames : if signame in self : self . tlines . remove ( signame ) self . sigs . pop ( signame , None ) resample ( sample_to , sigs = None , inplace = False , prefix = None , suffix = None , ** kwargs ) Resample Frame to a sample_to TLine. Parameters: sample_to ( TLine ) \u2013 TLine to resample to sigs ( str | list [ str ] | None , default: None ) \u2013 list of sigs to resample, full frame if None, by default None inplace ( bool | None , default: False ) \u2013 if True, will resample signals and append (id prefix or suffix is not None) or replace inplace. By default False prefix ( str | None , default: None ) \u2013 prefix to signame, by default None suffix ( str | None , default: None ) \u2013 suffix to signame, by default None **kwargs \u2013 Additional arguments passed to Sig.resample() Returns: Frame \u2013 Returns Self if inplace, else a new Frame Source code in ccg\\data\\tsdata.py 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 def resample ( self , sample_to : TLine , sigs : str | list [ str ] | None = None , inplace : bool | None = False , prefix : str | None = None , suffix : str | None = None , ** kwargs , ): \"\"\"Resample Frame to a `sample_to` TLine. Parameters ---------- sample_to : TLine TLine to resample to sigs : str | list[str] | None, optional list of sigs to resample, full frame if None, by default None inplace : bool | None, optional if True, will resample signals and append (id prefix or suffix is not None) or replace inplace. By default False prefix : str | None, optional prefix to signame, by default None suffix : str | None, optional suffix to signame, by default None **kwargs Additional arguments passed to `Sig.resample()` Returns ------- Frame Returns Self if inplace, else a new Frame \"\"\" if inplace : res = self else : res = Frame () if sigs is not None : if isinstance ( sigs , str ): sigs = [ sigs ] else : sigs = list ( self . sigs . keys ()) for sig in sigs : newsig = self . sigs [ sig ] . resample ( sample_to , ** kwargs ) if prefix is not None : newsig . name = prefix + newsig . name if suffix is not None : newsig . name = newsig . name + suffix if inplace and prefix is None and suffix is None : res . remove ( sig ) res . append ( newsig ) return res sort ( remove_safe_duplicates = False , remove_all_duplicates = False ) Sort signals by timeline for monoton increasing. Source code in ccg\\data\\tsdata.py 339 340 341 342 343 344 345 346 def sort ( self , remove_safe_duplicates = False , remove_all_duplicates = False ): \"\"\"Sort signals by timeline for monoton increasing.\"\"\" for _ , sig in self . sigs . items (): sig . sort_tline ( inplace = True , remove_safe_duplicates = remove_safe_duplicates , remove_all_duplicates = remove_all_duplicates , ) subset ( index , sigs = None ) Get a subset of frame. Allows slicing by signals and in timeline. Source code in ccg\\data\\tsdata.py 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 @profile def subset ( self , index : slice , sigs : list [ str ] = None ): \"\"\"Get a subset of frame. Allows slicing by signals and in timeline.\"\"\" res = Frame ( name = self . name ) if sigs is None or not sigs : sigs = self . sigs . keys () if isinstance ( index . start , datetime ): ind_start = index . start . timestamp () else : ind_start = index . start if isinstance ( index . stop , datetime ): ind_stop = index . stop . timestamp () else : ind_stop = index . stop if isinstance ( index . step , timedelta ): step = index . step . total_seconds () else : step = index . step if index . step is None : # No step, so dont resample for tline in self . tlines : if any ( x in sigs for x in self . tlines . sigs [ tline . idn ]): if index . start is None : start = tline . tstart else : start = ind_start if index . stop is None : # Since python is r-worded, this is a special case. # Need to make sure the last sample is included. stop = tline . tend + 0.000001 else : stop = ind_stop inds = np . logical_and ( tline . unix >= start , tline . unix < stop ) if np . any ( inds ): new_tline = TLine ( tline [ inds ]) for signame in self . tlines . sigs [ tline . idn ]: if signame in sigs : old_sig = self . sigs [ signame ] new_sig = Sig ( old_sig ) new_sig . data = old_sig . data [ inds ] new_sig . tline = new_tline res . append ( new_sig ) else : # Step was defined so we need to resample for tline in self . tlines : if index . start is None : start = tline . tstart else : start = ind_start if index . stop is None : stop = tline . tend else : stop = ind_stop new_tline = TLine ( tstart = start , tend = stop , period = step ) for signame in self . tlines . sigs [ tline . idn ]: if signame in sigs : res . append ( self . sigs [ signame ] . resample ( sample_to = new_tline )) return res valid ( gatecoll , tline = None ) Returns a new Frame, invalid data replaced with nan. calc'd on tline or combined TLine if None Parameters: gatecoll ( GateColl ) \u2013 Collection of gating conditions tline ( TLine | None , default: None ) \u2013 TLine to calculate validity on, by default None Returns: Frame \u2013 New instance of Frame Source code in ccg\\data\\tsdata.py 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 def valid ( self , gatecoll : GateColl , tline : TLine | None = None ) -> Frame : \"\"\"Returns a new Frame, invalid data replaced with nan. calc'd on `tline` or combined TLine if None Parameters ---------- gatecoll : GateColl Collection of gating conditions tline : TLine | None, optional TLine to calculate validity on, by default None Returns ------- Frame New instance of Frame \"\"\" res = Frame ( name = self . name ) # if tline is None: # tline = self.tlines.get_fastest() valid_sig = gatecoll . validate ( self , tline ) for tmp_tline in self . tlines : if tmp_tline . nsamples > 1 : b_valid = valid_sig . interp ( tmp_tline ) . data for sig in self . tlines . sigs [ tmp_tline . idn ]: newsig = Sig ( self [ sig ]) nan = np . NaN if newsig . data . dtype . kind in [ \"i\" , \"u\" ]: newsig . data = newsig . data . astype ( \"float\" ) elif newsig . data . dtype . kind in [ \"U\" , \"S\" ]: nan = \"\" newsig . data [ ~ b_valid ] = nan res . append ( newsig ) return res SgCoef Store Savitzky Golay coeficients. Source code in ccg\\data\\tsdata.py 2601 2602 2603 2604 2605 2606 2607 2608 2609 2610 2611 2612 2613 2614 2615 2616 2617 2618 2619 2620 2621 2622 2623 2624 2625 2626 2627 2628 2629 2630 2631 2632 2633 2634 2635 2636 2637 2638 2639 2640 2641 2642 2643 2644 class SgCoef : \"\"\"Store Savitzky Golay coeficients.\"\"\" __slots__ = ( \"orig_index\" , \"sample_to_index\" , \"n_win_orig\" , \"n_ord\" , \"conv\" , \"uniqinvs\" , \"n_uniq\" , \"inds\" , ) def __init__ ( self , orig_index : int = None , sample_to_index : int = None , n_win_orig : int = None , n_ord : int = None , conv : npt . NDArray = None , uniqinvs : npt . NDArray = None , n_uniq : int = None , inds : npt . NDArray = None , ): self . orig_index = orig_index self . sample_to_index = sample_to_index self . n_win_orig = n_win_orig self . n_ord = n_ord self . conv = conv self . uniqinvs = uniqinvs self . n_uniq = n_uniq self . inds = inds def clear ( self ): \"\"\"Clear SgCoef.\"\"\" self . orig_index = None self . sample_to_index = None self . n_win_orig = None self . n_ord = None self . conv = None self . uniqinvs = None self . n_uniq = None self . inds : npt . NDArray = None clear () Clear SgCoef. Source code in ccg\\data\\tsdata.py 2635 2636 2637 2638 2639 2640 2641 2642 2643 2644 def clear ( self ): \"\"\"Clear SgCoef.\"\"\" self . orig_index = None self . sample_to_index = None self . n_win_orig = None self . n_ord = None self . conv = None self . uniqinvs = None self . n_uniq = None self . inds : npt . NDArray = None Sig CCG Sig class. Contains signal data and timeline. Parameters: data ( Sig | NDArray | list | None , default: None ) \u2013 Data source for the signal. tline ( TLine | None , default: None ) \u2013 Timeline instance for signal. Must be same length as data. name ( str | None , default: None ) \u2013 Signal name, must be unique in a Frame . unit ( str | None , default: None ) \u2013 Optional unit. interp_method ( InterpMethod | None , default: None ) \u2013 interpolation method for signal. parent ( Frame | None , default: None ) \u2013 Reference to the 'Frame' if this is in a frame. connect_gaps ( bool | None , default: None ) \u2013 Option for plotting using Plot data_enum ( SigEnum | None , default: None ) \u2013 Enumeration definition to alias values, used for plotting string data. data_range ( list [ float ] | None , default: None ) \u2013 Used for plot scaling. **kwargs \u2013 Argument for inserting unknown attributes. Source code in ccg\\data\\tsdata.py 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622 1623 1624 1625 1626 1627 1628 1629 1630 1631 1632 1633 1634 1635 1636 1637 1638 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 1649 1650 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664 1665 1666 1667 1668 1669 1670 1671 1672 1673 1674 1675 1676 1677 1678 1679 1680 1681 1682 1683 1684 1685 1686 1687 1688 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699 1700 1701 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711 1712 1713 1714 1715 1716 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741 1742 1743 1744 1745 1746 1747 1748 1749 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 1767 1768 1769 1770 1771 1772 1773 1774 1775 1776 1777 1778 1779 1780 1781 1782 1783 1784 1785 1786 1787 1788 1789 1790 1791 1792 1793 1794 1795 1796 1797 1798 1799 1800 1801 1802 1803 1804 1805 1806 1807 1808 1809 1810 1811 1812 1813 class Sig : \"\"\" CCG Sig class. Contains signal data and timeline. Parameters ---------- data Data source for the signal. tline Timeline instance for signal. Must be same length as data. name Signal name, must be unique in a `Frame`. unit Optional unit. interp_method interpolation method for signal. parent Reference to the 'Frame' if this is in a frame. connect_gaps Option for plotting using `Plot` data_enum Enumeration definition to alias values, used for plotting string data. data_range Used for plot scaling. **kwargs Argument for inserting unknown attributes. \"\"\" _FGAP = 5 @profile def __init__ ( self , data : Sig | npt . NDArray | list | None = None , tline : TLine | None = None , name : str | None = None , unit : str | None = None , interp_method : InterpMethod | None = None , parent : Frame | None = None , connect_gaps : bool | None = None , data_enum : SigEnum | None = None , nsamples : int | None = None , dtype : npt . DTypeLike = None , data_range : list [ float ] | None = None , ** kwargs , ) -> None : self . parent = parent self . connect_gaps = connect_gaps self . data_enum = data_enum self . base_data = None self . _name = None self . _dtype = dtype self . _data : AllocData = None self . interp_method = None if nsamples is None : self . _shape = None else : self . _shape = ( nsamples ,) if tline is not None : self . tline = tline self . unit = unit self . data_range = data_range for key , value in kwargs . items (): setattr ( self , key , value ) if isinstance ( data , Sig ): # This is here to break references safely self . _dtype = data . _dtype self . _shape = data . _shape self . tline = TLine ( data . tline , nsamples = self . _shape ) self . data = data . _data self . data_range = data . data_range self . interp_method = data . interp_method if unit is None : self . unit = data . unit self . _name = data . name if data_enum is None : self . data_enum = data . data_enum if connect_gaps is None : self . connect_gaps = data . connect_gaps if data_range is not None : self . data_range = data_range for key , val in data . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : setattr ( self , key , val ) elif isinstance ( data , list ): self . data = np . array ( data ) elif isinstance ( data , np . ndarray ): self . data = data elif isinstance ( data , ( float , int , np . number )): if tline is not None : self . data = np . ones ( shape = tline . _unix . shape , dtype = type ( data )) * data # self.data = np.array([data] * tline.unix.size, dtype=type(data)) else : self . data = data elif isinstance ( data , str ): if tline is not None : self . data = np . array ([ data ] * tline . nsamples , dtype = type ( data )) else : self . data = data elif data is None : self . data = None # for pre-allocation else : raise NotImplementedError ( f \"Sig gen from { type ( data ) } is not implemented.\" ) if name is not None : self . _name = name if self . _data is None or self . _dtype . type is np . str_ : # This is a string type so make sure interp is nearest self . interp_method = InterpMethod . NEAREST else : if interp_method is not None : self . interp_method = interp_method if self . nsamples and self . nsamples != self . tline . nsamples : _LOGGER . warning ( \"Length of %s 's TLine: %i doesnt match length of it's data: %i \" , self . name , self . tline . nsamples , self . nsamples , ) @property def name ( self ) -> str : \"\"\"Return signal name.\"\"\" return self . _name @name . setter def name ( self , new_name ): if self . parent is not None : self . parent . _rename_sig ( # pylint: disable=access-member-before-definition self . _name , new_name ) self . _name = new_name @property def data ( self ) -> npt . NDArray : \"\"\"data getter\"\"\" return self . _data [:] @data . setter @profile def data ( self , value : npt . NDArray | AllocData | None ): if self . _data is None : # pre-allocate self . _data = AllocData ( data = value , shape = self . _shape , dtype = self . _dtype ) if self . _shape is None : self . _shape = self . _data . shape if self . _dtype is None : self . _dtype = self . _data . data . dtype if not hasattr ( self , \"tline\" ): self . tline = TLine ( nsamples = self . _shape ) else : self . _data . replace ( value ) @property def max ( self ) -> npt . NBitBase | None : \"\"\"Max value.\"\"\" if np . issubdtype ( self . data . dtype , np . number ): try : return np . nanmax ( self . data ) except ValueError : pass return None @property def min ( self ) -> npt . NBitBase | None : \"\"\"Min value.\"\"\" if np . issubdtype ( self . data . dtype , np . number ): try : return np . nanmin ( self . data ) except ValueError : pass return None @property def nsamples ( self ): return self . _data . nsamples @property def appx_bytes ( self ): \"\"\"Estimated size of data [bytes]. Excludes tline.\"\"\" return self . _data . appx_bytes @property def tstart ( self ): \"\"\"Start if tline.\"\"\" return self . tline . tstart @property def tend ( self ): \"\"\"End of tline.\"\"\" return self . tline . tend @property def tstart_iso ( self ): \"\"\"Start if tline.\"\"\" return self . tline . tstart_iso @property def tend_iso ( self ): \"\"\"End of tline.\"\"\" return self . tline . tend_iso @property def period ( self ): \"\"\"apprx period.\"\"\" return self . tline . period def calc_idn ( self ): \"\"\"Calculate hash for IDN.\"\"\" # tic = datetime.now() idn = xxhash . xxh3_64_intdigest ( self . _data . tobytes ()) # toc = datetime.now() - tic # _LOGGER.debug(\"IDN calc'd for %s in %.3f\", self.name, toc.total_seconds()) return idn + self . tline . idn @profile def append ( self , sig : Sig , interweave_tlines = False , remove_duplicates = False ): \"\"\"Append sig to signal.\"\"\" # Check if timelimes overlap check_overlap ( self , sig , interweave_tlines ) if self . parent is None : self . tline . append_inplace ( sig ) else : nshared = len ( self . parent . tlines . sigs [ self . tline . idn ]) if nshared == 1 : self . tline . append_inplace ( sig ) else : self . tline = self . tline . append_to_new ( sig ) self . _data . append ( sig . _data ) # pylint: disable=access-member-before-definition if not self . tline . is_monotonic_increasing : self . sort_tline ( inplace = True , remove_safe_duplicates = remove_duplicates ) if self . parent is not None : self . parent . tlines . remove ( self . name ) self . parent . tlines . append ( self ) # self.tline = tlref # 2/10/24 now in tlines.append() # get the rest of the attributes if sig . connect_gaps is not None : self . connect_gaps = sig . connect_gaps if sig . data_enum is not None : self . data_enum = sig . data_enum if sig . interp_method is not None : self . interp_method = sig . interp_method if sig . unit is not None : self . unit = sig . unit # Check for unknown attributes. the new signal value will overide the original. for key , val in sig . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : setattr ( self , key , val ) def convert_units ( self , unit : str ) -> Sig : \"\"\"Convert units in place\"\"\" if unit != self . unit : self . data = ccg . util . convert_units ( value = self . data , from_unit = self . unit , to_unit = unit ) if self . data_range : self . data_range = ccg . util . convert_units ( value = self . data_range , from_unit = self . unit , to_unit = unit ) self . unit = unit return self def as_unit ( self , unit : str ) -> Sig : \"\"\"return new sig converted to unit\"\"\" sig = Sig ( self ) sig . convert_units ( unit ) return sig def sort_tline ( self , inplace = True , remove_safe_duplicates = False , remove_all_duplicates = False , ): \"\"\"Sort signal by timeline. Parameters ---------- inplace Sorts signal in place, returns None. remove_duplicates Will remove duplicate timestamps if signal is also duplicated. Returns ------- Sig self if `inplace=True`. \"\"\" inds = np . argsort ( self . tline . unix , kind = \"stable\" ) if inplace : self . tline = TLine ( self . tline . unix [ inds ]) if self . nsamples > 0 : self . data = self . data [ inds ] if remove_safe_duplicates : self . _remove_duplicates ( remove_all_duplicates ) if self . parent is not None : self . parent . tlines . remove ( self . name ) self . parent . tlines . append ( self ) # self.tline = tlref # 2/10/24 now in tlines.append() return self sig = Sig ( self ) # TODO: clean this up to not define, then edit. sig . name = sig . name + \"_sorted\" sig . tline = TLine ( self . tline . unix [ inds ]) if self . nsamples > 0 : sig . data = sig . data [ inds ] if remove_safe_duplicates : sig . _remove_duplicates ( remove_all_duplicates ) # pylint: disable=access-member-before-definition return sig def _remove_duplicates ( self , remove_all_duplicates = False ): \"\"\"Removes duplicate samples if both time and data match. If `remove_all_duplicates=True`, will remove duplicates even if values dont match. **Must be sorted first** Use `self.sort_tline(remove_safe_duplicates=True, remove_all_duplicates=True)` \"\"\" # Check if its monoton increasing now. if not self . tline . is_monotonic_increasing : # find duplicate timestamps inds = self . tline . dt == 0 if self . data . dtype . kind in [ \"i\" , \"u\" , \"f\" ]: data_dt = np . diff ( self . data ) data_dt = data_dt == 0 else : data_dt = self . data [ 1 :] == self . data [ 0 : - 1 ] dups = inds & data_dt dups = np . append ( False , dups ) if np . any ( dups ): _LOGGER . debug ( \"Removed %i duplicates from %s .\" , np . sum ( dups ), self . name ) self . tline = TLine ( self . tline . unix [ ~ dups ]) self . data = self . data [ ~ dups ] # If there are still duplicates, there are different values at the same timestep. if remove_all_duplicates and not self . tline . is_monotonic_increasing : inds = self . tline . dt == 0 dups = inds dups = np . append ( False , dups ) if np . any ( dups ): _LOGGER . warning ( \"Removed %i duplicate timestamps with different values from %s .\" , np . sum ( dups ), self . name , ) self . tline = TLine ( self . tline . unix [ ~ dups ]) self . data = self . data [ ~ dups ] @profile def plot_prep ( self ) -> Sig : \"\"\"Prepare for plotting. Sorts tline and removes duplicates. Inserts NaNs in gaps if `connect_gaps=False | None`. Applies enum if it exists. \"\"\" res = self if not self . tline . is_monotonic_increasing : self . sort_tline ( remove_safe_duplicates = True ) if self . connect_gaps is None or not self . connect_gaps : gaps = np . greater ( self . tline . dt , self . _FGAP * self . tline . period , ) if np . sum ( gaps ) > 0 : res = Sig ( self ) # Make a copy before resampling. tline = TLine ( self . tline . unix [ np . append ( gaps , False )] + ( self . tline . dt [ gaps ] / 2 ) ) if self . _data . data . dtype . kind in ( \"i\" , \"u\" , \"b\" , \"M\" ): # Since numpy is r-worded and cant use a nan in an int, we need to convert to float self . _data . replace ( self . data . astype ( \"float\" , copy = False )) self . _dtype = self . _data . dtype nans = np . empty ( np . sum ( gaps ), dtype = self . _dtype ) nans [:] = np . nan res . append ( Sig ( data = nans , tline = tline ), interweave_tlines = True ) if res . data_enum is not None : res . base_data = res . data res . data = res . data_enum . data_to_enum ( res . data ) return res def interp ( self , points : npt . NDArray | TLine , extrapolate : bool = False ) -> Sig : \"\"\"Interpolate signal to points.\"\"\" if isinstance ( points , TLine ): points = points . unix if self . interp_method is None or self . interp_method == InterpMethod . LINEAR : new = ccg . util . linearinterp ( self . tline . unix , self . data , points , extrapolate ) elif self . interp_method == InterpMethod . ZOH : new = self . data [ np . maximum ( np . minimum ( np . searchsorted ( self . tline . unix , points , side = \"right\" ) - 1 , self . nsamples - 1 , ), 0 , ) ] else : # TODO: Implement other interp methods. raise NotImplementedError ( f \" { self . interp_method } not implemented.\" ) res = Sig ( self ) # To create a copy first res . data = new res . tline = TLine ( points ) return res @profile def resample ( self : Sig , sample_to : TLine , n_win : int = None , n_ord : int = None , gap_fraction : float = None , interp_gaps = False , ) -> Sig : \"\"\"Resample with Savitzky Golay filter. Parameters ---------- sample_to TLine to resample to n_win window size, should be odd. Is relative to the sample_to index n_ord order of the fit gap_fraction size of a gap relative to the window size to interpolate between Returns ------- New resampled Sig \"\"\" # Skip if the same and default window/order if ( sample_to != self . tline or n_win is not None or n_ord is not None or gap_fraction is not None ): tic = datetime . now () if n_win is None : n_win = 5 if n_ord is None : n_ord = 3 if gap_fraction is None : gap_fraction = 0.5 if self . data . dtype . kind in { \"U\" , \"S\" }: # This is a string type raise NotImplementedError ( \"Cant resample string type.\" ) if not sample_to . is_monotonic_increasing : sample_to = sample_to . sort () if not self . tline . is_monotonic_increasing : self . sort_tline () nsamplesnew = len ( sample_to ) # dt_new = sample_to.dt dtm_new = np . maximum ( sample_to . period , 0.001 ) dt_orig = self . tline . dt dtm_orig = np . maximum ( self . tline . period , 0.001 ) n_win_orig = int ( np . ceil ( max ( n_win , round ( n_win * dtm_new / dtm_orig ))) // 2 * 2 + 1 ) # Detect gaps larger than gap_fraction windows gaps = np . flatnonzero ( dt_orig > n_win_orig * dtm_orig * gap_fraction ) # interpolate between gaps ind_in_gap = [] for gap in gaps : origx = self . tline . unix [ gap : gap + 2 ] ind_in_gap . extend ( * np . where (( sample_to . unix > origx [ 0 ]) & ( sample_to . unix < origx [ 1 ])) ) if interp_gaps and len ( gaps ) > 0 : newx = np . concatenate ( ( self . tline . unix , sample_to . unix [ ind_in_gap ], ), ) newx . sort () orig = self . interp ( newx ) invalid = [] else : orig = self invalid = ind_in_gap inds , convs = orig . tline . savgol_coef ( sample_to , n_ord , n_win_orig , ) ys0 = np . empty (( nsamplesnew , n_win_orig )) ys0 [:, :] = np . reshape ( orig . data [ inds . ravel ()], ( nsamplesnew , n_win_orig ), ) # Calc diaganol only of dot product result = np . einsum ( \"ij,ji->i\" , ys0 [:, :], convs ) if np . any ( invalid ): result [ invalid ] = np . NaN res = Sig ( self ) # To get all attr of inital # then update to new values res . data = result res . tline = sample_to toc = datetime . now () - tic _LOGGER . debug ( \"Resampled %s from %s to %s samples in %.3f [s]\" , self . name , format ( self . nsamples , \",\" ), format ( res . nsamples , \",\" ), toc . total_seconds (), ) else : res = Sig ( self ) return res def dot ( self , n_dot : int = 1 , n_win : int = 5 , n_ord : int = 3 , ): \"\"\"Calculate Derivative of signal. Returns new sig.\"\"\" tic = datetime . now () inds , convs = self . tline . savgol_coef ( self . tline , n_ord , n_win , n_dot , ) ys0 = np . empty (( self . nsamples , n_win )) ys0 [:, :] = np . reshape ( self . data [ inds . ravel ()], ( self . nsamples , n_win ), ) # Calc diaganol only of dot product result = np . einsum ( \"ij,ji->i\" , ys0 [:, :], convs ) res = Sig ( self ) # To get all attr of inital # then update to new values res . name = f ' { res . name } _ { \"\" . join ([ \"dot\" ] * n_dot ) } ' res . unit = ( f ' { res . unit if res . unit else \"\" } /s { \"\" if n_dot == 1 else \"^\" + n_dot } ' ) res . data = result toc = datetime . now () - tic _LOGGER . debug ( \"Deriv of %s in %.3f [s]\" , self . name , toc . total_seconds (), ) return res def valid ( self , gatecoll : GateColl , frame : Frame = None ): \"\"\"Return new signal with invalid data replaced with nan's\"\"\" # tic = datetime.now() if frame is None and self . parent is None : raise ValueError ( \"`Sig.valid()` requires frame argument if sig has no parent.\" ) if frame is None : frame = self . parent res = Sig ( self ) # copy valid_sig = gatecoll . validate ( frame ) b_valid = valid_sig . interp ( self . tline ) . data nan = np . NaN if res . data . dtype . kind in [ \"i\" , \"u\" ]: res . data = res . data . astype ( \"float\" ) elif res . data . dtype . kind in [ \"U\" , \"S\" ]: nan = \"\" res . data [ ~ b_valid ] = nan # toc = datetime.now() - tic # _LOGGER.debug( # \"get valid sig %s in %.3f\", self.name, toc.total_seconds() # ) return res def __len__ ( self ) -> int : return self . nsamples def __repr__ ( self ) -> str : \"\"\"Return string representation.\"\"\" reprstr = f \" { self . __class__ . __qualname__ } ( { self . data . __repr__ () } )\" return reprstr def __str__ ( self ) -> str : \"\"\"Return readable string.\"\"\" return self . data . __str__ () def __add__ ( self , other ): \"\"\"add, resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , unit = self . unit , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] + %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . resample ( tline ) . data res . data = self . resample ( tline ) . data + other return res def __sub__ ( self , other ): \"\"\"subtract, resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , unit = self . unit , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] - %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . resample ( tline ) . data res . data = self . resample ( tline ) . data - other return res def __radd__ ( self , other ): \"\"\"add, resamples to parent.math_tline if exists. returns Sig.\"\"\" return self . __add__ ( other ) def __rsub__ ( self , other ): \"\"\"subtract, resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , unit = self . unit , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] - %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . resample ( tline ) . data res . data = other - self . resample ( tline ) . data return res def __mul__ ( self , other ): \"\"\"multiply(elementwise), resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): if ( self . unit and other . unit is None ) or other . unit . lower () == \"ratio\" : unit = self . unit elif ( self . unit is None or self . unit . lower () == \"ratio\" ) and other . unit : unit = other . unit elif self . unit and self . unit == other . unit : unit = self . unit + \"**2\" else : unit = f \" { self . unit } * { other . unit } \" other = other . resample ( tline ) . data else : unit = self . unit res . unit = unit res . data = self . resample ( tline ) . data * other return res def __truediv__ ( self , other ): \"\"\"divide(elementwise), resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): if ( self . unit and other . unit is None ) or other . unit . lower () == \"ratio\" : unit = self . unit elif ( self . unit is None or self . unit . lower () == \"ratio\" ) and other . unit : unit = other . unit elif self . unit and self . unit == other . unit : unit = \"ratio\" else : unit = f \" { self . unit } / { other . unit } \" other = other . resample ( tline ) . data else : unit = self . unit res . unit = unit res . data = self . resample ( tline ) . data / other return res def __pow__ ( self , other ): \"\"\"power, resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): other = other . resample ( tline ) . data unit = f \" { self . unit } **n\" elif len ( other ) == 1 : unit = f \" { self . unit } ** { other } \" if self . unit . lower () == \"ratio\" : unit = \"ratio\" res . unit = unit res . data = self . resample ( tline ) . data ** other return res def __abs__ ( self ): \"\"\"abs\"\"\" res = Sig ( self , name = f \"abs( { self . name } )\" , dtype = self . _dtype ) res . data = np . abs ( self . data ) return res def __neg__ ( self ): \"\"\"neg\"\"\" res = Sig ( self , name = f \"neg( { self . name } )\" , dtype = self . _dtype ) res . data = self . data * - 1 return res def __eq__ ( self , other ) -> bool : \"\"\"Check equality.\"\"\" if isinstance ( other , self . __class__ ): iseq = ( np . array_equal ( self . data , other . data ) and np . array_equal ( self . tline , other . tline ) and self . interp_method == other . interp_method and self . connect_gaps == other . connect_gaps and self . unit == other . unit ) if iseq : for key , val in self . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : try : iseq = iseq and val == getattr ( other , key ) except KeyError : iseq = False if iseq : # if its still true, we better check if theres an unk attr in the other for key , val in self . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : try : iseq = iseq and val == getattr ( self , key ) except KeyError : iseq = False return iseq else : return False # @profile def __getitem__ ( self , index : int | list [ int ] | slice | npt . NDArray ): \"\"\"Get item of Sig.\"\"\" if isinstance ( index , slice ) or isinstance ( index , int ): res = self . data [ index ] elif isinstance ( index , np . ndarray ) and index . dtype . kind in ( \"b\" ): # res = copy.deepcopy(self) # res.tline.unix = self.tline.unix[index] # res.data = self.data[index] # # Deepcopy is so slow. Lets try re-building signals instead unks = {} for key , val in self . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : unks . update ({ key : val }) res = Sig ( data = self . data [ index ], tline = TLine ( self . tline . unix [ index ]), name = self . name , unit = self . unit , interp_method = self . interp_method , connect_gaps = self . connect_gaps , data_enum = self . data_enum , ** unks , ) else : raise NotImplementedError ( \"unexpected index for signal\" ) return res def __setitem__ ( self , index : tuple [ slice | list | int | npt . NDArray ] | slice , value : list | npt . NDArray | str , ): \"\"\"Set item\"\"\" self . _data [ index ] = value def __iter__ ( self ): \"\"\"Iterate.\"\"\" return iter ( self . data ) def __next__ ( self ): \"\"\"Next.\"\"\" return next ( self . data ) def __deepcopy__ ( self , memo ): # pylint: disable= method-hidden \"\"\"Deepcopy of a CCGSig. Referenced frame is removed.\"\"\" deepcopy_method = self . __deepcopy__ self . __deepcopy__ = None cpy = copy . deepcopy ( self , memo ) cpy . parent = None # To avoid recursion and confusion self . __deepcopy__ = deepcopy_method # Copy the function object func = types . FunctionType ( deepcopy_method . __code__ , deepcopy_method . __globals__ , deepcopy_method . __name__ , deepcopy_method . __defaults__ , deepcopy_method . __closure__ , ) # Bind to cp and set bound_method = func . __get__ ( cpy , cpy . __class__ ) # pylint: disable=no-member cpy . __deepcopy__ = bound_method return cpy appx_bytes property Estimated size of data [bytes]. Excludes tline. data : npt . NDArray property writable data getter max : npt . NBitBase | None property Max value. min : npt . NBitBase | None property Min value. name : str property writable Return signal name. period property apprx period. tend property End of tline. tend_iso property End of tline. tstart property Start if tline. tstart_iso property Start if tline. __abs__ () abs Source code in ccg\\data\\tsdata.py 1705 1706 1707 1708 1709 def __abs__ ( self ): \"\"\"abs\"\"\" res = Sig ( self , name = f \"abs( { self . name } )\" , dtype = self . _dtype ) res . data = np . abs ( self . data ) return res __add__ ( other ) add, resamples to parent.math_tline if exists. returns Sig. Source code in ccg\\data\\tsdata.py 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 def __add__ ( self , other ): \"\"\"add, resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , unit = self . unit , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] + %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . resample ( tline ) . data res . data = self . resample ( tline ) . data + other return res __deepcopy__ ( memo ) Deepcopy of a CCGSig. Referenced frame is removed. Source code in ccg\\data\\tsdata.py 1792 1793 1794 1795 1796 1797 1798 1799 1800 1801 1802 1803 1804 1805 1806 1807 1808 1809 1810 1811 1812 1813 def __deepcopy__ ( self , memo ): # pylint: disable= method-hidden \"\"\"Deepcopy of a CCGSig. Referenced frame is removed.\"\"\" deepcopy_method = self . __deepcopy__ self . __deepcopy__ = None cpy = copy . deepcopy ( self , memo ) cpy . parent = None # To avoid recursion and confusion self . __deepcopy__ = deepcopy_method # Copy the function object func = types . FunctionType ( deepcopy_method . __code__ , deepcopy_method . __globals__ , deepcopy_method . __name__ , deepcopy_method . __defaults__ , deepcopy_method . __closure__ , ) # Bind to cp and set bound_method = func . __get__ ( cpy , cpy . __class__ ) # pylint: disable=no-member cpy . __deepcopy__ = bound_method return cpy __eq__ ( other ) Check equality. Source code in ccg\\data\\tsdata.py 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741 1742 1743 1744 1745 def __eq__ ( self , other ) -> bool : \"\"\"Check equality.\"\"\" if isinstance ( other , self . __class__ ): iseq = ( np . array_equal ( self . data , other . data ) and np . array_equal ( self . tline , other . tline ) and self . interp_method == other . interp_method and self . connect_gaps == other . connect_gaps and self . unit == other . unit ) if iseq : for key , val in self . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : try : iseq = iseq and val == getattr ( other , key ) except KeyError : iseq = False if iseq : # if its still true, we better check if theres an unk attr in the other for key , val in self . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : try : iseq = iseq and val == getattr ( self , key ) except KeyError : iseq = False return iseq else : return False __getitem__ ( index ) Get item of Sig. Source code in ccg\\data\\tsdata.py 1748 1749 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 1767 1768 1769 1770 1771 1772 1773 1774 def __getitem__ ( self , index : int | list [ int ] | slice | npt . NDArray ): \"\"\"Get item of Sig.\"\"\" if isinstance ( index , slice ) or isinstance ( index , int ): res = self . data [ index ] elif isinstance ( index , np . ndarray ) and index . dtype . kind in ( \"b\" ): # res = copy.deepcopy(self) # res.tline.unix = self.tline.unix[index] # res.data = self.data[index] # # Deepcopy is so slow. Lets try re-building signals instead unks = {} for key , val in self . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : unks . update ({ key : val }) res = Sig ( data = self . data [ index ], tline = TLine ( self . tline . unix [ index ]), name = self . name , unit = self . unit , interp_method = self . interp_method , connect_gaps = self . connect_gaps , data_enum = self . data_enum , ** unks , ) else : raise NotImplementedError ( \"unexpected index for signal\" ) return res __iter__ () Iterate. Source code in ccg\\data\\tsdata.py 1784 1785 1786 def __iter__ ( self ): \"\"\"Iterate.\"\"\" return iter ( self . data ) __mul__ ( other ) multiply(elementwise), resamples to parent.math_tline if exists. returns Sig. Source code in ccg\\data\\tsdata.py 1648 1649 1650 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664 1665 1666 def __mul__ ( self , other ): \"\"\"multiply(elementwise), resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): if ( self . unit and other . unit is None ) or other . unit . lower () == \"ratio\" : unit = self . unit elif ( self . unit is None or self . unit . lower () == \"ratio\" ) and other . unit : unit = other . unit elif self . unit and self . unit == other . unit : unit = self . unit + \"**2\" else : unit = f \" { self . unit } * { other . unit } \" other = other . resample ( tline ) . data else : unit = self . unit res . unit = unit res . data = self . resample ( tline ) . data * other return res __neg__ () neg Source code in ccg\\data\\tsdata.py 1711 1712 1713 1714 1715 def __neg__ ( self ): \"\"\"neg\"\"\" res = Sig ( self , name = f \"neg( { self . name } )\" , dtype = self . _dtype ) res . data = self . data * - 1 return res __next__ () Next. Source code in ccg\\data\\tsdata.py 1788 1789 1790 def __next__ ( self ): \"\"\"Next.\"\"\" return next ( self . data ) __pow__ ( other ) power, resamples to parent.math_tline if exists. returns Sig. Source code in ccg\\data\\tsdata.py 1688 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699 1700 1701 1702 1703 def __pow__ ( self , other ): \"\"\"power, resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): other = other . resample ( tline ) . data unit = f \" { self . unit } **n\" elif len ( other ) == 1 : unit = f \" { self . unit } ** { other } \" if self . unit . lower () == \"ratio\" : unit = \"ratio\" res . unit = unit res . data = self . resample ( tline ) . data ** other return res __radd__ ( other ) add, resamples to parent.math_tline if exists. returns Sig. Source code in ccg\\data\\tsdata.py 1626 1627 1628 def __radd__ ( self , other ): \"\"\"add, resamples to parent.math_tline if exists. returns Sig.\"\"\" return self . __add__ ( other ) __repr__ () Return string representation. Source code in ccg\\data\\tsdata.py 1581 1582 1583 1584 def __repr__ ( self ) -> str : \"\"\"Return string representation.\"\"\" reprstr = f \" { self . __class__ . __qualname__ } ( { self . data . __repr__ () } )\" return reprstr __rsub__ ( other ) subtract, resamples to parent.math_tline if exists. returns Sig. Source code in ccg\\data\\tsdata.py 1630 1631 1632 1633 1634 1635 1636 1637 1638 1639 1640 1641 1642 1643 1644 1645 1646 def __rsub__ ( self , other ): \"\"\"subtract, resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , unit = self . unit , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] - %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . resample ( tline ) . data res . data = other - self . resample ( tline ) . data return res __setitem__ ( index , value ) Set item Source code in ccg\\data\\tsdata.py 1776 1777 1778 1779 1780 1781 1782 def __setitem__ ( self , index : tuple [ slice | list | int | npt . NDArray ] | slice , value : list | npt . NDArray | str , ): \"\"\"Set item\"\"\" self . _data [ index ] = value __str__ () Return readable string. Source code in ccg\\data\\tsdata.py 1586 1587 1588 def __str__ ( self ) -> str : \"\"\"Return readable string.\"\"\" return self . data . __str__ () __sub__ ( other ) subtract, resamples to parent.math_tline if exists. returns Sig. Source code in ccg\\data\\tsdata.py 1608 1609 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622 1623 1624 def __sub__ ( self , other ): \"\"\"subtract, resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , unit = self . unit , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] - %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . resample ( tline ) . data res . data = self . resample ( tline ) . data - other return res __truediv__ ( other ) divide(elementwise), resamples to parent.math_tline if exists. returns Sig. Source code in ccg\\data\\tsdata.py 1668 1669 1670 1671 1672 1673 1674 1675 1676 1677 1678 1679 1680 1681 1682 1683 1684 1685 1686 def __truediv__ ( self , other ): \"\"\"divide(elementwise), resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): if ( self . unit and other . unit is None ) or other . unit . lower () == \"ratio\" : unit = self . unit elif ( self . unit is None or self . unit . lower () == \"ratio\" ) and other . unit : unit = other . unit elif self . unit and self . unit == other . unit : unit = \"ratio\" else : unit = f \" { self . unit } / { other . unit } \" other = other . resample ( tline ) . data else : unit = self . unit res . unit = unit res . data = self . resample ( tline ) . data / other return res append ( sig , interweave_tlines = False , remove_duplicates = False ) Append sig to signal. Source code in ccg\\data\\tsdata.py 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 @profile def append ( self , sig : Sig , interweave_tlines = False , remove_duplicates = False ): \"\"\"Append sig to signal.\"\"\" # Check if timelimes overlap check_overlap ( self , sig , interweave_tlines ) if self . parent is None : self . tline . append_inplace ( sig ) else : nshared = len ( self . parent . tlines . sigs [ self . tline . idn ]) if nshared == 1 : self . tline . append_inplace ( sig ) else : self . tline = self . tline . append_to_new ( sig ) self . _data . append ( sig . _data ) # pylint: disable=access-member-before-definition if not self . tline . is_monotonic_increasing : self . sort_tline ( inplace = True , remove_safe_duplicates = remove_duplicates ) if self . parent is not None : self . parent . tlines . remove ( self . name ) self . parent . tlines . append ( self ) # self.tline = tlref # 2/10/24 now in tlines.append() # get the rest of the attributes if sig . connect_gaps is not None : self . connect_gaps = sig . connect_gaps if sig . data_enum is not None : self . data_enum = sig . data_enum if sig . interp_method is not None : self . interp_method = sig . interp_method if sig . unit is not None : self . unit = sig . unit # Check for unknown attributes. the new signal value will overide the original. for key , val in sig . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : setattr ( self , key , val ) as_unit ( unit ) return new sig converted to unit Source code in ccg\\data\\tsdata.py 1240 1241 1242 1243 1244 def as_unit ( self , unit : str ) -> Sig : \"\"\"return new sig converted to unit\"\"\" sig = Sig ( self ) sig . convert_units ( unit ) return sig calc_idn () Calculate hash for IDN. Source code in ccg\\data\\tsdata.py 1180 1181 1182 1183 1184 1185 1186 1187 1188 def calc_idn ( self ): \"\"\"Calculate hash for IDN.\"\"\" # tic = datetime.now() idn = xxhash . xxh3_64_intdigest ( self . _data . tobytes ()) # toc = datetime.now() - tic # _LOGGER.debug(\"IDN calc'd for %s in %.3f\", self.name, toc.total_seconds()) return idn + self . tline . idn convert_units ( unit ) Convert units in place Source code in ccg\\data\\tsdata.py 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 def convert_units ( self , unit : str ) -> Sig : \"\"\"Convert units in place\"\"\" if unit != self . unit : self . data = ccg . util . convert_units ( value = self . data , from_unit = self . unit , to_unit = unit ) if self . data_range : self . data_range = ccg . util . convert_units ( value = self . data_range , from_unit = self . unit , to_unit = unit ) self . unit = unit return self dot ( n_dot = 1 , n_win = 5 , n_ord = 3 ) Calculate Derivative of signal. Returns new sig. Source code in ccg\\data\\tsdata.py 1512 1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 def dot ( self , n_dot : int = 1 , n_win : int = 5 , n_ord : int = 3 , ): \"\"\"Calculate Derivative of signal. Returns new sig.\"\"\" tic = datetime . now () inds , convs = self . tline . savgol_coef ( self . tline , n_ord , n_win , n_dot , ) ys0 = np . empty (( self . nsamples , n_win )) ys0 [:, :] = np . reshape ( self . data [ inds . ravel ()], ( self . nsamples , n_win ), ) # Calc diaganol only of dot product result = np . einsum ( \"ij,ji->i\" , ys0 [:, :], convs ) res = Sig ( self ) # To get all attr of inital # then update to new values res . name = f ' { res . name } _ { \"\" . join ([ \"dot\" ] * n_dot ) } ' res . unit = ( f ' { res . unit if res . unit else \"\" } /s { \"\" if n_dot == 1 else \"^\" + n_dot } ' ) res . data = result toc = datetime . now () - tic _LOGGER . debug ( \"Deriv of %s in %.3f [s]\" , self . name , toc . total_seconds (), ) return res interp ( points , extrapolate = False ) Interpolate signal to points. Source code in ccg\\data\\tsdata.py 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 def interp ( self , points : npt . NDArray | TLine , extrapolate : bool = False ) -> Sig : \"\"\"Interpolate signal to points.\"\"\" if isinstance ( points , TLine ): points = points . unix if self . interp_method is None or self . interp_method == InterpMethod . LINEAR : new = ccg . util . linearinterp ( self . tline . unix , self . data , points , extrapolate ) elif self . interp_method == InterpMethod . ZOH : new = self . data [ np . maximum ( np . minimum ( np . searchsorted ( self . tline . unix , points , side = \"right\" ) - 1 , self . nsamples - 1 , ), 0 , ) ] else : # TODO: Implement other interp methods. raise NotImplementedError ( f \" { self . interp_method } not implemented.\" ) res = Sig ( self ) # To create a copy first res . data = new res . tline = TLine ( points ) return res plot_prep () Prepare for plotting. Sorts tline and removes duplicates. Inserts NaNs in gaps if connect_gaps=False | None . Applies enum if it exists. Source code in ccg\\data\\tsdata.py 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 @profile def plot_prep ( self ) -> Sig : \"\"\"Prepare for plotting. Sorts tline and removes duplicates. Inserts NaNs in gaps if `connect_gaps=False | None`. Applies enum if it exists. \"\"\" res = self if not self . tline . is_monotonic_increasing : self . sort_tline ( remove_safe_duplicates = True ) if self . connect_gaps is None or not self . connect_gaps : gaps = np . greater ( self . tline . dt , self . _FGAP * self . tline . period , ) if np . sum ( gaps ) > 0 : res = Sig ( self ) # Make a copy before resampling. tline = TLine ( self . tline . unix [ np . append ( gaps , False )] + ( self . tline . dt [ gaps ] / 2 ) ) if self . _data . data . dtype . kind in ( \"i\" , \"u\" , \"b\" , \"M\" ): # Since numpy is r-worded and cant use a nan in an int, we need to convert to float self . _data . replace ( self . data . astype ( \"float\" , copy = False )) self . _dtype = self . _data . dtype nans = np . empty ( np . sum ( gaps ), dtype = self . _dtype ) nans [:] = np . nan res . append ( Sig ( data = nans , tline = tline ), interweave_tlines = True ) if res . data_enum is not None : res . base_data = res . data res . data = res . data_enum . data_to_enum ( res . data ) return res resample ( sample_to , n_win = None , n_ord = None , gap_fraction = None , interp_gaps = False ) Resample with Savitzky Golay filter. Parameters: sample_to ( TLine ) \u2013 TLine to resample to n_win ( int , default: None ) \u2013 window size, should be odd. Is relative to the sample_to index n_ord ( int , default: None ) \u2013 order of the fit gap_fraction ( float , default: None ) \u2013 size of a gap relative to the window size to interpolate between Returns: New resampled Sig \u2013 Source code in ccg\\data\\tsdata.py 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 @profile def resample ( self : Sig , sample_to : TLine , n_win : int = None , n_ord : int = None , gap_fraction : float = None , interp_gaps = False , ) -> Sig : \"\"\"Resample with Savitzky Golay filter. Parameters ---------- sample_to TLine to resample to n_win window size, should be odd. Is relative to the sample_to index n_ord order of the fit gap_fraction size of a gap relative to the window size to interpolate between Returns ------- New resampled Sig \"\"\" # Skip if the same and default window/order if ( sample_to != self . tline or n_win is not None or n_ord is not None or gap_fraction is not None ): tic = datetime . now () if n_win is None : n_win = 5 if n_ord is None : n_ord = 3 if gap_fraction is None : gap_fraction = 0.5 if self . data . dtype . kind in { \"U\" , \"S\" }: # This is a string type raise NotImplementedError ( \"Cant resample string type.\" ) if not sample_to . is_monotonic_increasing : sample_to = sample_to . sort () if not self . tline . is_monotonic_increasing : self . sort_tline () nsamplesnew = len ( sample_to ) # dt_new = sample_to.dt dtm_new = np . maximum ( sample_to . period , 0.001 ) dt_orig = self . tline . dt dtm_orig = np . maximum ( self . tline . period , 0.001 ) n_win_orig = int ( np . ceil ( max ( n_win , round ( n_win * dtm_new / dtm_orig ))) // 2 * 2 + 1 ) # Detect gaps larger than gap_fraction windows gaps = np . flatnonzero ( dt_orig > n_win_orig * dtm_orig * gap_fraction ) # interpolate between gaps ind_in_gap = [] for gap in gaps : origx = self . tline . unix [ gap : gap + 2 ] ind_in_gap . extend ( * np . where (( sample_to . unix > origx [ 0 ]) & ( sample_to . unix < origx [ 1 ])) ) if interp_gaps and len ( gaps ) > 0 : newx = np . concatenate ( ( self . tline . unix , sample_to . unix [ ind_in_gap ], ), ) newx . sort () orig = self . interp ( newx ) invalid = [] else : orig = self invalid = ind_in_gap inds , convs = orig . tline . savgol_coef ( sample_to , n_ord , n_win_orig , ) ys0 = np . empty (( nsamplesnew , n_win_orig )) ys0 [:, :] = np . reshape ( orig . data [ inds . ravel ()], ( nsamplesnew , n_win_orig ), ) # Calc diaganol only of dot product result = np . einsum ( \"ij,ji->i\" , ys0 [:, :], convs ) if np . any ( invalid ): result [ invalid ] = np . NaN res = Sig ( self ) # To get all attr of inital # then update to new values res . data = result res . tline = sample_to toc = datetime . now () - tic _LOGGER . debug ( \"Resampled %s from %s to %s samples in %.3f [s]\" , self . name , format ( self . nsamples , \",\" ), format ( res . nsamples , \",\" ), toc . total_seconds (), ) else : res = Sig ( self ) return res sort_tline ( inplace = True , remove_safe_duplicates = False , remove_all_duplicates = False ) Sort signal by timeline. Parameters: inplace \u2013 Sorts signal in place, returns None. remove_duplicates \u2013 Will remove duplicate timestamps if signal is also duplicated. Returns: Sig \u2013 self if inplace=True . Source code in ccg\\data\\tsdata.py 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 def sort_tline ( self , inplace = True , remove_safe_duplicates = False , remove_all_duplicates = False , ): \"\"\"Sort signal by timeline. Parameters ---------- inplace Sorts signal in place, returns None. remove_duplicates Will remove duplicate timestamps if signal is also duplicated. Returns ------- Sig self if `inplace=True`. \"\"\" inds = np . argsort ( self . tline . unix , kind = \"stable\" ) if inplace : self . tline = TLine ( self . tline . unix [ inds ]) if self . nsamples > 0 : self . data = self . data [ inds ] if remove_safe_duplicates : self . _remove_duplicates ( remove_all_duplicates ) if self . parent is not None : self . parent . tlines . remove ( self . name ) self . parent . tlines . append ( self ) # self.tline = tlref # 2/10/24 now in tlines.append() return self sig = Sig ( self ) # TODO: clean this up to not define, then edit. sig . name = sig . name + \"_sorted\" sig . tline = TLine ( self . tline . unix [ inds ]) if self . nsamples > 0 : sig . data = sig . data [ inds ] if remove_safe_duplicates : sig . _remove_duplicates ( remove_all_duplicates ) # pylint: disable=access-member-before-definition return sig valid ( gatecoll , frame = None ) Return new signal with invalid data replaced with nan's Source code in ccg\\data\\tsdata.py 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 1573 1574 1575 1576 def valid ( self , gatecoll : GateColl , frame : Frame = None ): \"\"\"Return new signal with invalid data replaced with nan's\"\"\" # tic = datetime.now() if frame is None and self . parent is None : raise ValueError ( \"`Sig.valid()` requires frame argument if sig has no parent.\" ) if frame is None : frame = self . parent res = Sig ( self ) # copy valid_sig = gatecoll . validate ( frame ) b_valid = valid_sig . interp ( self . tline ) . data nan = np . NaN if res . data . dtype . kind in [ \"i\" , \"u\" ]: res . data = res . data . astype ( \"float\" ) elif res . data . dtype . kind in [ \"U\" , \"S\" ]: nan = \"\" res . data [ ~ b_valid ] = nan # toc = datetime.now() - tic # _LOGGER.debug( # \"get valid sig %s in %.3f\", self.name, toc.total_seconds() # ) return res SigEnum Enumeration definition for CCGSig. Parameters: definition ( dict ) \u2013 Dictionary of conversion values. \"\" is a special key, default for unmatched values if missing, np.nan will be used. Example enumdef = {'v1':1,'v2':2,'':0,} data = np.array(['v1','v2','v3']) testenum = SigEnum(definition=enumdef) testenum.data_to_enum(data) Source code in ccg\\data\\tsdata.py 2554 2555 2556 2557 2558 2559 2560 2561 2562 2563 2564 2565 2566 2567 2568 2569 2570 2571 2572 2573 2574 2575 2576 2577 2578 2579 2580 2581 2582 2583 2584 2585 2586 2587 2588 2589 2590 2591 2592 2593 2594 2595 2596 2597 2598 class SigEnum : \"\"\"Enumeration definition for CCGSig. Parameters ---------- definition Dictionary of conversion values. \"\" is a special key, default for unmatched values if missing, np.nan will be used. Example ------- >>> enumdef = {'v1':1,'v2':2,'':0,} >>> data = np.array(['v1','v2','v3']) >>> testenum = SigEnum(definition=enumdef) >>> testenum.data_to_enum(data) >>> \"\"\" def __init__ ( self , definition : dict ): self . definition = definition def data_to_enum ( self , data : npt . NDArray ): \"\"\"Convert base data to enumerated type.\"\"\" rtn = np . empty ( data . shape ) unmatched = np . empty ( data . shape , dtype = np . bool_ ) unmatched [:] = True for key , val in self . definition . items (): if not key == \"\" : inds = data == key unmatched [ inds ] = False rtn [ inds ] = val if np . any ( unmatched ): try : rtn [ unmatched ] = self . definition [ \"\" ] except KeyError : rtn [ unmatched ] = np . nan return rtn def enum_to_data ( self , enum : npt . NDArray ): \"\"\"Convert enumerated data back to base data.\"\"\" rtn = np . empty ( enum . shape ) for key , val in self . definition . items (): inds = enum == val rtn [ inds ] = key return rtn data_to_enum ( data ) Convert base data to enumerated type. Source code in ccg\\data\\tsdata.py 2574 2575 2576 2577 2578 2579 2580 2581 2582 2583 2584 2585 2586 2587 2588 2589 2590 def data_to_enum ( self , data : npt . NDArray ): \"\"\"Convert base data to enumerated type.\"\"\" rtn = np . empty ( data . shape ) unmatched = np . empty ( data . shape , dtype = np . bool_ ) unmatched [:] = True for key , val in self . definition . items (): if not key == \"\" : inds = data == key unmatched [ inds ] = False rtn [ inds ] = val if np . any ( unmatched ): try : rtn [ unmatched ] = self . definition [ \"\" ] except KeyError : rtn [ unmatched ] = np . nan return rtn enum_to_data ( enum ) Convert enumerated data back to base data. Source code in ccg\\data\\tsdata.py 2592 2593 2594 2595 2596 2597 2598 def enum_to_data ( self , enum : npt . NDArray ): \"\"\"Convert enumerated data back to base data.\"\"\" rtn = np . empty ( enum . shape ) for key , val in self . definition . items (): inds = enum == val rtn [ inds ] = key return rtn TLine CCG Time Line. Source code in ccg\\data\\tsdata.py 1816 1817 1818 1819 1820 1821 1822 1823 1824 1825 1826 1827 1828 1829 1830 1831 1832 1833 1834 1835 1836 1837 1838 1839 1840 1841 1842 1843 1844 1845 1846 1847 1848 1849 1850 1851 1852 1853 1854 1855 1856 1857 1858 1859 1860 1861 1862 1863 1864 1865 1866 1867 1868 1869 1870 1871 1872 1873 1874 1875 1876 1877 1878 1879 1880 1881 1882 1883 1884 1885 1886 1887 1888 1889 1890 1891 1892 1893 1894 1895 1896 1897 1898 1899 1900 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 2025 2026 2027 2028 2029 2030 2031 2032 2033 2034 2035 2036 2037 2038 2039 2040 2041 2042 2043 2044 2045 2046 2047 2048 2049 2050 2051 2052 2053 2054 2055 2056 2057 2058 2059 2060 2061 2062 2063 2064 2065 2066 2067 2068 2069 2070 2071 2072 2073 2074 2075 2076 2077 2078 2079 2080 2081 2082 2083 2084 2085 2086 2087 2088 2089 2090 2091 2092 2093 2094 2095 2096 2097 2098 2099 2100 2101 2102 2103 2104 2105 2106 2107 2108 2109 2110 2111 2112 2113 2114 2115 2116 2117 2118 2119 2120 2121 2122 2123 2124 2125 2126 2127 2128 2129 2130 2131 2132 2133 2134 2135 2136 2137 2138 2139 2140 2141 2142 2143 2144 2145 2146 2147 2148 2149 2150 2151 2152 2153 2154 2155 2156 2157 2158 2159 2160 2161 2162 2163 2164 2165 2166 2167 2168 2169 2170 2171 2172 2173 2174 2175 2176 2177 2178 2179 2180 2181 2182 2183 2184 2185 2186 2187 2188 2189 2190 2191 2192 2193 2194 2195 2196 2197 2198 2199 2200 2201 2202 2203 2204 2205 2206 2207 2208 2209 2210 2211 2212 2213 2214 2215 2216 2217 2218 2219 2220 2221 2222 2223 2224 2225 2226 2227 2228 2229 2230 2231 2232 2233 2234 2235 2236 2237 2238 2239 2240 2241 2242 2243 2244 2245 class TLine : \"\"\"CCG Time Line.\"\"\" __slots__ = ( \"_iso\" , \"_sg\" , \"_datetime\" , \"_unix\" , \"_idn\" , \"_dt\" , \"_period\" , \"_is_monoton\" , \"parent\" , \"_shape\" , \"_unix\" , \"_period\" , ) @profile def __init__ ( self , data : ( TLine | npt . NDArray [ np . object_ ] | npt . NDArray [ np . number ] | npt . NDArray [ np . datetime64 ] | datetime | list ) = None , tstart : float | datetime = None , tend : float | datetime = None , nsamples : int | tuple [ int ] = None , period : float = None , sg_coef : SgCoef = None , parent : TLineCollection = None , ): if sg_coef is None : self . _sg = SgCoef () self . _iso : npt . NDArray [ np . datetime64 ] = None self . _datetime : npt . NDArray [ np . object_ ] = None self . _unix : AllocData = None self . _idn = None self . _dt = None self . _period : float | None = None self . _is_monoton : bool = None self . parent = parent # TODO: Clean up cases here. better fault detection. if nsamples is None : self . _shape = None elif isinstance ( nsamples , tuple ): self . _shape = nsamples elif isinstance ( nsamples , int ): self . _shape = ( nsamples ,) else : raise NotImplementedError ( f \"tline with nsamples of type { type ( nsamples ) } is not implemented.\" ) if data is not None : # if isinstance(data, (pd.DataFrame, pd.Series)): # if data.index is None: # raise ValueError(\"Data frame has no index.\") # if data.index.asi8 is None: # index = data.index.to_numpy() # else: # index = data.index.asi8 / 1e9 # self.unix = index # elif isinstance(data, pd.Index): # self.unix = data.asi8 / 1e9 if isinstance ( data , np . ndarray ) and data . dtype . kind == \"M\" : self . unix = ccg . util . datetime_to_unix ( data ) elif isinstance ( data , np . ndarray ) and isinstance ( data [ 0 ], datetime ): self . unix = np . array ([ t . timestamp () for t in data ]) elif isinstance ( data , np . ndarray ): self . unix = data . astype ( \"float\" ) elif isinstance ( data , datetime ): self . unix = np . array ([ data . timestamp ()]) elif isinstance ( data , TLine ): self . _shape = data . _shape self . unix = data . _unix self . _sg = data . _sg self . _idn = data . idn elif isinstance ( data , AllocData ): self . _shape = data . _shape self . unix = data elif isinstance ( data , list ): self . unix = np . array ( data ) else : raise NotImplementedError ( f \" { type ( data ) } is not supported.\" ) elif None not in { tstart , tend , nsamples } or None not in { tstart , tend , period }: if isinstance ( tstart , datetime ): tstart = tstart . timestamp () if isinstance ( tend , datetime ): tend = tend . timestamp () if nsamples is not None : self . unix = np . linspace ( start = tstart , stop = tend , num = nsamples ) elif period is not None : self . unix = np . arange ( start = tstart , stop = tend , step = period ) self . _period = period else : raise ValueError ( \"Missing nsamples or period.\" ) elif None not in { tstart , nsamples , period } or None not in { tend , nsamples , period , }: if isinstance ( tstart , datetime ): tstart = tstart . timestamp () if isinstance ( tend , datetime ): tend = tend . timestamp () if tend is None : tend = tstart + nsamples * period if tstart is None : tstart = tend - nsamples * period self . unix = np . linspace ( start = tstart , stop = tend , num = nsamples ) self . _period = period elif nsamples : # To pre-allocate self . unix = None else : raise ValueError @property def unix ( self ) -> npt . NDArray [ np . float_ ]: \"\"\"tline in unix\"\"\" return self . _unix [:] @unix . setter @profile def unix ( self , value : npt . NDArray [ np . float_ ] | AllocData ): if self . _unix is None : self . _unix = AllocData ( value , shape = self . _shape , dtype = np . dtype ( \"float64\" )) else : self . _unix . replace ( value ) # Need to clear lots of stuff if changing the timeline self . clear_cache () # @profile def calc_idn ( self ): \"\"\"Calculate hash for IDN.\"\"\" self . _idn = xxhash . xxh3_64_intdigest ( self . _unix . tobytes ()) return self . _idn @property # @profile def idn ( self ): \"\"\"return id number.\"\"\" if self . _idn is None : return self . calc_idn () return self . _idn @property def tstart ( self ) -> float : \"\"\"Start time.\"\"\" # TODO Check for monoton increasing first. return self . _unix [ 0 ] @property def tend ( self ) -> float : \"\"\"End time.\"\"\" return self . _unix [ - 1 ] @property def tstart_iso ( self ) -> np . datetime64 : \"\"\"Start time.\"\"\" # TODO Check for monoton increasing first. return self . iso [ 0 ] @property def tend_iso ( self ) -> np . datetime64 : \"\"\"End time.\"\"\" return self . iso [ - 1 ] @property def iso ( self ) -> npt . NDArray [ np . datetime64 ]: \"\"\"Array of iso formatted strings. Naive, but in local tz.\"\"\" if self . _iso is None : self . _iso = ccg . util . unix_to_iso ( self . unix ) return self . _iso @property def datetime ( self ) -> npt . NDArray [ np . object_ ]: \"\"\"Array of datetime.datetime.\"\"\" tic = datetime . now () if self . _datetime is None : if self . unix [ 0 ] > 32000000 : tmp = np . array ( [ datetime . fromtimestamp ( t ) . astimezone () for t in self . unix ] ) # SO SLOW else : tmp = np . array ([ datetime . fromtimestamp ( t ) for t in self . unix ]) self . _datetime = tmp toc = datetime . now () - tic if toc > timedelta ( seconds = 0.1 ): _LOGGER . debug ( \"datetime prop calc for %s took %.3f s\" , self . _idn , toc . total_seconds () ) return self . _datetime @property def appx_bytes ( self ): \"\"\"Estimated size of data [bytes]. Excludes tline.\"\"\" return self . _unix . appx_bytes @overload def __getitem__ ( self , ind : int | npt . NDArray [ np . int_ | np . bool_ ]) -> npt . NDArray : pass @overload def __getitem__ ( self , ind : slice ) -> TLine : pass def __getitem__ ( self , ind : int | npt . NDArray [ np . int_ | np . bool_ ] | slice ): \"\"\"Index tline.\"\"\" if isinstance ( ind , slice ): # A slice should return a new CCGTline. Vals should be unix or datetime. if isinstance ( ind . start , datetime ): ind_start = ind . start . timestamp () else : ind_start = ind . start if isinstance ( ind . stop , datetime ): ind_stop = ind . stop . timestamp () else : ind_stop = ind . stop if isinstance ( ind . step , timedelta ): step = ind . step . total_seconds () else : step = ind . step if ind . step is None : if ind . start is None : start = self . tstart else : start = ind_start if ind . stop is None : # Since python is r-worded, this is a special case. # Need to make sure the last sample is included. stop = self . tend + 0.000001 else : stop = ind_stop inds = np . logical_and ( self . unix >= start , self . unix < stop ) return TLine ( self . unix [ inds ]) else : # Step was defined so define a fresh tline i guess? _LOGGER . warning ( \"tline sliced with step defined. This is equiv to `CCGTline(tstart=slice.start,tenc=slice.stop,period=slice.step)`\" ) return TLine ( tstart = ind_start , tend = ind_stop , period = step ) return self . unix [ ind ] def __len__ ( self ) -> int : \"\"\"Length of timeline.\"\"\" return self . _unix . nsamples def __repr__ ( self ) -> str : \"\"\"Return string representation.\"\"\" # reprstr = f\"{self.__class__.__module__}.{self.__class__.__qualname__}({self.iso.__repr__()})\" reprstr = f \" { self . __class__ . __qualname__ } ( { self . iso . __repr__ () } )\" return reprstr def __str__ ( self ) -> str : \"\"\"Return readable string.\"\"\" return self . iso . __str__ () def __eq__ ( self , other ) -> bool : \"\"\"Check equality.\"\"\" if isinstance ( other , self . __class__ ): return np . array_equal ( self . unix , other . unix ) else : return False @property # profile def dt ( self ): \"\"\"delta t\"\"\" if self . _dt is None : if len ( self ) > 1 : self . _dt = np . diff ( self . unix ) else : self . _dt = np . array ([ 0 ]) return self . _dt @property def period ( self ) -> float : \"\"\"apprx period.\"\"\" if self . _period : return self . _period if self . nsamples > 1 : self . _period = stats . mode ( self . dt , keepdims = True ) . mode [ 0 ] else : self . _period = np . Inf return self . _period @property def nsamples ( self ): \"\"\"nsamples\"\"\" return len ( self ) @property # profile def is_monotonic_increasing ( self ): \"\"\"Return true if monotonic increasing.\"\"\" if self . _is_monoton is None : if len ( self ) == 1 : self . _is_monoton = True else : tmp = self . unix self . _is_monoton = np . all ( tmp [ 1 :] > tmp [: - 1 ]) return self . _is_monoton @profile def append_to_new ( self , sig : Sig ): \"\"\"Append timeline from sig to tline. Returns new timeline.\"\"\" nsamples = self . nsamples + sig . nsamples new_tline = TLine ( self , nsamples = nsamples ) new_tline . parent = None new_tline . append_inplace ( sig ) # new_tline = TLine(np.concatenate((self.unix, sig.tline.unix))) return new_tline @profile def append_inplace ( self , sig : Sig ): \"\"\"Append to tline in place. Dangerous if shared in a Frame.\"\"\" self . _unix . append ( sig . tline . _unix ) self . clear_cache () return self def index_at_time ( self , time : float | datetime ) -> int : \"\"\"Get the index of the first tstamp >= time.\"\"\" raise NotImplementedError def sort ( self ): \"\"\"Sort tline.\"\"\" raise NotImplementedError ( \"tline sort is not implemented.\" ) # Dont forget to re-calc idn def clear_cache ( self ): \"\"\"Clear the cached values.\"\"\" self . _sg . clear () old_idn = self . _idn self . _iso = None self . _datetime = None self . _idn = None self . _dt = None self . _period = None self . _is_monoton = None if self . parent is not None and old_idn != self . idn : self . parent . replace ( old_idn , self ) # @profile def savgol_coef ( self : TLine , sample_to_index : TLine , n_ord : int , n_win_orig : int , n_dot : int = 0 , ): \"\"\"Calculate Savitzky Golay coeficients.\"\"\" # Check if coef's are stored nsamplesnew = len ( sample_to_index ) if ( self . idn == self . _sg . orig_index and sample_to_index . idn == self . _sg . sample_to_index and n_ord == self . _sg . n_ord and n_win_orig == self . _sg . n_win_orig ): conv = self . _sg . conv uniqinvs = self . _sg . uniqinvs n_uniq = self . _sg . n_uniq inds = self . _sg . inds else : # Missing or different, so have to calc coef's nsamples = len ( self ) # Find orig samples near new samples ind0 = np . digitize ( sample_to_index . unix , self . unix ) ind0 = np . maximum ( np . minimum ( ind0 , nsamples - 1 , out = ind0 ), 0 , out = ind0 ) # saturate inds = ind0 [:, np . newaxis ] # make n x 1 offs = np . arange ( n_win_orig ) - int (( n_win_orig - 1 ) / 2 ) inds = inds + offs # Saturate the ends inds = np . maximum ( np . minimum ( inds , nsamples - 1 , out = inds ), 0 , out = inds ) indsz : npt . NDArray = self . unix [ inds . ravel ()] # to seconds indsz = indsz . reshape ( inds . shape ) torig = self . unix [ ind0 ] indsz = indsz - torig [:, np . newaxis ] # Find unique window spacings, round to appropriate resolution indsz = np . around ( indsz , 3 , out = indsz ) uniqz , uniqinvs = np . unique ( indsz , return_inverse = True , axis = 0 ) n_uniq = len ( uniqz ) pwrs = np . arange ( n_ord + 1 ) conv = np . empty (( n_uniq , n_win_orig , n_ord + 1 )) for i , uniq in enumerate ( uniqz ): j : npt . NDArray = uniq [:, np . newaxis ] ** pwrs try : tmp = np . linalg . inv ( j . T @ j ) @ j . T except np . linalg . LinAlgError : tmp = np . linalg . pinv ( j . T @ j ) @ j . T conv [ i , :, :] = tmp . T # Store inputs for validating accuracy of stored coef's # Compress or abbrev?? self . _sg . orig_index = self . idn self . _sg . sample_to_index = sample_to_index . idn self . _sg . n_win_orig = n_win_orig self . _sg . n_ord = n_ord # Store coef's self . _sg . conv = conv self . _sg . uniqinvs = uniqinvs self . _sg . n_uniq = n_uniq self . _sg . inds = inds # Calc coef's for this derivative convs = np . empty (( n_win_orig , nsamplesnew )) for i in range ( n_uniq ): convs [:, uniqinvs == i ] = conv [ i , :, n_dot ][:, np . newaxis ] return inds , convs appx_bytes property Estimated size of data [bytes]. Excludes tline. datetime : npt . NDArray [ np . object_ ] property Array of datetime.datetime. dt property delta t idn property return id number. is_monotonic_increasing property Return true if monotonic increasing. iso : npt . NDArray [ np . datetime64 ] property Array of iso formatted strings. Naive, but in local tz. nsamples property nsamples period : float property apprx period. tend : float property End time. tend_iso : np . datetime64 property End time. tstart : float property Start time. tstart_iso : np . datetime64 property Start time. unix : npt . NDArray [ np . float_ ] property writable tline in unix __eq__ ( other ) Check equality. Source code in ccg\\data\\tsdata.py 2083 2084 2085 2086 2087 2088 def __eq__ ( self , other ) -> bool : \"\"\"Check equality.\"\"\" if isinstance ( other , self . __class__ ): return np . array_equal ( self . unix , other . unix ) else : return False __getitem__ ( ind ) Index tline. Source code in ccg\\data\\tsdata.py 2031 2032 2033 2034 2035 2036 2037 2038 2039 2040 2041 2042 2043 2044 2045 2046 2047 2048 2049 2050 2051 2052 2053 2054 2055 2056 2057 2058 2059 2060 2061 2062 2063 2064 2065 2066 2067 def __getitem__ ( self , ind : int | npt . NDArray [ np . int_ | np . bool_ ] | slice ): \"\"\"Index tline.\"\"\" if isinstance ( ind , slice ): # A slice should return a new CCGTline. Vals should be unix or datetime. if isinstance ( ind . start , datetime ): ind_start = ind . start . timestamp () else : ind_start = ind . start if isinstance ( ind . stop , datetime ): ind_stop = ind . stop . timestamp () else : ind_stop = ind . stop if isinstance ( ind . step , timedelta ): step = ind . step . total_seconds () else : step = ind . step if ind . step is None : if ind . start is None : start = self . tstart else : start = ind_start if ind . stop is None : # Since python is r-worded, this is a special case. # Need to make sure the last sample is included. stop = self . tend + 0.000001 else : stop = ind_stop inds = np . logical_and ( self . unix >= start , self . unix < stop ) return TLine ( self . unix [ inds ]) else : # Step was defined so define a fresh tline i guess? _LOGGER . warning ( \"tline sliced with step defined. This is equiv to `CCGTline(tstart=slice.start,tenc=slice.stop,period=slice.step)`\" ) return TLine ( tstart = ind_start , tend = ind_stop , period = step ) return self . unix [ ind ] __len__ () Length of timeline. Source code in ccg\\data\\tsdata.py 2069 2070 2071 def __len__ ( self ) -> int : \"\"\"Length of timeline.\"\"\" return self . _unix . nsamples __repr__ () Return string representation. Source code in ccg\\data\\tsdata.py 2073 2074 2075 2076 2077 def __repr__ ( self ) -> str : \"\"\"Return string representation.\"\"\" # reprstr = f\"{self.__class__.__module__}.{self.__class__.__qualname__}({self.iso.__repr__()})\" reprstr = f \" { self . __class__ . __qualname__ } ( { self . iso . __repr__ () } )\" return reprstr __str__ () Return readable string. Source code in ccg\\data\\tsdata.py 2079 2080 2081 def __str__ ( self ) -> str : \"\"\"Return readable string.\"\"\" return self . iso . __str__ () append_inplace ( sig ) Append to tline in place. Dangerous if shared in a Frame. Source code in ccg\\data\\tsdata.py 2140 2141 2142 2143 2144 2145 @profile def append_inplace ( self , sig : Sig ): \"\"\"Append to tline in place. Dangerous if shared in a Frame.\"\"\" self . _unix . append ( sig . tline . _unix ) self . clear_cache () return self append_to_new ( sig ) Append timeline from sig to tline. Returns new timeline. Source code in ccg\\data\\tsdata.py 2130 2131 2132 2133 2134 2135 2136 2137 2138 @profile def append_to_new ( self , sig : Sig ): \"\"\"Append timeline from sig to tline. Returns new timeline.\"\"\" nsamples = self . nsamples + sig . nsamples new_tline = TLine ( self , nsamples = nsamples ) new_tline . parent = None new_tline . append_inplace ( sig ) # new_tline = TLine(np.concatenate((self.unix, sig.tline.unix))) return new_tline calc_idn () Calculate hash for IDN. Source code in ccg\\data\\tsdata.py 1956 1957 1958 1959 def calc_idn ( self ): \"\"\"Calculate hash for IDN.\"\"\" self . _idn = xxhash . xxh3_64_intdigest ( self . _unix . tobytes ()) return self . _idn clear_cache () Clear the cached values. Source code in ccg\\data\\tsdata.py 2156 2157 2158 2159 2160 2161 2162 2163 2164 2165 2166 2167 2168 2169 2170 def clear_cache ( self ): \"\"\"Clear the cached values.\"\"\" self . _sg . clear () old_idn = self . _idn self . _iso = None self . _datetime = None self . _idn = None self . _dt = None self . _period = None self . _is_monoton = None if self . parent is not None and old_idn != self . idn : self . parent . replace ( old_idn , self ) index_at_time ( time ) Get the index of the first tstamp >= time. Source code in ccg\\data\\tsdata.py 2147 2148 2149 def index_at_time ( self , time : float | datetime ) -> int : \"\"\"Get the index of the first tstamp >= time.\"\"\" raise NotImplementedError savgol_coef ( sample_to_index , n_ord , n_win_orig , n_dot = 0 ) Calculate Savitzky Golay coeficients. Source code in ccg\\data\\tsdata.py 2173 2174 2175 2176 2177 2178 2179 2180 2181 2182 2183 2184 2185 2186 2187 2188 2189 2190 2191 2192 2193 2194 2195 2196 2197 2198 2199 2200 2201 2202 2203 2204 2205 2206 2207 2208 2209 2210 2211 2212 2213 2214 2215 2216 2217 2218 2219 2220 2221 2222 2223 2224 2225 2226 2227 2228 2229 2230 2231 2232 2233 2234 2235 2236 2237 2238 2239 2240 2241 2242 2243 2244 2245 def savgol_coef ( self : TLine , sample_to_index : TLine , n_ord : int , n_win_orig : int , n_dot : int = 0 , ): \"\"\"Calculate Savitzky Golay coeficients.\"\"\" # Check if coef's are stored nsamplesnew = len ( sample_to_index ) if ( self . idn == self . _sg . orig_index and sample_to_index . idn == self . _sg . sample_to_index and n_ord == self . _sg . n_ord and n_win_orig == self . _sg . n_win_orig ): conv = self . _sg . conv uniqinvs = self . _sg . uniqinvs n_uniq = self . _sg . n_uniq inds = self . _sg . inds else : # Missing or different, so have to calc coef's nsamples = len ( self ) # Find orig samples near new samples ind0 = np . digitize ( sample_to_index . unix , self . unix ) ind0 = np . maximum ( np . minimum ( ind0 , nsamples - 1 , out = ind0 ), 0 , out = ind0 ) # saturate inds = ind0 [:, np . newaxis ] # make n x 1 offs = np . arange ( n_win_orig ) - int (( n_win_orig - 1 ) / 2 ) inds = inds + offs # Saturate the ends inds = np . maximum ( np . minimum ( inds , nsamples - 1 , out = inds ), 0 , out = inds ) indsz : npt . NDArray = self . unix [ inds . ravel ()] # to seconds indsz = indsz . reshape ( inds . shape ) torig = self . unix [ ind0 ] indsz = indsz - torig [:, np . newaxis ] # Find unique window spacings, round to appropriate resolution indsz = np . around ( indsz , 3 , out = indsz ) uniqz , uniqinvs = np . unique ( indsz , return_inverse = True , axis = 0 ) n_uniq = len ( uniqz ) pwrs = np . arange ( n_ord + 1 ) conv = np . empty (( n_uniq , n_win_orig , n_ord + 1 )) for i , uniq in enumerate ( uniqz ): j : npt . NDArray = uniq [:, np . newaxis ] ** pwrs try : tmp = np . linalg . inv ( j . T @ j ) @ j . T except np . linalg . LinAlgError : tmp = np . linalg . pinv ( j . T @ j ) @ j . T conv [ i , :, :] = tmp . T # Store inputs for validating accuracy of stored coef's # Compress or abbrev?? self . _sg . orig_index = self . idn self . _sg . sample_to_index = sample_to_index . idn self . _sg . n_win_orig = n_win_orig self . _sg . n_ord = n_ord # Store coef's self . _sg . conv = conv self . _sg . uniqinvs = uniqinvs self . _sg . n_uniq = n_uniq self . _sg . inds = inds # Calc coef's for this derivative convs = np . empty (( n_win_orig , nsamplesnew )) for i in range ( n_uniq ): convs [:, uniqinvs == i ] = conv [ i , :, n_dot ][:, np . newaxis ] return inds , convs sort () Sort tline. Source code in ccg\\data\\tsdata.py 2151 2152 2153 def sort ( self ): \"\"\"Sort tline.\"\"\" raise NotImplementedError ( \"tline sort is not implemented.\" ) TLineCollection Collection of timelines for Frame. Parameters: frame ( Frame ) \u2013 optional Frame to get timelines from. tlines ( TLine | list [ TLine ] , default: None ) \u2013 optional CCGTline or list of CCGTline. If used, signames is required. signames ( str | list [ str ] , default: None ) \u2013 required with tlines. If tlines is a list, must be equal length. If single tlines, can be a list. Source code in ccg\\data\\tsdata.py 2248 2249 2250 2251 2252 2253 2254 2255 2256 2257 2258 2259 2260 2261 2262 2263 2264 2265 2266 2267 2268 2269 2270 2271 2272 2273 2274 2275 2276 2277 2278 2279 2280 2281 2282 2283 2284 2285 2286 2287 2288 2289 2290 2291 2292 2293 2294 2295 2296 2297 2298 2299 2300 2301 2302 2303 2304 2305 2306 2307 2308 2309 2310 2311 2312 2313 2314 2315 2316 2317 2318 2319 2320 2321 2322 2323 2324 2325 2326 2327 2328 2329 2330 2331 2332 2333 2334 2335 2336 2337 2338 2339 2340 2341 2342 2343 2344 2345 2346 2347 2348 2349 2350 2351 2352 2353 2354 2355 2356 2357 2358 2359 2360 2361 2362 2363 2364 2365 2366 2367 2368 2369 2370 2371 2372 2373 2374 2375 2376 2377 2378 2379 2380 2381 2382 2383 2384 2385 2386 2387 2388 2389 2390 2391 2392 2393 2394 2395 2396 2397 2398 2399 2400 2401 2402 2403 2404 2405 2406 2407 2408 2409 2410 2411 2412 2413 2414 2415 2416 2417 2418 2419 2420 2421 2422 2423 2424 2425 2426 2427 2428 2429 2430 2431 2432 2433 2434 2435 2436 2437 2438 2439 2440 2441 2442 2443 2444 2445 2446 2447 2448 2449 2450 2451 2452 2453 2454 2455 2456 2457 2458 2459 2460 2461 2462 2463 2464 2465 2466 2467 2468 2469 2470 2471 2472 2473 2474 2475 2476 2477 2478 2479 2480 2481 2482 2483 2484 2485 2486 2487 2488 2489 2490 2491 2492 2493 2494 2495 2496 2497 2498 2499 2500 2501 2502 2503 2504 2505 2506 2507 2508 2509 2510 2511 2512 2513 2514 2515 2516 2517 2518 2519 2520 2521 2522 2523 2524 2525 2526 2527 2528 2529 2530 2531 2532 2533 2534 2535 2536 2537 2538 2539 2540 2541 2542 2543 2544 2545 2546 2547 2548 2549 2550 2551 class TLineCollection : \"\"\" Collection of timelines for Frame. Parameters ---------- frame optional Frame to get timelines from. tlines optional CCGTline or list of CCGTline. If used, signames is required. signames required with tlines. If tlines is a list, must be equal length. If single tlines, can be a list. \"\"\" def __init__ ( self , frame : Frame , tlines : TLine | list [ TLine ] = None , signames : str | list [ str ] = None , ) -> None : self . tlines : dict [ int , TLine ] = {} self . idns : dict [ str , int ] = {} self . sigs : dict [ int , list [ str ]] = {} if frame or tlines : self . append ( frameorsig = frame , tlines = tlines , signames = signames ) self . frame = frame @profile def append ( self , frameorsig : Sig | Frame = None , tlines : TLine | list [ TLine ] = None , signames : list [ str ] | list [ list [ str ]] = None , ) -> TLine : \"\"\" Append tline to collection. Parameters ---------- frame optional Frame to get timelines from. tlines optional CCGTline or list of CCGTline. If used, signames is required. signames required with tlines. Must be equal length list of lists of signames. Returns ------- CCGTimeline \"\"\" if frameorsig is not None : # if isinstance(frameorsig, pd.DataFrame): # tline = TLine(frameorsig) # tline.parent = self # if tline.idn in self.tlines: # self.check_sg(tline) # else: # self.tlines[tline.idn] = tline # tlref = self.tlines[tline.idn] # for col in frameorsig: # self.idns[col] = tline.idn # self.add_to_sigs(tline.idn, col) if isinstance ( frameorsig , Frame ): tlref = [] if frameorsig . nsigs > 0 : for tline in frameorsig . tlines : tline . parent = self # TODO: Check for reference issue in this case if tline . idn in self . tlines : self . check_sg ( tline ) else : self . tlines [ tline . idn ] = tline sigs = frameorsig . tlines . sigs [ tline . idn ] # Check if signame already exists with different tline idns_old = self . idns [ sigs ] if idns_old and np . any ( idns_old != tline . idn ): _LOGGER . error ( \"Existing signal( %s ) with different timeline has been replaced\" , sigs [ idns_old != tline . idn ], ) self . idns [ sigs ] = tline . idn self . add_to_sigs ( tline . idn , sigs ) tlref . append ( self . tlines [ tline . idn ]) elif isinstance ( frameorsig , Sig ): tline = frameorsig . tline tline . parent = self if tline . idn in self : self . check_sg ( tline ) else : self . tlines [ tline . idn ] = tline tlref = self . tlines [ tline . idn ] sigs = frameorsig . name # Check if signame already exists with different tline try : idns_old = self . idns [ sigs ] except KeyError : idns_old = None if any ([ idns_old == tline . idn ]): _LOGGER . error ( \"Existing signal( %s ) with different timeline\" , sigs [ idns_old != tline . idn ], ) self . idns [ sigs ] = tline . idn self . add_to_sigs ( tline . idn , sigs ) # Change 2/10/24 - fix reference to tline in sig here frameorsig . tline = tlref else : raise NotImplementedError ( f \"Appending tline from { type ( frameorsig ) } is not implemented\" ) if tlines is not None : if not isinstance ( tlines , list ): tlines = [ tlines ] if len ( signames ) != len ( tlines ): raise ValueError ( \"If tlines is specified and contains more than 1, signames must be same length.\" ) if signames is None : raise ValueError ( \"signames must be specified with tlines.\" ) tlref = [] for sigs , tline in zip ( signames , tlines ): tline . parent = self if tline . idn in self . tlines : self . check_sg ( tline ) else : self . tlines [ tline . idn ] = tline if not isinstance ( sigs , list ): sigs = [ sigs ] self . add_to_sigs ( tline . idn , sigs ) for sig in sigs : self . idns [ sig ] = tline . idn tlref . append ( tline ) return tlref def check_sg ( self , tline : TLine ): \"\"\"Check for existing _sg coef.\"\"\" # If sigs timeline has conv coef, but the cached doesnt, use it instead # pylint: disable=protected-access if tline . _sg . conv is not None and self . tlines [ tline . idn ] . _sg . conv is None : self . tlines [ tline . idn ] . _sg = tline . _sg def get_fastest ( self ): \"\"\"Return the approximate fastest tline from coll.\"\"\" tmp = self [ 0 ] fast = tmp . period for _ , tline in self . tlines . items (): if tline . period < fast : tmp = tline fast = tmp . period return tmp def remove ( self , signame ): \"\"\"Remove timeline for signame from collection. If other signals still use it, it will simply remove the reference. \"\"\" tl_idn = self . idns [ signame ] nref = len ( self . sigs [ tl_idn ]) if nref == 0 : raise ValueError ( \"No matching tline.\" ) if nref == 1 : self . tlines . pop ( tl_idn ) self . idns . pop ( signame ) self . sigs . pop ( tl_idn ) else : self . idns . pop ( signame ) self . sigs [ tl_idn ] . pop ( self . sigs [ tl_idn ] . index ( signame )) def replace ( self , old_tline : int | TLine , new_tline : TLine ): \"\"\"Replace the `old_tline` with `new_tline` in place.\"\"\" if isinstance ( old_tline , TLine ): old_idn = old_tline . idn else : old_idn = old_tline old_tline = self . tlines [ old_idn ] if old_idn in self . tlines : existing_sigs = self . sigs [ old_idn ] . copy () for existing in existing_sigs : self . remove ( existing ) old_tline . parent = None # To block the replace call in unix setter old_tline . unix = new_tline . unix self . append ( tlines = old_tline , signames = [ existing_sigs ]) @property def tstart ( self ): \"\"\"Earliest tstart in collection.\"\"\" tstart = None for _ , tline in self . tlines . items (): if tstart is None or tline . tstart < tstart : tstart = tline . tstart return tstart @property def tend ( self ): \"\"\"Latest tend in collection.\"\"\" tend = None for _ , tline in self . tlines . items (): if tend is None or tline . tend > tend : tend = tline . tend return tend @property def tstart_iso ( self ): \"\"\"Earliest start time in iso.\"\"\" return ccg . util . unix_to_iso ( self . tstart ) @property def tend_iso ( self ): \"\"\"Latest end time in iso.\"\"\" return ccg . util . unix_to_iso ( self . tend ) @property def n_tlines ( self ): \"\"\"Number of tlines in collection.\"\"\" return len ( self . tlines ) @property def nsamples ( self ): \"\"\"Number of samples in collection.\"\"\" nsamples = 0 for _ , tline in self . tlines . items (): nsamples += tline . nsamples return nsamples def add_to_sigs ( self , tline_idn : int , signame : str | list [ str ]): \"\"\"Add signal name to list.\"\"\" if isinstance ( signame , str ): signame = [ signame ] try : # try to extend incase it already exists. self . sigs [ tline_idn ] . extend ( signame ) except KeyError : # else define it as a list self . sigs [ tline_idn ] = signame def get_apprx_bytes ( self , tline : TLine ): \"\"\"Gets the approximate size of the tline and its associated signals. Parameters ---------- tline tline to get size for. Returns ------- Cumulative Bytes of tline and the signals associated with it. \"\"\" size = tline . appx_bytes for sig in self . sigs [ tline . idn ]: size += self . frame . sigs [ sig ] . appx_bytes return size def __getitem__ ( self , index : str | int ) -> TLine : if isinstance ( index , str ): return self . tlines [ self . idns [ index ]] elif isinstance ( index , int ): # TODO: Is this legit?? try : return self . tlines [ index ] except KeyError : return list ( self . tlines . values ())[ index ] else : raise NotImplementedError def __repr__ ( self ) -> str : \"\"\"Return string repr.\"\"\" isos = [] for tline in self . tlines . values (): isos . append ( repr ( tline )) # reprstr = f\"{self.__class__.__module__}.{self.__class__.__qualname__}([{', '.join(isos)}])\" reprstr = f \" { self . __class__ . __qualname__ } ([ { ', ' . join ( isos ) } ])\" return reprstr def __str__ ( self ): \"\"\"String rep.\"\"\" idnlist = self . tlines . keys () return f \"tline collection idns: { idnlist } \" def __eq__ ( self , other ) -> bool : \"\"\"Check equality.\"\"\" if isinstance ( other , self . __class__ ): eq = ( self . idns == other . idns and self . sigs == other . sigs and self . tlines == other . tlines ) return eq else : return False def __contains__ ( self , other ) -> bool : return other in self . tlines n_tlines property Number of tlines in collection. nsamples property Number of samples in collection. tend property Latest tend in collection. tend_iso property Latest end time in iso. tstart property Earliest tstart in collection. tstart_iso property Earliest start time in iso. __eq__ ( other ) Check equality. Source code in ccg\\data\\tsdata.py 2538 2539 2540 2541 2542 2543 2544 2545 2546 2547 2548 def __eq__ ( self , other ) -> bool : \"\"\"Check equality.\"\"\" if isinstance ( other , self . __class__ ): eq = ( self . idns == other . idns and self . sigs == other . sigs and self . tlines == other . tlines ) return eq else : return False __repr__ () Return string repr. Source code in ccg\\data\\tsdata.py 2524 2525 2526 2527 2528 2529 2530 2531 def __repr__ ( self ) -> str : \"\"\"Return string repr.\"\"\" isos = [] for tline in self . tlines . values (): isos . append ( repr ( tline )) # reprstr = f\"{self.__class__.__module__}.{self.__class__.__qualname__}([{', '.join(isos)}])\" reprstr = f \" { self . __class__ . __qualname__ } ([ { ', ' . join ( isos ) } ])\" return reprstr __str__ () String rep. Source code in ccg\\data\\tsdata.py 2533 2534 2535 2536 def __str__ ( self ): \"\"\"String rep.\"\"\" idnlist = self . tlines . keys () return f \"tline collection idns: { idnlist } \" add_to_sigs ( tline_idn , signame ) Add signal name to list. Source code in ccg\\data\\tsdata.py 2487 2488 2489 2490 2491 2492 2493 2494 def add_to_sigs ( self , tline_idn : int , signame : str | list [ str ]): \"\"\"Add signal name to list.\"\"\" if isinstance ( signame , str ): signame = [ signame ] try : # try to extend incase it already exists. self . sigs [ tline_idn ] . extend ( signame ) except KeyError : # else define it as a list self . sigs [ tline_idn ] = signame append ( frameorsig = None , tlines = None , signames = None ) Append tline to collection. Parameters: frame \u2013 optional Frame to get timelines from. tlines ( TLine | list [ TLine ] , default: None ) \u2013 optional CCGTline or list of CCGTline. If used, signames is required. signames ( list [ str ] | list [ list [ str ]] , default: None ) \u2013 required with tlines. Must be equal length list of lists of signames. Returns: CCGTimeline \u2013 Source code in ccg\\data\\tsdata.py 2276 2277 2278 2279 2280 2281 2282 2283 2284 2285 2286 2287 2288 2289 2290 2291 2292 2293 2294 2295 2296 2297 2298 2299 2300 2301 2302 2303 2304 2305 2306 2307 2308 2309 2310 2311 2312 2313 2314 2315 2316 2317 2318 2319 2320 2321 2322 2323 2324 2325 2326 2327 2328 2329 2330 2331 2332 2333 2334 2335 2336 2337 2338 2339 2340 2341 2342 2343 2344 2345 2346 2347 2348 2349 2350 2351 2352 2353 2354 2355 2356 2357 2358 2359 2360 2361 2362 2363 2364 2365 2366 2367 2368 2369 2370 2371 2372 2373 2374 2375 2376 2377 2378 2379 2380 2381 2382 2383 2384 2385 2386 2387 2388 2389 2390 2391 2392 2393 @profile def append ( self , frameorsig : Sig | Frame = None , tlines : TLine | list [ TLine ] = None , signames : list [ str ] | list [ list [ str ]] = None , ) -> TLine : \"\"\" Append tline to collection. Parameters ---------- frame optional Frame to get timelines from. tlines optional CCGTline or list of CCGTline. If used, signames is required. signames required with tlines. Must be equal length list of lists of signames. Returns ------- CCGTimeline \"\"\" if frameorsig is not None : # if isinstance(frameorsig, pd.DataFrame): # tline = TLine(frameorsig) # tline.parent = self # if tline.idn in self.tlines: # self.check_sg(tline) # else: # self.tlines[tline.idn] = tline # tlref = self.tlines[tline.idn] # for col in frameorsig: # self.idns[col] = tline.idn # self.add_to_sigs(tline.idn, col) if isinstance ( frameorsig , Frame ): tlref = [] if frameorsig . nsigs > 0 : for tline in frameorsig . tlines : tline . parent = self # TODO: Check for reference issue in this case if tline . idn in self . tlines : self . check_sg ( tline ) else : self . tlines [ tline . idn ] = tline sigs = frameorsig . tlines . sigs [ tline . idn ] # Check if signame already exists with different tline idns_old = self . idns [ sigs ] if idns_old and np . any ( idns_old != tline . idn ): _LOGGER . error ( \"Existing signal( %s ) with different timeline has been replaced\" , sigs [ idns_old != tline . idn ], ) self . idns [ sigs ] = tline . idn self . add_to_sigs ( tline . idn , sigs ) tlref . append ( self . tlines [ tline . idn ]) elif isinstance ( frameorsig , Sig ): tline = frameorsig . tline tline . parent = self if tline . idn in self : self . check_sg ( tline ) else : self . tlines [ tline . idn ] = tline tlref = self . tlines [ tline . idn ] sigs = frameorsig . name # Check if signame already exists with different tline try : idns_old = self . idns [ sigs ] except KeyError : idns_old = None if any ([ idns_old == tline . idn ]): _LOGGER . error ( \"Existing signal( %s ) with different timeline\" , sigs [ idns_old != tline . idn ], ) self . idns [ sigs ] = tline . idn self . add_to_sigs ( tline . idn , sigs ) # Change 2/10/24 - fix reference to tline in sig here frameorsig . tline = tlref else : raise NotImplementedError ( f \"Appending tline from { type ( frameorsig ) } is not implemented\" ) if tlines is not None : if not isinstance ( tlines , list ): tlines = [ tlines ] if len ( signames ) != len ( tlines ): raise ValueError ( \"If tlines is specified and contains more than 1, signames must be same length.\" ) if signames is None : raise ValueError ( \"signames must be specified with tlines.\" ) tlref = [] for sigs , tline in zip ( signames , tlines ): tline . parent = self if tline . idn in self . tlines : self . check_sg ( tline ) else : self . tlines [ tline . idn ] = tline if not isinstance ( sigs , list ): sigs = [ sigs ] self . add_to_sigs ( tline . idn , sigs ) for sig in sigs : self . idns [ sig ] = tline . idn tlref . append ( tline ) return tlref check_sg ( tline ) Check for existing _sg coef. Source code in ccg\\data\\tsdata.py 2395 2396 2397 2398 2399 2400 def check_sg ( self , tline : TLine ): \"\"\"Check for existing _sg coef.\"\"\" # If sigs timeline has conv coef, but the cached doesnt, use it instead # pylint: disable=protected-access if tline . _sg . conv is not None and self . tlines [ tline . idn ] . _sg . conv is None : self . tlines [ tline . idn ] . _sg = tline . _sg get_apprx_bytes ( tline ) Gets the approximate size of the tline and its associated signals. Parameters: tline ( TLine ) \u2013 tline to get size for. Returns: Cumulative Bytes of tline and the signals associated with it. \u2013 Source code in ccg\\data\\tsdata.py 2496 2497 2498 2499 2500 2501 2502 2503 2504 2505 2506 2507 2508 2509 2510 def get_apprx_bytes ( self , tline : TLine ): \"\"\"Gets the approximate size of the tline and its associated signals. Parameters ---------- tline tline to get size for. Returns ------- Cumulative Bytes of tline and the signals associated with it. \"\"\" size = tline . appx_bytes for sig in self . sigs [ tline . idn ]: size += self . frame . sigs [ sig ] . appx_bytes return size get_fastest () Return the approximate fastest tline from coll. Source code in ccg\\data\\tsdata.py 2402 2403 2404 2405 2406 2407 2408 2409 2410 2411 def get_fastest ( self ): \"\"\"Return the approximate fastest tline from coll.\"\"\" tmp = self [ 0 ] fast = tmp . period for _ , tline in self . tlines . items (): if tline . period < fast : tmp = tline fast = tmp . period return tmp remove ( signame ) Remove timeline for signame from collection. If other signals still use it, it will simply remove the reference. Source code in ccg\\data\\tsdata.py 2413 2414 2415 2416 2417 2418 2419 2420 2421 2422 2423 2424 2425 2426 2427 2428 def remove ( self , signame ): \"\"\"Remove timeline for signame from collection. If other signals still use it, it will simply remove the reference. \"\"\" tl_idn = self . idns [ signame ] nref = len ( self . sigs [ tl_idn ]) if nref == 0 : raise ValueError ( \"No matching tline.\" ) if nref == 1 : self . tlines . pop ( tl_idn ) self . idns . pop ( signame ) self . sigs . pop ( tl_idn ) else : self . idns . pop ( signame ) self . sigs [ tl_idn ] . pop ( self . sigs [ tl_idn ] . index ( signame )) replace ( old_tline , new_tline ) Replace the old_tline with new_tline in place. Source code in ccg\\data\\tsdata.py 2430 2431 2432 2433 2434 2435 2436 2437 2438 2439 2440 2441 2442 2443 2444 def replace ( self , old_tline : int | TLine , new_tline : TLine ): \"\"\"Replace the `old_tline` with `new_tline` in place.\"\"\" if isinstance ( old_tline , TLine ): old_idn = old_tline . idn else : old_idn = old_tline old_tline = self . tlines [ old_idn ] if old_idn in self . tlines : existing_sigs = self . sigs [ old_idn ] . copy () for existing in existing_sigs : self . remove ( existing ) old_tline . parent = None # To block the replace call in unix setter old_tline . unix = new_tline . unix self . append ( tlines = old_tline , signames = [ existing_sigs ]) get_math_tline ( sig1 , sig2 ) returns timeline for math. sig1.parent.math_tline if it exits, or fastest. Source code in ccg\\data\\tsdata.py 2647 2648 2649 2650 2651 2652 2653 2654 2655 def get_math_tline ( sig1 : Sig , sig2 : Sig | npt . NDArray | float | int ): \"\"\"returns timeline for math. sig1.parent.math_tline if it exits, or fastest.\"\"\" if sig1 . parent and sig1 . parent . math_tline : return sig1 . parent . math_tline if isinstance ( sig2 , Sig ) and sig2 . parent and sig2 . parent . math_tline : return sig2 . parent . math_tline if isinstance ( sig2 , Sig ) and sig1 . tline . period > sig2 . tline . period : return sig2 . tline return sig1 . tline","title":"tsdata"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Frame","text":"Collection of Time Series data. Parameters: data ( Sig | list [ Sig ] | None , default: None ) \u2013 TS Data, by default None. References to Sig will be broken. name ( str | None , default: None ) \u2013 Frame name, by default None math_tline ( TLine | None , default: None ) \u2013 TLine for Frame wide math, by default None Attributes: sigs ( dict [ str , Sig ] ) \u2013 dictionary of Sigs tlines ( TLineCollection ) \u2013 Collection of timelines, referenced by Sigs name ( str ) \u2013 Frame Name nsigs ( int ) \u2013 nsamples ( int ) \u2013 tend ( float | None ) \u2013 tstart ( float | None ) \u2013 tline ( TLine | None ) \u2013 Source code in ccg\\data\\tsdata.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 class Frame : \"\"\"Collection of Time Series data. Parameters ---------- data : Sig | list[Sig] | None, optional TS Data, by default None. References to Sig will be broken. name : str | None, optional Frame name, by default None math_tline : TLine | None, optional TLine for Frame wide math, by default None Attributes ------- sigs : dict[str, Sig] dictionary of Sigs tlines: TLineCollection Collection of timelines, referenced by Sigs name: str Frame Name nsigs nsamples tend tstart tline \"\"\" CUTOFF = 0.5 # For difflib compares def __init__ ( self , data : Sig | list [ Sig ] | None = None , name : str | None = None , math_tline : TLine | None = None , ) -> None : self . sigs : dict [ str , Sig ] = {} self . tlines = TLineCollection ( self ) self . name = name sigs = [] self . math_tline = math_tline # if isinstance(data, pd.DataFrame): # tline = TLine(data) # for col in data: # sig = Sig( # data=data[col], # tline=tline, # name=col, # frame=self, # ) # sigs.append(sig) if isinstance ( data , Sig ): sigs . append ( data ) elif isinstance ( data , list ): for sig in data : sigs . append ( sig ) elif data is None : pass else : raise NotImplementedError ( f \"Frame generation from { type ( data ) } is not implemented.\" ) self . append ( sigs ) @property def nsigs ( self ) -> int : \"\"\"Number of Sigs in collection.\"\"\" return len ( self . sigs ) @property def nsamples ( self ) -> int : \"\"\"Cumulative samples (counting unique timelines as well).\"\"\" nsamples = self . tlines . nsamples for _ , sig in self . sigs . items (): nsamples += sig . nsamples return nsamples @property def tend ( self ) -> float | None : \"\"\"Latest end time from TLine collection. Returns ------- float Time in unix. \"\"\" return self . tlines . tend @property def tstart ( self ) -> float | None : \"\"\"Earliest start time from TLine collection. Returns ------- float Time in unix. \"\"\" return self . tlines . tstart @property def tend_iso ( self ) -> npt . NDArray [ np . datetime64 ]: \"\"\"Latest end time from TLine collection. Returns ------- float Time in iso. \"\"\" return self . tlines . tend_iso @property def tstart_iso ( self ): \"\"\"Earliest start time from TLine collection. Returns ------- float Time in iso. \"\"\" return self . tlines . tstart_iso # def calc_idn(self): # \"\"\"Calculate hash for IDN.\"\"\" # tic = datetime.now() # idn = xxhash.xxh3_64(self.sigs).intdigest() # toc = datetime.now() - tic # _LOGGER.debug(\"IDN calc'd for %s in %.3f\", self.name, toc.total_seconds()) # return idn def resample ( self , sample_to : TLine , sigs : str | list [ str ] | None = None , inplace : bool | None = False , prefix : str | None = None , suffix : str | None = None , ** kwargs , ): \"\"\"Resample Frame to a `sample_to` TLine. Parameters ---------- sample_to : TLine TLine to resample to sigs : str | list[str] | None, optional list of sigs to resample, full frame if None, by default None inplace : bool | None, optional if True, will resample signals and append (id prefix or suffix is not None) or replace inplace. By default False prefix : str | None, optional prefix to signame, by default None suffix : str | None, optional suffix to signame, by default None **kwargs Additional arguments passed to `Sig.resample()` Returns ------- Frame Returns Self if inplace, else a new Frame \"\"\" if inplace : res = self else : res = Frame () if sigs is not None : if isinstance ( sigs , str ): sigs = [ sigs ] else : sigs = list ( self . sigs . keys ()) for sig in sigs : newsig = self . sigs [ sig ] . resample ( sample_to , ** kwargs ) if prefix is not None : newsig . name = prefix + newsig . name if suffix is not None : newsig . name = newsig . name + suffix if inplace and prefix is None and suffix is None : res . remove ( sig ) res . append ( newsig ) return res def append ( self , item : Sig | Frame | list [ Sig ], append_existing_signals : bool = False , interweave_tlines : bool = False , ): \"\"\"Append to CCG Frame in place.\"\"\" if isinstance ( item , Frame ): sigs_to_apnd = list ( item . sigs . keys ()) for _ , new_sigs in item . tlines . sigs . items (): for sig in new_sigs : if append_existing_signals and sig in self and sig in sigs_to_apnd : check_overlap ( self [ sig ], item [ sig ], interweave_tlines ) old_idn = self . tlines . idns [ sig ] new_tline = self . tlines [ old_idn ] . append_to_new ( item [ sig ]) if new_tline . is_monotonic_increasing : for old_sig in list ( self . tlines . sigs [ old_idn ]): if old_sig in item : self . tlines . remove ( old_sig ) self [ old_sig ] . tline = new_tline self . tlines . append ( self [ old_sig ]) # for references self [ old_sig ] . _data . append ( item [ old_sig ] . _data ) # get the rest of the attributes if item [ old_sig ] . connect_gaps is not None : self [ old_sig ] . connect_gaps = item [ old_sig ] . connect_gaps if item [ old_sig ] . data_enum is not None : self [ old_sig ] . data_enum = item [ old_sig ] . data_enum if item [ old_sig ] . interp_method is not None : self [ old_sig ] . interp_method = item [ old_sig ] . interp_method if item [ old_sig ] . unit is not None : self [ old_sig ] . unit = item [ old_sig ] . unit # Check for unknown attributes. the new signal value will overide the original. for key , val in item [ old_sig ] . __dict__ . items (): if ( not key . startswith ( \"_\" ) and key not in SIG_ATTRS ): setattr ( self [ old_sig ], key , val ) sigs_to_apnd . remove ( old_sig ) else : raise NotImplementedError ( \"batch appends not implemented for non-monoton\" ) for signame in sigs_to_apnd : sig = item [ signame ] self . _append_sig ( sig , append_existing_signals , interweave_tlines ) elif isinstance ( item , list ): for sig in item : self . _append_sig ( sig , append_existing_signals , interweave_tlines ) else : self . _append_sig ( item , append_existing_signals , interweave_tlines ) @profile def _append_sig ( self , sig : Sig , append_existing_signals : bool = False , interweave_tlines : bool = False , ): \"\"\"Append a signal to Frame.\"\"\" # create a new sig to break references to existing sig_copy = Sig ( sig ) # Check for matching name if sig_copy . name in self . sigs : if append_existing_signals : self . sigs [ sig_copy . name ] . append ( sig_copy , interweave_tlines = interweave_tlines , remove_duplicates = False , ) else : _LOGGER . warning ( \"Sig %s already exists, use append_existing_signals=True.\" , sig . name , ) else : self . tlines . append ( sig_copy ) # sig_copy.tline = tlref # replace with the tline reference # 2/10/24 now in tlines.append() sig_copy . parent = self self . sigs [ sig_copy . name ] = sig_copy def _rename_sig ( self , oldname , newname ): \"\"\" Rename signal references in frame. Use `frm['oldname'].name = newname` to rename signal and update frame references together. \"\"\" self . sigs [ newname ] = self . sigs . pop ( oldname ) self . tlines . idns [ newname ] = self . tlines . idns . pop ( oldname ) ind = self . tlines . sigs [ self . tlines . idns [ newname ]] . index ( oldname ) self . tlines . sigs [ self . tlines . idns [ newname ]][ ind ] = newname def sort ( self , remove_safe_duplicates = False , remove_all_duplicates = False ): \"\"\"Sort signals by timeline for monoton increasing.\"\"\" for _ , sig in self . sigs . items (): sig . sort_tline ( inplace = True , remove_safe_duplicates = remove_safe_duplicates , remove_all_duplicates = remove_all_duplicates , ) # def to_pandas(self) -> pd.DataFrame: # \"\"\"Convert CCGFrame to pd.DataFrame.\"\"\" # serieslist = [] # for sig in self: # serieslist.append(sig.to_pandas()) # pddf = pd.concat(serieslist, join=\"outer\", axis=1) # return pddf def clear ( self ): \"\"\"Clears frame in place.\"\"\" self . sigs : dict [ str , Sig ] = {} self . tlines = TLineCollection ( self ) def clean_names ( self ): \"\"\"Cleans signal names.\"\"\" rename_list = {} for signame , _ in self . sigs . items (): clean_name = ccg . util . clean_name ( signame ) if clean_name != signame : rename_list . update ({ signame : clean_name }) for signame , clean_name in rename_list . items (): _LOGGER . debug ( \" %s renamed to %s \" , signame , clean_name ) self [ signame ] . name = clean_name def remove ( self , signames : str | list [ str ]): \"\"\"Removes sigs from frame.\"\"\" if not isinstance ( signames , list ): signames = [ signames ] for signame in signames : if signame in self : self . tlines . remove ( signame ) self . sigs . pop ( signame , None ) def plot ( self ): \"\"\"Plot data frame.\"\"\" from ccg.ui.plot import Plot plt = Plot ( self ) plt . plot () def valid ( self , gatecoll : GateColl , tline : TLine | None = None ) -> Frame : \"\"\"Returns a new Frame, invalid data replaced with nan. calc'd on `tline` or combined TLine if None Parameters ---------- gatecoll : GateColl Collection of gating conditions tline : TLine | None, optional TLine to calculate validity on, by default None Returns ------- Frame New instance of Frame \"\"\" res = Frame ( name = self . name ) # if tline is None: # tline = self.tlines.get_fastest() valid_sig = gatecoll . validate ( self , tline ) for tmp_tline in self . tlines : if tmp_tline . nsamples > 1 : b_valid = valid_sig . interp ( tmp_tline ) . data for sig in self . tlines . sigs [ tmp_tline . idn ]: newsig = Sig ( self [ sig ]) nan = np . NaN if newsig . data . dtype . kind in [ \"i\" , \"u\" ]: newsig . data = newsig . data . astype ( \"float\" ) elif newsig . data . dtype . kind in [ \"U\" , \"S\" ]: nan = \"\" newsig . data [ ~ b_valid ] = nan res . append ( newsig ) return res @property def tline ( self ) -> TLine | None : \"\"\"If frame has only one tline, return it.\"\"\" if self . tlines . n_tlines == 1 : return list ( self . tlines . tlines . values ())[ 0 ] else : raise ValueError ( f \" { 'frame' if self . name is None else self . name } has more than one tline,\" + f \" { 'frame' if self . name is None else self . name } .tline() invalid.\" ) @profile def from_excel ( self , filename : str | Path , tline_col : int | str = None , signame_row : int = None , signame_regex : str = None , filedata : BytesIO | StringIO | bytes = None , sigunit_row : int = None , sigdata_row : int = None , ) -> Frame : \"\"\"Generate frame from excel file. Parameters ---------- filename tline_col Column to use for an index signame_row Row with names to parse with _regex signame_regex regex string to parse signal names. Use named groups for parameters to pass into Sig instatiation, for example name, units, etc. example here: https://regex101.com/r/bfBrdf/6 filedata string or bytes io. filename will only be used for ext, name, etc. \"\"\" tic = datetime . now () if isinstance ( filename , str ): filename = Path ( filename ) if signame_row is None : signame_row = 0 if tline_col is None : tline_col = 0 if signame_regex is None : signame_regex = r \"(?P<name>^.*?)(?:(?:\\s?\\((?P<unit>(?!.*\\().*)\\))|$)\" # Default regex `signal name (unit)`-> `{'name':'signal name','unit':'unit'` # https://regex101.com/r/bfBrdf/6 regex = re . compile ( signame_regex ) data = self . read_filedata ( filename , filedata ) toc = datetime . now () - tic _LOGGER . debug ( \"read %s in %.3f .\" , filename , toc . total_seconds ()) tic = datetime . now () if isinstance ( signame_row , str ): for i , row in enumerate ( data ): if row [ 0 ] == signame_row : signame_row = i break else : raise ValueError ( f \"Signal Name Row: { signame_row } not found in first column of data file.\" ) signames = data [ signame_row , :] . astype ( \"str\" ) signames = np . char . strip ( signames ) if sigunit_row is not None : sigunits = data [ sigunit_row , :] . astype ( \"str\" ) sig_args = [ { \"name\" : name , \"unit\" : unit } for name , unit in zip ( signames , sigunits ) ] else : sig_args = [ regex . match ( signame ) . groupdict () for signame in signames ] # Check for duplicate names and add _dup existing = [] for sig in sig_args : if sig [ \"name\" ] not in existing : existing . append ( sig [ \"name\" ]) else : existing . append ( sig [ \"name\" ] + \"_dup\" ) sig [ \"name\" ] = sig [ \"name\" ] + \"_dup\" if isinstance ( tline_col , str ): tline_col = np . where ( signames == tline_col ) if tline_col [ 0 ] . size == 0 : raise ValueError ( \"tline_col is not in signames.\" ) else : tline_col = [ tline_col ] if sigdata_row is None : sigdata_row = signame_row + 1 tmp : npt . NDArray = data [ sigdata_row :, tline_col ] . ravel () try : tmp = tmp . astype ( \"float\" ) except ValueError : tmp = tmp . astype ( type ( tmp [ 0 ])) tline = TLine ( tmp ) for i , kwargs in enumerate ( sig_args ): if i != tline_col [ 0 ]: sigtype = type ( data [ sigdata_row , i ]) sigdata = data [ sigdata_row :, i ] . ravel () . astype ( sigtype ) if sigtype is str : try : sigdata = sigdata . astype ( float ) except ValueError : pass new_sig = Sig ( data = sigdata , tline = tline , ** kwargs , ) self . append ( new_sig ) toc = datetime . now () - tic _LOGGER . debug ( \"built frame in %.3f .\" , toc . total_seconds ()) tic = datetime . now () return self @profile def read_filedata ( self , filename : Path , filedata : BytesIO | StringIO | bytes | None = None ): \"\"\"Reads file data for building frame from file\"\"\" ext = filename . suffix if ext in [ \".xlsx\" , \".xlsm\" , \".XLSX\" , \".XLSM\" ]: # Use openpyxl if filedata is None : wb = openpyxl . load_workbook ( filename = filename , read_only = True , data_only = True ) else : wb = openpyxl . load_workbook ( filename = filedata , read_only = True , data_only = True ) ws = wb . active data = ws . values data = np . array ( list ( data )) wb . close () elif ext in [ \".xls\" , \".XLS\" ]: # Use xlrd wb_xls : xlrd . book . Book = xlrd . open_workbook ( filename = filename , file_contents = filedata ) ws = wb_xls . sheet_by_index ( 0 ) # data = np.array(ws._cell_values) data = np . empty ( shape = ( ws . nrows , ws . ncols ), dtype = \"O\" ) for i in range ( ws . ncols ): data [:, i ] = ws . col_values ( i ) elif ext in [ \".csv\" , \".CSV\" ]: if filedata is None : with open ( filename , \"r\" , encoding = \"utf8\" ) as file : csvreader = csv . reader ( file , dialect = \"excel\" ) tmp = list ( csvreader ) max_col = max ( map ( len , tmp )) data = np . array ( [ tmp_row + [ None ] * ( max_col - len ( tmp_row )) for tmp_row in tmp ], dtype = \"O\" , ) else : if isinstance ( filedata , bytes ): csvreader = csv . reader ( io . StringIO ( filedata . decode ( \"utf-8\" ))) else : csvreader = csv . reader ( filedata ) tmp = list ( csvreader ) max_col = max ( map ( len , tmp )) data = np . array ( [ tmp_row + [ None ] * ( max_col - len ( tmp_row )) for tmp_row in tmp ], dtype = \"O\" , ) else : raise NotImplementedError ( f \"Frame from Excel not implemented for ext: { ext } \" ) return data # async def read_filedata_async( # self, filename: Path, filedata: BytesIO | StringIO | bytes = None # ): # \"\"\"Reads file data for building frame from file\"\"\" # ext = filename.suffix # if ext in [\".xlsx\", \".xlsm\", \".XLSX\", \".XLSM\"]: # # Use openpyxl # if filedata is None: # wb = openpyxl.load_workbook( # filename=filename, read_only=True, data_only=True # ) # else: # wb = openpyxl.load_workbook( # filename=filedata, read_only=True, data_only=True # ) # ws = wb.active # data = ws.values # data = np.array(list(data)) # wb.close() # elif ext in [\".xls\", \".XLS\"]: # # Use xlrd # wb_xls: xlrd.book.Book = xlrd.open_workbook( # filename=filename, file_contents=filedata # ) # ws = wb_xls.sheet_by_index(0) # # data = np.array(ws._cell_values) # data = np.empty(shape=(ws.nrows, ws.ncols), dtype=\"O\") # for i in range(ws.ncols): # data[:, i] = ws.col_values(i) # elif ext in [\".csv\", \".CSV\"]: # if filedata is None: # async with aiofiles.open(filename, \"r\", encoding=\"utf8\") as file: # csvreader = aiocsv.AsyncReader(file, dialect=\"excel\") # tmp = await list(csvreader) # max_col = max(map(len, tmp)) # data = np.array( # [ # tmp_row + [None] * (max_col - len(tmp_row)) # for tmp_row in tmp # ], # dtype=\"O\", # ) # else: # if isinstance(filedata, bytes): # csvreader = aiocsv.AsyncReader( # io.StringIO(filedata.decode(\"utf-8\")) # ) # else: # csvreader = aiocsv.AsyncReader(filedata) # tmp = await list(csvreader) # max_col = max(map(len, tmp)) # data = np.array( # [tmp_row + [None] * (max_col - len(tmp_row)) for tmp_row in tmp], # dtype=\"O\", # ) # else: # raise NotImplementedError( # f\"Frame from Excel not implemented for ext: {ext}\" # ) # return data def __getattr__ ( self , signame : str ) -> Sig : \"\"\"Provides dot notation access to Sigs if their names conform to dot notation. Parameters ---------- signame : str Must conform to dot notation (no spaces or special characters, starts with non numeric char, etc.) Returns ------- Sig Reference to Sig in Self \"\"\" if signame . startswith ( \"_\" ): raise AttributeError # Probably dont want to let it return _** return self . __getitem__ ( signame ) @overload def __getitem__ ( self , index : str ) -> Sig : pass @overload def __getitem__ ( self , index : Frame | list [ str ] | slice | set [ str ] | tuple [ str ] ) -> Frame : pass @profile def __getitem__ ( self , index : Frame | list [ str ] | set [ str ] | tuple [ str ] | str | slice ) -> Frame | Sig : \"\"\"Frame item getter. Parameters ---------- index : Frame | list[str] | slice | set[str] | str Frame, list of Sig names, slice of Returns ------- Frame | Sig New instance of Frame if index is Frame, list[str], slice. Reference to the Sig if str is a sig name. Examples -------- >>>TEST_LIST = [1.0, 2.0, 3.0] >>>TEST_ARR = np.array(TEST_LIST) >>>TEST_TIME = [0.0, 1.0, 2.0] >>>TEST_TLINE = TLine(TEST_TIME) >>>TEST_SIG = Sig(data=TEST_ARR, tline=TEST_TLINE, name=\"TestSig\") >>>assert frm[\"TestSig\"] == TEST_SIG # The reference to TEST_SIG was broken when appended to frm >>>assert frm[\"TestSig\"] is frm.sigs[\"TestSig\"] # The reference is preserved to the Sig in frm >>>assert frm[[\"TestSig\", \"TestSig2\"]] is not frm # The reference is broken to frm >>>assert frm[[\"TestSig\", \"TestSig2\"]] == frm >>>slicedfrm = frm[0:1.1] # sliced in time, with no step there is no resample >>>assert slicedfrm.tstart == 0.0 >>>assert slicedfrm.tend == 1.0 >>>assert slicedfrm.TestSig.nsamples == 2 # note 2 samples since no step was defined in slice >>>sliced_w_resample = frm[0:1.1:0.1] # Sliced in time, resamples to slice since step was defined. >>>assert sliced_w_resample.tstart == 0.0 >>>assert sliced_w_resample.tend == 1.0 >>>assert sliced_w_resample.TestSig.nsamples == 11 # note 2 samples since no step was defined in slice \"\"\" res = Frame ( name = self . name ) if isinstance ( index , Frame ): # This should be a boolean frame with indices that should be returned raise NotImplementedError ( \"Get item by boolean index is not implemented.\" ) if isinstance ( index , str ): self . _check_dot ( index ) if index not in self . sigs : index = self . check_for_alt ( index ) return self . sigs [ index ] if isinstance ( index , list | set | tuple ): if not index : # if empty return all sigs index = list ( self . sigs . keys ()) for signame in index : # Check for _dot notation, calculate derivatives if not present self . _check_dot ( signame ) if signame not in self . sigs : signame = self . check_for_alt ( signame ) res . append ( self . sigs [ signame ]) # improve to slice instead of re-build? elif isinstance ( index , slice ): # slicing is in time axis. if isinstance ( index . start , datetime ): ind_start = index . start . timestamp () else : ind_start = index . start if isinstance ( index . stop , datetime ): ind_stop = index . stop . timestamp () else : ind_stop = index . stop if isinstance ( index . step , timedelta ): step = index . step . total_seconds () else : step = index . step if index . step is None : # No step, so dont resample for tline in self . tlines : if index . start is None : start = tline . tstart else : start = ind_start if index . stop is None : # Since python is r-worded, this is a special case. # Need to make sure the last sample is included. stop = tline . tend + 0.000001 else : stop = ind_stop inds = np . logical_and ( tline . unix >= start , tline . unix < stop ) if np . any ( inds ): new_tline = TLine ( tline [ inds ]) for signame in self . tlines . sigs [ tline . idn ]: unks = {} old_sig = self . sigs [ signame ] for key , val in old_sig . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : unks . update ({ key : val }) new_sig = Sig ( data = old_sig . data [ inds ], tline = new_tline , name = old_sig . name , unit = old_sig . unit , interp_method = old_sig . interp_method , connect_gaps = old_sig . connect_gaps , data_enum = old_sig . data_enum , ** unks , ) res . append ( new_sig ) else : # Step was defined so we need to resample for tline in self . tlines : if index . start is None : start = tline . tstart else : start = ind_start if index . stop is None : stop = tline . tend else : stop = ind_stop new_tline = TLine ( tstart = start , tend = stop , period = step ) for signame in self . tlines . sigs [ tline . idn ]: res . append ( self . sigs [ signame ] . resample ( sample_to = new_tline )) else : raise NotImplementedError ( f \"Get item for index of type { type ( index ) } not implemented\" ) return res @profile def check_for_alt ( self , index ): \"\"\"Check for alternate name in case of missing dot notation\"\"\" # alt = difflib.get_close_matches( # index, self.sigs.keys(), n=1, cutoff=self.CUTOFF # ) alt = extractOne ( index , self . sigs . keys ()) if alt : if len ( alt [ 0 ]) != len ( index ): raise KeyError ( f \"' { index } ' is not in frame: { self . name } \" ) deltas_ok = [ x == \".\" or x == \" \" if x != y else True for x , y in zip ( index , alt [ 0 ]) ] if all ( deltas_ok ): index = alt [ 0 ] else : raise KeyError ( f \"' { index } ' is not in frame: { self . name } \" ) else : raise KeyError ( f \"' { index } ' is not in frame: { self . name } \" ) return index def __contains__ ( self , key ): \"\"\"Checks if key is a signame in frame\"\"\" self . _check_dot ( key ) res = key in self . sigs if res : return True else : try : _ = self . check_for_alt ( key ) return True except KeyError : return False def _check_dot ( self , signame : str ): \"\"\"Check if signame is _dot and calc deriv if needed.\"\"\" if signame not in self . sigs : if \"_dot\" in signame : n_dot = signame . count ( \"dot\" ) base_name = signame [ 0 : signame . index ( \"_dot\" )] if base_name not in self . sigs : base_name = self . check_for_alt ( base_name ) if base_name + \"_\" + \"dot\" * n_dot not in self . sigs : new_sig = self [ base_name ] . dot ( n_dot ) self . append ( new_sig ) @profile def subset ( self , index : slice , sigs : list [ str ] = None ): \"\"\"Get a subset of frame. Allows slicing by signals and in timeline.\"\"\" res = Frame ( name = self . name ) if sigs is None or not sigs : sigs = self . sigs . keys () if isinstance ( index . start , datetime ): ind_start = index . start . timestamp () else : ind_start = index . start if isinstance ( index . stop , datetime ): ind_stop = index . stop . timestamp () else : ind_stop = index . stop if isinstance ( index . step , timedelta ): step = index . step . total_seconds () else : step = index . step if index . step is None : # No step, so dont resample for tline in self . tlines : if any ( x in sigs for x in self . tlines . sigs [ tline . idn ]): if index . start is None : start = tline . tstart else : start = ind_start if index . stop is None : # Since python is r-worded, this is a special case. # Need to make sure the last sample is included. stop = tline . tend + 0.000001 else : stop = ind_stop inds = np . logical_and ( tline . unix >= start , tline . unix < stop ) if np . any ( inds ): new_tline = TLine ( tline [ inds ]) for signame in self . tlines . sigs [ tline . idn ]: if signame in sigs : old_sig = self . sigs [ signame ] new_sig = Sig ( old_sig ) new_sig . data = old_sig . data [ inds ] new_sig . tline = new_tline res . append ( new_sig ) else : # Step was defined so we need to resample for tline in self . tlines : if index . start is None : start = tline . tstart else : start = ind_start if index . stop is None : stop = tline . tend else : stop = ind_stop new_tline = TLine ( tstart = start , tend = stop , period = step ) for signame in self . tlines . sigs [ tline . idn ]: if signame in sigs : res . append ( self . sigs [ signame ] . resample ( sample_to = new_tline )) return res def __iter__ ( self ): \"\"\"Iterate.\"\"\" return iter ( self . sigs . values ()) def __repr__ ( self ) -> str : \"\"\"Return repr string.\"\"\" sigs = self . sigs . keys () reprstr = f \" { self . __class__ . __qualname__ } ([ { ', ' . join ( sigs ) } ])\" return reprstr def __eq__ ( self , other : Self ) -> bool : \"\"\"Check equality.\"\"\" if isinstance ( other , self . __class__ ): iseq = self . sigs == other . sigs and self . tlines == other . tlines return iseq return False","title":"Frame"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Frame.nsamples","text":"Cumulative samples (counting unique timelines as well).","title":"nsamples"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Frame.nsigs","text":"Number of Sigs in collection.","title":"nsigs"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Frame.tend","text":"Latest end time from TLine collection. Returns: float \u2013 Time in unix.","title":"tend"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Frame.tend_iso","text":"Latest end time from TLine collection. Returns: float \u2013 Time in iso.","title":"tend_iso"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Frame.tline","text":"If frame has only one tline, return it.","title":"tline"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Frame.tstart","text":"Earliest start time from TLine collection. Returns: float \u2013 Time in unix.","title":"tstart"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Frame.tstart_iso","text":"Earliest start time from TLine collection. Returns: float \u2013 Time in iso.","title":"tstart_iso"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Frame.__contains__","text":"Checks if key is a signame in frame Source code in ccg\\data\\tsdata.py 858 859 860 861 862 863 864 865 866 867 868 869 def __contains__ ( self , key ): \"\"\"Checks if key is a signame in frame\"\"\" self . _check_dot ( key ) res = key in self . sigs if res : return True else : try : _ = self . check_for_alt ( key ) return True except KeyError : return False","title":"__contains__"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Frame.__eq__","text":"Check equality. Source code in ccg\\data\\tsdata.py 955 956 957 958 959 960 961 def __eq__ ( self , other : Self ) -> bool : \"\"\"Check equality.\"\"\" if isinstance ( other , self . __class__ ): iseq = self . sigs == other . sigs and self . tlines == other . tlines return iseq return False","title":"__eq__"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Frame.__getattr__","text":"Provides dot notation access to Sigs if their names conform to dot notation. Parameters: signame ( str ) \u2013 Must conform to dot notation (no spaces or special characters, starts with non numeric char, etc.) Returns: Sig \u2013 Reference to Sig in Self Source code in ccg\\data\\tsdata.py 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 def __getattr__ ( self , signame : str ) -> Sig : \"\"\"Provides dot notation access to Sigs if their names conform to dot notation. Parameters ---------- signame : str Must conform to dot notation (no spaces or special characters, starts with non numeric char, etc.) Returns ------- Sig Reference to Sig in Self \"\"\" if signame . startswith ( \"_\" ): raise AttributeError # Probably dont want to let it return _** return self . __getitem__ ( signame )","title":"__getattr__"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Frame.__getitem__","text":"Frame item getter. Parameters: index ( Frame | list [ str ] | slice | set [ str ] | str ) \u2013 Frame, list of Sig names, slice of Returns: Frame | Sig \u2013 New instance of Frame if index is Frame, list[str], slice. Reference to the Sig if str is a sig name. Examples: >>>TEST_LIST = [1.0, 2.0, 3.0] >>>TEST_ARR = np.array(TEST_LIST) >>>TEST_TIME = [0.0, 1.0, 2.0] >>>TEST_TLINE = TLine(TEST_TIME) >>>TEST_SIG = Sig(data=TEST_ARR, tline=TEST_TLINE, name=\"TestSig\") >>>assert frm[\"TestSig\"] == TEST_SIG # The reference to TEST_SIG was broken when appended to frm >>>assert frm[\"TestSig\"] is frm.sigs[\"TestSig\"] # The reference is preserved to the Sig in frm >>>assert frm[[\"TestSig\", \"TestSig2\"]] is not frm # The reference is broken to frm >>>assert frm[[\"TestSig\", \"TestSig2\"]] == frm >>>slicedfrm = frm[0:1.1] # sliced in time, with no step there is no resample >>>assert slicedfrm.tstart == 0.0 >>>assert slicedfrm.tend == 1.0 >>>assert slicedfrm.TestSig.nsamples == 2 # note 2 samples since no step was defined in slice >>>sliced_w_resample = frm[0:1.1:0.1] # Sliced in time, resamples to slice since step was defined. >>>assert sliced_w_resample.tstart == 0.0 >>>assert sliced_w_resample.tend == 1.0 >>>assert sliced_w_resample.TestSig.nsamples == 11 # note 2 samples since no step was defined in slice Source code in ccg\\data\\tsdata.py 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 @profile def __getitem__ ( self , index : Frame | list [ str ] | set [ str ] | tuple [ str ] | str | slice ) -> Frame | Sig : \"\"\"Frame item getter. Parameters ---------- index : Frame | list[str] | slice | set[str] | str Frame, list of Sig names, slice of Returns ------- Frame | Sig New instance of Frame if index is Frame, list[str], slice. Reference to the Sig if str is a sig name. Examples -------- >>>TEST_LIST = [1.0, 2.0, 3.0] >>>TEST_ARR = np.array(TEST_LIST) >>>TEST_TIME = [0.0, 1.0, 2.0] >>>TEST_TLINE = TLine(TEST_TIME) >>>TEST_SIG = Sig(data=TEST_ARR, tline=TEST_TLINE, name=\"TestSig\") >>>assert frm[\"TestSig\"] == TEST_SIG # The reference to TEST_SIG was broken when appended to frm >>>assert frm[\"TestSig\"] is frm.sigs[\"TestSig\"] # The reference is preserved to the Sig in frm >>>assert frm[[\"TestSig\", \"TestSig2\"]] is not frm # The reference is broken to frm >>>assert frm[[\"TestSig\", \"TestSig2\"]] == frm >>>slicedfrm = frm[0:1.1] # sliced in time, with no step there is no resample >>>assert slicedfrm.tstart == 0.0 >>>assert slicedfrm.tend == 1.0 >>>assert slicedfrm.TestSig.nsamples == 2 # note 2 samples since no step was defined in slice >>>sliced_w_resample = frm[0:1.1:0.1] # Sliced in time, resamples to slice since step was defined. >>>assert sliced_w_resample.tstart == 0.0 >>>assert sliced_w_resample.tend == 1.0 >>>assert sliced_w_resample.TestSig.nsamples == 11 # note 2 samples since no step was defined in slice \"\"\" res = Frame ( name = self . name ) if isinstance ( index , Frame ): # This should be a boolean frame with indices that should be returned raise NotImplementedError ( \"Get item by boolean index is not implemented.\" ) if isinstance ( index , str ): self . _check_dot ( index ) if index not in self . sigs : index = self . check_for_alt ( index ) return self . sigs [ index ] if isinstance ( index , list | set | tuple ): if not index : # if empty return all sigs index = list ( self . sigs . keys ()) for signame in index : # Check for _dot notation, calculate derivatives if not present self . _check_dot ( signame ) if signame not in self . sigs : signame = self . check_for_alt ( signame ) res . append ( self . sigs [ signame ]) # improve to slice instead of re-build? elif isinstance ( index , slice ): # slicing is in time axis. if isinstance ( index . start , datetime ): ind_start = index . start . timestamp () else : ind_start = index . start if isinstance ( index . stop , datetime ): ind_stop = index . stop . timestamp () else : ind_stop = index . stop if isinstance ( index . step , timedelta ): step = index . step . total_seconds () else : step = index . step if index . step is None : # No step, so dont resample for tline in self . tlines : if index . start is None : start = tline . tstart else : start = ind_start if index . stop is None : # Since python is r-worded, this is a special case. # Need to make sure the last sample is included. stop = tline . tend + 0.000001 else : stop = ind_stop inds = np . logical_and ( tline . unix >= start , tline . unix < stop ) if np . any ( inds ): new_tline = TLine ( tline [ inds ]) for signame in self . tlines . sigs [ tline . idn ]: unks = {} old_sig = self . sigs [ signame ] for key , val in old_sig . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : unks . update ({ key : val }) new_sig = Sig ( data = old_sig . data [ inds ], tline = new_tline , name = old_sig . name , unit = old_sig . unit , interp_method = old_sig . interp_method , connect_gaps = old_sig . connect_gaps , data_enum = old_sig . data_enum , ** unks , ) res . append ( new_sig ) else : # Step was defined so we need to resample for tline in self . tlines : if index . start is None : start = tline . tstart else : start = ind_start if index . stop is None : stop = tline . tend else : stop = ind_stop new_tline = TLine ( tstart = start , tend = stop , period = step ) for signame in self . tlines . sigs [ tline . idn ]: res . append ( self . sigs [ signame ] . resample ( sample_to = new_tline )) else : raise NotImplementedError ( f \"Get item for index of type { type ( index ) } not implemented\" ) return res","title":"__getitem__"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Frame.__iter__","text":"Iterate. Source code in ccg\\data\\tsdata.py 945 946 947 def __iter__ ( self ): \"\"\"Iterate.\"\"\" return iter ( self . sigs . values ())","title":"__iter__"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Frame.__repr__","text":"Return repr string. Source code in ccg\\data\\tsdata.py 949 950 951 952 953 def __repr__ ( self ) -> str : \"\"\"Return repr string.\"\"\" sigs = self . sigs . keys () reprstr = f \" { self . __class__ . __qualname__ } ([ { ', ' . join ( sigs ) } ])\" return reprstr","title":"__repr__"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Frame.append","text":"Append to CCG Frame in place. Source code in ccg\\data\\tsdata.py 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 def append ( self , item : Sig | Frame | list [ Sig ], append_existing_signals : bool = False , interweave_tlines : bool = False , ): \"\"\"Append to CCG Frame in place.\"\"\" if isinstance ( item , Frame ): sigs_to_apnd = list ( item . sigs . keys ()) for _ , new_sigs in item . tlines . sigs . items (): for sig in new_sigs : if append_existing_signals and sig in self and sig in sigs_to_apnd : check_overlap ( self [ sig ], item [ sig ], interweave_tlines ) old_idn = self . tlines . idns [ sig ] new_tline = self . tlines [ old_idn ] . append_to_new ( item [ sig ]) if new_tline . is_monotonic_increasing : for old_sig in list ( self . tlines . sigs [ old_idn ]): if old_sig in item : self . tlines . remove ( old_sig ) self [ old_sig ] . tline = new_tline self . tlines . append ( self [ old_sig ]) # for references self [ old_sig ] . _data . append ( item [ old_sig ] . _data ) # get the rest of the attributes if item [ old_sig ] . connect_gaps is not None : self [ old_sig ] . connect_gaps = item [ old_sig ] . connect_gaps if item [ old_sig ] . data_enum is not None : self [ old_sig ] . data_enum = item [ old_sig ] . data_enum if item [ old_sig ] . interp_method is not None : self [ old_sig ] . interp_method = item [ old_sig ] . interp_method if item [ old_sig ] . unit is not None : self [ old_sig ] . unit = item [ old_sig ] . unit # Check for unknown attributes. the new signal value will overide the original. for key , val in item [ old_sig ] . __dict__ . items (): if ( not key . startswith ( \"_\" ) and key not in SIG_ATTRS ): setattr ( self [ old_sig ], key , val ) sigs_to_apnd . remove ( old_sig ) else : raise NotImplementedError ( \"batch appends not implemented for non-monoton\" ) for signame in sigs_to_apnd : sig = item [ signame ] self . _append_sig ( sig , append_existing_signals , interweave_tlines ) elif isinstance ( item , list ): for sig in item : self . _append_sig ( sig , append_existing_signals , interweave_tlines ) else : self . _append_sig ( item , append_existing_signals , interweave_tlines )","title":"append"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Frame.check_for_alt","text":"Check for alternate name in case of missing dot notation Source code in ccg\\data\\tsdata.py 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 @profile def check_for_alt ( self , index ): \"\"\"Check for alternate name in case of missing dot notation\"\"\" # alt = difflib.get_close_matches( # index, self.sigs.keys(), n=1, cutoff=self.CUTOFF # ) alt = extractOne ( index , self . sigs . keys ()) if alt : if len ( alt [ 0 ]) != len ( index ): raise KeyError ( f \"' { index } ' is not in frame: { self . name } \" ) deltas_ok = [ x == \".\" or x == \" \" if x != y else True for x , y in zip ( index , alt [ 0 ]) ] if all ( deltas_ok ): index = alt [ 0 ] else : raise KeyError ( f \"' { index } ' is not in frame: { self . name } \" ) else : raise KeyError ( f \"' { index } ' is not in frame: { self . name } \" ) return index","title":"check_for_alt"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Frame.clean_names","text":"Cleans signal names. Source code in ccg\\data\\tsdata.py 363 364 365 366 367 368 369 370 371 372 373 def clean_names ( self ): \"\"\"Cleans signal names.\"\"\" rename_list = {} for signame , _ in self . sigs . items (): clean_name = ccg . util . clean_name ( signame ) if clean_name != signame : rename_list . update ({ signame : clean_name }) for signame , clean_name in rename_list . items (): _LOGGER . debug ( \" %s renamed to %s \" , signame , clean_name ) self [ signame ] . name = clean_name","title":"clean_names"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Frame.clear","text":"Clears frame in place. Source code in ccg\\data\\tsdata.py 358 359 360 361 def clear ( self ): \"\"\"Clears frame in place.\"\"\" self . sigs : dict [ str , Sig ] = {} self . tlines = TLineCollection ( self )","title":"clear"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Frame.from_excel","text":"Generate frame from excel file. Parameters: filename ( str | Path ) \u2013 tline_col ( int | str , default: None ) \u2013 Column to use for an index signame_row ( int , default: None ) \u2013 Row with names to parse with _regex signame_regex ( str , default: None ) \u2013 regex string to parse signal names. Use named groups for parameters to pass into Sig instatiation, for example name, units, etc. example here: https://regex101.com/r/bfBrdf/6 filedata ( BytesIO | StringIO | bytes , default: None ) \u2013 string or bytes io. filename will only be used for ext, name, etc. Source code in ccg\\data\\tsdata.py 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 @profile def from_excel ( self , filename : str | Path , tline_col : int | str = None , signame_row : int = None , signame_regex : str = None , filedata : BytesIO | StringIO | bytes = None , sigunit_row : int = None , sigdata_row : int = None , ) -> Frame : \"\"\"Generate frame from excel file. Parameters ---------- filename tline_col Column to use for an index signame_row Row with names to parse with _regex signame_regex regex string to parse signal names. Use named groups for parameters to pass into Sig instatiation, for example name, units, etc. example here: https://regex101.com/r/bfBrdf/6 filedata string or bytes io. filename will only be used for ext, name, etc. \"\"\" tic = datetime . now () if isinstance ( filename , str ): filename = Path ( filename ) if signame_row is None : signame_row = 0 if tline_col is None : tline_col = 0 if signame_regex is None : signame_regex = r \"(?P<name>^.*?)(?:(?:\\s?\\((?P<unit>(?!.*\\().*)\\))|$)\" # Default regex `signal name (unit)`-> `{'name':'signal name','unit':'unit'` # https://regex101.com/r/bfBrdf/6 regex = re . compile ( signame_regex ) data = self . read_filedata ( filename , filedata ) toc = datetime . now () - tic _LOGGER . debug ( \"read %s in %.3f .\" , filename , toc . total_seconds ()) tic = datetime . now () if isinstance ( signame_row , str ): for i , row in enumerate ( data ): if row [ 0 ] == signame_row : signame_row = i break else : raise ValueError ( f \"Signal Name Row: { signame_row } not found in first column of data file.\" ) signames = data [ signame_row , :] . astype ( \"str\" ) signames = np . char . strip ( signames ) if sigunit_row is not None : sigunits = data [ sigunit_row , :] . astype ( \"str\" ) sig_args = [ { \"name\" : name , \"unit\" : unit } for name , unit in zip ( signames , sigunits ) ] else : sig_args = [ regex . match ( signame ) . groupdict () for signame in signames ] # Check for duplicate names and add _dup existing = [] for sig in sig_args : if sig [ \"name\" ] not in existing : existing . append ( sig [ \"name\" ]) else : existing . append ( sig [ \"name\" ] + \"_dup\" ) sig [ \"name\" ] = sig [ \"name\" ] + \"_dup\" if isinstance ( tline_col , str ): tline_col = np . where ( signames == tline_col ) if tline_col [ 0 ] . size == 0 : raise ValueError ( \"tline_col is not in signames.\" ) else : tline_col = [ tline_col ] if sigdata_row is None : sigdata_row = signame_row + 1 tmp : npt . NDArray = data [ sigdata_row :, tline_col ] . ravel () try : tmp = tmp . astype ( \"float\" ) except ValueError : tmp = tmp . astype ( type ( tmp [ 0 ])) tline = TLine ( tmp ) for i , kwargs in enumerate ( sig_args ): if i != tline_col [ 0 ]: sigtype = type ( data [ sigdata_row , i ]) sigdata = data [ sigdata_row :, i ] . ravel () . astype ( sigtype ) if sigtype is str : try : sigdata = sigdata . astype ( float ) except ValueError : pass new_sig = Sig ( data = sigdata , tline = tline , ** kwargs , ) self . append ( new_sig ) toc = datetime . now () - tic _LOGGER . debug ( \"built frame in %.3f .\" , toc . total_seconds ()) tic = datetime . now () return self","title":"from_excel"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Frame.plot","text":"Plot data frame. Source code in ccg\\data\\tsdata.py 384 385 386 387 388 389 def plot ( self ): \"\"\"Plot data frame.\"\"\" from ccg.ui.plot import Plot plt = Plot ( self ) plt . plot ()","title":"plot"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Frame.read_filedata","text":"Reads file data for building frame from file Source code in ccg\\data\\tsdata.py 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 @profile def read_filedata ( self , filename : Path , filedata : BytesIO | StringIO | bytes | None = None ): \"\"\"Reads file data for building frame from file\"\"\" ext = filename . suffix if ext in [ \".xlsx\" , \".xlsm\" , \".XLSX\" , \".XLSM\" ]: # Use openpyxl if filedata is None : wb = openpyxl . load_workbook ( filename = filename , read_only = True , data_only = True ) else : wb = openpyxl . load_workbook ( filename = filedata , read_only = True , data_only = True ) ws = wb . active data = ws . values data = np . array ( list ( data )) wb . close () elif ext in [ \".xls\" , \".XLS\" ]: # Use xlrd wb_xls : xlrd . book . Book = xlrd . open_workbook ( filename = filename , file_contents = filedata ) ws = wb_xls . sheet_by_index ( 0 ) # data = np.array(ws._cell_values) data = np . empty ( shape = ( ws . nrows , ws . ncols ), dtype = \"O\" ) for i in range ( ws . ncols ): data [:, i ] = ws . col_values ( i ) elif ext in [ \".csv\" , \".CSV\" ]: if filedata is None : with open ( filename , \"r\" , encoding = \"utf8\" ) as file : csvreader = csv . reader ( file , dialect = \"excel\" ) tmp = list ( csvreader ) max_col = max ( map ( len , tmp )) data = np . array ( [ tmp_row + [ None ] * ( max_col - len ( tmp_row )) for tmp_row in tmp ], dtype = \"O\" , ) else : if isinstance ( filedata , bytes ): csvreader = csv . reader ( io . StringIO ( filedata . decode ( \"utf-8\" ))) else : csvreader = csv . reader ( filedata ) tmp = list ( csvreader ) max_col = max ( map ( len , tmp )) data = np . array ( [ tmp_row + [ None ] * ( max_col - len ( tmp_row )) for tmp_row in tmp ], dtype = \"O\" , ) else : raise NotImplementedError ( f \"Frame from Excel not implemented for ext: { ext } \" ) return data","title":"read_filedata"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Frame.remove","text":"Removes sigs from frame. Source code in ccg\\data\\tsdata.py 375 376 377 378 379 380 381 382 def remove ( self , signames : str | list [ str ]): \"\"\"Removes sigs from frame.\"\"\" if not isinstance ( signames , list ): signames = [ signames ] for signame in signames : if signame in self : self . tlines . remove ( signame ) self . sigs . pop ( signame , None )","title":"remove"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Frame.resample","text":"Resample Frame to a sample_to TLine. Parameters: sample_to ( TLine ) \u2013 TLine to resample to sigs ( str | list [ str ] | None , default: None ) \u2013 list of sigs to resample, full frame if None, by default None inplace ( bool | None , default: False ) \u2013 if True, will resample signals and append (id prefix or suffix is not None) or replace inplace. By default False prefix ( str | None , default: None ) \u2013 prefix to signame, by default None suffix ( str | None , default: None ) \u2013 suffix to signame, by default None **kwargs \u2013 Additional arguments passed to Sig.resample() Returns: Frame \u2013 Returns Self if inplace, else a new Frame Source code in ccg\\data\\tsdata.py 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 def resample ( self , sample_to : TLine , sigs : str | list [ str ] | None = None , inplace : bool | None = False , prefix : str | None = None , suffix : str | None = None , ** kwargs , ): \"\"\"Resample Frame to a `sample_to` TLine. Parameters ---------- sample_to : TLine TLine to resample to sigs : str | list[str] | None, optional list of sigs to resample, full frame if None, by default None inplace : bool | None, optional if True, will resample signals and append (id prefix or suffix is not None) or replace inplace. By default False prefix : str | None, optional prefix to signame, by default None suffix : str | None, optional suffix to signame, by default None **kwargs Additional arguments passed to `Sig.resample()` Returns ------- Frame Returns Self if inplace, else a new Frame \"\"\" if inplace : res = self else : res = Frame () if sigs is not None : if isinstance ( sigs , str ): sigs = [ sigs ] else : sigs = list ( self . sigs . keys ()) for sig in sigs : newsig = self . sigs [ sig ] . resample ( sample_to , ** kwargs ) if prefix is not None : newsig . name = prefix + newsig . name if suffix is not None : newsig . name = newsig . name + suffix if inplace and prefix is None and suffix is None : res . remove ( sig ) res . append ( newsig ) return res","title":"resample"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Frame.sort","text":"Sort signals by timeline for monoton increasing. Source code in ccg\\data\\tsdata.py 339 340 341 342 343 344 345 346 def sort ( self , remove_safe_duplicates = False , remove_all_duplicates = False ): \"\"\"Sort signals by timeline for monoton increasing.\"\"\" for _ , sig in self . sigs . items (): sig . sort_tline ( inplace = True , remove_safe_duplicates = remove_safe_duplicates , remove_all_duplicates = remove_all_duplicates , )","title":"sort"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Frame.subset","text":"Get a subset of frame. Allows slicing by signals and in timeline. Source code in ccg\\data\\tsdata.py 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 @profile def subset ( self , index : slice , sigs : list [ str ] = None ): \"\"\"Get a subset of frame. Allows slicing by signals and in timeline.\"\"\" res = Frame ( name = self . name ) if sigs is None or not sigs : sigs = self . sigs . keys () if isinstance ( index . start , datetime ): ind_start = index . start . timestamp () else : ind_start = index . start if isinstance ( index . stop , datetime ): ind_stop = index . stop . timestamp () else : ind_stop = index . stop if isinstance ( index . step , timedelta ): step = index . step . total_seconds () else : step = index . step if index . step is None : # No step, so dont resample for tline in self . tlines : if any ( x in sigs for x in self . tlines . sigs [ tline . idn ]): if index . start is None : start = tline . tstart else : start = ind_start if index . stop is None : # Since python is r-worded, this is a special case. # Need to make sure the last sample is included. stop = tline . tend + 0.000001 else : stop = ind_stop inds = np . logical_and ( tline . unix >= start , tline . unix < stop ) if np . any ( inds ): new_tline = TLine ( tline [ inds ]) for signame in self . tlines . sigs [ tline . idn ]: if signame in sigs : old_sig = self . sigs [ signame ] new_sig = Sig ( old_sig ) new_sig . data = old_sig . data [ inds ] new_sig . tline = new_tline res . append ( new_sig ) else : # Step was defined so we need to resample for tline in self . tlines : if index . start is None : start = tline . tstart else : start = ind_start if index . stop is None : stop = tline . tend else : stop = ind_stop new_tline = TLine ( tstart = start , tend = stop , period = step ) for signame in self . tlines . sigs [ tline . idn ]: if signame in sigs : res . append ( self . sigs [ signame ] . resample ( sample_to = new_tline )) return res","title":"subset"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Frame.valid","text":"Returns a new Frame, invalid data replaced with nan. calc'd on tline or combined TLine if None Parameters: gatecoll ( GateColl ) \u2013 Collection of gating conditions tline ( TLine | None , default: None ) \u2013 TLine to calculate validity on, by default None Returns: Frame \u2013 New instance of Frame Source code in ccg\\data\\tsdata.py 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 def valid ( self , gatecoll : GateColl , tline : TLine | None = None ) -> Frame : \"\"\"Returns a new Frame, invalid data replaced with nan. calc'd on `tline` or combined TLine if None Parameters ---------- gatecoll : GateColl Collection of gating conditions tline : TLine | None, optional TLine to calculate validity on, by default None Returns ------- Frame New instance of Frame \"\"\" res = Frame ( name = self . name ) # if tline is None: # tline = self.tlines.get_fastest() valid_sig = gatecoll . validate ( self , tline ) for tmp_tline in self . tlines : if tmp_tline . nsamples > 1 : b_valid = valid_sig . interp ( tmp_tline ) . data for sig in self . tlines . sigs [ tmp_tline . idn ]: newsig = Sig ( self [ sig ]) nan = np . NaN if newsig . data . dtype . kind in [ \"i\" , \"u\" ]: newsig . data = newsig . data . astype ( \"float\" ) elif newsig . data . dtype . kind in [ \"U\" , \"S\" ]: nan = \"\" newsig . data [ ~ b_valid ] = nan res . append ( newsig ) return res","title":"valid"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.SgCoef","text":"Store Savitzky Golay coeficients. Source code in ccg\\data\\tsdata.py 2601 2602 2603 2604 2605 2606 2607 2608 2609 2610 2611 2612 2613 2614 2615 2616 2617 2618 2619 2620 2621 2622 2623 2624 2625 2626 2627 2628 2629 2630 2631 2632 2633 2634 2635 2636 2637 2638 2639 2640 2641 2642 2643 2644 class SgCoef : \"\"\"Store Savitzky Golay coeficients.\"\"\" __slots__ = ( \"orig_index\" , \"sample_to_index\" , \"n_win_orig\" , \"n_ord\" , \"conv\" , \"uniqinvs\" , \"n_uniq\" , \"inds\" , ) def __init__ ( self , orig_index : int = None , sample_to_index : int = None , n_win_orig : int = None , n_ord : int = None , conv : npt . NDArray = None , uniqinvs : npt . NDArray = None , n_uniq : int = None , inds : npt . NDArray = None , ): self . orig_index = orig_index self . sample_to_index = sample_to_index self . n_win_orig = n_win_orig self . n_ord = n_ord self . conv = conv self . uniqinvs = uniqinvs self . n_uniq = n_uniq self . inds = inds def clear ( self ): \"\"\"Clear SgCoef.\"\"\" self . orig_index = None self . sample_to_index = None self . n_win_orig = None self . n_ord = None self . conv = None self . uniqinvs = None self . n_uniq = None self . inds : npt . NDArray = None","title":"SgCoef"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.SgCoef.clear","text":"Clear SgCoef. Source code in ccg\\data\\tsdata.py 2635 2636 2637 2638 2639 2640 2641 2642 2643 2644 def clear ( self ): \"\"\"Clear SgCoef.\"\"\" self . orig_index = None self . sample_to_index = None self . n_win_orig = None self . n_ord = None self . conv = None self . uniqinvs = None self . n_uniq = None self . inds : npt . NDArray = None","title":"clear"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Sig","text":"CCG Sig class. Contains signal data and timeline. Parameters: data ( Sig | NDArray | list | None , default: None ) \u2013 Data source for the signal. tline ( TLine | None , default: None ) \u2013 Timeline instance for signal. Must be same length as data. name ( str | None , default: None ) \u2013 Signal name, must be unique in a Frame . unit ( str | None , default: None ) \u2013 Optional unit. interp_method ( InterpMethod | None , default: None ) \u2013 interpolation method for signal. parent ( Frame | None , default: None ) \u2013 Reference to the 'Frame' if this is in a frame. connect_gaps ( bool | None , default: None ) \u2013 Option for plotting using Plot data_enum ( SigEnum | None , default: None ) \u2013 Enumeration definition to alias values, used for plotting string data. data_range ( list [ float ] | None , default: None ) \u2013 Used for plot scaling. **kwargs \u2013 Argument for inserting unknown attributes. Source code in ccg\\data\\tsdata.py 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622 1623 1624 1625 1626 1627 1628 1629 1630 1631 1632 1633 1634 1635 1636 1637 1638 1639 1640 1641 1642 1643 1644 1645 1646 1647 1648 1649 1650 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664 1665 1666 1667 1668 1669 1670 1671 1672 1673 1674 1675 1676 1677 1678 1679 1680 1681 1682 1683 1684 1685 1686 1687 1688 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699 1700 1701 1702 1703 1704 1705 1706 1707 1708 1709 1710 1711 1712 1713 1714 1715 1716 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741 1742 1743 1744 1745 1746 1747 1748 1749 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 1767 1768 1769 1770 1771 1772 1773 1774 1775 1776 1777 1778 1779 1780 1781 1782 1783 1784 1785 1786 1787 1788 1789 1790 1791 1792 1793 1794 1795 1796 1797 1798 1799 1800 1801 1802 1803 1804 1805 1806 1807 1808 1809 1810 1811 1812 1813 class Sig : \"\"\" CCG Sig class. Contains signal data and timeline. Parameters ---------- data Data source for the signal. tline Timeline instance for signal. Must be same length as data. name Signal name, must be unique in a `Frame`. unit Optional unit. interp_method interpolation method for signal. parent Reference to the 'Frame' if this is in a frame. connect_gaps Option for plotting using `Plot` data_enum Enumeration definition to alias values, used for plotting string data. data_range Used for plot scaling. **kwargs Argument for inserting unknown attributes. \"\"\" _FGAP = 5 @profile def __init__ ( self , data : Sig | npt . NDArray | list | None = None , tline : TLine | None = None , name : str | None = None , unit : str | None = None , interp_method : InterpMethod | None = None , parent : Frame | None = None , connect_gaps : bool | None = None , data_enum : SigEnum | None = None , nsamples : int | None = None , dtype : npt . DTypeLike = None , data_range : list [ float ] | None = None , ** kwargs , ) -> None : self . parent = parent self . connect_gaps = connect_gaps self . data_enum = data_enum self . base_data = None self . _name = None self . _dtype = dtype self . _data : AllocData = None self . interp_method = None if nsamples is None : self . _shape = None else : self . _shape = ( nsamples ,) if tline is not None : self . tline = tline self . unit = unit self . data_range = data_range for key , value in kwargs . items (): setattr ( self , key , value ) if isinstance ( data , Sig ): # This is here to break references safely self . _dtype = data . _dtype self . _shape = data . _shape self . tline = TLine ( data . tline , nsamples = self . _shape ) self . data = data . _data self . data_range = data . data_range self . interp_method = data . interp_method if unit is None : self . unit = data . unit self . _name = data . name if data_enum is None : self . data_enum = data . data_enum if connect_gaps is None : self . connect_gaps = data . connect_gaps if data_range is not None : self . data_range = data_range for key , val in data . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : setattr ( self , key , val ) elif isinstance ( data , list ): self . data = np . array ( data ) elif isinstance ( data , np . ndarray ): self . data = data elif isinstance ( data , ( float , int , np . number )): if tline is not None : self . data = np . ones ( shape = tline . _unix . shape , dtype = type ( data )) * data # self.data = np.array([data] * tline.unix.size, dtype=type(data)) else : self . data = data elif isinstance ( data , str ): if tline is not None : self . data = np . array ([ data ] * tline . nsamples , dtype = type ( data )) else : self . data = data elif data is None : self . data = None # for pre-allocation else : raise NotImplementedError ( f \"Sig gen from { type ( data ) } is not implemented.\" ) if name is not None : self . _name = name if self . _data is None or self . _dtype . type is np . str_ : # This is a string type so make sure interp is nearest self . interp_method = InterpMethod . NEAREST else : if interp_method is not None : self . interp_method = interp_method if self . nsamples and self . nsamples != self . tline . nsamples : _LOGGER . warning ( \"Length of %s 's TLine: %i doesnt match length of it's data: %i \" , self . name , self . tline . nsamples , self . nsamples , ) @property def name ( self ) -> str : \"\"\"Return signal name.\"\"\" return self . _name @name . setter def name ( self , new_name ): if self . parent is not None : self . parent . _rename_sig ( # pylint: disable=access-member-before-definition self . _name , new_name ) self . _name = new_name @property def data ( self ) -> npt . NDArray : \"\"\"data getter\"\"\" return self . _data [:] @data . setter @profile def data ( self , value : npt . NDArray | AllocData | None ): if self . _data is None : # pre-allocate self . _data = AllocData ( data = value , shape = self . _shape , dtype = self . _dtype ) if self . _shape is None : self . _shape = self . _data . shape if self . _dtype is None : self . _dtype = self . _data . data . dtype if not hasattr ( self , \"tline\" ): self . tline = TLine ( nsamples = self . _shape ) else : self . _data . replace ( value ) @property def max ( self ) -> npt . NBitBase | None : \"\"\"Max value.\"\"\" if np . issubdtype ( self . data . dtype , np . number ): try : return np . nanmax ( self . data ) except ValueError : pass return None @property def min ( self ) -> npt . NBitBase | None : \"\"\"Min value.\"\"\" if np . issubdtype ( self . data . dtype , np . number ): try : return np . nanmin ( self . data ) except ValueError : pass return None @property def nsamples ( self ): return self . _data . nsamples @property def appx_bytes ( self ): \"\"\"Estimated size of data [bytes]. Excludes tline.\"\"\" return self . _data . appx_bytes @property def tstart ( self ): \"\"\"Start if tline.\"\"\" return self . tline . tstart @property def tend ( self ): \"\"\"End of tline.\"\"\" return self . tline . tend @property def tstart_iso ( self ): \"\"\"Start if tline.\"\"\" return self . tline . tstart_iso @property def tend_iso ( self ): \"\"\"End of tline.\"\"\" return self . tline . tend_iso @property def period ( self ): \"\"\"apprx period.\"\"\" return self . tline . period def calc_idn ( self ): \"\"\"Calculate hash for IDN.\"\"\" # tic = datetime.now() idn = xxhash . xxh3_64_intdigest ( self . _data . tobytes ()) # toc = datetime.now() - tic # _LOGGER.debug(\"IDN calc'd for %s in %.3f\", self.name, toc.total_seconds()) return idn + self . tline . idn @profile def append ( self , sig : Sig , interweave_tlines = False , remove_duplicates = False ): \"\"\"Append sig to signal.\"\"\" # Check if timelimes overlap check_overlap ( self , sig , interweave_tlines ) if self . parent is None : self . tline . append_inplace ( sig ) else : nshared = len ( self . parent . tlines . sigs [ self . tline . idn ]) if nshared == 1 : self . tline . append_inplace ( sig ) else : self . tline = self . tline . append_to_new ( sig ) self . _data . append ( sig . _data ) # pylint: disable=access-member-before-definition if not self . tline . is_monotonic_increasing : self . sort_tline ( inplace = True , remove_safe_duplicates = remove_duplicates ) if self . parent is not None : self . parent . tlines . remove ( self . name ) self . parent . tlines . append ( self ) # self.tline = tlref # 2/10/24 now in tlines.append() # get the rest of the attributes if sig . connect_gaps is not None : self . connect_gaps = sig . connect_gaps if sig . data_enum is not None : self . data_enum = sig . data_enum if sig . interp_method is not None : self . interp_method = sig . interp_method if sig . unit is not None : self . unit = sig . unit # Check for unknown attributes. the new signal value will overide the original. for key , val in sig . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : setattr ( self , key , val ) def convert_units ( self , unit : str ) -> Sig : \"\"\"Convert units in place\"\"\" if unit != self . unit : self . data = ccg . util . convert_units ( value = self . data , from_unit = self . unit , to_unit = unit ) if self . data_range : self . data_range = ccg . util . convert_units ( value = self . data_range , from_unit = self . unit , to_unit = unit ) self . unit = unit return self def as_unit ( self , unit : str ) -> Sig : \"\"\"return new sig converted to unit\"\"\" sig = Sig ( self ) sig . convert_units ( unit ) return sig def sort_tline ( self , inplace = True , remove_safe_duplicates = False , remove_all_duplicates = False , ): \"\"\"Sort signal by timeline. Parameters ---------- inplace Sorts signal in place, returns None. remove_duplicates Will remove duplicate timestamps if signal is also duplicated. Returns ------- Sig self if `inplace=True`. \"\"\" inds = np . argsort ( self . tline . unix , kind = \"stable\" ) if inplace : self . tline = TLine ( self . tline . unix [ inds ]) if self . nsamples > 0 : self . data = self . data [ inds ] if remove_safe_duplicates : self . _remove_duplicates ( remove_all_duplicates ) if self . parent is not None : self . parent . tlines . remove ( self . name ) self . parent . tlines . append ( self ) # self.tline = tlref # 2/10/24 now in tlines.append() return self sig = Sig ( self ) # TODO: clean this up to not define, then edit. sig . name = sig . name + \"_sorted\" sig . tline = TLine ( self . tline . unix [ inds ]) if self . nsamples > 0 : sig . data = sig . data [ inds ] if remove_safe_duplicates : sig . _remove_duplicates ( remove_all_duplicates ) # pylint: disable=access-member-before-definition return sig def _remove_duplicates ( self , remove_all_duplicates = False ): \"\"\"Removes duplicate samples if both time and data match. If `remove_all_duplicates=True`, will remove duplicates even if values dont match. **Must be sorted first** Use `self.sort_tline(remove_safe_duplicates=True, remove_all_duplicates=True)` \"\"\" # Check if its monoton increasing now. if not self . tline . is_monotonic_increasing : # find duplicate timestamps inds = self . tline . dt == 0 if self . data . dtype . kind in [ \"i\" , \"u\" , \"f\" ]: data_dt = np . diff ( self . data ) data_dt = data_dt == 0 else : data_dt = self . data [ 1 :] == self . data [ 0 : - 1 ] dups = inds & data_dt dups = np . append ( False , dups ) if np . any ( dups ): _LOGGER . debug ( \"Removed %i duplicates from %s .\" , np . sum ( dups ), self . name ) self . tline = TLine ( self . tline . unix [ ~ dups ]) self . data = self . data [ ~ dups ] # If there are still duplicates, there are different values at the same timestep. if remove_all_duplicates and not self . tline . is_monotonic_increasing : inds = self . tline . dt == 0 dups = inds dups = np . append ( False , dups ) if np . any ( dups ): _LOGGER . warning ( \"Removed %i duplicate timestamps with different values from %s .\" , np . sum ( dups ), self . name , ) self . tline = TLine ( self . tline . unix [ ~ dups ]) self . data = self . data [ ~ dups ] @profile def plot_prep ( self ) -> Sig : \"\"\"Prepare for plotting. Sorts tline and removes duplicates. Inserts NaNs in gaps if `connect_gaps=False | None`. Applies enum if it exists. \"\"\" res = self if not self . tline . is_monotonic_increasing : self . sort_tline ( remove_safe_duplicates = True ) if self . connect_gaps is None or not self . connect_gaps : gaps = np . greater ( self . tline . dt , self . _FGAP * self . tline . period , ) if np . sum ( gaps ) > 0 : res = Sig ( self ) # Make a copy before resampling. tline = TLine ( self . tline . unix [ np . append ( gaps , False )] + ( self . tline . dt [ gaps ] / 2 ) ) if self . _data . data . dtype . kind in ( \"i\" , \"u\" , \"b\" , \"M\" ): # Since numpy is r-worded and cant use a nan in an int, we need to convert to float self . _data . replace ( self . data . astype ( \"float\" , copy = False )) self . _dtype = self . _data . dtype nans = np . empty ( np . sum ( gaps ), dtype = self . _dtype ) nans [:] = np . nan res . append ( Sig ( data = nans , tline = tline ), interweave_tlines = True ) if res . data_enum is not None : res . base_data = res . data res . data = res . data_enum . data_to_enum ( res . data ) return res def interp ( self , points : npt . NDArray | TLine , extrapolate : bool = False ) -> Sig : \"\"\"Interpolate signal to points.\"\"\" if isinstance ( points , TLine ): points = points . unix if self . interp_method is None or self . interp_method == InterpMethod . LINEAR : new = ccg . util . linearinterp ( self . tline . unix , self . data , points , extrapolate ) elif self . interp_method == InterpMethod . ZOH : new = self . data [ np . maximum ( np . minimum ( np . searchsorted ( self . tline . unix , points , side = \"right\" ) - 1 , self . nsamples - 1 , ), 0 , ) ] else : # TODO: Implement other interp methods. raise NotImplementedError ( f \" { self . interp_method } not implemented.\" ) res = Sig ( self ) # To create a copy first res . data = new res . tline = TLine ( points ) return res @profile def resample ( self : Sig , sample_to : TLine , n_win : int = None , n_ord : int = None , gap_fraction : float = None , interp_gaps = False , ) -> Sig : \"\"\"Resample with Savitzky Golay filter. Parameters ---------- sample_to TLine to resample to n_win window size, should be odd. Is relative to the sample_to index n_ord order of the fit gap_fraction size of a gap relative to the window size to interpolate between Returns ------- New resampled Sig \"\"\" # Skip if the same and default window/order if ( sample_to != self . tline or n_win is not None or n_ord is not None or gap_fraction is not None ): tic = datetime . now () if n_win is None : n_win = 5 if n_ord is None : n_ord = 3 if gap_fraction is None : gap_fraction = 0.5 if self . data . dtype . kind in { \"U\" , \"S\" }: # This is a string type raise NotImplementedError ( \"Cant resample string type.\" ) if not sample_to . is_monotonic_increasing : sample_to = sample_to . sort () if not self . tline . is_monotonic_increasing : self . sort_tline () nsamplesnew = len ( sample_to ) # dt_new = sample_to.dt dtm_new = np . maximum ( sample_to . period , 0.001 ) dt_orig = self . tline . dt dtm_orig = np . maximum ( self . tline . period , 0.001 ) n_win_orig = int ( np . ceil ( max ( n_win , round ( n_win * dtm_new / dtm_orig ))) // 2 * 2 + 1 ) # Detect gaps larger than gap_fraction windows gaps = np . flatnonzero ( dt_orig > n_win_orig * dtm_orig * gap_fraction ) # interpolate between gaps ind_in_gap = [] for gap in gaps : origx = self . tline . unix [ gap : gap + 2 ] ind_in_gap . extend ( * np . where (( sample_to . unix > origx [ 0 ]) & ( sample_to . unix < origx [ 1 ])) ) if interp_gaps and len ( gaps ) > 0 : newx = np . concatenate ( ( self . tline . unix , sample_to . unix [ ind_in_gap ], ), ) newx . sort () orig = self . interp ( newx ) invalid = [] else : orig = self invalid = ind_in_gap inds , convs = orig . tline . savgol_coef ( sample_to , n_ord , n_win_orig , ) ys0 = np . empty (( nsamplesnew , n_win_orig )) ys0 [:, :] = np . reshape ( orig . data [ inds . ravel ()], ( nsamplesnew , n_win_orig ), ) # Calc diaganol only of dot product result = np . einsum ( \"ij,ji->i\" , ys0 [:, :], convs ) if np . any ( invalid ): result [ invalid ] = np . NaN res = Sig ( self ) # To get all attr of inital # then update to new values res . data = result res . tline = sample_to toc = datetime . now () - tic _LOGGER . debug ( \"Resampled %s from %s to %s samples in %.3f [s]\" , self . name , format ( self . nsamples , \",\" ), format ( res . nsamples , \",\" ), toc . total_seconds (), ) else : res = Sig ( self ) return res def dot ( self , n_dot : int = 1 , n_win : int = 5 , n_ord : int = 3 , ): \"\"\"Calculate Derivative of signal. Returns new sig.\"\"\" tic = datetime . now () inds , convs = self . tline . savgol_coef ( self . tline , n_ord , n_win , n_dot , ) ys0 = np . empty (( self . nsamples , n_win )) ys0 [:, :] = np . reshape ( self . data [ inds . ravel ()], ( self . nsamples , n_win ), ) # Calc diaganol only of dot product result = np . einsum ( \"ij,ji->i\" , ys0 [:, :], convs ) res = Sig ( self ) # To get all attr of inital # then update to new values res . name = f ' { res . name } _ { \"\" . join ([ \"dot\" ] * n_dot ) } ' res . unit = ( f ' { res . unit if res . unit else \"\" } /s { \"\" if n_dot == 1 else \"^\" + n_dot } ' ) res . data = result toc = datetime . now () - tic _LOGGER . debug ( \"Deriv of %s in %.3f [s]\" , self . name , toc . total_seconds (), ) return res def valid ( self , gatecoll : GateColl , frame : Frame = None ): \"\"\"Return new signal with invalid data replaced with nan's\"\"\" # tic = datetime.now() if frame is None and self . parent is None : raise ValueError ( \"`Sig.valid()` requires frame argument if sig has no parent.\" ) if frame is None : frame = self . parent res = Sig ( self ) # copy valid_sig = gatecoll . validate ( frame ) b_valid = valid_sig . interp ( self . tline ) . data nan = np . NaN if res . data . dtype . kind in [ \"i\" , \"u\" ]: res . data = res . data . astype ( \"float\" ) elif res . data . dtype . kind in [ \"U\" , \"S\" ]: nan = \"\" res . data [ ~ b_valid ] = nan # toc = datetime.now() - tic # _LOGGER.debug( # \"get valid sig %s in %.3f\", self.name, toc.total_seconds() # ) return res def __len__ ( self ) -> int : return self . nsamples def __repr__ ( self ) -> str : \"\"\"Return string representation.\"\"\" reprstr = f \" { self . __class__ . __qualname__ } ( { self . data . __repr__ () } )\" return reprstr def __str__ ( self ) -> str : \"\"\"Return readable string.\"\"\" return self . data . __str__ () def __add__ ( self , other ): \"\"\"add, resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , unit = self . unit , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] + %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . resample ( tline ) . data res . data = self . resample ( tline ) . data + other return res def __sub__ ( self , other ): \"\"\"subtract, resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , unit = self . unit , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] - %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . resample ( tline ) . data res . data = self . resample ( tline ) . data - other return res def __radd__ ( self , other ): \"\"\"add, resamples to parent.math_tline if exists. returns Sig.\"\"\" return self . __add__ ( other ) def __rsub__ ( self , other ): \"\"\"subtract, resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , unit = self . unit , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] - %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . resample ( tline ) . data res . data = other - self . resample ( tline ) . data return res def __mul__ ( self , other ): \"\"\"multiply(elementwise), resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): if ( self . unit and other . unit is None ) or other . unit . lower () == \"ratio\" : unit = self . unit elif ( self . unit is None or self . unit . lower () == \"ratio\" ) and other . unit : unit = other . unit elif self . unit and self . unit == other . unit : unit = self . unit + \"**2\" else : unit = f \" { self . unit } * { other . unit } \" other = other . resample ( tline ) . data else : unit = self . unit res . unit = unit res . data = self . resample ( tline ) . data * other return res def __truediv__ ( self , other ): \"\"\"divide(elementwise), resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): if ( self . unit and other . unit is None ) or other . unit . lower () == \"ratio\" : unit = self . unit elif ( self . unit is None or self . unit . lower () == \"ratio\" ) and other . unit : unit = other . unit elif self . unit and self . unit == other . unit : unit = \"ratio\" else : unit = f \" { self . unit } / { other . unit } \" other = other . resample ( tline ) . data else : unit = self . unit res . unit = unit res . data = self . resample ( tline ) . data / other return res def __pow__ ( self , other ): \"\"\"power, resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): other = other . resample ( tline ) . data unit = f \" { self . unit } **n\" elif len ( other ) == 1 : unit = f \" { self . unit } ** { other } \" if self . unit . lower () == \"ratio\" : unit = \"ratio\" res . unit = unit res . data = self . resample ( tline ) . data ** other return res def __abs__ ( self ): \"\"\"abs\"\"\" res = Sig ( self , name = f \"abs( { self . name } )\" , dtype = self . _dtype ) res . data = np . abs ( self . data ) return res def __neg__ ( self ): \"\"\"neg\"\"\" res = Sig ( self , name = f \"neg( { self . name } )\" , dtype = self . _dtype ) res . data = self . data * - 1 return res def __eq__ ( self , other ) -> bool : \"\"\"Check equality.\"\"\" if isinstance ( other , self . __class__ ): iseq = ( np . array_equal ( self . data , other . data ) and np . array_equal ( self . tline , other . tline ) and self . interp_method == other . interp_method and self . connect_gaps == other . connect_gaps and self . unit == other . unit ) if iseq : for key , val in self . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : try : iseq = iseq and val == getattr ( other , key ) except KeyError : iseq = False if iseq : # if its still true, we better check if theres an unk attr in the other for key , val in self . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : try : iseq = iseq and val == getattr ( self , key ) except KeyError : iseq = False return iseq else : return False # @profile def __getitem__ ( self , index : int | list [ int ] | slice | npt . NDArray ): \"\"\"Get item of Sig.\"\"\" if isinstance ( index , slice ) or isinstance ( index , int ): res = self . data [ index ] elif isinstance ( index , np . ndarray ) and index . dtype . kind in ( \"b\" ): # res = copy.deepcopy(self) # res.tline.unix = self.tline.unix[index] # res.data = self.data[index] # # Deepcopy is so slow. Lets try re-building signals instead unks = {} for key , val in self . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : unks . update ({ key : val }) res = Sig ( data = self . data [ index ], tline = TLine ( self . tline . unix [ index ]), name = self . name , unit = self . unit , interp_method = self . interp_method , connect_gaps = self . connect_gaps , data_enum = self . data_enum , ** unks , ) else : raise NotImplementedError ( \"unexpected index for signal\" ) return res def __setitem__ ( self , index : tuple [ slice | list | int | npt . NDArray ] | slice , value : list | npt . NDArray | str , ): \"\"\"Set item\"\"\" self . _data [ index ] = value def __iter__ ( self ): \"\"\"Iterate.\"\"\" return iter ( self . data ) def __next__ ( self ): \"\"\"Next.\"\"\" return next ( self . data ) def __deepcopy__ ( self , memo ): # pylint: disable= method-hidden \"\"\"Deepcopy of a CCGSig. Referenced frame is removed.\"\"\" deepcopy_method = self . __deepcopy__ self . __deepcopy__ = None cpy = copy . deepcopy ( self , memo ) cpy . parent = None # To avoid recursion and confusion self . __deepcopy__ = deepcopy_method # Copy the function object func = types . FunctionType ( deepcopy_method . __code__ , deepcopy_method . __globals__ , deepcopy_method . __name__ , deepcopy_method . __defaults__ , deepcopy_method . __closure__ , ) # Bind to cp and set bound_method = func . __get__ ( cpy , cpy . __class__ ) # pylint: disable=no-member cpy . __deepcopy__ = bound_method return cpy","title":"Sig"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Sig.appx_bytes","text":"Estimated size of data [bytes]. Excludes tline.","title":"appx_bytes"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Sig.data","text":"data getter","title":"data"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Sig.max","text":"Max value.","title":"max"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Sig.min","text":"Min value.","title":"min"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Sig.name","text":"Return signal name.","title":"name"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Sig.period","text":"apprx period.","title":"period"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Sig.tend","text":"End of tline.","title":"tend"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Sig.tend_iso","text":"End of tline.","title":"tend_iso"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Sig.tstart","text":"Start if tline.","title":"tstart"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Sig.tstart_iso","text":"Start if tline.","title":"tstart_iso"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Sig.__abs__","text":"abs Source code in ccg\\data\\tsdata.py 1705 1706 1707 1708 1709 def __abs__ ( self ): \"\"\"abs\"\"\" res = Sig ( self , name = f \"abs( { self . name } )\" , dtype = self . _dtype ) res . data = np . abs ( self . data ) return res","title":"__abs__"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Sig.__add__","text":"add, resamples to parent.math_tline if exists. returns Sig. Source code in ccg\\data\\tsdata.py 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 def __add__ ( self , other ): \"\"\"add, resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , unit = self . unit , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] + %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . resample ( tline ) . data res . data = self . resample ( tline ) . data + other return res","title":"__add__"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Sig.__deepcopy__","text":"Deepcopy of a CCGSig. Referenced frame is removed. Source code in ccg\\data\\tsdata.py 1792 1793 1794 1795 1796 1797 1798 1799 1800 1801 1802 1803 1804 1805 1806 1807 1808 1809 1810 1811 1812 1813 def __deepcopy__ ( self , memo ): # pylint: disable= method-hidden \"\"\"Deepcopy of a CCGSig. Referenced frame is removed.\"\"\" deepcopy_method = self . __deepcopy__ self . __deepcopy__ = None cpy = copy . deepcopy ( self , memo ) cpy . parent = None # To avoid recursion and confusion self . __deepcopy__ = deepcopy_method # Copy the function object func = types . FunctionType ( deepcopy_method . __code__ , deepcopy_method . __globals__ , deepcopy_method . __name__ , deepcopy_method . __defaults__ , deepcopy_method . __closure__ , ) # Bind to cp and set bound_method = func . __get__ ( cpy , cpy . __class__ ) # pylint: disable=no-member cpy . __deepcopy__ = bound_method return cpy","title":"__deepcopy__"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Sig.__eq__","text":"Check equality. Source code in ccg\\data\\tsdata.py 1717 1718 1719 1720 1721 1722 1723 1724 1725 1726 1727 1728 1729 1730 1731 1732 1733 1734 1735 1736 1737 1738 1739 1740 1741 1742 1743 1744 1745 def __eq__ ( self , other ) -> bool : \"\"\"Check equality.\"\"\" if isinstance ( other , self . __class__ ): iseq = ( np . array_equal ( self . data , other . data ) and np . array_equal ( self . tline , other . tline ) and self . interp_method == other . interp_method and self . connect_gaps == other . connect_gaps and self . unit == other . unit ) if iseq : for key , val in self . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : try : iseq = iseq and val == getattr ( other , key ) except KeyError : iseq = False if iseq : # if its still true, we better check if theres an unk attr in the other for key , val in self . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : try : iseq = iseq and val == getattr ( self , key ) except KeyError : iseq = False return iseq else : return False","title":"__eq__"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Sig.__getitem__","text":"Get item of Sig. Source code in ccg\\data\\tsdata.py 1748 1749 1750 1751 1752 1753 1754 1755 1756 1757 1758 1759 1760 1761 1762 1763 1764 1765 1766 1767 1768 1769 1770 1771 1772 1773 1774 def __getitem__ ( self , index : int | list [ int ] | slice | npt . NDArray ): \"\"\"Get item of Sig.\"\"\" if isinstance ( index , slice ) or isinstance ( index , int ): res = self . data [ index ] elif isinstance ( index , np . ndarray ) and index . dtype . kind in ( \"b\" ): # res = copy.deepcopy(self) # res.tline.unix = self.tline.unix[index] # res.data = self.data[index] # # Deepcopy is so slow. Lets try re-building signals instead unks = {} for key , val in self . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : unks . update ({ key : val }) res = Sig ( data = self . data [ index ], tline = TLine ( self . tline . unix [ index ]), name = self . name , unit = self . unit , interp_method = self . interp_method , connect_gaps = self . connect_gaps , data_enum = self . data_enum , ** unks , ) else : raise NotImplementedError ( \"unexpected index for signal\" ) return res","title":"__getitem__"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Sig.__iter__","text":"Iterate. Source code in ccg\\data\\tsdata.py 1784 1785 1786 def __iter__ ( self ): \"\"\"Iterate.\"\"\" return iter ( self . data )","title":"__iter__"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Sig.__mul__","text":"multiply(elementwise), resamples to parent.math_tline if exists. returns Sig. Source code in ccg\\data\\tsdata.py 1648 1649 1650 1651 1652 1653 1654 1655 1656 1657 1658 1659 1660 1661 1662 1663 1664 1665 1666 def __mul__ ( self , other ): \"\"\"multiply(elementwise), resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): if ( self . unit and other . unit is None ) or other . unit . lower () == \"ratio\" : unit = self . unit elif ( self . unit is None or self . unit . lower () == \"ratio\" ) and other . unit : unit = other . unit elif self . unit and self . unit == other . unit : unit = self . unit + \"**2\" else : unit = f \" { self . unit } * { other . unit } \" other = other . resample ( tline ) . data else : unit = self . unit res . unit = unit res . data = self . resample ( tline ) . data * other return res","title":"__mul__"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Sig.__neg__","text":"neg Source code in ccg\\data\\tsdata.py 1711 1712 1713 1714 1715 def __neg__ ( self ): \"\"\"neg\"\"\" res = Sig ( self , name = f \"neg( { self . name } )\" , dtype = self . _dtype ) res . data = self . data * - 1 return res","title":"__neg__"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Sig.__next__","text":"Next. Source code in ccg\\data\\tsdata.py 1788 1789 1790 def __next__ ( self ): \"\"\"Next.\"\"\" return next ( self . data )","title":"__next__"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Sig.__pow__","text":"power, resamples to parent.math_tline if exists. returns Sig. Source code in ccg\\data\\tsdata.py 1688 1689 1690 1691 1692 1693 1694 1695 1696 1697 1698 1699 1700 1701 1702 1703 def __pow__ ( self , other ): \"\"\"power, resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): other = other . resample ( tline ) . data unit = f \" { self . unit } **n\" elif len ( other ) == 1 : unit = f \" { self . unit } ** { other } \" if self . unit . lower () == \"ratio\" : unit = \"ratio\" res . unit = unit res . data = self . resample ( tline ) . data ** other return res","title":"__pow__"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Sig.__radd__","text":"add, resamples to parent.math_tline if exists. returns Sig. Source code in ccg\\data\\tsdata.py 1626 1627 1628 def __radd__ ( self , other ): \"\"\"add, resamples to parent.math_tline if exists. returns Sig.\"\"\" return self . __add__ ( other )","title":"__radd__"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Sig.__repr__","text":"Return string representation. Source code in ccg\\data\\tsdata.py 1581 1582 1583 1584 def __repr__ ( self ) -> str : \"\"\"Return string representation.\"\"\" reprstr = f \" { self . __class__ . __qualname__ } ( { self . data . __repr__ () } )\" return reprstr","title":"__repr__"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Sig.__rsub__","text":"subtract, resamples to parent.math_tline if exists. returns Sig. Source code in ccg\\data\\tsdata.py 1630 1631 1632 1633 1634 1635 1636 1637 1638 1639 1640 1641 1642 1643 1644 1645 1646 def __rsub__ ( self , other ): \"\"\"subtract, resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , unit = self . unit , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] - %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . resample ( tline ) . data res . data = other - self . resample ( tline ) . data return res","title":"__rsub__"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Sig.__setitem__","text":"Set item Source code in ccg\\data\\tsdata.py 1776 1777 1778 1779 1780 1781 1782 def __setitem__ ( self , index : tuple [ slice | list | int | npt . NDArray ] | slice , value : list | npt . NDArray | str , ): \"\"\"Set item\"\"\" self . _data [ index ] = value","title":"__setitem__"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Sig.__str__","text":"Return readable string. Source code in ccg\\data\\tsdata.py 1586 1587 1588 def __str__ ( self ) -> str : \"\"\"Return readable string.\"\"\" return self . data . __str__ ()","title":"__str__"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Sig.__sub__","text":"subtract, resamples to parent.math_tline if exists. returns Sig. Source code in ccg\\data\\tsdata.py 1608 1609 1610 1611 1612 1613 1614 1615 1616 1617 1618 1619 1620 1621 1622 1623 1624 def __sub__ ( self , other ): \"\"\"subtract, resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , unit = self . unit , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): if self . unit != other . unit : _LOGGER . warning ( \"Units incompatible in %s [ %s ] - %s [ %s ]\" , self . name , self . unit , other . name , other . unit , ) other = other . resample ( tline ) . data res . data = self . resample ( tline ) . data - other return res","title":"__sub__"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Sig.__truediv__","text":"divide(elementwise), resamples to parent.math_tline if exists. returns Sig. Source code in ccg\\data\\tsdata.py 1668 1669 1670 1671 1672 1673 1674 1675 1676 1677 1678 1679 1680 1681 1682 1683 1684 1685 1686 def __truediv__ ( self , other ): \"\"\"divide(elementwise), resamples to parent.math_tline if exists. returns Sig.\"\"\" tline = get_math_tline ( self , other ) res = Sig ( name = \"_result\" , tline = tline , dtype = self . _dtype ) if isinstance ( other , Sig ): if ( self . unit and other . unit is None ) or other . unit . lower () == \"ratio\" : unit = self . unit elif ( self . unit is None or self . unit . lower () == \"ratio\" ) and other . unit : unit = other . unit elif self . unit and self . unit == other . unit : unit = \"ratio\" else : unit = f \" { self . unit } / { other . unit } \" other = other . resample ( tline ) . data else : unit = self . unit res . unit = unit res . data = self . resample ( tline ) . data / other return res","title":"__truediv__"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Sig.append","text":"Append sig to signal. Source code in ccg\\data\\tsdata.py 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 @profile def append ( self , sig : Sig , interweave_tlines = False , remove_duplicates = False ): \"\"\"Append sig to signal.\"\"\" # Check if timelimes overlap check_overlap ( self , sig , interweave_tlines ) if self . parent is None : self . tline . append_inplace ( sig ) else : nshared = len ( self . parent . tlines . sigs [ self . tline . idn ]) if nshared == 1 : self . tline . append_inplace ( sig ) else : self . tline = self . tline . append_to_new ( sig ) self . _data . append ( sig . _data ) # pylint: disable=access-member-before-definition if not self . tline . is_monotonic_increasing : self . sort_tline ( inplace = True , remove_safe_duplicates = remove_duplicates ) if self . parent is not None : self . parent . tlines . remove ( self . name ) self . parent . tlines . append ( self ) # self.tline = tlref # 2/10/24 now in tlines.append() # get the rest of the attributes if sig . connect_gaps is not None : self . connect_gaps = sig . connect_gaps if sig . data_enum is not None : self . data_enum = sig . data_enum if sig . interp_method is not None : self . interp_method = sig . interp_method if sig . unit is not None : self . unit = sig . unit # Check for unknown attributes. the new signal value will overide the original. for key , val in sig . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS : setattr ( self , key , val )","title":"append"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Sig.as_unit","text":"return new sig converted to unit Source code in ccg\\data\\tsdata.py 1240 1241 1242 1243 1244 def as_unit ( self , unit : str ) -> Sig : \"\"\"return new sig converted to unit\"\"\" sig = Sig ( self ) sig . convert_units ( unit ) return sig","title":"as_unit"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Sig.calc_idn","text":"Calculate hash for IDN. Source code in ccg\\data\\tsdata.py 1180 1181 1182 1183 1184 1185 1186 1187 1188 def calc_idn ( self ): \"\"\"Calculate hash for IDN.\"\"\" # tic = datetime.now() idn = xxhash . xxh3_64_intdigest ( self . _data . tobytes ()) # toc = datetime.now() - tic # _LOGGER.debug(\"IDN calc'd for %s in %.3f\", self.name, toc.total_seconds()) return idn + self . tline . idn","title":"calc_idn"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Sig.convert_units","text":"Convert units in place Source code in ccg\\data\\tsdata.py 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 def convert_units ( self , unit : str ) -> Sig : \"\"\"Convert units in place\"\"\" if unit != self . unit : self . data = ccg . util . convert_units ( value = self . data , from_unit = self . unit , to_unit = unit ) if self . data_range : self . data_range = ccg . util . convert_units ( value = self . data_range , from_unit = self . unit , to_unit = unit ) self . unit = unit return self","title":"convert_units"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Sig.dot","text":"Calculate Derivative of signal. Returns new sig. Source code in ccg\\data\\tsdata.py 1512 1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 def dot ( self , n_dot : int = 1 , n_win : int = 5 , n_ord : int = 3 , ): \"\"\"Calculate Derivative of signal. Returns new sig.\"\"\" tic = datetime . now () inds , convs = self . tline . savgol_coef ( self . tline , n_ord , n_win , n_dot , ) ys0 = np . empty (( self . nsamples , n_win )) ys0 [:, :] = np . reshape ( self . data [ inds . ravel ()], ( self . nsamples , n_win ), ) # Calc diaganol only of dot product result = np . einsum ( \"ij,ji->i\" , ys0 [:, :], convs ) res = Sig ( self ) # To get all attr of inital # then update to new values res . name = f ' { res . name } _ { \"\" . join ([ \"dot\" ] * n_dot ) } ' res . unit = ( f ' { res . unit if res . unit else \"\" } /s { \"\" if n_dot == 1 else \"^\" + n_dot } ' ) res . data = result toc = datetime . now () - tic _LOGGER . debug ( \"Deriv of %s in %.3f [s]\" , self . name , toc . total_seconds (), ) return res","title":"dot"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Sig.interp","text":"Interpolate signal to points. Source code in ccg\\data\\tsdata.py 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 def interp ( self , points : npt . NDArray | TLine , extrapolate : bool = False ) -> Sig : \"\"\"Interpolate signal to points.\"\"\" if isinstance ( points , TLine ): points = points . unix if self . interp_method is None or self . interp_method == InterpMethod . LINEAR : new = ccg . util . linearinterp ( self . tline . unix , self . data , points , extrapolate ) elif self . interp_method == InterpMethod . ZOH : new = self . data [ np . maximum ( np . minimum ( np . searchsorted ( self . tline . unix , points , side = \"right\" ) - 1 , self . nsamples - 1 , ), 0 , ) ] else : # TODO: Implement other interp methods. raise NotImplementedError ( f \" { self . interp_method } not implemented.\" ) res = Sig ( self ) # To create a copy first res . data = new res . tline = TLine ( points ) return res","title":"interp"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Sig.plot_prep","text":"Prepare for plotting. Sorts tline and removes duplicates. Inserts NaNs in gaps if connect_gaps=False | None . Applies enum if it exists. Source code in ccg\\data\\tsdata.py 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 @profile def plot_prep ( self ) -> Sig : \"\"\"Prepare for plotting. Sorts tline and removes duplicates. Inserts NaNs in gaps if `connect_gaps=False | None`. Applies enum if it exists. \"\"\" res = self if not self . tline . is_monotonic_increasing : self . sort_tline ( remove_safe_duplicates = True ) if self . connect_gaps is None or not self . connect_gaps : gaps = np . greater ( self . tline . dt , self . _FGAP * self . tline . period , ) if np . sum ( gaps ) > 0 : res = Sig ( self ) # Make a copy before resampling. tline = TLine ( self . tline . unix [ np . append ( gaps , False )] + ( self . tline . dt [ gaps ] / 2 ) ) if self . _data . data . dtype . kind in ( \"i\" , \"u\" , \"b\" , \"M\" ): # Since numpy is r-worded and cant use a nan in an int, we need to convert to float self . _data . replace ( self . data . astype ( \"float\" , copy = False )) self . _dtype = self . _data . dtype nans = np . empty ( np . sum ( gaps ), dtype = self . _dtype ) nans [:] = np . nan res . append ( Sig ( data = nans , tline = tline ), interweave_tlines = True ) if res . data_enum is not None : res . base_data = res . data res . data = res . data_enum . data_to_enum ( res . data ) return res","title":"plot_prep"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Sig.resample","text":"Resample with Savitzky Golay filter. Parameters: sample_to ( TLine ) \u2013 TLine to resample to n_win ( int , default: None ) \u2013 window size, should be odd. Is relative to the sample_to index n_ord ( int , default: None ) \u2013 order of the fit gap_fraction ( float , default: None ) \u2013 size of a gap relative to the window size to interpolate between Returns: New resampled Sig \u2013 Source code in ccg\\data\\tsdata.py 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 @profile def resample ( self : Sig , sample_to : TLine , n_win : int = None , n_ord : int = None , gap_fraction : float = None , interp_gaps = False , ) -> Sig : \"\"\"Resample with Savitzky Golay filter. Parameters ---------- sample_to TLine to resample to n_win window size, should be odd. Is relative to the sample_to index n_ord order of the fit gap_fraction size of a gap relative to the window size to interpolate between Returns ------- New resampled Sig \"\"\" # Skip if the same and default window/order if ( sample_to != self . tline or n_win is not None or n_ord is not None or gap_fraction is not None ): tic = datetime . now () if n_win is None : n_win = 5 if n_ord is None : n_ord = 3 if gap_fraction is None : gap_fraction = 0.5 if self . data . dtype . kind in { \"U\" , \"S\" }: # This is a string type raise NotImplementedError ( \"Cant resample string type.\" ) if not sample_to . is_monotonic_increasing : sample_to = sample_to . sort () if not self . tline . is_monotonic_increasing : self . sort_tline () nsamplesnew = len ( sample_to ) # dt_new = sample_to.dt dtm_new = np . maximum ( sample_to . period , 0.001 ) dt_orig = self . tline . dt dtm_orig = np . maximum ( self . tline . period , 0.001 ) n_win_orig = int ( np . ceil ( max ( n_win , round ( n_win * dtm_new / dtm_orig ))) // 2 * 2 + 1 ) # Detect gaps larger than gap_fraction windows gaps = np . flatnonzero ( dt_orig > n_win_orig * dtm_orig * gap_fraction ) # interpolate between gaps ind_in_gap = [] for gap in gaps : origx = self . tline . unix [ gap : gap + 2 ] ind_in_gap . extend ( * np . where (( sample_to . unix > origx [ 0 ]) & ( sample_to . unix < origx [ 1 ])) ) if interp_gaps and len ( gaps ) > 0 : newx = np . concatenate ( ( self . tline . unix , sample_to . unix [ ind_in_gap ], ), ) newx . sort () orig = self . interp ( newx ) invalid = [] else : orig = self invalid = ind_in_gap inds , convs = orig . tline . savgol_coef ( sample_to , n_ord , n_win_orig , ) ys0 = np . empty (( nsamplesnew , n_win_orig )) ys0 [:, :] = np . reshape ( orig . data [ inds . ravel ()], ( nsamplesnew , n_win_orig ), ) # Calc diaganol only of dot product result = np . einsum ( \"ij,ji->i\" , ys0 [:, :], convs ) if np . any ( invalid ): result [ invalid ] = np . NaN res = Sig ( self ) # To get all attr of inital # then update to new values res . data = result res . tline = sample_to toc = datetime . now () - tic _LOGGER . debug ( \"Resampled %s from %s to %s samples in %.3f [s]\" , self . name , format ( self . nsamples , \",\" ), format ( res . nsamples , \",\" ), toc . total_seconds (), ) else : res = Sig ( self ) return res","title":"resample"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Sig.sort_tline","text":"Sort signal by timeline. Parameters: inplace \u2013 Sorts signal in place, returns None. remove_duplicates \u2013 Will remove duplicate timestamps if signal is also duplicated. Returns: Sig \u2013 self if inplace=True . Source code in ccg\\data\\tsdata.py 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 def sort_tline ( self , inplace = True , remove_safe_duplicates = False , remove_all_duplicates = False , ): \"\"\"Sort signal by timeline. Parameters ---------- inplace Sorts signal in place, returns None. remove_duplicates Will remove duplicate timestamps if signal is also duplicated. Returns ------- Sig self if `inplace=True`. \"\"\" inds = np . argsort ( self . tline . unix , kind = \"stable\" ) if inplace : self . tline = TLine ( self . tline . unix [ inds ]) if self . nsamples > 0 : self . data = self . data [ inds ] if remove_safe_duplicates : self . _remove_duplicates ( remove_all_duplicates ) if self . parent is not None : self . parent . tlines . remove ( self . name ) self . parent . tlines . append ( self ) # self.tline = tlref # 2/10/24 now in tlines.append() return self sig = Sig ( self ) # TODO: clean this up to not define, then edit. sig . name = sig . name + \"_sorted\" sig . tline = TLine ( self . tline . unix [ inds ]) if self . nsamples > 0 : sig . data = sig . data [ inds ] if remove_safe_duplicates : sig . _remove_duplicates ( remove_all_duplicates ) # pylint: disable=access-member-before-definition return sig","title":"sort_tline"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.Sig.valid","text":"Return new signal with invalid data replaced with nan's Source code in ccg\\data\\tsdata.py 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 1573 1574 1575 1576 def valid ( self , gatecoll : GateColl , frame : Frame = None ): \"\"\"Return new signal with invalid data replaced with nan's\"\"\" # tic = datetime.now() if frame is None and self . parent is None : raise ValueError ( \"`Sig.valid()` requires frame argument if sig has no parent.\" ) if frame is None : frame = self . parent res = Sig ( self ) # copy valid_sig = gatecoll . validate ( frame ) b_valid = valid_sig . interp ( self . tline ) . data nan = np . NaN if res . data . dtype . kind in [ \"i\" , \"u\" ]: res . data = res . data . astype ( \"float\" ) elif res . data . dtype . kind in [ \"U\" , \"S\" ]: nan = \"\" res . data [ ~ b_valid ] = nan # toc = datetime.now() - tic # _LOGGER.debug( # \"get valid sig %s in %.3f\", self.name, toc.total_seconds() # ) return res","title":"valid"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.SigEnum","text":"Enumeration definition for CCGSig. Parameters: definition ( dict ) \u2013 Dictionary of conversion values. \"\" is a special key, default for unmatched values if missing, np.nan will be used. Example enumdef = {'v1':1,'v2':2,'':0,} data = np.array(['v1','v2','v3']) testenum = SigEnum(definition=enumdef) testenum.data_to_enum(data) Source code in ccg\\data\\tsdata.py 2554 2555 2556 2557 2558 2559 2560 2561 2562 2563 2564 2565 2566 2567 2568 2569 2570 2571 2572 2573 2574 2575 2576 2577 2578 2579 2580 2581 2582 2583 2584 2585 2586 2587 2588 2589 2590 2591 2592 2593 2594 2595 2596 2597 2598 class SigEnum : \"\"\"Enumeration definition for CCGSig. Parameters ---------- definition Dictionary of conversion values. \"\" is a special key, default for unmatched values if missing, np.nan will be used. Example ------- >>> enumdef = {'v1':1,'v2':2,'':0,} >>> data = np.array(['v1','v2','v3']) >>> testenum = SigEnum(definition=enumdef) >>> testenum.data_to_enum(data) >>> \"\"\" def __init__ ( self , definition : dict ): self . definition = definition def data_to_enum ( self , data : npt . NDArray ): \"\"\"Convert base data to enumerated type.\"\"\" rtn = np . empty ( data . shape ) unmatched = np . empty ( data . shape , dtype = np . bool_ ) unmatched [:] = True for key , val in self . definition . items (): if not key == \"\" : inds = data == key unmatched [ inds ] = False rtn [ inds ] = val if np . any ( unmatched ): try : rtn [ unmatched ] = self . definition [ \"\" ] except KeyError : rtn [ unmatched ] = np . nan return rtn def enum_to_data ( self , enum : npt . NDArray ): \"\"\"Convert enumerated data back to base data.\"\"\" rtn = np . empty ( enum . shape ) for key , val in self . definition . items (): inds = enum == val rtn [ inds ] = key return rtn","title":"SigEnum"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.SigEnum.data_to_enum","text":"Convert base data to enumerated type. Source code in ccg\\data\\tsdata.py 2574 2575 2576 2577 2578 2579 2580 2581 2582 2583 2584 2585 2586 2587 2588 2589 2590 def data_to_enum ( self , data : npt . NDArray ): \"\"\"Convert base data to enumerated type.\"\"\" rtn = np . empty ( data . shape ) unmatched = np . empty ( data . shape , dtype = np . bool_ ) unmatched [:] = True for key , val in self . definition . items (): if not key == \"\" : inds = data == key unmatched [ inds ] = False rtn [ inds ] = val if np . any ( unmatched ): try : rtn [ unmatched ] = self . definition [ \"\" ] except KeyError : rtn [ unmatched ] = np . nan return rtn","title":"data_to_enum"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.SigEnum.enum_to_data","text":"Convert enumerated data back to base data. Source code in ccg\\data\\tsdata.py 2592 2593 2594 2595 2596 2597 2598 def enum_to_data ( self , enum : npt . NDArray ): \"\"\"Convert enumerated data back to base data.\"\"\" rtn = np . empty ( enum . shape ) for key , val in self . definition . items (): inds = enum == val rtn [ inds ] = key return rtn","title":"enum_to_data"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLine","text":"CCG Time Line. Source code in ccg\\data\\tsdata.py 1816 1817 1818 1819 1820 1821 1822 1823 1824 1825 1826 1827 1828 1829 1830 1831 1832 1833 1834 1835 1836 1837 1838 1839 1840 1841 1842 1843 1844 1845 1846 1847 1848 1849 1850 1851 1852 1853 1854 1855 1856 1857 1858 1859 1860 1861 1862 1863 1864 1865 1866 1867 1868 1869 1870 1871 1872 1873 1874 1875 1876 1877 1878 1879 1880 1881 1882 1883 1884 1885 1886 1887 1888 1889 1890 1891 1892 1893 1894 1895 1896 1897 1898 1899 1900 1901 1902 1903 1904 1905 1906 1907 1908 1909 1910 1911 1912 1913 1914 1915 1916 1917 1918 1919 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 1931 1932 1933 1934 1935 1936 1937 1938 1939 1940 1941 1942 1943 1944 1945 1946 1947 1948 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 1961 1962 1963 1964 1965 1966 1967 1968 1969 1970 1971 1972 1973 1974 1975 1976 1977 1978 1979 1980 1981 1982 1983 1984 1985 1986 1987 1988 1989 1990 1991 1992 1993 1994 1995 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020 2021 2022 2023 2024 2025 2026 2027 2028 2029 2030 2031 2032 2033 2034 2035 2036 2037 2038 2039 2040 2041 2042 2043 2044 2045 2046 2047 2048 2049 2050 2051 2052 2053 2054 2055 2056 2057 2058 2059 2060 2061 2062 2063 2064 2065 2066 2067 2068 2069 2070 2071 2072 2073 2074 2075 2076 2077 2078 2079 2080 2081 2082 2083 2084 2085 2086 2087 2088 2089 2090 2091 2092 2093 2094 2095 2096 2097 2098 2099 2100 2101 2102 2103 2104 2105 2106 2107 2108 2109 2110 2111 2112 2113 2114 2115 2116 2117 2118 2119 2120 2121 2122 2123 2124 2125 2126 2127 2128 2129 2130 2131 2132 2133 2134 2135 2136 2137 2138 2139 2140 2141 2142 2143 2144 2145 2146 2147 2148 2149 2150 2151 2152 2153 2154 2155 2156 2157 2158 2159 2160 2161 2162 2163 2164 2165 2166 2167 2168 2169 2170 2171 2172 2173 2174 2175 2176 2177 2178 2179 2180 2181 2182 2183 2184 2185 2186 2187 2188 2189 2190 2191 2192 2193 2194 2195 2196 2197 2198 2199 2200 2201 2202 2203 2204 2205 2206 2207 2208 2209 2210 2211 2212 2213 2214 2215 2216 2217 2218 2219 2220 2221 2222 2223 2224 2225 2226 2227 2228 2229 2230 2231 2232 2233 2234 2235 2236 2237 2238 2239 2240 2241 2242 2243 2244 2245 class TLine : \"\"\"CCG Time Line.\"\"\" __slots__ = ( \"_iso\" , \"_sg\" , \"_datetime\" , \"_unix\" , \"_idn\" , \"_dt\" , \"_period\" , \"_is_monoton\" , \"parent\" , \"_shape\" , \"_unix\" , \"_period\" , ) @profile def __init__ ( self , data : ( TLine | npt . NDArray [ np . object_ ] | npt . NDArray [ np . number ] | npt . NDArray [ np . datetime64 ] | datetime | list ) = None , tstart : float | datetime = None , tend : float | datetime = None , nsamples : int | tuple [ int ] = None , period : float = None , sg_coef : SgCoef = None , parent : TLineCollection = None , ): if sg_coef is None : self . _sg = SgCoef () self . _iso : npt . NDArray [ np . datetime64 ] = None self . _datetime : npt . NDArray [ np . object_ ] = None self . _unix : AllocData = None self . _idn = None self . _dt = None self . _period : float | None = None self . _is_monoton : bool = None self . parent = parent # TODO: Clean up cases here. better fault detection. if nsamples is None : self . _shape = None elif isinstance ( nsamples , tuple ): self . _shape = nsamples elif isinstance ( nsamples , int ): self . _shape = ( nsamples ,) else : raise NotImplementedError ( f \"tline with nsamples of type { type ( nsamples ) } is not implemented.\" ) if data is not None : # if isinstance(data, (pd.DataFrame, pd.Series)): # if data.index is None: # raise ValueError(\"Data frame has no index.\") # if data.index.asi8 is None: # index = data.index.to_numpy() # else: # index = data.index.asi8 / 1e9 # self.unix = index # elif isinstance(data, pd.Index): # self.unix = data.asi8 / 1e9 if isinstance ( data , np . ndarray ) and data . dtype . kind == \"M\" : self . unix = ccg . util . datetime_to_unix ( data ) elif isinstance ( data , np . ndarray ) and isinstance ( data [ 0 ], datetime ): self . unix = np . array ([ t . timestamp () for t in data ]) elif isinstance ( data , np . ndarray ): self . unix = data . astype ( \"float\" ) elif isinstance ( data , datetime ): self . unix = np . array ([ data . timestamp ()]) elif isinstance ( data , TLine ): self . _shape = data . _shape self . unix = data . _unix self . _sg = data . _sg self . _idn = data . idn elif isinstance ( data , AllocData ): self . _shape = data . _shape self . unix = data elif isinstance ( data , list ): self . unix = np . array ( data ) else : raise NotImplementedError ( f \" { type ( data ) } is not supported.\" ) elif None not in { tstart , tend , nsamples } or None not in { tstart , tend , period }: if isinstance ( tstart , datetime ): tstart = tstart . timestamp () if isinstance ( tend , datetime ): tend = tend . timestamp () if nsamples is not None : self . unix = np . linspace ( start = tstart , stop = tend , num = nsamples ) elif period is not None : self . unix = np . arange ( start = tstart , stop = tend , step = period ) self . _period = period else : raise ValueError ( \"Missing nsamples or period.\" ) elif None not in { tstart , nsamples , period } or None not in { tend , nsamples , period , }: if isinstance ( tstart , datetime ): tstart = tstart . timestamp () if isinstance ( tend , datetime ): tend = tend . timestamp () if tend is None : tend = tstart + nsamples * period if tstart is None : tstart = tend - nsamples * period self . unix = np . linspace ( start = tstart , stop = tend , num = nsamples ) self . _period = period elif nsamples : # To pre-allocate self . unix = None else : raise ValueError @property def unix ( self ) -> npt . NDArray [ np . float_ ]: \"\"\"tline in unix\"\"\" return self . _unix [:] @unix . setter @profile def unix ( self , value : npt . NDArray [ np . float_ ] | AllocData ): if self . _unix is None : self . _unix = AllocData ( value , shape = self . _shape , dtype = np . dtype ( \"float64\" )) else : self . _unix . replace ( value ) # Need to clear lots of stuff if changing the timeline self . clear_cache () # @profile def calc_idn ( self ): \"\"\"Calculate hash for IDN.\"\"\" self . _idn = xxhash . xxh3_64_intdigest ( self . _unix . tobytes ()) return self . _idn @property # @profile def idn ( self ): \"\"\"return id number.\"\"\" if self . _idn is None : return self . calc_idn () return self . _idn @property def tstart ( self ) -> float : \"\"\"Start time.\"\"\" # TODO Check for monoton increasing first. return self . _unix [ 0 ] @property def tend ( self ) -> float : \"\"\"End time.\"\"\" return self . _unix [ - 1 ] @property def tstart_iso ( self ) -> np . datetime64 : \"\"\"Start time.\"\"\" # TODO Check for monoton increasing first. return self . iso [ 0 ] @property def tend_iso ( self ) -> np . datetime64 : \"\"\"End time.\"\"\" return self . iso [ - 1 ] @property def iso ( self ) -> npt . NDArray [ np . datetime64 ]: \"\"\"Array of iso formatted strings. Naive, but in local tz.\"\"\" if self . _iso is None : self . _iso = ccg . util . unix_to_iso ( self . unix ) return self . _iso @property def datetime ( self ) -> npt . NDArray [ np . object_ ]: \"\"\"Array of datetime.datetime.\"\"\" tic = datetime . now () if self . _datetime is None : if self . unix [ 0 ] > 32000000 : tmp = np . array ( [ datetime . fromtimestamp ( t ) . astimezone () for t in self . unix ] ) # SO SLOW else : tmp = np . array ([ datetime . fromtimestamp ( t ) for t in self . unix ]) self . _datetime = tmp toc = datetime . now () - tic if toc > timedelta ( seconds = 0.1 ): _LOGGER . debug ( \"datetime prop calc for %s took %.3f s\" , self . _idn , toc . total_seconds () ) return self . _datetime @property def appx_bytes ( self ): \"\"\"Estimated size of data [bytes]. Excludes tline.\"\"\" return self . _unix . appx_bytes @overload def __getitem__ ( self , ind : int | npt . NDArray [ np . int_ | np . bool_ ]) -> npt . NDArray : pass @overload def __getitem__ ( self , ind : slice ) -> TLine : pass def __getitem__ ( self , ind : int | npt . NDArray [ np . int_ | np . bool_ ] | slice ): \"\"\"Index tline.\"\"\" if isinstance ( ind , slice ): # A slice should return a new CCGTline. Vals should be unix or datetime. if isinstance ( ind . start , datetime ): ind_start = ind . start . timestamp () else : ind_start = ind . start if isinstance ( ind . stop , datetime ): ind_stop = ind . stop . timestamp () else : ind_stop = ind . stop if isinstance ( ind . step , timedelta ): step = ind . step . total_seconds () else : step = ind . step if ind . step is None : if ind . start is None : start = self . tstart else : start = ind_start if ind . stop is None : # Since python is r-worded, this is a special case. # Need to make sure the last sample is included. stop = self . tend + 0.000001 else : stop = ind_stop inds = np . logical_and ( self . unix >= start , self . unix < stop ) return TLine ( self . unix [ inds ]) else : # Step was defined so define a fresh tline i guess? _LOGGER . warning ( \"tline sliced with step defined. This is equiv to `CCGTline(tstart=slice.start,tenc=slice.stop,period=slice.step)`\" ) return TLine ( tstart = ind_start , tend = ind_stop , period = step ) return self . unix [ ind ] def __len__ ( self ) -> int : \"\"\"Length of timeline.\"\"\" return self . _unix . nsamples def __repr__ ( self ) -> str : \"\"\"Return string representation.\"\"\" # reprstr = f\"{self.__class__.__module__}.{self.__class__.__qualname__}({self.iso.__repr__()})\" reprstr = f \" { self . __class__ . __qualname__ } ( { self . iso . __repr__ () } )\" return reprstr def __str__ ( self ) -> str : \"\"\"Return readable string.\"\"\" return self . iso . __str__ () def __eq__ ( self , other ) -> bool : \"\"\"Check equality.\"\"\" if isinstance ( other , self . __class__ ): return np . array_equal ( self . unix , other . unix ) else : return False @property # profile def dt ( self ): \"\"\"delta t\"\"\" if self . _dt is None : if len ( self ) > 1 : self . _dt = np . diff ( self . unix ) else : self . _dt = np . array ([ 0 ]) return self . _dt @property def period ( self ) -> float : \"\"\"apprx period.\"\"\" if self . _period : return self . _period if self . nsamples > 1 : self . _period = stats . mode ( self . dt , keepdims = True ) . mode [ 0 ] else : self . _period = np . Inf return self . _period @property def nsamples ( self ): \"\"\"nsamples\"\"\" return len ( self ) @property # profile def is_monotonic_increasing ( self ): \"\"\"Return true if monotonic increasing.\"\"\" if self . _is_monoton is None : if len ( self ) == 1 : self . _is_monoton = True else : tmp = self . unix self . _is_monoton = np . all ( tmp [ 1 :] > tmp [: - 1 ]) return self . _is_monoton @profile def append_to_new ( self , sig : Sig ): \"\"\"Append timeline from sig to tline. Returns new timeline.\"\"\" nsamples = self . nsamples + sig . nsamples new_tline = TLine ( self , nsamples = nsamples ) new_tline . parent = None new_tline . append_inplace ( sig ) # new_tline = TLine(np.concatenate((self.unix, sig.tline.unix))) return new_tline @profile def append_inplace ( self , sig : Sig ): \"\"\"Append to tline in place. Dangerous if shared in a Frame.\"\"\" self . _unix . append ( sig . tline . _unix ) self . clear_cache () return self def index_at_time ( self , time : float | datetime ) -> int : \"\"\"Get the index of the first tstamp >= time.\"\"\" raise NotImplementedError def sort ( self ): \"\"\"Sort tline.\"\"\" raise NotImplementedError ( \"tline sort is not implemented.\" ) # Dont forget to re-calc idn def clear_cache ( self ): \"\"\"Clear the cached values.\"\"\" self . _sg . clear () old_idn = self . _idn self . _iso = None self . _datetime = None self . _idn = None self . _dt = None self . _period = None self . _is_monoton = None if self . parent is not None and old_idn != self . idn : self . parent . replace ( old_idn , self ) # @profile def savgol_coef ( self : TLine , sample_to_index : TLine , n_ord : int , n_win_orig : int , n_dot : int = 0 , ): \"\"\"Calculate Savitzky Golay coeficients.\"\"\" # Check if coef's are stored nsamplesnew = len ( sample_to_index ) if ( self . idn == self . _sg . orig_index and sample_to_index . idn == self . _sg . sample_to_index and n_ord == self . _sg . n_ord and n_win_orig == self . _sg . n_win_orig ): conv = self . _sg . conv uniqinvs = self . _sg . uniqinvs n_uniq = self . _sg . n_uniq inds = self . _sg . inds else : # Missing or different, so have to calc coef's nsamples = len ( self ) # Find orig samples near new samples ind0 = np . digitize ( sample_to_index . unix , self . unix ) ind0 = np . maximum ( np . minimum ( ind0 , nsamples - 1 , out = ind0 ), 0 , out = ind0 ) # saturate inds = ind0 [:, np . newaxis ] # make n x 1 offs = np . arange ( n_win_orig ) - int (( n_win_orig - 1 ) / 2 ) inds = inds + offs # Saturate the ends inds = np . maximum ( np . minimum ( inds , nsamples - 1 , out = inds ), 0 , out = inds ) indsz : npt . NDArray = self . unix [ inds . ravel ()] # to seconds indsz = indsz . reshape ( inds . shape ) torig = self . unix [ ind0 ] indsz = indsz - torig [:, np . newaxis ] # Find unique window spacings, round to appropriate resolution indsz = np . around ( indsz , 3 , out = indsz ) uniqz , uniqinvs = np . unique ( indsz , return_inverse = True , axis = 0 ) n_uniq = len ( uniqz ) pwrs = np . arange ( n_ord + 1 ) conv = np . empty (( n_uniq , n_win_orig , n_ord + 1 )) for i , uniq in enumerate ( uniqz ): j : npt . NDArray = uniq [:, np . newaxis ] ** pwrs try : tmp = np . linalg . inv ( j . T @ j ) @ j . T except np . linalg . LinAlgError : tmp = np . linalg . pinv ( j . T @ j ) @ j . T conv [ i , :, :] = tmp . T # Store inputs for validating accuracy of stored coef's # Compress or abbrev?? self . _sg . orig_index = self . idn self . _sg . sample_to_index = sample_to_index . idn self . _sg . n_win_orig = n_win_orig self . _sg . n_ord = n_ord # Store coef's self . _sg . conv = conv self . _sg . uniqinvs = uniqinvs self . _sg . n_uniq = n_uniq self . _sg . inds = inds # Calc coef's for this derivative convs = np . empty (( n_win_orig , nsamplesnew )) for i in range ( n_uniq ): convs [:, uniqinvs == i ] = conv [ i , :, n_dot ][:, np . newaxis ] return inds , convs","title":"TLine"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLine.appx_bytes","text":"Estimated size of data [bytes]. Excludes tline.","title":"appx_bytes"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLine.datetime","text":"Array of datetime.datetime.","title":"datetime"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLine.dt","text":"delta t","title":"dt"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLine.idn","text":"return id number.","title":"idn"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLine.is_monotonic_increasing","text":"Return true if monotonic increasing.","title":"is_monotonic_increasing"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLine.iso","text":"Array of iso formatted strings. Naive, but in local tz.","title":"iso"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLine.nsamples","text":"nsamples","title":"nsamples"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLine.period","text":"apprx period.","title":"period"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLine.tend","text":"End time.","title":"tend"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLine.tend_iso","text":"End time.","title":"tend_iso"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLine.tstart","text":"Start time.","title":"tstart"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLine.tstart_iso","text":"Start time.","title":"tstart_iso"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLine.unix","text":"tline in unix","title":"unix"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLine.__eq__","text":"Check equality. Source code in ccg\\data\\tsdata.py 2083 2084 2085 2086 2087 2088 def __eq__ ( self , other ) -> bool : \"\"\"Check equality.\"\"\" if isinstance ( other , self . __class__ ): return np . array_equal ( self . unix , other . unix ) else : return False","title":"__eq__"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLine.__getitem__","text":"Index tline. Source code in ccg\\data\\tsdata.py 2031 2032 2033 2034 2035 2036 2037 2038 2039 2040 2041 2042 2043 2044 2045 2046 2047 2048 2049 2050 2051 2052 2053 2054 2055 2056 2057 2058 2059 2060 2061 2062 2063 2064 2065 2066 2067 def __getitem__ ( self , ind : int | npt . NDArray [ np . int_ | np . bool_ ] | slice ): \"\"\"Index tline.\"\"\" if isinstance ( ind , slice ): # A slice should return a new CCGTline. Vals should be unix or datetime. if isinstance ( ind . start , datetime ): ind_start = ind . start . timestamp () else : ind_start = ind . start if isinstance ( ind . stop , datetime ): ind_stop = ind . stop . timestamp () else : ind_stop = ind . stop if isinstance ( ind . step , timedelta ): step = ind . step . total_seconds () else : step = ind . step if ind . step is None : if ind . start is None : start = self . tstart else : start = ind_start if ind . stop is None : # Since python is r-worded, this is a special case. # Need to make sure the last sample is included. stop = self . tend + 0.000001 else : stop = ind_stop inds = np . logical_and ( self . unix >= start , self . unix < stop ) return TLine ( self . unix [ inds ]) else : # Step was defined so define a fresh tline i guess? _LOGGER . warning ( \"tline sliced with step defined. This is equiv to `CCGTline(tstart=slice.start,tenc=slice.stop,period=slice.step)`\" ) return TLine ( tstart = ind_start , tend = ind_stop , period = step ) return self . unix [ ind ]","title":"__getitem__"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLine.__len__","text":"Length of timeline. Source code in ccg\\data\\tsdata.py 2069 2070 2071 def __len__ ( self ) -> int : \"\"\"Length of timeline.\"\"\" return self . _unix . nsamples","title":"__len__"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLine.__repr__","text":"Return string representation. Source code in ccg\\data\\tsdata.py 2073 2074 2075 2076 2077 def __repr__ ( self ) -> str : \"\"\"Return string representation.\"\"\" # reprstr = f\"{self.__class__.__module__}.{self.__class__.__qualname__}({self.iso.__repr__()})\" reprstr = f \" { self . __class__ . __qualname__ } ( { self . iso . __repr__ () } )\" return reprstr","title":"__repr__"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLine.__str__","text":"Return readable string. Source code in ccg\\data\\tsdata.py 2079 2080 2081 def __str__ ( self ) -> str : \"\"\"Return readable string.\"\"\" return self . iso . __str__ ()","title":"__str__"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLine.append_inplace","text":"Append to tline in place. Dangerous if shared in a Frame. Source code in ccg\\data\\tsdata.py 2140 2141 2142 2143 2144 2145 @profile def append_inplace ( self , sig : Sig ): \"\"\"Append to tline in place. Dangerous if shared in a Frame.\"\"\" self . _unix . append ( sig . tline . _unix ) self . clear_cache () return self","title":"append_inplace"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLine.append_to_new","text":"Append timeline from sig to tline. Returns new timeline. Source code in ccg\\data\\tsdata.py 2130 2131 2132 2133 2134 2135 2136 2137 2138 @profile def append_to_new ( self , sig : Sig ): \"\"\"Append timeline from sig to tline. Returns new timeline.\"\"\" nsamples = self . nsamples + sig . nsamples new_tline = TLine ( self , nsamples = nsamples ) new_tline . parent = None new_tline . append_inplace ( sig ) # new_tline = TLine(np.concatenate((self.unix, sig.tline.unix))) return new_tline","title":"append_to_new"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLine.calc_idn","text":"Calculate hash for IDN. Source code in ccg\\data\\tsdata.py 1956 1957 1958 1959 def calc_idn ( self ): \"\"\"Calculate hash for IDN.\"\"\" self . _idn = xxhash . xxh3_64_intdigest ( self . _unix . tobytes ()) return self . _idn","title":"calc_idn"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLine.clear_cache","text":"Clear the cached values. Source code in ccg\\data\\tsdata.py 2156 2157 2158 2159 2160 2161 2162 2163 2164 2165 2166 2167 2168 2169 2170 def clear_cache ( self ): \"\"\"Clear the cached values.\"\"\" self . _sg . clear () old_idn = self . _idn self . _iso = None self . _datetime = None self . _idn = None self . _dt = None self . _period = None self . _is_monoton = None if self . parent is not None and old_idn != self . idn : self . parent . replace ( old_idn , self )","title":"clear_cache"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLine.index_at_time","text":"Get the index of the first tstamp >= time. Source code in ccg\\data\\tsdata.py 2147 2148 2149 def index_at_time ( self , time : float | datetime ) -> int : \"\"\"Get the index of the first tstamp >= time.\"\"\" raise NotImplementedError","title":"index_at_time"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLine.savgol_coef","text":"Calculate Savitzky Golay coeficients. Source code in ccg\\data\\tsdata.py 2173 2174 2175 2176 2177 2178 2179 2180 2181 2182 2183 2184 2185 2186 2187 2188 2189 2190 2191 2192 2193 2194 2195 2196 2197 2198 2199 2200 2201 2202 2203 2204 2205 2206 2207 2208 2209 2210 2211 2212 2213 2214 2215 2216 2217 2218 2219 2220 2221 2222 2223 2224 2225 2226 2227 2228 2229 2230 2231 2232 2233 2234 2235 2236 2237 2238 2239 2240 2241 2242 2243 2244 2245 def savgol_coef ( self : TLine , sample_to_index : TLine , n_ord : int , n_win_orig : int , n_dot : int = 0 , ): \"\"\"Calculate Savitzky Golay coeficients.\"\"\" # Check if coef's are stored nsamplesnew = len ( sample_to_index ) if ( self . idn == self . _sg . orig_index and sample_to_index . idn == self . _sg . sample_to_index and n_ord == self . _sg . n_ord and n_win_orig == self . _sg . n_win_orig ): conv = self . _sg . conv uniqinvs = self . _sg . uniqinvs n_uniq = self . _sg . n_uniq inds = self . _sg . inds else : # Missing or different, so have to calc coef's nsamples = len ( self ) # Find orig samples near new samples ind0 = np . digitize ( sample_to_index . unix , self . unix ) ind0 = np . maximum ( np . minimum ( ind0 , nsamples - 1 , out = ind0 ), 0 , out = ind0 ) # saturate inds = ind0 [:, np . newaxis ] # make n x 1 offs = np . arange ( n_win_orig ) - int (( n_win_orig - 1 ) / 2 ) inds = inds + offs # Saturate the ends inds = np . maximum ( np . minimum ( inds , nsamples - 1 , out = inds ), 0 , out = inds ) indsz : npt . NDArray = self . unix [ inds . ravel ()] # to seconds indsz = indsz . reshape ( inds . shape ) torig = self . unix [ ind0 ] indsz = indsz - torig [:, np . newaxis ] # Find unique window spacings, round to appropriate resolution indsz = np . around ( indsz , 3 , out = indsz ) uniqz , uniqinvs = np . unique ( indsz , return_inverse = True , axis = 0 ) n_uniq = len ( uniqz ) pwrs = np . arange ( n_ord + 1 ) conv = np . empty (( n_uniq , n_win_orig , n_ord + 1 )) for i , uniq in enumerate ( uniqz ): j : npt . NDArray = uniq [:, np . newaxis ] ** pwrs try : tmp = np . linalg . inv ( j . T @ j ) @ j . T except np . linalg . LinAlgError : tmp = np . linalg . pinv ( j . T @ j ) @ j . T conv [ i , :, :] = tmp . T # Store inputs for validating accuracy of stored coef's # Compress or abbrev?? self . _sg . orig_index = self . idn self . _sg . sample_to_index = sample_to_index . idn self . _sg . n_win_orig = n_win_orig self . _sg . n_ord = n_ord # Store coef's self . _sg . conv = conv self . _sg . uniqinvs = uniqinvs self . _sg . n_uniq = n_uniq self . _sg . inds = inds # Calc coef's for this derivative convs = np . empty (( n_win_orig , nsamplesnew )) for i in range ( n_uniq ): convs [:, uniqinvs == i ] = conv [ i , :, n_dot ][:, np . newaxis ] return inds , convs","title":"savgol_coef"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLine.sort","text":"Sort tline. Source code in ccg\\data\\tsdata.py 2151 2152 2153 def sort ( self ): \"\"\"Sort tline.\"\"\" raise NotImplementedError ( \"tline sort is not implemented.\" )","title":"sort"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLineCollection","text":"Collection of timelines for Frame. Parameters: frame ( Frame ) \u2013 optional Frame to get timelines from. tlines ( TLine | list [ TLine ] , default: None ) \u2013 optional CCGTline or list of CCGTline. If used, signames is required. signames ( str | list [ str ] , default: None ) \u2013 required with tlines. If tlines is a list, must be equal length. If single tlines, can be a list. Source code in ccg\\data\\tsdata.py 2248 2249 2250 2251 2252 2253 2254 2255 2256 2257 2258 2259 2260 2261 2262 2263 2264 2265 2266 2267 2268 2269 2270 2271 2272 2273 2274 2275 2276 2277 2278 2279 2280 2281 2282 2283 2284 2285 2286 2287 2288 2289 2290 2291 2292 2293 2294 2295 2296 2297 2298 2299 2300 2301 2302 2303 2304 2305 2306 2307 2308 2309 2310 2311 2312 2313 2314 2315 2316 2317 2318 2319 2320 2321 2322 2323 2324 2325 2326 2327 2328 2329 2330 2331 2332 2333 2334 2335 2336 2337 2338 2339 2340 2341 2342 2343 2344 2345 2346 2347 2348 2349 2350 2351 2352 2353 2354 2355 2356 2357 2358 2359 2360 2361 2362 2363 2364 2365 2366 2367 2368 2369 2370 2371 2372 2373 2374 2375 2376 2377 2378 2379 2380 2381 2382 2383 2384 2385 2386 2387 2388 2389 2390 2391 2392 2393 2394 2395 2396 2397 2398 2399 2400 2401 2402 2403 2404 2405 2406 2407 2408 2409 2410 2411 2412 2413 2414 2415 2416 2417 2418 2419 2420 2421 2422 2423 2424 2425 2426 2427 2428 2429 2430 2431 2432 2433 2434 2435 2436 2437 2438 2439 2440 2441 2442 2443 2444 2445 2446 2447 2448 2449 2450 2451 2452 2453 2454 2455 2456 2457 2458 2459 2460 2461 2462 2463 2464 2465 2466 2467 2468 2469 2470 2471 2472 2473 2474 2475 2476 2477 2478 2479 2480 2481 2482 2483 2484 2485 2486 2487 2488 2489 2490 2491 2492 2493 2494 2495 2496 2497 2498 2499 2500 2501 2502 2503 2504 2505 2506 2507 2508 2509 2510 2511 2512 2513 2514 2515 2516 2517 2518 2519 2520 2521 2522 2523 2524 2525 2526 2527 2528 2529 2530 2531 2532 2533 2534 2535 2536 2537 2538 2539 2540 2541 2542 2543 2544 2545 2546 2547 2548 2549 2550 2551 class TLineCollection : \"\"\" Collection of timelines for Frame. Parameters ---------- frame optional Frame to get timelines from. tlines optional CCGTline or list of CCGTline. If used, signames is required. signames required with tlines. If tlines is a list, must be equal length. If single tlines, can be a list. \"\"\" def __init__ ( self , frame : Frame , tlines : TLine | list [ TLine ] = None , signames : str | list [ str ] = None , ) -> None : self . tlines : dict [ int , TLine ] = {} self . idns : dict [ str , int ] = {} self . sigs : dict [ int , list [ str ]] = {} if frame or tlines : self . append ( frameorsig = frame , tlines = tlines , signames = signames ) self . frame = frame @profile def append ( self , frameorsig : Sig | Frame = None , tlines : TLine | list [ TLine ] = None , signames : list [ str ] | list [ list [ str ]] = None , ) -> TLine : \"\"\" Append tline to collection. Parameters ---------- frame optional Frame to get timelines from. tlines optional CCGTline or list of CCGTline. If used, signames is required. signames required with tlines. Must be equal length list of lists of signames. Returns ------- CCGTimeline \"\"\" if frameorsig is not None : # if isinstance(frameorsig, pd.DataFrame): # tline = TLine(frameorsig) # tline.parent = self # if tline.idn in self.tlines: # self.check_sg(tline) # else: # self.tlines[tline.idn] = tline # tlref = self.tlines[tline.idn] # for col in frameorsig: # self.idns[col] = tline.idn # self.add_to_sigs(tline.idn, col) if isinstance ( frameorsig , Frame ): tlref = [] if frameorsig . nsigs > 0 : for tline in frameorsig . tlines : tline . parent = self # TODO: Check for reference issue in this case if tline . idn in self . tlines : self . check_sg ( tline ) else : self . tlines [ tline . idn ] = tline sigs = frameorsig . tlines . sigs [ tline . idn ] # Check if signame already exists with different tline idns_old = self . idns [ sigs ] if idns_old and np . any ( idns_old != tline . idn ): _LOGGER . error ( \"Existing signal( %s ) with different timeline has been replaced\" , sigs [ idns_old != tline . idn ], ) self . idns [ sigs ] = tline . idn self . add_to_sigs ( tline . idn , sigs ) tlref . append ( self . tlines [ tline . idn ]) elif isinstance ( frameorsig , Sig ): tline = frameorsig . tline tline . parent = self if tline . idn in self : self . check_sg ( tline ) else : self . tlines [ tline . idn ] = tline tlref = self . tlines [ tline . idn ] sigs = frameorsig . name # Check if signame already exists with different tline try : idns_old = self . idns [ sigs ] except KeyError : idns_old = None if any ([ idns_old == tline . idn ]): _LOGGER . error ( \"Existing signal( %s ) with different timeline\" , sigs [ idns_old != tline . idn ], ) self . idns [ sigs ] = tline . idn self . add_to_sigs ( tline . idn , sigs ) # Change 2/10/24 - fix reference to tline in sig here frameorsig . tline = tlref else : raise NotImplementedError ( f \"Appending tline from { type ( frameorsig ) } is not implemented\" ) if tlines is not None : if not isinstance ( tlines , list ): tlines = [ tlines ] if len ( signames ) != len ( tlines ): raise ValueError ( \"If tlines is specified and contains more than 1, signames must be same length.\" ) if signames is None : raise ValueError ( \"signames must be specified with tlines.\" ) tlref = [] for sigs , tline in zip ( signames , tlines ): tline . parent = self if tline . idn in self . tlines : self . check_sg ( tline ) else : self . tlines [ tline . idn ] = tline if not isinstance ( sigs , list ): sigs = [ sigs ] self . add_to_sigs ( tline . idn , sigs ) for sig in sigs : self . idns [ sig ] = tline . idn tlref . append ( tline ) return tlref def check_sg ( self , tline : TLine ): \"\"\"Check for existing _sg coef.\"\"\" # If sigs timeline has conv coef, but the cached doesnt, use it instead # pylint: disable=protected-access if tline . _sg . conv is not None and self . tlines [ tline . idn ] . _sg . conv is None : self . tlines [ tline . idn ] . _sg = tline . _sg def get_fastest ( self ): \"\"\"Return the approximate fastest tline from coll.\"\"\" tmp = self [ 0 ] fast = tmp . period for _ , tline in self . tlines . items (): if tline . period < fast : tmp = tline fast = tmp . period return tmp def remove ( self , signame ): \"\"\"Remove timeline for signame from collection. If other signals still use it, it will simply remove the reference. \"\"\" tl_idn = self . idns [ signame ] nref = len ( self . sigs [ tl_idn ]) if nref == 0 : raise ValueError ( \"No matching tline.\" ) if nref == 1 : self . tlines . pop ( tl_idn ) self . idns . pop ( signame ) self . sigs . pop ( tl_idn ) else : self . idns . pop ( signame ) self . sigs [ tl_idn ] . pop ( self . sigs [ tl_idn ] . index ( signame )) def replace ( self , old_tline : int | TLine , new_tline : TLine ): \"\"\"Replace the `old_tline` with `new_tline` in place.\"\"\" if isinstance ( old_tline , TLine ): old_idn = old_tline . idn else : old_idn = old_tline old_tline = self . tlines [ old_idn ] if old_idn in self . tlines : existing_sigs = self . sigs [ old_idn ] . copy () for existing in existing_sigs : self . remove ( existing ) old_tline . parent = None # To block the replace call in unix setter old_tline . unix = new_tline . unix self . append ( tlines = old_tline , signames = [ existing_sigs ]) @property def tstart ( self ): \"\"\"Earliest tstart in collection.\"\"\" tstart = None for _ , tline in self . tlines . items (): if tstart is None or tline . tstart < tstart : tstart = tline . tstart return tstart @property def tend ( self ): \"\"\"Latest tend in collection.\"\"\" tend = None for _ , tline in self . tlines . items (): if tend is None or tline . tend > tend : tend = tline . tend return tend @property def tstart_iso ( self ): \"\"\"Earliest start time in iso.\"\"\" return ccg . util . unix_to_iso ( self . tstart ) @property def tend_iso ( self ): \"\"\"Latest end time in iso.\"\"\" return ccg . util . unix_to_iso ( self . tend ) @property def n_tlines ( self ): \"\"\"Number of tlines in collection.\"\"\" return len ( self . tlines ) @property def nsamples ( self ): \"\"\"Number of samples in collection.\"\"\" nsamples = 0 for _ , tline in self . tlines . items (): nsamples += tline . nsamples return nsamples def add_to_sigs ( self , tline_idn : int , signame : str | list [ str ]): \"\"\"Add signal name to list.\"\"\" if isinstance ( signame , str ): signame = [ signame ] try : # try to extend incase it already exists. self . sigs [ tline_idn ] . extend ( signame ) except KeyError : # else define it as a list self . sigs [ tline_idn ] = signame def get_apprx_bytes ( self , tline : TLine ): \"\"\"Gets the approximate size of the tline and its associated signals. Parameters ---------- tline tline to get size for. Returns ------- Cumulative Bytes of tline and the signals associated with it. \"\"\" size = tline . appx_bytes for sig in self . sigs [ tline . idn ]: size += self . frame . sigs [ sig ] . appx_bytes return size def __getitem__ ( self , index : str | int ) -> TLine : if isinstance ( index , str ): return self . tlines [ self . idns [ index ]] elif isinstance ( index , int ): # TODO: Is this legit?? try : return self . tlines [ index ] except KeyError : return list ( self . tlines . values ())[ index ] else : raise NotImplementedError def __repr__ ( self ) -> str : \"\"\"Return string repr.\"\"\" isos = [] for tline in self . tlines . values (): isos . append ( repr ( tline )) # reprstr = f\"{self.__class__.__module__}.{self.__class__.__qualname__}([{', '.join(isos)}])\" reprstr = f \" { self . __class__ . __qualname__ } ([ { ', ' . join ( isos ) } ])\" return reprstr def __str__ ( self ): \"\"\"String rep.\"\"\" idnlist = self . tlines . keys () return f \"tline collection idns: { idnlist } \" def __eq__ ( self , other ) -> bool : \"\"\"Check equality.\"\"\" if isinstance ( other , self . __class__ ): eq = ( self . idns == other . idns and self . sigs == other . sigs and self . tlines == other . tlines ) return eq else : return False def __contains__ ( self , other ) -> bool : return other in self . tlines","title":"TLineCollection"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLineCollection.n_tlines","text":"Number of tlines in collection.","title":"n_tlines"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLineCollection.nsamples","text":"Number of samples in collection.","title":"nsamples"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLineCollection.tend","text":"Latest tend in collection.","title":"tend"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLineCollection.tend_iso","text":"Latest end time in iso.","title":"tend_iso"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLineCollection.tstart","text":"Earliest tstart in collection.","title":"tstart"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLineCollection.tstart_iso","text":"Earliest start time in iso.","title":"tstart_iso"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLineCollection.__eq__","text":"Check equality. Source code in ccg\\data\\tsdata.py 2538 2539 2540 2541 2542 2543 2544 2545 2546 2547 2548 def __eq__ ( self , other ) -> bool : \"\"\"Check equality.\"\"\" if isinstance ( other , self . __class__ ): eq = ( self . idns == other . idns and self . sigs == other . sigs and self . tlines == other . tlines ) return eq else : return False","title":"__eq__"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLineCollection.__repr__","text":"Return string repr. Source code in ccg\\data\\tsdata.py 2524 2525 2526 2527 2528 2529 2530 2531 def __repr__ ( self ) -> str : \"\"\"Return string repr.\"\"\" isos = [] for tline in self . tlines . values (): isos . append ( repr ( tline )) # reprstr = f\"{self.__class__.__module__}.{self.__class__.__qualname__}([{', '.join(isos)}])\" reprstr = f \" { self . __class__ . __qualname__ } ([ { ', ' . join ( isos ) } ])\" return reprstr","title":"__repr__"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLineCollection.__str__","text":"String rep. Source code in ccg\\data\\tsdata.py 2533 2534 2535 2536 def __str__ ( self ): \"\"\"String rep.\"\"\" idnlist = self . tlines . keys () return f \"tline collection idns: { idnlist } \"","title":"__str__"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLineCollection.add_to_sigs","text":"Add signal name to list. Source code in ccg\\data\\tsdata.py 2487 2488 2489 2490 2491 2492 2493 2494 def add_to_sigs ( self , tline_idn : int , signame : str | list [ str ]): \"\"\"Add signal name to list.\"\"\" if isinstance ( signame , str ): signame = [ signame ] try : # try to extend incase it already exists. self . sigs [ tline_idn ] . extend ( signame ) except KeyError : # else define it as a list self . sigs [ tline_idn ] = signame","title":"add_to_sigs"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLineCollection.append","text":"Append tline to collection. Parameters: frame \u2013 optional Frame to get timelines from. tlines ( TLine | list [ TLine ] , default: None ) \u2013 optional CCGTline or list of CCGTline. If used, signames is required. signames ( list [ str ] | list [ list [ str ]] , default: None ) \u2013 required with tlines. Must be equal length list of lists of signames. Returns: CCGTimeline \u2013 Source code in ccg\\data\\tsdata.py 2276 2277 2278 2279 2280 2281 2282 2283 2284 2285 2286 2287 2288 2289 2290 2291 2292 2293 2294 2295 2296 2297 2298 2299 2300 2301 2302 2303 2304 2305 2306 2307 2308 2309 2310 2311 2312 2313 2314 2315 2316 2317 2318 2319 2320 2321 2322 2323 2324 2325 2326 2327 2328 2329 2330 2331 2332 2333 2334 2335 2336 2337 2338 2339 2340 2341 2342 2343 2344 2345 2346 2347 2348 2349 2350 2351 2352 2353 2354 2355 2356 2357 2358 2359 2360 2361 2362 2363 2364 2365 2366 2367 2368 2369 2370 2371 2372 2373 2374 2375 2376 2377 2378 2379 2380 2381 2382 2383 2384 2385 2386 2387 2388 2389 2390 2391 2392 2393 @profile def append ( self , frameorsig : Sig | Frame = None , tlines : TLine | list [ TLine ] = None , signames : list [ str ] | list [ list [ str ]] = None , ) -> TLine : \"\"\" Append tline to collection. Parameters ---------- frame optional Frame to get timelines from. tlines optional CCGTline or list of CCGTline. If used, signames is required. signames required with tlines. Must be equal length list of lists of signames. Returns ------- CCGTimeline \"\"\" if frameorsig is not None : # if isinstance(frameorsig, pd.DataFrame): # tline = TLine(frameorsig) # tline.parent = self # if tline.idn in self.tlines: # self.check_sg(tline) # else: # self.tlines[tline.idn] = tline # tlref = self.tlines[tline.idn] # for col in frameorsig: # self.idns[col] = tline.idn # self.add_to_sigs(tline.idn, col) if isinstance ( frameorsig , Frame ): tlref = [] if frameorsig . nsigs > 0 : for tline in frameorsig . tlines : tline . parent = self # TODO: Check for reference issue in this case if tline . idn in self . tlines : self . check_sg ( tline ) else : self . tlines [ tline . idn ] = tline sigs = frameorsig . tlines . sigs [ tline . idn ] # Check if signame already exists with different tline idns_old = self . idns [ sigs ] if idns_old and np . any ( idns_old != tline . idn ): _LOGGER . error ( \"Existing signal( %s ) with different timeline has been replaced\" , sigs [ idns_old != tline . idn ], ) self . idns [ sigs ] = tline . idn self . add_to_sigs ( tline . idn , sigs ) tlref . append ( self . tlines [ tline . idn ]) elif isinstance ( frameorsig , Sig ): tline = frameorsig . tline tline . parent = self if tline . idn in self : self . check_sg ( tline ) else : self . tlines [ tline . idn ] = tline tlref = self . tlines [ tline . idn ] sigs = frameorsig . name # Check if signame already exists with different tline try : idns_old = self . idns [ sigs ] except KeyError : idns_old = None if any ([ idns_old == tline . idn ]): _LOGGER . error ( \"Existing signal( %s ) with different timeline\" , sigs [ idns_old != tline . idn ], ) self . idns [ sigs ] = tline . idn self . add_to_sigs ( tline . idn , sigs ) # Change 2/10/24 - fix reference to tline in sig here frameorsig . tline = tlref else : raise NotImplementedError ( f \"Appending tline from { type ( frameorsig ) } is not implemented\" ) if tlines is not None : if not isinstance ( tlines , list ): tlines = [ tlines ] if len ( signames ) != len ( tlines ): raise ValueError ( \"If tlines is specified and contains more than 1, signames must be same length.\" ) if signames is None : raise ValueError ( \"signames must be specified with tlines.\" ) tlref = [] for sigs , tline in zip ( signames , tlines ): tline . parent = self if tline . idn in self . tlines : self . check_sg ( tline ) else : self . tlines [ tline . idn ] = tline if not isinstance ( sigs , list ): sigs = [ sigs ] self . add_to_sigs ( tline . idn , sigs ) for sig in sigs : self . idns [ sig ] = tline . idn tlref . append ( tline ) return tlref","title":"append"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLineCollection.check_sg","text":"Check for existing _sg coef. Source code in ccg\\data\\tsdata.py 2395 2396 2397 2398 2399 2400 def check_sg ( self , tline : TLine ): \"\"\"Check for existing _sg coef.\"\"\" # If sigs timeline has conv coef, but the cached doesnt, use it instead # pylint: disable=protected-access if tline . _sg . conv is not None and self . tlines [ tline . idn ] . _sg . conv is None : self . tlines [ tline . idn ] . _sg = tline . _sg","title":"check_sg"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLineCollection.get_apprx_bytes","text":"Gets the approximate size of the tline and its associated signals. Parameters: tline ( TLine ) \u2013 tline to get size for. Returns: Cumulative Bytes of tline and the signals associated with it. \u2013 Source code in ccg\\data\\tsdata.py 2496 2497 2498 2499 2500 2501 2502 2503 2504 2505 2506 2507 2508 2509 2510 def get_apprx_bytes ( self , tline : TLine ): \"\"\"Gets the approximate size of the tline and its associated signals. Parameters ---------- tline tline to get size for. Returns ------- Cumulative Bytes of tline and the signals associated with it. \"\"\" size = tline . appx_bytes for sig in self . sigs [ tline . idn ]: size += self . frame . sigs [ sig ] . appx_bytes return size","title":"get_apprx_bytes"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLineCollection.get_fastest","text":"Return the approximate fastest tline from coll. Source code in ccg\\data\\tsdata.py 2402 2403 2404 2405 2406 2407 2408 2409 2410 2411 def get_fastest ( self ): \"\"\"Return the approximate fastest tline from coll.\"\"\" tmp = self [ 0 ] fast = tmp . period for _ , tline in self . tlines . items (): if tline . period < fast : tmp = tline fast = tmp . period return tmp","title":"get_fastest"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLineCollection.remove","text":"Remove timeline for signame from collection. If other signals still use it, it will simply remove the reference. Source code in ccg\\data\\tsdata.py 2413 2414 2415 2416 2417 2418 2419 2420 2421 2422 2423 2424 2425 2426 2427 2428 def remove ( self , signame ): \"\"\"Remove timeline for signame from collection. If other signals still use it, it will simply remove the reference. \"\"\" tl_idn = self . idns [ signame ] nref = len ( self . sigs [ tl_idn ]) if nref == 0 : raise ValueError ( \"No matching tline.\" ) if nref == 1 : self . tlines . pop ( tl_idn ) self . idns . pop ( signame ) self . sigs . pop ( tl_idn ) else : self . idns . pop ( signame ) self . sigs [ tl_idn ] . pop ( self . sigs [ tl_idn ] . index ( signame ))","title":"remove"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.TLineCollection.replace","text":"Replace the old_tline with new_tline in place. Source code in ccg\\data\\tsdata.py 2430 2431 2432 2433 2434 2435 2436 2437 2438 2439 2440 2441 2442 2443 2444 def replace ( self , old_tline : int | TLine , new_tline : TLine ): \"\"\"Replace the `old_tline` with `new_tline` in place.\"\"\" if isinstance ( old_tline , TLine ): old_idn = old_tline . idn else : old_idn = old_tline old_tline = self . tlines [ old_idn ] if old_idn in self . tlines : existing_sigs = self . sigs [ old_idn ] . copy () for existing in existing_sigs : self . remove ( existing ) old_tline . parent = None # To block the replace call in unix setter old_tline . unix = new_tline . unix self . append ( tlines = old_tline , signames = [ existing_sigs ])","title":"replace"},{"location":"reference/ccg/data/tsdata/#ccg.data.tsdata.get_math_tline","text":"returns timeline for math. sig1.parent.math_tline if it exits, or fastest. Source code in ccg\\data\\tsdata.py 2647 2648 2649 2650 2651 2652 2653 2654 2655 def get_math_tline ( sig1 : Sig , sig2 : Sig | npt . NDArray | float | int ): \"\"\"returns timeline for math. sig1.parent.math_tline if it exits, or fastest.\"\"\" if sig1 . parent and sig1 . parent . math_tline : return sig1 . parent . math_tline if isinstance ( sig2 , Sig ) and sig2 . parent and sig2 . parent . math_tline : return sig2 . parent . math_tline if isinstance ( sig2 , Sig ) and sig1 . tline . period > sig2 . tline . period : return sig2 . tline return sig1 . tline","title":"get_math_tline"},{"location":"reference/ccg/db/","text":"","title":"db"},{"location":"reference/ccg/db/mongo/","text":"CCG Database driver for MongoDB. Client MongoDB connection client. Manages connection to MongoDB. Parameters: dbpass ( str , default: None ) \u2013 user level password for database auth. dbuser ( str , default: None ) \u2013 user level username for database auth. dbadmin \u2013 Admin level username. Only required for changing permissions, new databases, etc. dbadminpass \u2013 Admin level password. dbloc ( str , default: 'localhost' ) \u2013 DB location or connection string. dbauthsrc ( str , default: 'admin' ) \u2013 DB for authentication, usually \"admin\" . dbrepset ( str , default: None ) \u2013 Replica set name. Source code in ccg\\db\\mongo.py 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 class Client : \"\"\"MongoDB connection client. Manages connection to MongoDB. Parameters ---------- dbpass user level password for database auth. dbuser user level username for database auth. dbadmin Admin level username. Only required for changing permissions, new databases, etc. dbadminpass Admin level password. dbloc DB location or connection string. dbauthsrc DB for authentication, usually `\"admin\"`. dbrepset Replica set name. \"\"\" def __init__ ( self , dbpass : str = None , dbuser : str = None , # dbadmin: str = None, # dbadminpass: str = None, dbloc : str = \"localhost\" , dbauthsrc : str = \"admin\" , dbrepset : str = None , ) -> None : if dbuser is None or dbpass is None : # Check env variables for login cred's dbuser = os . environ . get ( \"DBUSER\" ) dbpass = os . environ . get ( \"DBPASS\" ) if dbuser is None or dbpass is None : print ( \"Enter your database user and pass. To avoid typing them in, you can put them into environment variables DBUSER and DBPASS.\" ) dbuser = input ( \"User: \" ) dbpass = getpass . getpass ( \"Pass: \" ) connstr = f \"mongodb:// { dbuser } : { dbpass } @ { dbloc } /?authSource= { dbauthsrc } \" if dbrepset : connstr = connstr + f \"&replicaSet= { dbrepset } \" self . client = MongoClient ( connstr ) # TODO: implement admin client to add roles for user if necessary def list_dbs ( self ): \"\"\"List data bases\"\"\" return self . client . list_database_names () def __getattr__ ( self , db_name : str ): \"\"\"Get a database from client.\"\"\" return self . __getitem__ ( db_name ) def __getitem__ ( self , db_name : str ): \"\"\"Get a database from client.\"\"\" return DB ( self . client [ db_name ]) __getattr__ ( db_name ) Get a database from client. Source code in ccg\\db\\mongo.py 191 192 193 def __getattr__ ( self , db_name : str ): \"\"\"Get a database from client.\"\"\" return self . __getitem__ ( db_name ) __getitem__ ( db_name ) Get a database from client. Source code in ccg\\db\\mongo.py 195 196 197 def __getitem__ ( self , db_name : str ): \"\"\"Get a database from client.\"\"\" return DB ( self . client [ db_name ]) list_dbs () List data bases Source code in ccg\\db\\mongo.py 187 188 189 def list_dbs ( self ): \"\"\"List data bases\"\"\" return self . client . list_database_names () Coll Database collection. Source code in ccg\\db\\mongo.py 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 class Coll : \"\"\"Database collection.\"\"\" indexes = [ IndexModel ( [ ( SIG_LIST , ASCENDING ), ( TEND , ASCENDING ), ( TSTART , ASCENDING ), ] ), # for <v3 Remove soon? IndexModel ( [ ( SIGS + \".\" + NAME , ASCENDING ), ( TEND , ASCENDING ), ( TSTART , ASCENDING ), ] ), # for >v3 IndexModel ([( TEND , ASCENDING )]), ] def __init__ ( self , coll : Collection ): self . coll = coll self . check_index () def check_index ( self ): \"\"\"Create indexes if they dont exist.\"\"\" self . coll . create_indexes ( self . indexes ) def get_details ( self ): \"\"\"Get collection details.\"\"\" return self . coll . estimated_document_count () def drop ( self ): \"\"\"Drop collection.\"\"\" self . coll . drop () def list_sigs ( self ): \"\"\"list signals in collection\"\"\" # v2 v2_list = self . coll . distinct ( SIG_LIST ) v3_list = self . coll . distinct ( SIGS + \".\" + NAME ) final = set ([ * v2_list , * v3_list ]) final = list ( filter ( lambda item : item is not None , final )) return final # @profile def write ( self , data : Frame | Sig , allow_overlapping = False , replace_ids : list [ ObjectId ] = None , ): \"\"\"Write data to collection. Parameters ---------- data data frame or sig to write to collection. allow_overlapping If True, this will read documents with overlapping timelines, append and interweave the data, then write to the collection. replace_ids List of ObjectIds to replace in the write op. Assumes that req'd manipulations have already been performed on `data`. \"\"\" # TODO: retry for mongo errors? # bin data. tic = datetime . now () if data . nsamples > 0 : overlap = self . check_overlapping ( data , exclude_ids = replace_ids ) if overlap : if allow_overlapping : # Read overlapping data and append it to data. data , docs_to_delete = self . get_overlapping ( data , exclude_ids = replace_ids ) else : raise OverlappingData ( \"Overlapping data in collection. Use `allow_overlapping=True` to interweave new data into existing.\" ) docs = to_docs ( data ) toc = datetime . now () - tic _LOGGER . debug ( \"Frame binned in %s [s]\" , toc . total_seconds ()) _LOGGER . debug ( \"Frame compressed from %s [kB] to %s [kB]. %.1f%% \" , format ( getsize ( data ) / 1000 , \",.2\" ), format ( getsize ( docs ) / 1000 , \",.2\" ), ( 1 - getsize ( docs ) / getsize ( data )) * 100 , ) tic = datetime . now () bulk_ops = [ InsertOne ( doc ) for doc in docs ] if overlap : bulk_ops . append ( DeleteMany ({ \"_id\" : { \"$in\" : docs_to_delete }})) if replace_ids is not None : bulk_ops . append ( DeleteMany ({ \"_id\" : { \"$in\" : replace_ids }})) res = self . coll . bulk_write ( bulk_ops , ordered = True ) # TODO: Confirm results here... toc = datetime . now () - tic _LOGGER . info ( \"Inserted: %s , Deleted: %s , Modified: %s , in %s . %s in %s [s]. \\n From %s to %s .\" , res . inserted_count , res . deleted_count , res . modified_count , self . coll . database . name , self . coll . name , toc . total_seconds (), data . tstart_iso , data . tend_iso , ) else : _LOGGER . info ( \"Empty frame passed to ` %s . %s .write()`.\" , self . coll . database . name , self . coll . name , ) def read ( self , sigs : list [ str ] = None , tstart : datetime | float = None , tend : datetime | float = None , ) -> Frame : \"\"\"Read data from collection. Parameters ---------- sigs List of signal names to read. Reads all if `sigs=None`. tstart Start time in unix to read from. Reads all if `tstart=None`. tend End time in unix. Reads all if `tend=None`. Returns ------- CCGFrame CCGFrame read from collection. \"\"\" frm , _ = self . read_full_docs ( sigs , tstart , tend ) # Trim to requested times and signals frm = frm . subset ( slice ( tstart , tend ), sigs ) return frm def read_full_docs ( self , sigs : list [ str ] = None , tstart : datetime | float = None , tend : datetime | float = None , exclude_ids : list [ ObjectId ] = None , ) -> tuple [ Frame , list [ ObjectId ]]: \"\"\"Read documents from collection. Parameters ---------- sigs List of signal names to read. Reads all if `sigs=None`. tstart Start time in unix to read from. Reads all if `tstart=None`. tend End time in unix. Reads all if `tend=None`. exclude_ids Will not read docs with `_id` in `exclude_ids`, Returns ------- CCGFrame CCGFrame read from collection. list[ObjectId] document id's read from DB. \"\"\" tic = datetime . now () if isinstance ( tstart , datetime ): tstart = tstart . timestamp () if isinstance ( tend , datetime ): tend = tend . timestamp () if sigs is not None : if not isinstance ( sigs , list ): sigs = [ sigs ] query = { \"$or\" : [{ SIG_LIST : { \"$in\" : sigs }}, { SIGS + \".\" + NAME : { \"$in\" : sigs }}] } # To work with pre and post v3 bins else : query = {} # find last bin that starts before start. if tstart is not None : query . update ({ TEND : { \"$gte\" : tstart }}) if tend is not None : query . update ({ TSTART : { \"$lte\" : tend }}) if exclude_ids is not None : query . update ({ \"_id\" : { \"$nin\" : exclude_ids }}) # Find total samples for each signal for pre-allocation. getv3 = { BIN_VER : { \"$gte\" : 3 }} | query aggr = [ { \"$match\" : getv3 }, { \"$project\" : { \"_id\" : 0 , SIGS + \".\" + TYPE : 1 , SIGS + \".\" + NAME : 1 , NSAMPLES : 1 , } }, { \"$unwind\" : \"$\" + SIGS }, { \"$group\" : { \"_id\" : \"$\" + SIGS + \".\" + NAME , \"nsamples\" : { \"$sum\" : \"$\" + NSAMPLES }, \"dtype\" : { \"$last\" : \"$\" + SIGS + \".\" + TYPE }, } }, ] aggrtd = self . coll . aggregate ( aggr ) # _LOGGER.debug(\"%s\", aggrtd.explain()) # [\"queryPlanner\"][\"winningPlan\"]) sig_details = {} for doc in aggrtd : sig_details [ doc [ \"_id\" ]] = { \"nsamples\" : doc [ \"nsamples\" ], \"dtype\" : doc [ \"dtype\" ], } docs = self . coll . find ( query ) # _LOGGER.debug(\"%s\", docs.explain()[\"queryPlanner\"][\"winningPlan\"]) if not sig_details : sig_details = None frm , ids = docs_to_frame ( docs , sig_details ) toc = datetime . now () - tic _LOGGER . debug ( \"Read %i docs with %s samples in %.3f [s]\" , docs . retrieved , format ( frm . nsamples , \",\" ), toc . total_seconds (), ) return frm , ids def check_overlapping ( self , frame : Frame , exclude_ids : list [ ObjectId ] = None ): \"\"\"Check collection for tline overlap for this frame. Parameters ---------- frame Data to compare to db for signal and timeline overlap. exclude_ids List of document ids to exclude from the comparison. Useful when modifying docs. \"\"\" for tline in frame . tlines : query = { SIG_LIST : { \"$in\" : frame . tlines . sigs [ tline . idn ]}, TEND : { \"$gte\" : tline . tstart }, TSTART : { \"$lte\" : tline . tend }, } if exclude_ids is not None : query . update ({ \"_id\" : { \"$nin\" : exclude_ids }}) cnt = self . coll . count_documents ( query ) if cnt > 0 : return True return False def get_tstart ( self , signame : str ) -> float : \"\"\"Get start time of sig in collection.\"\"\" tstart = self . coll . find_one ( filter = { SIG_LIST : { \"$in\" : [ signame ]}}, sort = [( TSTART , ASCENDING )], projection = { TSTART : True }, ) return None if tstart is None else tstart [ TSTART ] def get_tend ( self , signame : str ) -> float : \"\"\"Get end time of sig in collection.\"\"\" tend = self . coll . find_one ( filter = { SIG_LIST : { \"$in\" : [ signame ]}}, sort = [( TEND , DESCENDING )], projection = { TEND : True }, ) return None if tend is None else tend [ TEND ] def get_overlapping ( self , frame : Frame , exclude_ids : list [ ObjectId ] = None ) -> tuple [ Frame , list [ ObjectId ]]: \"\"\"Read overlapping data and append to frame.\"\"\" to_delete = [] new_frame = Frame () for tline in frame . tlines : db_frm , ids = self . read_full_docs ( frame . tlines . sigs [ tline . idn ], tstart = tline . tstart , tend = tline . tend , exclude_ids = exclude_ids , ) new_frame . append ( db_frm , append_existing_signals = True , interweave_tlines = True ) for idn in ids : to_delete . append ( idn ) # Be careful not to modify frame in the above for loop. new_frame . append ( frame , append_existing_signals = True , interweave_tlines = True ) return new_frame , to_delete def __getattr__ ( self , coll_name : str ): \"\"\"Get a sub collection from this collection.\"\"\" if not coll_name . startswith ( \"_\" ): # if it starts with _ then it probably isnt a valid collection name, do nothing. return self . __getitem__ ( coll_name ) def __getitem__ ( self , coll_name : str ): \"\"\"Get a sub collection from this collection.\"\"\" if coll_name is not None : return Coll ( self . coll [ coll_name ]) else : return self . coll def __iter__ ( self ): pass __getattr__ ( coll_name ) Get a sub collection from this collection. Source code in ccg\\db\\mongo.py 543 544 545 546 547 def __getattr__ ( self , coll_name : str ): \"\"\"Get a sub collection from this collection.\"\"\" if not coll_name . startswith ( \"_\" ): # if it starts with _ then it probably isnt a valid collection name, do nothing. return self . __getitem__ ( coll_name ) __getitem__ ( coll_name ) Get a sub collection from this collection. Source code in ccg\\db\\mongo.py 549 550 551 552 553 554 def __getitem__ ( self , coll_name : str ): \"\"\"Get a sub collection from this collection.\"\"\" if coll_name is not None : return Coll ( self . coll [ coll_name ]) else : return self . coll check_index () Create indexes if they dont exist. Source code in ccg\\db\\mongo.py 252 253 254 def check_index ( self ): \"\"\"Create indexes if they dont exist.\"\"\" self . coll . create_indexes ( self . indexes ) check_overlapping ( frame , exclude_ids = None ) Check collection for tline overlap for this frame. Parameters: frame ( Frame ) \u2013 Data to compare to db for signal and timeline overlap. exclude_ids ( list [ ObjectId ] , default: None ) \u2013 List of document ids to exclude from the comparison. Useful when modifying docs. Source code in ccg\\db\\mongo.py 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 def check_overlapping ( self , frame : Frame , exclude_ids : list [ ObjectId ] = None ): \"\"\"Check collection for tline overlap for this frame. Parameters ---------- frame Data to compare to db for signal and timeline overlap. exclude_ids List of document ids to exclude from the comparison. Useful when modifying docs. \"\"\" for tline in frame . tlines : query = { SIG_LIST : { \"$in\" : frame . tlines . sigs [ tline . idn ]}, TEND : { \"$gte\" : tline . tstart }, TSTART : { \"$lte\" : tline . tend }, } if exclude_ids is not None : query . update ({ \"_id\" : { \"$nin\" : exclude_ids }}) cnt = self . coll . count_documents ( query ) if cnt > 0 : return True return False drop () Drop collection. Source code in ccg\\db\\mongo.py 260 261 262 def drop ( self ): \"\"\"Drop collection.\"\"\" self . coll . drop () get_details () Get collection details. Source code in ccg\\db\\mongo.py 256 257 258 def get_details ( self ): \"\"\"Get collection details.\"\"\" return self . coll . estimated_document_count () get_overlapping ( frame , exclude_ids = None ) Read overlapping data and append to frame. Source code in ccg\\db\\mongo.py 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 def get_overlapping ( self , frame : Frame , exclude_ids : list [ ObjectId ] = None ) -> tuple [ Frame , list [ ObjectId ]]: \"\"\"Read overlapping data and append to frame.\"\"\" to_delete = [] new_frame = Frame () for tline in frame . tlines : db_frm , ids = self . read_full_docs ( frame . tlines . sigs [ tline . idn ], tstart = tline . tstart , tend = tline . tend , exclude_ids = exclude_ids , ) new_frame . append ( db_frm , append_existing_signals = True , interweave_tlines = True ) for idn in ids : to_delete . append ( idn ) # Be careful not to modify frame in the above for loop. new_frame . append ( frame , append_existing_signals = True , interweave_tlines = True ) return new_frame , to_delete get_tend ( signame ) Get end time of sig in collection. Source code in ccg\\db\\mongo.py 510 511 512 513 514 515 516 517 518 def get_tend ( self , signame : str ) -> float : \"\"\"Get end time of sig in collection.\"\"\" tend = self . coll . find_one ( filter = { SIG_LIST : { \"$in\" : [ signame ]}}, sort = [( TEND , DESCENDING )], projection = { TEND : True }, ) return None if tend is None else tend [ TEND ] get_tstart ( signame ) Get start time of sig in collection. Source code in ccg\\db\\mongo.py 500 501 502 503 504 505 506 507 508 def get_tstart ( self , signame : str ) -> float : \"\"\"Get start time of sig in collection.\"\"\" tstart = self . coll . find_one ( filter = { SIG_LIST : { \"$in\" : [ signame ]}}, sort = [( TSTART , ASCENDING )], projection = { TSTART : True }, ) return None if tstart is None else tstart [ TSTART ] list_sigs () list signals in collection Source code in ccg\\db\\mongo.py 264 265 266 267 268 269 270 271 272 273 def list_sigs ( self ): \"\"\"list signals in collection\"\"\" # v2 v2_list = self . coll . distinct ( SIG_LIST ) v3_list = self . coll . distinct ( SIGS + \".\" + NAME ) final = set ([ * v2_list , * v3_list ]) final = list ( filter ( lambda item : item is not None , final )) return final read ( sigs = None , tstart = None , tend = None ) Read data from collection. Parameters: sigs ( list [ str ] , default: None ) \u2013 List of signal names to read. Reads all if sigs=None . tstart ( datetime | float , default: None ) \u2013 Start time in unix to read from. Reads all if tstart=None . tend ( datetime | float , default: None ) \u2013 End time in unix. Reads all if tend=None . Returns: CCGFrame \u2013 CCGFrame read from collection. Source code in ccg\\db\\mongo.py 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 def read ( self , sigs : list [ str ] = None , tstart : datetime | float = None , tend : datetime | float = None , ) -> Frame : \"\"\"Read data from collection. Parameters ---------- sigs List of signal names to read. Reads all if `sigs=None`. tstart Start time in unix to read from. Reads all if `tstart=None`. tend End time in unix. Reads all if `tend=None`. Returns ------- CCGFrame CCGFrame read from collection. \"\"\" frm , _ = self . read_full_docs ( sigs , tstart , tend ) # Trim to requested times and signals frm = frm . subset ( slice ( tstart , tend ), sigs ) return frm read_full_docs ( sigs = None , tstart = None , tend = None , exclude_ids = None ) Read documents from collection. Parameters: sigs ( list [ str ] , default: None ) \u2013 List of signal names to read. Reads all if sigs=None . tstart ( datetime | float , default: None ) \u2013 Start time in unix to read from. Reads all if tstart=None . tend ( datetime | float , default: None ) \u2013 End time in unix. Reads all if tend=None . exclude_ids ( list [ ObjectId ] , default: None ) \u2013 Will not read docs with _id in exclude_ids , Returns: CCGFrame \u2013 CCGFrame read from collection. list [ ObjectId ] \u2013 document id's read from DB. Source code in ccg\\db\\mongo.py 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 def read_full_docs ( self , sigs : list [ str ] = None , tstart : datetime | float = None , tend : datetime | float = None , exclude_ids : list [ ObjectId ] = None , ) -> tuple [ Frame , list [ ObjectId ]]: \"\"\"Read documents from collection. Parameters ---------- sigs List of signal names to read. Reads all if `sigs=None`. tstart Start time in unix to read from. Reads all if `tstart=None`. tend End time in unix. Reads all if `tend=None`. exclude_ids Will not read docs with `_id` in `exclude_ids`, Returns ------- CCGFrame CCGFrame read from collection. list[ObjectId] document id's read from DB. \"\"\" tic = datetime . now () if isinstance ( tstart , datetime ): tstart = tstart . timestamp () if isinstance ( tend , datetime ): tend = tend . timestamp () if sigs is not None : if not isinstance ( sigs , list ): sigs = [ sigs ] query = { \"$or\" : [{ SIG_LIST : { \"$in\" : sigs }}, { SIGS + \".\" + NAME : { \"$in\" : sigs }}] } # To work with pre and post v3 bins else : query = {} # find last bin that starts before start. if tstart is not None : query . update ({ TEND : { \"$gte\" : tstart }}) if tend is not None : query . update ({ TSTART : { \"$lte\" : tend }}) if exclude_ids is not None : query . update ({ \"_id\" : { \"$nin\" : exclude_ids }}) # Find total samples for each signal for pre-allocation. getv3 = { BIN_VER : { \"$gte\" : 3 }} | query aggr = [ { \"$match\" : getv3 }, { \"$project\" : { \"_id\" : 0 , SIGS + \".\" + TYPE : 1 , SIGS + \".\" + NAME : 1 , NSAMPLES : 1 , } }, { \"$unwind\" : \"$\" + SIGS }, { \"$group\" : { \"_id\" : \"$\" + SIGS + \".\" + NAME , \"nsamples\" : { \"$sum\" : \"$\" + NSAMPLES }, \"dtype\" : { \"$last\" : \"$\" + SIGS + \".\" + TYPE }, } }, ] aggrtd = self . coll . aggregate ( aggr ) # _LOGGER.debug(\"%s\", aggrtd.explain()) # [\"queryPlanner\"][\"winningPlan\"]) sig_details = {} for doc in aggrtd : sig_details [ doc [ \"_id\" ]] = { \"nsamples\" : doc [ \"nsamples\" ], \"dtype\" : doc [ \"dtype\" ], } docs = self . coll . find ( query ) # _LOGGER.debug(\"%s\", docs.explain()[\"queryPlanner\"][\"winningPlan\"]) if not sig_details : sig_details = None frm , ids = docs_to_frame ( docs , sig_details ) toc = datetime . now () - tic _LOGGER . debug ( \"Read %i docs with %s samples in %.3f [s]\" , docs . retrieved , format ( frm . nsamples , \",\" ), toc . total_seconds (), ) return frm , ids write ( data , allow_overlapping = False , replace_ids = None ) Write data to collection. Parameters: data ( Frame | Sig ) \u2013 data frame or sig to write to collection. allow_overlapping \u2013 If True, this will read documents with overlapping timelines, append and interweave the data, then write to the collection. replace_ids ( list [ ObjectId ] , default: None ) \u2013 List of ObjectIds to replace in the write op. Assumes that req'd manipulations have already been performed on data . Source code in ccg\\db\\mongo.py 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 def write ( self , data : Frame | Sig , allow_overlapping = False , replace_ids : list [ ObjectId ] = None , ): \"\"\"Write data to collection. Parameters ---------- data data frame or sig to write to collection. allow_overlapping If True, this will read documents with overlapping timelines, append and interweave the data, then write to the collection. replace_ids List of ObjectIds to replace in the write op. Assumes that req'd manipulations have already been performed on `data`. \"\"\" # TODO: retry for mongo errors? # bin data. tic = datetime . now () if data . nsamples > 0 : overlap = self . check_overlapping ( data , exclude_ids = replace_ids ) if overlap : if allow_overlapping : # Read overlapping data and append it to data. data , docs_to_delete = self . get_overlapping ( data , exclude_ids = replace_ids ) else : raise OverlappingData ( \"Overlapping data in collection. Use `allow_overlapping=True` to interweave new data into existing.\" ) docs = to_docs ( data ) toc = datetime . now () - tic _LOGGER . debug ( \"Frame binned in %s [s]\" , toc . total_seconds ()) _LOGGER . debug ( \"Frame compressed from %s [kB] to %s [kB]. %.1f%% \" , format ( getsize ( data ) / 1000 , \",.2\" ), format ( getsize ( docs ) / 1000 , \",.2\" ), ( 1 - getsize ( docs ) / getsize ( data )) * 100 , ) tic = datetime . now () bulk_ops = [ InsertOne ( doc ) for doc in docs ] if overlap : bulk_ops . append ( DeleteMany ({ \"_id\" : { \"$in\" : docs_to_delete }})) if replace_ids is not None : bulk_ops . append ( DeleteMany ({ \"_id\" : { \"$in\" : replace_ids }})) res = self . coll . bulk_write ( bulk_ops , ordered = True ) # TODO: Confirm results here... toc = datetime . now () - tic _LOGGER . info ( \"Inserted: %s , Deleted: %s , Modified: %s , in %s . %s in %s [s]. \\n From %s to %s .\" , res . inserted_count , res . deleted_count , res . modified_count , self . coll . database . name , self . coll . name , toc . total_seconds (), data . tstart_iso , data . tend_iso , ) else : _LOGGER . info ( \"Empty frame passed to ` %s . %s .write()`.\" , self . coll . database . name , self . coll . name , ) DB Database instance. Source code in ccg\\db\\mongo.py 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 class DB : \"\"\"Database instance.\"\"\" def __init__ ( self , db : Database ): self . _db = db def list_colls ( self ): \"\"\"List collections in DB\"\"\" return self . _db . list_collection_names () def is_coll ( self , coll_name : str ): \"\"\"Returns True if coll in DB collections.\"\"\" return coll_name in self . list_colls () def __getattr__ ( self , coll_name : str ): \"\"\"Get a collection from database.\"\"\" return self . __getitem__ ( coll_name ) def __getitem__ ( self , coll_name : str ): \"\"\"Get a collection from database.\"\"\" return Coll ( self . _db [ coll_name ]) def __iter__ ( self ): \"\"\"Define to avoid accidentally creating collection.\"\"\" return iter ( self . list_colls ()) __getattr__ ( coll_name ) Get a collection from database. Source code in ccg\\db\\mongo.py 214 215 216 def __getattr__ ( self , coll_name : str ): \"\"\"Get a collection from database.\"\"\" return self . __getitem__ ( coll_name ) __getitem__ ( coll_name ) Get a collection from database. Source code in ccg\\db\\mongo.py 218 219 220 def __getitem__ ( self , coll_name : str ): \"\"\"Get a collection from database.\"\"\" return Coll ( self . _db [ coll_name ]) __iter__ () Define to avoid accidentally creating collection. Source code in ccg\\db\\mongo.py 222 223 224 def __iter__ ( self ): \"\"\"Define to avoid accidentally creating collection.\"\"\" return iter ( self . list_colls ()) is_coll ( coll_name ) Returns True if coll in DB collections. Source code in ccg\\db\\mongo.py 210 211 212 def is_coll ( self , coll_name : str ): \"\"\"Returns True if coll in DB collections.\"\"\" return coll_name in self . list_colls () list_colls () List collections in DB Source code in ccg\\db\\mongo.py 206 207 208 def list_colls ( self ): \"\"\"List collections in DB\"\"\" return self . _db . list_collection_names () DBErr Bases: Exception CCGDB Error. Source code in ccg\\db\\mongo.py 747 748 class DBErr ( Exception ): \"\"\"CCGDB Error.\"\"\" DeletionError Bases: DBErr Issue deleting docs in collection. Source code in ccg\\db\\mongo.py 755 756 class DeletionError ( DBErr ): \"\"\"Issue deleting docs in collection.\"\"\" OverlappingData Bases: DBErr Overlapping data in collection. Source code in ccg\\db\\mongo.py 751 752 class OverlappingData ( DBErr ): \"\"\"Overlapping data in collection.\"\"\" docs_to_frame ( docs , sig_details = None ) Build CCGFrame from DB docs. Parameters: docs ( Cursor ) \u2013 pymongo cursor to documents. sigs \u2013 dict of {signame:{nsamples:int, dtype:str}} for pre-allocation. Returns: Frame of data \u2013 list[ObjectId] of document id's \u2013 Source code in ccg\\db\\mongo.py 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 def docs_to_frame ( docs : Cursor , sig_details : dict [ str , dict [ str , Any ]] = None ) -> tuple [ Frame , list [ ObjectId ]]: \"\"\"Build CCGFrame from DB docs. Parameters ---------- docs pymongo cursor to documents. sigs dict of `{signame:{nsamples:int, dtype:str}}` for pre-allocation. Returns ------- Frame of data list[ObjectId] of document id's \"\"\" frm = Frame () tmp : dict [ str , Sig ] = {} if sig_details is not None : # pre-allocate frame, leave it in a dict for speed. for sig , details in sig_details . items (): tmp [ sig ] = Sig ( name = sig , nsamples = details [ \"nsamples\" ], dtype = np . dtype ( details [ \"dtype\" ]) ) ids = [] for doc in docs : # Build Frame... tline = TLine ( np . frombuffer ( lz4 . decompress ( doc [ TLINE ]), dtype = float )) ids . append ( doc [ \"_id\" ]) if doc [ BIN_VER ] >= 3 : for sig_doc in doc [ SIGS ]: try : unks = sig_doc [ UNK_KEYS ] except KeyError : unks = {} connect_gaps = sig_doc [ CONNECT_GAPS ] try : data_enum = SigEnum ( definition = sig_doc [ DATA_ENUM ]) except KeyError : data_enum = None sig = Sig ( data = np . frombuffer ( lz4 . decompress ( sig_doc [ DATA ]), dtype = sig_doc [ TYPE ] ), tline = tline , name = sig_doc [ NAME ], unit = sig_doc [ UNIT ], interp_method = None if sig_doc [ INTERP_METHOD ] is None else InterpMethod ( sig_doc [ INTERP_METHOD ]), data_enum = data_enum , connect_gaps = connect_gaps , ** unks , ) if sig_details is not None : tmp [ sig_doc [ NAME ]] . append ( sig , interweave_tlines = True ) else : frm . append ( sig , append_existing_signals = True , interweave_tlines = True ) else : for sig_name , sig_doc in doc [ SIGS ] . items (): if doc [ BIN_VER ] >= 1 : try : unks = sig_doc [ UNK_KEYS ] except KeyError : unks = {} connect_gaps = sig_doc [ CONNECT_GAPS ] try : data_enum = SigEnum ( definition = sig_doc [ DATA_ENUM ]) except KeyError : data_enum = None else : connect_gaps = None unks = {} data_enum = None sig = Sig ( data = np . frombuffer ( lz4 . decompress ( sig_doc [ DATA ]), dtype = sig_doc [ TYPE ] ), tline = tline , name = sig_name , unit = sig_doc [ UNIT ], interp_method = InterpMethod ( sig_doc [ INTERP_METHOD ]), data_enum = data_enum , connect_gaps = connect_gaps , ** unks , ) frm . append ( sig , append_existing_signals = True , interweave_tlines = True ) if sig_details is not None : for sig_name , sig in tmp . items (): frm . append ( sig , append_existing_signals = True , interweave_tlines = True ) return frm , ids to_doc ( data , tline , ensure_encodable = False ) Build doc for MongoDB. Parameters: data ( Frame ) \u2013 CCGFrame to get data from. tline ( TLine ) \u2013 Tline for this document, will get the signal data corresponding to this tline from data. Returns: Dict for MongoDB. \u2013 Source code in ccg\\db\\mongo.py 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 def to_doc ( data : Frame , tline : TLine , ensure_encodable = False ): \"\"\"Build doc for MongoDB. Parameters ---------- data CCGFrame to get data from. tline Tline for this document, will get the signal data corresponding to this tline from data. Returns ------- Dict for MongoDB. \"\"\" # TODO: Improve ensure_encodable. res = { FRAME_NAME : data . name , SIGS : [], # SIG_LIST: data.tlines.sigs[tline.idn], TLINE : Binary ( lz4 . compress ( tline . unix . tostring ())), NSAMPLES : tline . nsamples , TSTART : tline . tstart , TEND : tline . tend , BIN_VER : CUR_BIN_VER , } for sig in data . tlines . sigs [ tline . idn ]: ccgsig = data . sigs [ sig ] res [ SIGS ] . append ( { NAME : sig , TYPE : str ( ccgsig . data . dtype ), DATA : Binary ( lz4 . compress ( ccgsig . data )), UNIT : ccgsig . unit , INTERP_METHOD : ccgsig . interp_method , CONNECT_GAPS : ccgsig . connect_gaps , } ) if ccgsig . data_enum is not None : res [ SIGS ][ - 1 ] . update ({ DATA_ENUM : ccgsig . data_enum . definition }) # Add unknown fields to doc if possible. unk = {} for key , val in ccgsig . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS [ CUR_BIN_VER ]: try : if ensure_encodable : bson . encode ({ key : val }) # Is there a better way to check if valid? unk . update ({ key : val }) except bson . InvalidDocument : _LOGGER . warning ( \" %s . %s is not BSON encodable.\" , sig , key ) if unk : res [ SIGS ][ - 1 ] . update ({ UNK_KEYS : unk }) return res to_docs ( data ) Bin CCGFrame data to a list of dicts. Docs for MongoDB. Source code in ccg\\db\\mongo.py 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 def to_docs ( data : Frame ) -> list [ dict ]: \"\"\"Bin CCGFrame data to a list of dicts. Docs for MongoDB.\"\"\" docs = [] if data is not None : for tline in data . tlines : size = data . tlines . get_apprx_bytes ( tline ) if size < DOC_MAXSIZE : docs . append ( to_doc ( data , tline )) else : # Split this tline and its sigs approximately evenly so that all fit. nsplit = math . ceil ( size / DOC_MAXSIZE ) smps = math . ceil (( tline . nsamples ) / nsplit ) for i in range ( nsplit ): slc = slice ( tline [ i * smps ], tline [ min (( i + 1 ) * smps , tline . nsamples - 1 )] ) tmp = data . subset ( index = slc , sigs = data . tlines . sigs [ tline . idn ]) _ = tmp . tlines . get_apprx_bytes ( tmp . tlines [ 0 ]) # TODO: improve the accuracy of the seqmenting. docs . append ( to_doc ( tmp , tmp . tlines [ 0 ])) return docs","title":"mongo"},{"location":"reference/ccg/db/mongo/#ccg.db.mongo.Client","text":"MongoDB connection client. Manages connection to MongoDB. Parameters: dbpass ( str , default: None ) \u2013 user level password for database auth. dbuser ( str , default: None ) \u2013 user level username for database auth. dbadmin \u2013 Admin level username. Only required for changing permissions, new databases, etc. dbadminpass \u2013 Admin level password. dbloc ( str , default: 'localhost' ) \u2013 DB location or connection string. dbauthsrc ( str , default: 'admin' ) \u2013 DB for authentication, usually \"admin\" . dbrepset ( str , default: None ) \u2013 Replica set name. Source code in ccg\\db\\mongo.py 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 class Client : \"\"\"MongoDB connection client. Manages connection to MongoDB. Parameters ---------- dbpass user level password for database auth. dbuser user level username for database auth. dbadmin Admin level username. Only required for changing permissions, new databases, etc. dbadminpass Admin level password. dbloc DB location or connection string. dbauthsrc DB for authentication, usually `\"admin\"`. dbrepset Replica set name. \"\"\" def __init__ ( self , dbpass : str = None , dbuser : str = None , # dbadmin: str = None, # dbadminpass: str = None, dbloc : str = \"localhost\" , dbauthsrc : str = \"admin\" , dbrepset : str = None , ) -> None : if dbuser is None or dbpass is None : # Check env variables for login cred's dbuser = os . environ . get ( \"DBUSER\" ) dbpass = os . environ . get ( \"DBPASS\" ) if dbuser is None or dbpass is None : print ( \"Enter your database user and pass. To avoid typing them in, you can put them into environment variables DBUSER and DBPASS.\" ) dbuser = input ( \"User: \" ) dbpass = getpass . getpass ( \"Pass: \" ) connstr = f \"mongodb:// { dbuser } : { dbpass } @ { dbloc } /?authSource= { dbauthsrc } \" if dbrepset : connstr = connstr + f \"&replicaSet= { dbrepset } \" self . client = MongoClient ( connstr ) # TODO: implement admin client to add roles for user if necessary def list_dbs ( self ): \"\"\"List data bases\"\"\" return self . client . list_database_names () def __getattr__ ( self , db_name : str ): \"\"\"Get a database from client.\"\"\" return self . __getitem__ ( db_name ) def __getitem__ ( self , db_name : str ): \"\"\"Get a database from client.\"\"\" return DB ( self . client [ db_name ])","title":"Client"},{"location":"reference/ccg/db/mongo/#ccg.db.mongo.Client.__getattr__","text":"Get a database from client. Source code in ccg\\db\\mongo.py 191 192 193 def __getattr__ ( self , db_name : str ): \"\"\"Get a database from client.\"\"\" return self . __getitem__ ( db_name )","title":"__getattr__"},{"location":"reference/ccg/db/mongo/#ccg.db.mongo.Client.__getitem__","text":"Get a database from client. Source code in ccg\\db\\mongo.py 195 196 197 def __getitem__ ( self , db_name : str ): \"\"\"Get a database from client.\"\"\" return DB ( self . client [ db_name ])","title":"__getitem__"},{"location":"reference/ccg/db/mongo/#ccg.db.mongo.Client.list_dbs","text":"List data bases Source code in ccg\\db\\mongo.py 187 188 189 def list_dbs ( self ): \"\"\"List data bases\"\"\" return self . client . list_database_names ()","title":"list_dbs"},{"location":"reference/ccg/db/mongo/#ccg.db.mongo.Coll","text":"Database collection. Source code in ccg\\db\\mongo.py 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 class Coll : \"\"\"Database collection.\"\"\" indexes = [ IndexModel ( [ ( SIG_LIST , ASCENDING ), ( TEND , ASCENDING ), ( TSTART , ASCENDING ), ] ), # for <v3 Remove soon? IndexModel ( [ ( SIGS + \".\" + NAME , ASCENDING ), ( TEND , ASCENDING ), ( TSTART , ASCENDING ), ] ), # for >v3 IndexModel ([( TEND , ASCENDING )]), ] def __init__ ( self , coll : Collection ): self . coll = coll self . check_index () def check_index ( self ): \"\"\"Create indexes if they dont exist.\"\"\" self . coll . create_indexes ( self . indexes ) def get_details ( self ): \"\"\"Get collection details.\"\"\" return self . coll . estimated_document_count () def drop ( self ): \"\"\"Drop collection.\"\"\" self . coll . drop () def list_sigs ( self ): \"\"\"list signals in collection\"\"\" # v2 v2_list = self . coll . distinct ( SIG_LIST ) v3_list = self . coll . distinct ( SIGS + \".\" + NAME ) final = set ([ * v2_list , * v3_list ]) final = list ( filter ( lambda item : item is not None , final )) return final # @profile def write ( self , data : Frame | Sig , allow_overlapping = False , replace_ids : list [ ObjectId ] = None , ): \"\"\"Write data to collection. Parameters ---------- data data frame or sig to write to collection. allow_overlapping If True, this will read documents with overlapping timelines, append and interweave the data, then write to the collection. replace_ids List of ObjectIds to replace in the write op. Assumes that req'd manipulations have already been performed on `data`. \"\"\" # TODO: retry for mongo errors? # bin data. tic = datetime . now () if data . nsamples > 0 : overlap = self . check_overlapping ( data , exclude_ids = replace_ids ) if overlap : if allow_overlapping : # Read overlapping data and append it to data. data , docs_to_delete = self . get_overlapping ( data , exclude_ids = replace_ids ) else : raise OverlappingData ( \"Overlapping data in collection. Use `allow_overlapping=True` to interweave new data into existing.\" ) docs = to_docs ( data ) toc = datetime . now () - tic _LOGGER . debug ( \"Frame binned in %s [s]\" , toc . total_seconds ()) _LOGGER . debug ( \"Frame compressed from %s [kB] to %s [kB]. %.1f%% \" , format ( getsize ( data ) / 1000 , \",.2\" ), format ( getsize ( docs ) / 1000 , \",.2\" ), ( 1 - getsize ( docs ) / getsize ( data )) * 100 , ) tic = datetime . now () bulk_ops = [ InsertOne ( doc ) for doc in docs ] if overlap : bulk_ops . append ( DeleteMany ({ \"_id\" : { \"$in\" : docs_to_delete }})) if replace_ids is not None : bulk_ops . append ( DeleteMany ({ \"_id\" : { \"$in\" : replace_ids }})) res = self . coll . bulk_write ( bulk_ops , ordered = True ) # TODO: Confirm results here... toc = datetime . now () - tic _LOGGER . info ( \"Inserted: %s , Deleted: %s , Modified: %s , in %s . %s in %s [s]. \\n From %s to %s .\" , res . inserted_count , res . deleted_count , res . modified_count , self . coll . database . name , self . coll . name , toc . total_seconds (), data . tstart_iso , data . tend_iso , ) else : _LOGGER . info ( \"Empty frame passed to ` %s . %s .write()`.\" , self . coll . database . name , self . coll . name , ) def read ( self , sigs : list [ str ] = None , tstart : datetime | float = None , tend : datetime | float = None , ) -> Frame : \"\"\"Read data from collection. Parameters ---------- sigs List of signal names to read. Reads all if `sigs=None`. tstart Start time in unix to read from. Reads all if `tstart=None`. tend End time in unix. Reads all if `tend=None`. Returns ------- CCGFrame CCGFrame read from collection. \"\"\" frm , _ = self . read_full_docs ( sigs , tstart , tend ) # Trim to requested times and signals frm = frm . subset ( slice ( tstart , tend ), sigs ) return frm def read_full_docs ( self , sigs : list [ str ] = None , tstart : datetime | float = None , tend : datetime | float = None , exclude_ids : list [ ObjectId ] = None , ) -> tuple [ Frame , list [ ObjectId ]]: \"\"\"Read documents from collection. Parameters ---------- sigs List of signal names to read. Reads all if `sigs=None`. tstart Start time in unix to read from. Reads all if `tstart=None`. tend End time in unix. Reads all if `tend=None`. exclude_ids Will not read docs with `_id` in `exclude_ids`, Returns ------- CCGFrame CCGFrame read from collection. list[ObjectId] document id's read from DB. \"\"\" tic = datetime . now () if isinstance ( tstart , datetime ): tstart = tstart . timestamp () if isinstance ( tend , datetime ): tend = tend . timestamp () if sigs is not None : if not isinstance ( sigs , list ): sigs = [ sigs ] query = { \"$or\" : [{ SIG_LIST : { \"$in\" : sigs }}, { SIGS + \".\" + NAME : { \"$in\" : sigs }}] } # To work with pre and post v3 bins else : query = {} # find last bin that starts before start. if tstart is not None : query . update ({ TEND : { \"$gte\" : tstart }}) if tend is not None : query . update ({ TSTART : { \"$lte\" : tend }}) if exclude_ids is not None : query . update ({ \"_id\" : { \"$nin\" : exclude_ids }}) # Find total samples for each signal for pre-allocation. getv3 = { BIN_VER : { \"$gte\" : 3 }} | query aggr = [ { \"$match\" : getv3 }, { \"$project\" : { \"_id\" : 0 , SIGS + \".\" + TYPE : 1 , SIGS + \".\" + NAME : 1 , NSAMPLES : 1 , } }, { \"$unwind\" : \"$\" + SIGS }, { \"$group\" : { \"_id\" : \"$\" + SIGS + \".\" + NAME , \"nsamples\" : { \"$sum\" : \"$\" + NSAMPLES }, \"dtype\" : { \"$last\" : \"$\" + SIGS + \".\" + TYPE }, } }, ] aggrtd = self . coll . aggregate ( aggr ) # _LOGGER.debug(\"%s\", aggrtd.explain()) # [\"queryPlanner\"][\"winningPlan\"]) sig_details = {} for doc in aggrtd : sig_details [ doc [ \"_id\" ]] = { \"nsamples\" : doc [ \"nsamples\" ], \"dtype\" : doc [ \"dtype\" ], } docs = self . coll . find ( query ) # _LOGGER.debug(\"%s\", docs.explain()[\"queryPlanner\"][\"winningPlan\"]) if not sig_details : sig_details = None frm , ids = docs_to_frame ( docs , sig_details ) toc = datetime . now () - tic _LOGGER . debug ( \"Read %i docs with %s samples in %.3f [s]\" , docs . retrieved , format ( frm . nsamples , \",\" ), toc . total_seconds (), ) return frm , ids def check_overlapping ( self , frame : Frame , exclude_ids : list [ ObjectId ] = None ): \"\"\"Check collection for tline overlap for this frame. Parameters ---------- frame Data to compare to db for signal and timeline overlap. exclude_ids List of document ids to exclude from the comparison. Useful when modifying docs. \"\"\" for tline in frame . tlines : query = { SIG_LIST : { \"$in\" : frame . tlines . sigs [ tline . idn ]}, TEND : { \"$gte\" : tline . tstart }, TSTART : { \"$lte\" : tline . tend }, } if exclude_ids is not None : query . update ({ \"_id\" : { \"$nin\" : exclude_ids }}) cnt = self . coll . count_documents ( query ) if cnt > 0 : return True return False def get_tstart ( self , signame : str ) -> float : \"\"\"Get start time of sig in collection.\"\"\" tstart = self . coll . find_one ( filter = { SIG_LIST : { \"$in\" : [ signame ]}}, sort = [( TSTART , ASCENDING )], projection = { TSTART : True }, ) return None if tstart is None else tstart [ TSTART ] def get_tend ( self , signame : str ) -> float : \"\"\"Get end time of sig in collection.\"\"\" tend = self . coll . find_one ( filter = { SIG_LIST : { \"$in\" : [ signame ]}}, sort = [( TEND , DESCENDING )], projection = { TEND : True }, ) return None if tend is None else tend [ TEND ] def get_overlapping ( self , frame : Frame , exclude_ids : list [ ObjectId ] = None ) -> tuple [ Frame , list [ ObjectId ]]: \"\"\"Read overlapping data and append to frame.\"\"\" to_delete = [] new_frame = Frame () for tline in frame . tlines : db_frm , ids = self . read_full_docs ( frame . tlines . sigs [ tline . idn ], tstart = tline . tstart , tend = tline . tend , exclude_ids = exclude_ids , ) new_frame . append ( db_frm , append_existing_signals = True , interweave_tlines = True ) for idn in ids : to_delete . append ( idn ) # Be careful not to modify frame in the above for loop. new_frame . append ( frame , append_existing_signals = True , interweave_tlines = True ) return new_frame , to_delete def __getattr__ ( self , coll_name : str ): \"\"\"Get a sub collection from this collection.\"\"\" if not coll_name . startswith ( \"_\" ): # if it starts with _ then it probably isnt a valid collection name, do nothing. return self . __getitem__ ( coll_name ) def __getitem__ ( self , coll_name : str ): \"\"\"Get a sub collection from this collection.\"\"\" if coll_name is not None : return Coll ( self . coll [ coll_name ]) else : return self . coll def __iter__ ( self ): pass","title":"Coll"},{"location":"reference/ccg/db/mongo/#ccg.db.mongo.Coll.__getattr__","text":"Get a sub collection from this collection. Source code in ccg\\db\\mongo.py 543 544 545 546 547 def __getattr__ ( self , coll_name : str ): \"\"\"Get a sub collection from this collection.\"\"\" if not coll_name . startswith ( \"_\" ): # if it starts with _ then it probably isnt a valid collection name, do nothing. return self . __getitem__ ( coll_name )","title":"__getattr__"},{"location":"reference/ccg/db/mongo/#ccg.db.mongo.Coll.__getitem__","text":"Get a sub collection from this collection. Source code in ccg\\db\\mongo.py 549 550 551 552 553 554 def __getitem__ ( self , coll_name : str ): \"\"\"Get a sub collection from this collection.\"\"\" if coll_name is not None : return Coll ( self . coll [ coll_name ]) else : return self . coll","title":"__getitem__"},{"location":"reference/ccg/db/mongo/#ccg.db.mongo.Coll.check_index","text":"Create indexes if they dont exist. Source code in ccg\\db\\mongo.py 252 253 254 def check_index ( self ): \"\"\"Create indexes if they dont exist.\"\"\" self . coll . create_indexes ( self . indexes )","title":"check_index"},{"location":"reference/ccg/db/mongo/#ccg.db.mongo.Coll.check_overlapping","text":"Check collection for tline overlap for this frame. Parameters: frame ( Frame ) \u2013 Data to compare to db for signal and timeline overlap. exclude_ids ( list [ ObjectId ] , default: None ) \u2013 List of document ids to exclude from the comparison. Useful when modifying docs. Source code in ccg\\db\\mongo.py 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 def check_overlapping ( self , frame : Frame , exclude_ids : list [ ObjectId ] = None ): \"\"\"Check collection for tline overlap for this frame. Parameters ---------- frame Data to compare to db for signal and timeline overlap. exclude_ids List of document ids to exclude from the comparison. Useful when modifying docs. \"\"\" for tline in frame . tlines : query = { SIG_LIST : { \"$in\" : frame . tlines . sigs [ tline . idn ]}, TEND : { \"$gte\" : tline . tstart }, TSTART : { \"$lte\" : tline . tend }, } if exclude_ids is not None : query . update ({ \"_id\" : { \"$nin\" : exclude_ids }}) cnt = self . coll . count_documents ( query ) if cnt > 0 : return True return False","title":"check_overlapping"},{"location":"reference/ccg/db/mongo/#ccg.db.mongo.Coll.drop","text":"Drop collection. Source code in ccg\\db\\mongo.py 260 261 262 def drop ( self ): \"\"\"Drop collection.\"\"\" self . coll . drop ()","title":"drop"},{"location":"reference/ccg/db/mongo/#ccg.db.mongo.Coll.get_details","text":"Get collection details. Source code in ccg\\db\\mongo.py 256 257 258 def get_details ( self ): \"\"\"Get collection details.\"\"\" return self . coll . estimated_document_count ()","title":"get_details"},{"location":"reference/ccg/db/mongo/#ccg.db.mongo.Coll.get_overlapping","text":"Read overlapping data and append to frame. Source code in ccg\\db\\mongo.py 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 def get_overlapping ( self , frame : Frame , exclude_ids : list [ ObjectId ] = None ) -> tuple [ Frame , list [ ObjectId ]]: \"\"\"Read overlapping data and append to frame.\"\"\" to_delete = [] new_frame = Frame () for tline in frame . tlines : db_frm , ids = self . read_full_docs ( frame . tlines . sigs [ tline . idn ], tstart = tline . tstart , tend = tline . tend , exclude_ids = exclude_ids , ) new_frame . append ( db_frm , append_existing_signals = True , interweave_tlines = True ) for idn in ids : to_delete . append ( idn ) # Be careful not to modify frame in the above for loop. new_frame . append ( frame , append_existing_signals = True , interweave_tlines = True ) return new_frame , to_delete","title":"get_overlapping"},{"location":"reference/ccg/db/mongo/#ccg.db.mongo.Coll.get_tend","text":"Get end time of sig in collection. Source code in ccg\\db\\mongo.py 510 511 512 513 514 515 516 517 518 def get_tend ( self , signame : str ) -> float : \"\"\"Get end time of sig in collection.\"\"\" tend = self . coll . find_one ( filter = { SIG_LIST : { \"$in\" : [ signame ]}}, sort = [( TEND , DESCENDING )], projection = { TEND : True }, ) return None if tend is None else tend [ TEND ]","title":"get_tend"},{"location":"reference/ccg/db/mongo/#ccg.db.mongo.Coll.get_tstart","text":"Get start time of sig in collection. Source code in ccg\\db\\mongo.py 500 501 502 503 504 505 506 507 508 def get_tstart ( self , signame : str ) -> float : \"\"\"Get start time of sig in collection.\"\"\" tstart = self . coll . find_one ( filter = { SIG_LIST : { \"$in\" : [ signame ]}}, sort = [( TSTART , ASCENDING )], projection = { TSTART : True }, ) return None if tstart is None else tstart [ TSTART ]","title":"get_tstart"},{"location":"reference/ccg/db/mongo/#ccg.db.mongo.Coll.list_sigs","text":"list signals in collection Source code in ccg\\db\\mongo.py 264 265 266 267 268 269 270 271 272 273 def list_sigs ( self ): \"\"\"list signals in collection\"\"\" # v2 v2_list = self . coll . distinct ( SIG_LIST ) v3_list = self . coll . distinct ( SIGS + \".\" + NAME ) final = set ([ * v2_list , * v3_list ]) final = list ( filter ( lambda item : item is not None , final )) return final","title":"list_sigs"},{"location":"reference/ccg/db/mongo/#ccg.db.mongo.Coll.read","text":"Read data from collection. Parameters: sigs ( list [ str ] , default: None ) \u2013 List of signal names to read. Reads all if sigs=None . tstart ( datetime | float , default: None ) \u2013 Start time in unix to read from. Reads all if tstart=None . tend ( datetime | float , default: None ) \u2013 End time in unix. Reads all if tend=None . Returns: CCGFrame \u2013 CCGFrame read from collection. Source code in ccg\\db\\mongo.py 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 def read ( self , sigs : list [ str ] = None , tstart : datetime | float = None , tend : datetime | float = None , ) -> Frame : \"\"\"Read data from collection. Parameters ---------- sigs List of signal names to read. Reads all if `sigs=None`. tstart Start time in unix to read from. Reads all if `tstart=None`. tend End time in unix. Reads all if `tend=None`. Returns ------- CCGFrame CCGFrame read from collection. \"\"\" frm , _ = self . read_full_docs ( sigs , tstart , tend ) # Trim to requested times and signals frm = frm . subset ( slice ( tstart , tend ), sigs ) return frm","title":"read"},{"location":"reference/ccg/db/mongo/#ccg.db.mongo.Coll.read_full_docs","text":"Read documents from collection. Parameters: sigs ( list [ str ] , default: None ) \u2013 List of signal names to read. Reads all if sigs=None . tstart ( datetime | float , default: None ) \u2013 Start time in unix to read from. Reads all if tstart=None . tend ( datetime | float , default: None ) \u2013 End time in unix. Reads all if tend=None . exclude_ids ( list [ ObjectId ] , default: None ) \u2013 Will not read docs with _id in exclude_ids , Returns: CCGFrame \u2013 CCGFrame read from collection. list [ ObjectId ] \u2013 document id's read from DB. Source code in ccg\\db\\mongo.py 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 def read_full_docs ( self , sigs : list [ str ] = None , tstart : datetime | float = None , tend : datetime | float = None , exclude_ids : list [ ObjectId ] = None , ) -> tuple [ Frame , list [ ObjectId ]]: \"\"\"Read documents from collection. Parameters ---------- sigs List of signal names to read. Reads all if `sigs=None`. tstart Start time in unix to read from. Reads all if `tstart=None`. tend End time in unix. Reads all if `tend=None`. exclude_ids Will not read docs with `_id` in `exclude_ids`, Returns ------- CCGFrame CCGFrame read from collection. list[ObjectId] document id's read from DB. \"\"\" tic = datetime . now () if isinstance ( tstart , datetime ): tstart = tstart . timestamp () if isinstance ( tend , datetime ): tend = tend . timestamp () if sigs is not None : if not isinstance ( sigs , list ): sigs = [ sigs ] query = { \"$or\" : [{ SIG_LIST : { \"$in\" : sigs }}, { SIGS + \".\" + NAME : { \"$in\" : sigs }}] } # To work with pre and post v3 bins else : query = {} # find last bin that starts before start. if tstart is not None : query . update ({ TEND : { \"$gte\" : tstart }}) if tend is not None : query . update ({ TSTART : { \"$lte\" : tend }}) if exclude_ids is not None : query . update ({ \"_id\" : { \"$nin\" : exclude_ids }}) # Find total samples for each signal for pre-allocation. getv3 = { BIN_VER : { \"$gte\" : 3 }} | query aggr = [ { \"$match\" : getv3 }, { \"$project\" : { \"_id\" : 0 , SIGS + \".\" + TYPE : 1 , SIGS + \".\" + NAME : 1 , NSAMPLES : 1 , } }, { \"$unwind\" : \"$\" + SIGS }, { \"$group\" : { \"_id\" : \"$\" + SIGS + \".\" + NAME , \"nsamples\" : { \"$sum\" : \"$\" + NSAMPLES }, \"dtype\" : { \"$last\" : \"$\" + SIGS + \".\" + TYPE }, } }, ] aggrtd = self . coll . aggregate ( aggr ) # _LOGGER.debug(\"%s\", aggrtd.explain()) # [\"queryPlanner\"][\"winningPlan\"]) sig_details = {} for doc in aggrtd : sig_details [ doc [ \"_id\" ]] = { \"nsamples\" : doc [ \"nsamples\" ], \"dtype\" : doc [ \"dtype\" ], } docs = self . coll . find ( query ) # _LOGGER.debug(\"%s\", docs.explain()[\"queryPlanner\"][\"winningPlan\"]) if not sig_details : sig_details = None frm , ids = docs_to_frame ( docs , sig_details ) toc = datetime . now () - tic _LOGGER . debug ( \"Read %i docs with %s samples in %.3f [s]\" , docs . retrieved , format ( frm . nsamples , \",\" ), toc . total_seconds (), ) return frm , ids","title":"read_full_docs"},{"location":"reference/ccg/db/mongo/#ccg.db.mongo.Coll.write","text":"Write data to collection. Parameters: data ( Frame | Sig ) \u2013 data frame or sig to write to collection. allow_overlapping \u2013 If True, this will read documents with overlapping timelines, append and interweave the data, then write to the collection. replace_ids ( list [ ObjectId ] , default: None ) \u2013 List of ObjectIds to replace in the write op. Assumes that req'd manipulations have already been performed on data . Source code in ccg\\db\\mongo.py 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 def write ( self , data : Frame | Sig , allow_overlapping = False , replace_ids : list [ ObjectId ] = None , ): \"\"\"Write data to collection. Parameters ---------- data data frame or sig to write to collection. allow_overlapping If True, this will read documents with overlapping timelines, append and interweave the data, then write to the collection. replace_ids List of ObjectIds to replace in the write op. Assumes that req'd manipulations have already been performed on `data`. \"\"\" # TODO: retry for mongo errors? # bin data. tic = datetime . now () if data . nsamples > 0 : overlap = self . check_overlapping ( data , exclude_ids = replace_ids ) if overlap : if allow_overlapping : # Read overlapping data and append it to data. data , docs_to_delete = self . get_overlapping ( data , exclude_ids = replace_ids ) else : raise OverlappingData ( \"Overlapping data in collection. Use `allow_overlapping=True` to interweave new data into existing.\" ) docs = to_docs ( data ) toc = datetime . now () - tic _LOGGER . debug ( \"Frame binned in %s [s]\" , toc . total_seconds ()) _LOGGER . debug ( \"Frame compressed from %s [kB] to %s [kB]. %.1f%% \" , format ( getsize ( data ) / 1000 , \",.2\" ), format ( getsize ( docs ) / 1000 , \",.2\" ), ( 1 - getsize ( docs ) / getsize ( data )) * 100 , ) tic = datetime . now () bulk_ops = [ InsertOne ( doc ) for doc in docs ] if overlap : bulk_ops . append ( DeleteMany ({ \"_id\" : { \"$in\" : docs_to_delete }})) if replace_ids is not None : bulk_ops . append ( DeleteMany ({ \"_id\" : { \"$in\" : replace_ids }})) res = self . coll . bulk_write ( bulk_ops , ordered = True ) # TODO: Confirm results here... toc = datetime . now () - tic _LOGGER . info ( \"Inserted: %s , Deleted: %s , Modified: %s , in %s . %s in %s [s]. \\n From %s to %s .\" , res . inserted_count , res . deleted_count , res . modified_count , self . coll . database . name , self . coll . name , toc . total_seconds (), data . tstart_iso , data . tend_iso , ) else : _LOGGER . info ( \"Empty frame passed to ` %s . %s .write()`.\" , self . coll . database . name , self . coll . name , )","title":"write"},{"location":"reference/ccg/db/mongo/#ccg.db.mongo.DB","text":"Database instance. Source code in ccg\\db\\mongo.py 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 class DB : \"\"\"Database instance.\"\"\" def __init__ ( self , db : Database ): self . _db = db def list_colls ( self ): \"\"\"List collections in DB\"\"\" return self . _db . list_collection_names () def is_coll ( self , coll_name : str ): \"\"\"Returns True if coll in DB collections.\"\"\" return coll_name in self . list_colls () def __getattr__ ( self , coll_name : str ): \"\"\"Get a collection from database.\"\"\" return self . __getitem__ ( coll_name ) def __getitem__ ( self , coll_name : str ): \"\"\"Get a collection from database.\"\"\" return Coll ( self . _db [ coll_name ]) def __iter__ ( self ): \"\"\"Define to avoid accidentally creating collection.\"\"\" return iter ( self . list_colls ())","title":"DB"},{"location":"reference/ccg/db/mongo/#ccg.db.mongo.DB.__getattr__","text":"Get a collection from database. Source code in ccg\\db\\mongo.py 214 215 216 def __getattr__ ( self , coll_name : str ): \"\"\"Get a collection from database.\"\"\" return self . __getitem__ ( coll_name )","title":"__getattr__"},{"location":"reference/ccg/db/mongo/#ccg.db.mongo.DB.__getitem__","text":"Get a collection from database. Source code in ccg\\db\\mongo.py 218 219 220 def __getitem__ ( self , coll_name : str ): \"\"\"Get a collection from database.\"\"\" return Coll ( self . _db [ coll_name ])","title":"__getitem__"},{"location":"reference/ccg/db/mongo/#ccg.db.mongo.DB.__iter__","text":"Define to avoid accidentally creating collection. Source code in ccg\\db\\mongo.py 222 223 224 def __iter__ ( self ): \"\"\"Define to avoid accidentally creating collection.\"\"\" return iter ( self . list_colls ())","title":"__iter__"},{"location":"reference/ccg/db/mongo/#ccg.db.mongo.DB.is_coll","text":"Returns True if coll in DB collections. Source code in ccg\\db\\mongo.py 210 211 212 def is_coll ( self , coll_name : str ): \"\"\"Returns True if coll in DB collections.\"\"\" return coll_name in self . list_colls ()","title":"is_coll"},{"location":"reference/ccg/db/mongo/#ccg.db.mongo.DB.list_colls","text":"List collections in DB Source code in ccg\\db\\mongo.py 206 207 208 def list_colls ( self ): \"\"\"List collections in DB\"\"\" return self . _db . list_collection_names ()","title":"list_colls"},{"location":"reference/ccg/db/mongo/#ccg.db.mongo.DBErr","text":"Bases: Exception CCGDB Error. Source code in ccg\\db\\mongo.py 747 748 class DBErr ( Exception ): \"\"\"CCGDB Error.\"\"\"","title":"DBErr"},{"location":"reference/ccg/db/mongo/#ccg.db.mongo.DeletionError","text":"Bases: DBErr Issue deleting docs in collection. Source code in ccg\\db\\mongo.py 755 756 class DeletionError ( DBErr ): \"\"\"Issue deleting docs in collection.\"\"\"","title":"DeletionError"},{"location":"reference/ccg/db/mongo/#ccg.db.mongo.OverlappingData","text":"Bases: DBErr Overlapping data in collection. Source code in ccg\\db\\mongo.py 751 752 class OverlappingData ( DBErr ): \"\"\"Overlapping data in collection.\"\"\"","title":"OverlappingData"},{"location":"reference/ccg/db/mongo/#ccg.db.mongo.docs_to_frame","text":"Build CCGFrame from DB docs. Parameters: docs ( Cursor ) \u2013 pymongo cursor to documents. sigs \u2013 dict of {signame:{nsamples:int, dtype:str}} for pre-allocation. Returns: Frame of data \u2013 list[ObjectId] of document id's \u2013 Source code in ccg\\db\\mongo.py 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 def docs_to_frame ( docs : Cursor , sig_details : dict [ str , dict [ str , Any ]] = None ) -> tuple [ Frame , list [ ObjectId ]]: \"\"\"Build CCGFrame from DB docs. Parameters ---------- docs pymongo cursor to documents. sigs dict of `{signame:{nsamples:int, dtype:str}}` for pre-allocation. Returns ------- Frame of data list[ObjectId] of document id's \"\"\" frm = Frame () tmp : dict [ str , Sig ] = {} if sig_details is not None : # pre-allocate frame, leave it in a dict for speed. for sig , details in sig_details . items (): tmp [ sig ] = Sig ( name = sig , nsamples = details [ \"nsamples\" ], dtype = np . dtype ( details [ \"dtype\" ]) ) ids = [] for doc in docs : # Build Frame... tline = TLine ( np . frombuffer ( lz4 . decompress ( doc [ TLINE ]), dtype = float )) ids . append ( doc [ \"_id\" ]) if doc [ BIN_VER ] >= 3 : for sig_doc in doc [ SIGS ]: try : unks = sig_doc [ UNK_KEYS ] except KeyError : unks = {} connect_gaps = sig_doc [ CONNECT_GAPS ] try : data_enum = SigEnum ( definition = sig_doc [ DATA_ENUM ]) except KeyError : data_enum = None sig = Sig ( data = np . frombuffer ( lz4 . decompress ( sig_doc [ DATA ]), dtype = sig_doc [ TYPE ] ), tline = tline , name = sig_doc [ NAME ], unit = sig_doc [ UNIT ], interp_method = None if sig_doc [ INTERP_METHOD ] is None else InterpMethod ( sig_doc [ INTERP_METHOD ]), data_enum = data_enum , connect_gaps = connect_gaps , ** unks , ) if sig_details is not None : tmp [ sig_doc [ NAME ]] . append ( sig , interweave_tlines = True ) else : frm . append ( sig , append_existing_signals = True , interweave_tlines = True ) else : for sig_name , sig_doc in doc [ SIGS ] . items (): if doc [ BIN_VER ] >= 1 : try : unks = sig_doc [ UNK_KEYS ] except KeyError : unks = {} connect_gaps = sig_doc [ CONNECT_GAPS ] try : data_enum = SigEnum ( definition = sig_doc [ DATA_ENUM ]) except KeyError : data_enum = None else : connect_gaps = None unks = {} data_enum = None sig = Sig ( data = np . frombuffer ( lz4 . decompress ( sig_doc [ DATA ]), dtype = sig_doc [ TYPE ] ), tline = tline , name = sig_name , unit = sig_doc [ UNIT ], interp_method = InterpMethod ( sig_doc [ INTERP_METHOD ]), data_enum = data_enum , connect_gaps = connect_gaps , ** unks , ) frm . append ( sig , append_existing_signals = True , interweave_tlines = True ) if sig_details is not None : for sig_name , sig in tmp . items (): frm . append ( sig , append_existing_signals = True , interweave_tlines = True ) return frm , ids","title":"docs_to_frame"},{"location":"reference/ccg/db/mongo/#ccg.db.mongo.to_doc","text":"Build doc for MongoDB. Parameters: data ( Frame ) \u2013 CCGFrame to get data from. tline ( TLine ) \u2013 Tline for this document, will get the signal data corresponding to this tline from data. Returns: Dict for MongoDB. \u2013 Source code in ccg\\db\\mongo.py 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 def to_doc ( data : Frame , tline : TLine , ensure_encodable = False ): \"\"\"Build doc for MongoDB. Parameters ---------- data CCGFrame to get data from. tline Tline for this document, will get the signal data corresponding to this tline from data. Returns ------- Dict for MongoDB. \"\"\" # TODO: Improve ensure_encodable. res = { FRAME_NAME : data . name , SIGS : [], # SIG_LIST: data.tlines.sigs[tline.idn], TLINE : Binary ( lz4 . compress ( tline . unix . tostring ())), NSAMPLES : tline . nsamples , TSTART : tline . tstart , TEND : tline . tend , BIN_VER : CUR_BIN_VER , } for sig in data . tlines . sigs [ tline . idn ]: ccgsig = data . sigs [ sig ] res [ SIGS ] . append ( { NAME : sig , TYPE : str ( ccgsig . data . dtype ), DATA : Binary ( lz4 . compress ( ccgsig . data )), UNIT : ccgsig . unit , INTERP_METHOD : ccgsig . interp_method , CONNECT_GAPS : ccgsig . connect_gaps , } ) if ccgsig . data_enum is not None : res [ SIGS ][ - 1 ] . update ({ DATA_ENUM : ccgsig . data_enum . definition }) # Add unknown fields to doc if possible. unk = {} for key , val in ccgsig . __dict__ . items (): if not key . startswith ( \"_\" ) and key not in SIG_ATTRS [ CUR_BIN_VER ]: try : if ensure_encodable : bson . encode ({ key : val }) # Is there a better way to check if valid? unk . update ({ key : val }) except bson . InvalidDocument : _LOGGER . warning ( \" %s . %s is not BSON encodable.\" , sig , key ) if unk : res [ SIGS ][ - 1 ] . update ({ UNK_KEYS : unk }) return res","title":"to_doc"},{"location":"reference/ccg/db/mongo/#ccg.db.mongo.to_docs","text":"Bin CCGFrame data to a list of dicts. Docs for MongoDB. Source code in ccg\\db\\mongo.py 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 def to_docs ( data : Frame ) -> list [ dict ]: \"\"\"Bin CCGFrame data to a list of dicts. Docs for MongoDB.\"\"\" docs = [] if data is not None : for tline in data . tlines : size = data . tlines . get_apprx_bytes ( tline ) if size < DOC_MAXSIZE : docs . append ( to_doc ( data , tline )) else : # Split this tline and its sigs approximately evenly so that all fit. nsplit = math . ceil ( size / DOC_MAXSIZE ) smps = math . ceil (( tline . nsamples ) / nsplit ) for i in range ( nsplit ): slc = slice ( tline [ i * smps ], tline [ min (( i + 1 ) * smps , tline . nsamples - 1 )] ) tmp = data . subset ( index = slc , sigs = data . tlines . sigs [ tline . idn ]) _ = tmp . tlines . get_apprx_bytes ( tmp . tlines [ 0 ]) # TODO: improve the accuracy of the seqmenting. docs . append ( to_doc ( tmp , tmp . tlines [ 0 ])) return docs","title":"to_docs"},{"location":"reference/ccg/ui/","text":"","title":"ui"},{"location":"reference/ccg/ui/panel/","text":"Panel app driver. CalData Class to contain cal data and its handlers. Source code in ccg\\ui\\panel.py 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 class CalData : \"\"\"Class to contain cal data and its handlers.\"\"\" def __init__ ( self , data : Tbl | None = None ): self . table_data = data if self . table_data is not None : self . widget = pn . Column ( sizing_mode = \"stretch_width\" , css_classes = [ \"cdata\" ], name = data . name ) else : self . widget = pn . Column ( sizing_mode = \"stretch_width\" , css_classes = [ \"cdata\" ]) self . additional_gate : GateColl | None = None # self.fig.fig = None # self.plt_widget = pn.pane.Plotly( # self.fig.fig, # height=600, # width_policy=\"fit\", # sizing_mode=\"stretch_width\", # css_classes=[\"plot\"], # align=(\"start\", \"center\"), # link_figure=False, # ) self . build_panel_widget () def build_panel_widget ( self ) -> pn . Column : \"\"\"Build CalData widget for param.\"\"\" tic = datetime . datetime . now () res = self . widget if self . table_data is not None : # tic = datetime.datetime.now() # res.name = self.table_data.name # Can't modify name, need to decide if its ok to init with None prec_args = self . build_prec_args () assert isinstance ( prec_args , dict ) self . cdata = CalDataTbl ( name = self . table_data . name , table_name = f \" { self . table_data . name } [ { self . table_data . unit } ]\" , data = self . table_data . data . T . tolist (), colorscale = \"RdBu\" , ** prec_args , ) prec_args [ \"data_precision\" ] = 1 self . count = CalDataTbl ( name = \"Count\" , table_name = \"Count [samples]\" , data = self . table_data . count . T . tolist (), editable = False , colorscale = \"Blues\" , ** prec_args , ) prec_args [ \"data_precision\" ] = 2 self . delta_perc = CalDataTbl ( name = \"Delta %\" , table_name = \"Delta (current/orig-1) [%]\" , data = self . table_data . delta_perc . T . tolist (), editable = False , colorscale = \"RdBu\" , colorscale_center = 0 , ** prec_args , ) self . cdata . param . watch ( self . update_axes , [ \"axis_breakpoints\" ]) self . cdata . param . watch ( self . update_table_data , [ \"data\" ]) self . cdata . param . watch ( self . highlight_selected , [ \"selected_cells\" ]) self . cdata . param . watch ( self . undo , [ \"undo\" ]) self . cdata . param . watch ( self . reset , [ \"reset\" ]) toc = datetime . datetime . now () - tic _LOGGER . debug ( \"caldatas in %.3f \" , toc . total_seconds ()) tic = datetime . datetime . now () plt = plotgo . Plot ( self . table_data ) self . fig = plt self . plt_widget = pn . pane . Plotly ( self . fig . fig , height = 600 , width_policy = \"fit\" , sizing_mode = \"stretch_width\" , css_classes = [ \"plot\" ], align = ( \"start\" , \"center\" ), link_figure = False , ) toc = datetime . datetime . now () - tic _LOGGER . debug ( \"Built plot in %.3f \" , toc . total_seconds ()) tic = datetime . datetime . now () # self.plt_widget.param.watch( # self.plot_click, [\"click_data\"], onlychanged=False # ) self . f_orig = pn . widgets . FloatSlider ( name = \"Damping Factor\" , start = 0 , end = 1 , step = 0.01 , value = self . table_data . f_orig , ) self . smoothing = [] for j in range ( self . table_data . n_dim ): self . smoothing . append ( pn . widgets . FloatSlider ( name = f \" { self . table_data . axes [ j ] . name } Smoothing\" , start = 0 , end = 1 , step = 0.01 , value = self . table_data . f_smooth [ j ], ) ) self . fit_button = pn . widgets . Button ( name = \"Fit\" , disabled = True ) self . commit_button = pn . widgets . Button ( name = \"Commit\" , disabled = False ) self . color_sig = pn . widgets . MultiChoice ( name = \"Scatter Data Color Source:\" , delete_button = True , max_items = 1 , placeholder = \"Select a signal name or `Relative Density` for color axis\" , # doesnt seem to work ) self . additional_gate_path = pn . widgets . TextInput ( name = \"Table Specific Gate Config File\" , placeholder = \"Gate config filename...\" , ) self . additional_gate_path . param . watch ( self . load_additional_gate , [ \"value\" ]) self . tabs = pn . Tabs ( self . cdata , self . delta_perc , self . count , dynamic = False , ) self . tabs . param . watch ( self . changed_tabs , [ \"active\" ]) res . extend ( [ pn . Row ( self . tabs , pn . Column ( self . f_orig , * self . smoothing , self . fit_button , self . commit_button , self . color_sig , self . additional_gate_path , width = 280 , ), sizing_mode = \"stretch_width\" , ), self . plt_widget , # self.plt_widget.controls(jslink=True), ] ) self . fit_button . on_click ( self . fit_data ) self . commit_button . on_click ( self . commit_fit ) # toc = datetime.datetime.now() - tic # _LOGGER.debug(\"Built cal_data widget in %.3f\", toc.total_seconds()) toc = datetime . datetime . now () - tic _LOGGER . debug ( \"finished cal_data widget in %.3f \" , toc . total_seconds ()) return res def build_prec_args ( self ): \"\"\"Build the prec_args dictionary for CalDataTbl.\"\"\" if self . table_data is not None : axes_data = self . table_data . axes prec_args = { \"axis_names\" : [ f \" { axis . name } [ { axis . unit } ]\" for axis in axes_data ], \"axis_breakpoints\" : [ axis . data . tolist () for axis in axes_data ], \"axis_precisions\" : [ axis . precision for axis in axes_data ], \"data_precision\" : self . table_data . precision , \"locked\" : self . table_data . locked . T . tolist (), } return prec_args @property def row_off ( self ) -> int | None : \"\"\"Row offset for cal data table\"\"\" if self . table_data is None : return None if self . table_data . n_dim in ( 2 , 1 ): return 3 if self . table_data . n_dim == 3 : raise NotImplementedError ( \"3d table data not implemented\" ) elif self . table_data . n_dim == 0 : return 1 else : return None @property def col_off ( self ) -> int | None : \"\"\"Column offset for cal data table\"\"\" if self . table_data is None : return None if self . table_data . n_dim == 2 : return 1 if self . table_data . n_dim in ( 1 , 0 ): return 0 else : return None def load_additional_gate ( self , event : param . parameterized . Event | None = None ): \"\"\"Load a table specific gate config\"\"\" if event is not None : try : file_path = Path ( event . new ) if file_path and str ( file_path ) != \".\" : self . additional_gate = gatecoll_from_file ( file_path ) else : self . additional_gate = None event . obj . name = \"Table Specific Gate Config File\" event . obj . styles = { \"background\" : None } except OSError : event . obj . name = \"Invalid File Name\" event . obj . styles = { \"background\" : \"#e03838\" } self . additional_gate = None def undo ( self , event : param . parameterized . Event ): \"\"\"Undo last change to table.\"\"\" if event . new : self . table_data . undo () if self . table_data . n_dim == 2 : self . cdata . axis_breakpoints [ 1 ] = self . table_data . axes [ 1 ] . data . tolist () if self . table_data . n_dim > 0 : self . cdata . axis_breakpoints [ 0 ] = self . table_data . axes [ 0 ] . data . tolist () self . cdata . undo = False self . update_all_tables () self . update_table_plot () def reset ( self , event : param . parameterized . Event ): \"\"\"Reset selected cells to orig.\"\"\" if event . new : axis0_edit = False axis1_edit = False data_edit = False self . table_data . snapshot () # Take snapshot before making changes. # print(\"selected cell = \", self.cdata.selected_cells) for cell in self . cdata . selected_cells : if cell [ \"row\" ] < self . row_off : # This is axis0 axis0_edit = True self . table_data . axes [ 0 ][ cell [ \"col\" ] - self . col_off ] = ( self . table_data . _archive [ \"orig\" ][ - 1 ] . axes [ 0 ][ cell [ \"col\" ] - self . col_off ] ) elif cell [ \"col\" ] < self . col_off : # This is axis1 axis1_edit = True self . table_data . axes [ 1 ][ cell [ \"row\" ] - self . row_off ] = ( self . table_data . _archive [ \"orig\" ][ - 1 ] . axes [ 1 ][ cell [ \"row\" ] - self . row_off ] ) else : data_edit = True if self . table_data . n_dim == 2 : self . table_data . data [ cell [ \"col\" ] - self . col_off , cell [ \"row\" ] - self . row_off ] = self . table_data . _archive [ \"orig\" ][ - 1 ] . data [ cell [ \"col\" ] - self . col_off , cell [ \"row\" ] - self . row_off ] else : self . table_data . data [ cell [ \"col\" ] - self . col_off ] = ( self . table_data . _archive [ \"orig\" ][ - 1 ] . data [ cell [ \"col\" ] - self . col_off ] ) if axis0_edit : self . cdata . axis_breakpoints [ 0 ] = self . table_data . axes [ 0 ] . data . tolist () # To trigger interpolation self . table_data . axes [ 0 ] = self . table_data . axes [ 0 ] data_edit = True if axis1_edit : self . cdata . axis_breakpoints [ 1 ] = self . table_data . axes [ 1 ] . data . tolist () # To trigger interpolation self . table_data . axes [ 1 ] = self . table_data . axes [ 1 ] data_edit = True if data_edit : self . cdata . data = self . table_data . data . T . tolist () self . cdata . reset = False self . update_all_tables () self . update_table_plot () def changed_tabs ( self , event : param . parameterized . Event ): if event . old == 0 : self . cdata . selected_cells = [] def update_axes ( self , event : param . parameterized . Event ): \"\"\"handle updates to axes\"\"\" if not event . obj . undo and not event . obj . reset : new_axes_data = event . new for index , axis in enumerate ( new_axes_data ): self . table_data . axes [ index ] . data = np . array ( axis , dtype = self . table_data . axes [ index ] . data . dtype ) self . update_all_tables () self . update_table_plot () def update_table_plot ( self , _ : param . parameterized . Event = None ): \"\"\"Update table traces in plot.\"\"\" tic = datetime . datetime . now () if self . table_data . n_dim == 2 : keys = [ \"x\" , \"y\" , \"z\" ] ntrace = 4 elif self . table_data . n_dim == 1 : keys = [ \"x\" , \"y\" ] ntrace = 2 else : keys = [ \"y\" ] ntrace = 2 tmptrc = self . fig . build_traces_from_tbl ( self . table_data ) # with self.fig.fig.batch_update(): for i in range ( ntrace ): # 4 table traces newdata = { key : tmptrc [ i ][ key ] for key in keys } self . fig . fig . update_traces ( newdata , selector = i , overwrite = False ) self . plt_widget . param . trigger ( \"object\" ) toc = datetime . datetime . now () - tic _LOGGER . debug ( \"Update %s plot in %.3f \" , self . table_data . name , toc . total_seconds () ) def update_plot ( self , _ : param . parameterized . Event = None ): \"\"\"Updates the whole plot\"\"\" if isinstance ( self . fig , plotgo . Plot ): tmptrc = self . fig . build_traces_from_tbl ( self . table_data ) n = 0 for i , _ in enumerate ( self . fig . fig . data ): self . fig . fig . update_traces ( tmptrc [ i ], selector = i ) n = i for i in range ( n + 1 , len ( tmptrc )): self . fig . fig . add_trace ( tmptrc [ i ]) event = DummyEvent ( old = [], new = self . cdata . selected_cells ) self . highlight_selected ( event ) else : util . merge_dict ( self . fig , Plot ( self . table_data ) . to_dict ()) event = DummyEvent ( old = [], new = self . cdata . selected_cells ) self . highlight_selected ( event ) def plot_click ( self , event : param . parameterized . Event ): \"\"\"Plot Clicked\"\"\" n = event . new [ \"points\" ][ 0 ][ \"curveNumber\" ] if n == 2 : x = event . new [ \"points\" ][ 0 ][ \"x\" ] y = event . new [ \"points\" ][ 0 ][ \"y\" ] xind = np . where ( self . table_data . axes [ 0 ] . data == x )[ 0 ] yind = np . where ( self . table_data . axes [ 1 ] . data == y )[ 0 ] row = yind [ 0 ] + 3 col = xind [ 0 ] + 1 idn = f \"cal-data- { row } - { col } - { self . cdata . idn } \" active_cell = { \"row\" : row , \"col\" : col , \"id\" : idn } self . cdata . active_cell = active_cell self . cdata . n_cell = self . cdata . n_cell + 1 def highlight_selected ( self , event : param . parameterized . Event ): \"\"\"This will updated the plt trace to highlight the selected cells from event.obj.selected_cells\"\"\" tic = datetime . datetime . now () if self . table_data . n_dim == 2 : trcnum = 3 else : trcnum = 1 old_inds , new_inds = self . find_highlight_inds ( event ) tmp = self . build_selction_update ( old_selected = old_inds , selected = new_inds , trace_num = trcnum ) # with self.fig.fig.batch_update(): self . fig . fig . update_traces ( ** tmp ) self . plt_widget . param . trigger ( \"object\" ) toc = datetime . datetime . now () - tic _LOGGER . debug ( \"Update %s plot selection in %.3f \" , self . table_data . name , toc . total_seconds (), ) def find_highlight_inds ( self , event : param . parameterized . Event ): \"\"\"Finds indices for highlighting func\"\"\" old_inds = [] new_inds = [] if event : new_rows = [] new_cols = [] ndim = self . table_data . n_dim for cell in event . new : row_offset = cell [ \"row\" ] - self . row_off col_offset = cell [ \"col\" ] - self . col_off if row_offset == - 1 : if ndim == 2 : new_rows . extend ( range ( len ( self . table_data . axes [ 1 ]))) new_cols . extend ([ col_offset ] * len ( self . table_data . axes [ 1 ])) else : new_rows . append ( 0 ) new_cols . append ( col_offset ) elif col_offset == - 1 : new_rows . extend ([ row_offset ] * len ( self . table_data . axes [ 0 ])) new_cols . extend ( range ( len ( self . table_data . axes [ 0 ]))) else : new_rows . append ( row_offset ) new_cols . append ( col_offset ) old_rows = [] old_cols = [] for cell in event . old : row_offset = cell [ \"row\" ] - self . row_off col_offset = cell [ \"col\" ] - self . col_off if row_offset == - 1 : if ndim == 2 : old_rows . extend ( range ( len ( self . table_data . axes [ 1 ]))) old_cols . extend ([ col_offset ] * len ( self . table_data . axes [ 1 ])) else : old_rows . append ( 0 ) old_cols . append ( col_offset ) elif col_offset == - 1 : old_rows . extend ([ row_offset ] * len ( self . table_data . axes [ 0 ])) old_cols . extend ( range ( len ( self . table_data . axes [ 0 ]))) else : old_rows . append ( row_offset ) old_cols . append ( col_offset ) if ( np . all ( np . greater_equal ( new_rows , 0 )) and np . all ( np . greater_equal ( new_cols , 0 )) and ( len ( old_cols ) + len ( new_cols )) > 0 ): shp = tuple ( x + 1 for x in self . table_data . axes . table_shape ) if ndim < 2 : shp = self . table_data . axes . table_shape if old_rows : if ndim == 0 : old_inds = [ 0 ] elif ndim == 2 : old_inds = np . concatenate ( ( old_inds , np . ravel_multi_index ( ( old_cols , old_rows ), shp [:: - 1 ], order = \"f\" ) + np . prod ( shp ) - shp [ 0 ], ) ) else : old_inds = np . ravel_multi_index ( ( old_rows , old_cols ), shp , order = \"f\" ) # New Inds if new_rows : if ndim == 0 : new_inds = [ 0 ] elif ndim == 2 : new_inds = np . concatenate ( ( new_inds , np . ravel_multi_index ( ( new_cols , new_rows ), shp [:: - 1 ], order = \"f\" ) + np . prod ( shp ) - shp [ 0 ], ) ) else : new_inds = np . ravel_multi_index ( ( new_rows , new_cols ), shp , order = \"f\" ) return old_inds , new_inds def build_selction_update ( self , old_selected : list | npt . NDArray = None , selected : list | npt . NDArray = None , trace_num : int = 0 , ): \"\"\"Build update for selection\"\"\" # Can't use selectedpoints... argh if selected is None : selected = [] if old_selected is None : old_selected = [] trc = self . fig . fig . data [ trace_num ] color = np . copy ( np . atleast_1d ( trc [ \"marker\" ][ \"color\" ])) # so it knows to update size = np . copy ( np . atleast_1d ( trc [ \"marker\" ][ \"size\" ])) if not isinstance ( color , ( list , np . ndarray )) or len ( color ) != len ( trc [ \"y\" ]): color = np . array ([ color ] * len ( trc [ \"y\" ])) if not isinstance ( size , ( list , np . ndarray )) or len ( size ) != len ( trc [ \"y\" ]): size = np . array ([ size ] * len ( trc [ \"y\" ])) # reset old selection first # reset old if not in new for ind in old_selected : if ind not in selected : ind = int ( ind ) color [ ind ] = util . shift_lightness ( str ( color [ ind ]), 1 / 1.8 ) size [ ind ] = size [ ind ] / 2 # set new if not in old for ind in selected : if ind not in old_selected : ind = int ( ind ) color [ ind ] = util . shift_lightness ( str ( color [ ind ]), 1.8 ) size [ ind ] = size [ ind ] * 2 return { \"marker\" : { \"color\" : color , \"size\" : size }, \"selector\" : trace_num , } def update_all_tables ( self ): \"\"\"Update all the tables.\"\"\" self . cdata . data = self . table_data . data . T . tolist () # self.cdata.update_colors() self . cdata . n_data += 1 self . update_delta_table () self . count . data = self . table_data . count . T . tolist () self . count . axis_breakpoints = self . cdata . axis_breakpoints # self.count.update_colors() self . count . n_data += 1 def update_delta_table ( self ): \"\"\"Update all the tables.\"\"\" self . delta_perc . data = self . table_data . delta_perc . T . tolist () self . delta_perc . axis_breakpoints = self . cdata . axis_breakpoints # self.delta_perc.update_colors() self . delta_perc . n_data += 1 def update_table_data ( self , event : param . parameterized . Event ): \"\"\"Update the table data if changes from client.\"\"\" self . table_data . data = np . array ( event . new , dtype = self . table_data . dtype ) . T self . cdata . n_data += 1 # self.cdata.update_colors() # self.cdata.n_color += 1 self . update_delta_table () self . update_table_plot ( event ) def fit_data ( self , _ : param . parameterized . Event , block_update = False ): \"\"\"fit param to scatter data.\"\"\" if self . table_data and self . table_data . scatter_data [ 0 ] is not None : self . table_data . data = self . table_data . orig . data self . table_data . locked = np . array ( self . cdata . locked ) . T self . table_data . f_orig = self . f_orig . value self . table_data . f_smooth = [ f . value for f in self . smoothing ] self . table_data . fit ( saturate = True ) if not block_update : self . update_all_tables () self . update_table_plot () def commit_fit ( self , _ : param . parameterized . Event | None = None ): \"\"\"commit current value to orig\"\"\" if self . table_data : self . table_data . snapshot ( \"orig\" ) self . update_delta_table () self . update_table_plot () col_off : int | None property Column offset for cal data table row_off : int | None property Row offset for cal data table build_panel_widget () Build CalData widget for param. Source code in ccg\\ui\\panel.py 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 def build_panel_widget ( self ) -> pn . Column : \"\"\"Build CalData widget for param.\"\"\" tic = datetime . datetime . now () res = self . widget if self . table_data is not None : # tic = datetime.datetime.now() # res.name = self.table_data.name # Can't modify name, need to decide if its ok to init with None prec_args = self . build_prec_args () assert isinstance ( prec_args , dict ) self . cdata = CalDataTbl ( name = self . table_data . name , table_name = f \" { self . table_data . name } [ { self . table_data . unit } ]\" , data = self . table_data . data . T . tolist (), colorscale = \"RdBu\" , ** prec_args , ) prec_args [ \"data_precision\" ] = 1 self . count = CalDataTbl ( name = \"Count\" , table_name = \"Count [samples]\" , data = self . table_data . count . T . tolist (), editable = False , colorscale = \"Blues\" , ** prec_args , ) prec_args [ \"data_precision\" ] = 2 self . delta_perc = CalDataTbl ( name = \"Delta %\" , table_name = \"Delta (current/orig-1) [%]\" , data = self . table_data . delta_perc . T . tolist (), editable = False , colorscale = \"RdBu\" , colorscale_center = 0 , ** prec_args , ) self . cdata . param . watch ( self . update_axes , [ \"axis_breakpoints\" ]) self . cdata . param . watch ( self . update_table_data , [ \"data\" ]) self . cdata . param . watch ( self . highlight_selected , [ \"selected_cells\" ]) self . cdata . param . watch ( self . undo , [ \"undo\" ]) self . cdata . param . watch ( self . reset , [ \"reset\" ]) toc = datetime . datetime . now () - tic _LOGGER . debug ( \"caldatas in %.3f \" , toc . total_seconds ()) tic = datetime . datetime . now () plt = plotgo . Plot ( self . table_data ) self . fig = plt self . plt_widget = pn . pane . Plotly ( self . fig . fig , height = 600 , width_policy = \"fit\" , sizing_mode = \"stretch_width\" , css_classes = [ \"plot\" ], align = ( \"start\" , \"center\" ), link_figure = False , ) toc = datetime . datetime . now () - tic _LOGGER . debug ( \"Built plot in %.3f \" , toc . total_seconds ()) tic = datetime . datetime . now () # self.plt_widget.param.watch( # self.plot_click, [\"click_data\"], onlychanged=False # ) self . f_orig = pn . widgets . FloatSlider ( name = \"Damping Factor\" , start = 0 , end = 1 , step = 0.01 , value = self . table_data . f_orig , ) self . smoothing = [] for j in range ( self . table_data . n_dim ): self . smoothing . append ( pn . widgets . FloatSlider ( name = f \" { self . table_data . axes [ j ] . name } Smoothing\" , start = 0 , end = 1 , step = 0.01 , value = self . table_data . f_smooth [ j ], ) ) self . fit_button = pn . widgets . Button ( name = \"Fit\" , disabled = True ) self . commit_button = pn . widgets . Button ( name = \"Commit\" , disabled = False ) self . color_sig = pn . widgets . MultiChoice ( name = \"Scatter Data Color Source:\" , delete_button = True , max_items = 1 , placeholder = \"Select a signal name or `Relative Density` for color axis\" , # doesnt seem to work ) self . additional_gate_path = pn . widgets . TextInput ( name = \"Table Specific Gate Config File\" , placeholder = \"Gate config filename...\" , ) self . additional_gate_path . param . watch ( self . load_additional_gate , [ \"value\" ]) self . tabs = pn . Tabs ( self . cdata , self . delta_perc , self . count , dynamic = False , ) self . tabs . param . watch ( self . changed_tabs , [ \"active\" ]) res . extend ( [ pn . Row ( self . tabs , pn . Column ( self . f_orig , * self . smoothing , self . fit_button , self . commit_button , self . color_sig , self . additional_gate_path , width = 280 , ), sizing_mode = \"stretch_width\" , ), self . plt_widget , # self.plt_widget.controls(jslink=True), ] ) self . fit_button . on_click ( self . fit_data ) self . commit_button . on_click ( self . commit_fit ) # toc = datetime.datetime.now() - tic # _LOGGER.debug(\"Built cal_data widget in %.3f\", toc.total_seconds()) toc = datetime . datetime . now () - tic _LOGGER . debug ( \"finished cal_data widget in %.3f \" , toc . total_seconds ()) return res build_prec_args () Build the prec_args dictionary for CalDataTbl. Source code in ccg\\ui\\panel.py 523 524 525 526 527 528 529 530 531 532 533 534 535 536 def build_prec_args ( self ): \"\"\"Build the prec_args dictionary for CalDataTbl.\"\"\" if self . table_data is not None : axes_data = self . table_data . axes prec_args = { \"axis_names\" : [ f \" { axis . name } [ { axis . unit } ]\" for axis in axes_data ], \"axis_breakpoints\" : [ axis . data . tolist () for axis in axes_data ], \"axis_precisions\" : [ axis . precision for axis in axes_data ], \"data_precision\" : self . table_data . precision , \"locked\" : self . table_data . locked . T . tolist (), } return prec_args build_selction_update ( old_selected = None , selected = None , trace_num = 0 ) Build update for selection Source code in ccg\\ui\\panel.py 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 def build_selction_update ( self , old_selected : list | npt . NDArray = None , selected : list | npt . NDArray = None , trace_num : int = 0 , ): \"\"\"Build update for selection\"\"\" # Can't use selectedpoints... argh if selected is None : selected = [] if old_selected is None : old_selected = [] trc = self . fig . fig . data [ trace_num ] color = np . copy ( np . atleast_1d ( trc [ \"marker\" ][ \"color\" ])) # so it knows to update size = np . copy ( np . atleast_1d ( trc [ \"marker\" ][ \"size\" ])) if not isinstance ( color , ( list , np . ndarray )) or len ( color ) != len ( trc [ \"y\" ]): color = np . array ([ color ] * len ( trc [ \"y\" ])) if not isinstance ( size , ( list , np . ndarray )) or len ( size ) != len ( trc [ \"y\" ]): size = np . array ([ size ] * len ( trc [ \"y\" ])) # reset old selection first # reset old if not in new for ind in old_selected : if ind not in selected : ind = int ( ind ) color [ ind ] = util . shift_lightness ( str ( color [ ind ]), 1 / 1.8 ) size [ ind ] = size [ ind ] / 2 # set new if not in old for ind in selected : if ind not in old_selected : ind = int ( ind ) color [ ind ] = util . shift_lightness ( str ( color [ ind ]), 1.8 ) size [ ind ] = size [ ind ] * 2 return { \"marker\" : { \"color\" : color , \"size\" : size }, \"selector\" : trace_num , } commit_fit ( _ = None ) commit current value to orig Source code in ccg\\ui\\panel.py 928 929 930 931 932 933 def commit_fit ( self , _ : param . parameterized . Event | None = None ): \"\"\"commit current value to orig\"\"\" if self . table_data : self . table_data . snapshot ( \"orig\" ) self . update_delta_table () self . update_table_plot () find_highlight_inds ( event ) Finds indices for highlighting func Source code in ccg\\ui\\panel.py 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 def find_highlight_inds ( self , event : param . parameterized . Event ): \"\"\"Finds indices for highlighting func\"\"\" old_inds = [] new_inds = [] if event : new_rows = [] new_cols = [] ndim = self . table_data . n_dim for cell in event . new : row_offset = cell [ \"row\" ] - self . row_off col_offset = cell [ \"col\" ] - self . col_off if row_offset == - 1 : if ndim == 2 : new_rows . extend ( range ( len ( self . table_data . axes [ 1 ]))) new_cols . extend ([ col_offset ] * len ( self . table_data . axes [ 1 ])) else : new_rows . append ( 0 ) new_cols . append ( col_offset ) elif col_offset == - 1 : new_rows . extend ([ row_offset ] * len ( self . table_data . axes [ 0 ])) new_cols . extend ( range ( len ( self . table_data . axes [ 0 ]))) else : new_rows . append ( row_offset ) new_cols . append ( col_offset ) old_rows = [] old_cols = [] for cell in event . old : row_offset = cell [ \"row\" ] - self . row_off col_offset = cell [ \"col\" ] - self . col_off if row_offset == - 1 : if ndim == 2 : old_rows . extend ( range ( len ( self . table_data . axes [ 1 ]))) old_cols . extend ([ col_offset ] * len ( self . table_data . axes [ 1 ])) else : old_rows . append ( 0 ) old_cols . append ( col_offset ) elif col_offset == - 1 : old_rows . extend ([ row_offset ] * len ( self . table_data . axes [ 0 ])) old_cols . extend ( range ( len ( self . table_data . axes [ 0 ]))) else : old_rows . append ( row_offset ) old_cols . append ( col_offset ) if ( np . all ( np . greater_equal ( new_rows , 0 )) and np . all ( np . greater_equal ( new_cols , 0 )) and ( len ( old_cols ) + len ( new_cols )) > 0 ): shp = tuple ( x + 1 for x in self . table_data . axes . table_shape ) if ndim < 2 : shp = self . table_data . axes . table_shape if old_rows : if ndim == 0 : old_inds = [ 0 ] elif ndim == 2 : old_inds = np . concatenate ( ( old_inds , np . ravel_multi_index ( ( old_cols , old_rows ), shp [:: - 1 ], order = \"f\" ) + np . prod ( shp ) - shp [ 0 ], ) ) else : old_inds = np . ravel_multi_index ( ( old_rows , old_cols ), shp , order = \"f\" ) # New Inds if new_rows : if ndim == 0 : new_inds = [ 0 ] elif ndim == 2 : new_inds = np . concatenate ( ( new_inds , np . ravel_multi_index ( ( new_cols , new_rows ), shp [:: - 1 ], order = \"f\" ) + np . prod ( shp ) - shp [ 0 ], ) ) else : new_inds = np . ravel_multi_index ( ( new_rows , new_cols ), shp , order = \"f\" ) return old_inds , new_inds fit_data ( _ , block_update = False ) fit param to scatter data. Source code in ccg\\ui\\panel.py 915 916 917 918 919 920 921 922 923 924 925 926 def fit_data ( self , _ : param . parameterized . Event , block_update = False ): \"\"\"fit param to scatter data.\"\"\" if self . table_data and self . table_data . scatter_data [ 0 ] is not None : self . table_data . data = self . table_data . orig . data self . table_data . locked = np . array ( self . cdata . locked ) . T self . table_data . f_orig = self . f_orig . value self . table_data . f_smooth = [ f . value for f in self . smoothing ] self . table_data . fit ( saturate = True ) if not block_update : self . update_all_tables () self . update_table_plot () highlight_selected ( event ) This will updated the plt trace to highlight the selected cells from event.obj.selected_cells Source code in ccg\\ui\\panel.py 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 def highlight_selected ( self , event : param . parameterized . Event ): \"\"\"This will updated the plt trace to highlight the selected cells from event.obj.selected_cells\"\"\" tic = datetime . datetime . now () if self . table_data . n_dim == 2 : trcnum = 3 else : trcnum = 1 old_inds , new_inds = self . find_highlight_inds ( event ) tmp = self . build_selction_update ( old_selected = old_inds , selected = new_inds , trace_num = trcnum ) # with self.fig.fig.batch_update(): self . fig . fig . update_traces ( ** tmp ) self . plt_widget . param . trigger ( \"object\" ) toc = datetime . datetime . now () - tic _LOGGER . debug ( \"Update %s plot selection in %.3f \" , self . table_data . name , toc . total_seconds (), ) load_additional_gate ( event = None ) Load a table specific gate config Source code in ccg\\ui\\panel.py 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 def load_additional_gate ( self , event : param . parameterized . Event | None = None ): \"\"\"Load a table specific gate config\"\"\" if event is not None : try : file_path = Path ( event . new ) if file_path and str ( file_path ) != \".\" : self . additional_gate = gatecoll_from_file ( file_path ) else : self . additional_gate = None event . obj . name = \"Table Specific Gate Config File\" event . obj . styles = { \"background\" : None } except OSError : event . obj . name = \"Invalid File Name\" event . obj . styles = { \"background\" : \"#e03838\" } self . additional_gate = None plot_click ( event ) Plot Clicked Source code in ccg\\ui\\panel.py 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 def plot_click ( self , event : param . parameterized . Event ): \"\"\"Plot Clicked\"\"\" n = event . new [ \"points\" ][ 0 ][ \"curveNumber\" ] if n == 2 : x = event . new [ \"points\" ][ 0 ][ \"x\" ] y = event . new [ \"points\" ][ 0 ][ \"y\" ] xind = np . where ( self . table_data . axes [ 0 ] . data == x )[ 0 ] yind = np . where ( self . table_data . axes [ 1 ] . data == y )[ 0 ] row = yind [ 0 ] + 3 col = xind [ 0 ] + 1 idn = f \"cal-data- { row } - { col } - { self . cdata . idn } \" active_cell = { \"row\" : row , \"col\" : col , \"id\" : idn } self . cdata . active_cell = active_cell self . cdata . n_cell = self . cdata . n_cell + 1 reset ( event ) Reset selected cells to orig. Source code in ccg\\ui\\panel.py 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 def reset ( self , event : param . parameterized . Event ): \"\"\"Reset selected cells to orig.\"\"\" if event . new : axis0_edit = False axis1_edit = False data_edit = False self . table_data . snapshot () # Take snapshot before making changes. # print(\"selected cell = \", self.cdata.selected_cells) for cell in self . cdata . selected_cells : if cell [ \"row\" ] < self . row_off : # This is axis0 axis0_edit = True self . table_data . axes [ 0 ][ cell [ \"col\" ] - self . col_off ] = ( self . table_data . _archive [ \"orig\" ][ - 1 ] . axes [ 0 ][ cell [ \"col\" ] - self . col_off ] ) elif cell [ \"col\" ] < self . col_off : # This is axis1 axis1_edit = True self . table_data . axes [ 1 ][ cell [ \"row\" ] - self . row_off ] = ( self . table_data . _archive [ \"orig\" ][ - 1 ] . axes [ 1 ][ cell [ \"row\" ] - self . row_off ] ) else : data_edit = True if self . table_data . n_dim == 2 : self . table_data . data [ cell [ \"col\" ] - self . col_off , cell [ \"row\" ] - self . row_off ] = self . table_data . _archive [ \"orig\" ][ - 1 ] . data [ cell [ \"col\" ] - self . col_off , cell [ \"row\" ] - self . row_off ] else : self . table_data . data [ cell [ \"col\" ] - self . col_off ] = ( self . table_data . _archive [ \"orig\" ][ - 1 ] . data [ cell [ \"col\" ] - self . col_off ] ) if axis0_edit : self . cdata . axis_breakpoints [ 0 ] = self . table_data . axes [ 0 ] . data . tolist () # To trigger interpolation self . table_data . axes [ 0 ] = self . table_data . axes [ 0 ] data_edit = True if axis1_edit : self . cdata . axis_breakpoints [ 1 ] = self . table_data . axes [ 1 ] . data . tolist () # To trigger interpolation self . table_data . axes [ 1 ] = self . table_data . axes [ 1 ] data_edit = True if data_edit : self . cdata . data = self . table_data . data . T . tolist () self . cdata . reset = False self . update_all_tables () self . update_table_plot () undo ( event ) Undo last change to table. Source code in ccg\\ui\\panel.py 581 582 583 584 585 586 587 588 589 590 591 592 def undo ( self , event : param . parameterized . Event ): \"\"\"Undo last change to table.\"\"\" if event . new : self . table_data . undo () if self . table_data . n_dim == 2 : self . cdata . axis_breakpoints [ 1 ] = self . table_data . axes [ 1 ] . data . tolist () if self . table_data . n_dim > 0 : self . cdata . axis_breakpoints [ 0 ] = self . table_data . axes [ 0 ] . data . tolist () self . cdata . undo = False self . update_all_tables () self . update_table_plot () update_all_tables () Update all the tables. Source code in ccg\\ui\\panel.py 888 889 890 891 892 893 894 895 896 897 def update_all_tables ( self ): \"\"\"Update all the tables.\"\"\" self . cdata . data = self . table_data . data . T . tolist () # self.cdata.update_colors() self . cdata . n_data += 1 self . update_delta_table () self . count . data = self . table_data . count . T . tolist () self . count . axis_breakpoints = self . cdata . axis_breakpoints # self.count.update_colors() self . count . n_data += 1 update_axes ( event ) handle updates to axes Source code in ccg\\ui\\panel.py 655 656 657 658 659 660 661 662 663 664 665 def update_axes ( self , event : param . parameterized . Event ): \"\"\"handle updates to axes\"\"\" if not event . obj . undo and not event . obj . reset : new_axes_data = event . new for index , axis in enumerate ( new_axes_data ): self . table_data . axes [ index ] . data = np . array ( axis , dtype = self . table_data . axes [ index ] . data . dtype ) self . update_all_tables () self . update_table_plot () update_delta_table () Update all the tables. Source code in ccg\\ui\\panel.py 899 900 901 902 903 904 def update_delta_table ( self ): \"\"\"Update all the tables.\"\"\" self . delta_perc . data = self . table_data . delta_perc . T . tolist () self . delta_perc . axis_breakpoints = self . cdata . axis_breakpoints # self.delta_perc.update_colors() self . delta_perc . n_data += 1 update_plot ( _ = None ) Updates the whole plot Source code in ccg\\ui\\panel.py 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 def update_plot ( self , _ : param . parameterized . Event = None ): \"\"\"Updates the whole plot\"\"\" if isinstance ( self . fig , plotgo . Plot ): tmptrc = self . fig . build_traces_from_tbl ( self . table_data ) n = 0 for i , _ in enumerate ( self . fig . fig . data ): self . fig . fig . update_traces ( tmptrc [ i ], selector = i ) n = i for i in range ( n + 1 , len ( tmptrc )): self . fig . fig . add_trace ( tmptrc [ i ]) event = DummyEvent ( old = [], new = self . cdata . selected_cells ) self . highlight_selected ( event ) else : util . merge_dict ( self . fig , Plot ( self . table_data ) . to_dict ()) event = DummyEvent ( old = [], new = self . cdata . selected_cells ) self . highlight_selected ( event ) update_table_data ( event ) Update the table data if changes from client. Source code in ccg\\ui\\panel.py 906 907 908 909 910 911 912 913 def update_table_data ( self , event : param . parameterized . Event ): \"\"\"Update the table data if changes from client.\"\"\" self . table_data . data = np . array ( event . new , dtype = self . table_data . dtype ) . T self . cdata . n_data += 1 # self.cdata.update_colors() # self.cdata.n_color += 1 self . update_delta_table () self . update_table_plot ( event ) update_table_plot ( _ = None ) Update table traces in plot. Source code in ccg\\ui\\panel.py 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 def update_table_plot ( self , _ : param . parameterized . Event = None ): \"\"\"Update table traces in plot.\"\"\" tic = datetime . datetime . now () if self . table_data . n_dim == 2 : keys = [ \"x\" , \"y\" , \"z\" ] ntrace = 4 elif self . table_data . n_dim == 1 : keys = [ \"x\" , \"y\" ] ntrace = 2 else : keys = [ \"y\" ] ntrace = 2 tmptrc = self . fig . build_traces_from_tbl ( self . table_data ) # with self.fig.fig.batch_update(): for i in range ( ntrace ): # 4 table traces newdata = { key : tmptrc [ i ][ key ] for key in keys } self . fig . fig . update_traces ( newdata , selector = i , overwrite = False ) self . plt_widget . param . trigger ( \"object\" ) toc = datetime . datetime . now () - tic _LOGGER . debug ( \"Update %s plot in %.3f \" , self . table_data . name , toc . total_seconds () ) CalDataTabs A class to manage tabbed widgets of CalDatas. Attributes: tabs ( dict [ str , CalData ] ) \u2013 A dictionary mapping tab names to CalData objects. widget ( Tabs ) \u2013 A Panel Tabs object that contains the tabbed widgets. Methods: __init__ \u2013 Initializes the CalDataTabs object. update_tabs \u2013 Updates the tabs with a new set of Tbls objects. _set_no_cal_loaded \u2013 Sets the widget to display a \"No Cal Loaded\" message. Source code in ccg\\ui\\panel.py 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 class CalDataTabs : \"\"\" A class to manage tabbed widgets of CalDatas. Attributes ---------- tabs : dict[str, CalData] A dictionary mapping tab names to CalData objects. widget : pn.Tabs A Panel Tabs object that contains the tabbed widgets. Methods ------- __init__(tbls: Tbls | None = None): Initializes the CalDataTabs object. update_tabs(tbls: Tbls): Updates the tabs with a new set of Tbls objects. _set_no_cal_loaded(): Sets the widget to display a \"No Cal Loaded\" message. \"\"\" def __init__ ( self , tbls : Tbls | None = None ): self . tabs : dict [ str , CalData ] = {} self . widget = pn . Tabs ( dynamic = True , tabs_location = \"left\" , css_classes = [ \"tabs-left\" ], align = \"center\" , sizing_mode = \"stretch_width\" , ) if tbls : self . update_tabs ( tbls ) else : self . _set_no_cal_loaded () self . widget . param . watch ( self . update_active_tabs , [ \"active\" ]) def update_tabs ( self , tbls : Tbls ): \"\"\" Updates the tabs with a new set of Tbls objects. Parameters ---------- tbls : Tbls A Tbls object containing the new tabs to add. \"\"\" self . widget . clear () # Clear the existing widget for tbl in tbls : cdata = CalData ( tbl ) self . tabs [ tbl . name ] = cdata if len ( tbl . name ) > 32 : # TODO: Check if this hurts the update_active_tabs name = \"...\" + tbl . name [ - 28 :] else : name = tbl . name self . widget . append (( name , cdata . widget )) def _set_no_cal_loaded ( self ): try : self . widget [:] = [ pn . Column ( pn . Spacer ( height = 0 ), pn . pane . SVG ( \"CCG_logo_full_darkbg.svg\" , alt_text = \"Competition Controls Group logo.\" , link_url = \"competitioncontrols.com\" , width = 800 , align = \"center\" , ), sizing_mode = \"stretch_width\" , name = \"No Cal Loaded\" , ) ] except OSError : pass def update_active_tabs ( self , event : param . parameterized . Event | None = None ): \"\"\"hack to update table on active\"\"\" name = self . widget . objects [ event . new ] . name self . tabs [ name ] . update_all_tables () self . tabs [ name ] . update_table_plot () oldname = self . widget . objects [ event . old ] . name self . tabs [ oldname ] . cdata . selected_cells = [] def __getitem__ ( self , key ): \"\"\"getitem\"\"\" if isinstance ( key , int ): return list ( self . tabs . values ())[ key ] return self . tabs [ key ] def __len__ ( self ): \"\"\"len\"\"\" return len ( self . tabs ) __getitem__ ( key ) getitem Source code in ccg\\ui\\panel.py 1019 1020 1021 1022 1023 def __getitem__ ( self , key ): \"\"\"getitem\"\"\" if isinstance ( key , int ): return list ( self . tabs . values ())[ key ] return self . tabs [ key ] __len__ () len Source code in ccg\\ui\\panel.py 1025 1026 1027 def __len__ ( self ): \"\"\"len\"\"\" return len ( self . tabs ) update_active_tabs ( event = None ) hack to update table on active Source code in ccg\\ui\\panel.py 1011 1012 1013 1014 1015 1016 1017 def update_active_tabs ( self , event : param . parameterized . Event | None = None ): \"\"\"hack to update table on active\"\"\" name = self . widget . objects [ event . new ] . name self . tabs [ name ] . update_all_tables () self . tabs [ name ] . update_table_plot () oldname = self . widget . objects [ event . old ] . name self . tabs [ oldname ] . cdata . selected_cells = [] update_tabs ( tbls ) Updates the tabs with a new set of Tbls objects. Parameters: tbls ( Tbls ) \u2013 A Tbls object containing the new tabs to add. Source code in ccg\\ui\\panel.py 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 def update_tabs ( self , tbls : Tbls ): \"\"\" Updates the tabs with a new set of Tbls objects. Parameters ---------- tbls : Tbls A Tbls object containing the new tabs to add. \"\"\" self . widget . clear () # Clear the existing widget for tbl in tbls : cdata = CalData ( tbl ) self . tabs [ tbl . name ] = cdata if len ( tbl . name ) > 32 : # TODO: Check if this hurts the update_active_tabs name = \"...\" + tbl . name [ - 28 :] else : name = tbl . name self . widget . append (( name , cdata . widget )) CalDataTbl Bases: ReactiveHTML Base class for custom table data control. Source code in ccg\\ui\\panel.py 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 class CalDataTbl ( pn . reactive . ReactiveHTML ): \"\"\"Base class for custom table data control.\"\"\" table_name = param . String ( doc = \"Param Name.\" ) axis_names = param . List ( doc = \"Axis Names.\" , default = []) axis_breakpoints = param . List ( doc = \"Axis Breakpoints.\" , default = []) axis_precisions = param . List ( doc = \"Axis Precisions.\" , default = []) data = param . List ( doc = \"Param Data.\" ) data_precision = param . Integer ( default = 1 , doc = \"Data Precision\" ) n_data = param . Integer ( default = 0 , doc = \"Flag to indicate update from python.\" ) n_color = param . Integer ( default = 0 , doc = \"Flag to indicate update from python.\" ) active_cell = param . Dict ( doc = \"Active Cell\" ) n_cell = param . Integer ( default = 0 , doc = \"Flag to indicate update from python.\" ) selected_cells = param . List ( doc = \"Selected Cells\" , default = []) locked = param . List ( doc = \"Locked Cells\" ) idn = param . String ( default = \"\" , doc = \"table id\" ) undo = param . Boolean ( default = False , doc = \"flag for python undo\" ) reset = param . Boolean ( default = False , doc = \"flag for python reset of selected cells\" ) editable = param . Boolean ( default = True , doc = \"flag for if table is editable\" ) colorscale = param . String ( default = \"Turbo\" , doc = \"Colorscale for table cell colors\" ) colorscale_center = param . Number ( default = None , doc = \"Center colorscale around this value\" ) light_font = param . String ( default = \"#e5e5e5\" , doc = \"Colorscale for table cell colors\" ) dark_font = param . String ( default = \"#434343\" , doc = \"Colorscale for table cell colors\" ) colors = param . List ( doc = \"Cell colors.\" ) font_colors = param . List ( doc = \"Font colors.\" ) _scripts = text_to_scripts ( Path ( __file__ ) . parent . joinpath ( \"caldata_scripts.js\" )) def __init__ ( self , ** kwargs ): \"\"\"Initiate and Update Colors\"\"\" super () . __init__ ( ** kwargs ) self . colors_bind = pn . bind ( self . calc_colors , data = self . param . data , colorscale = self . param . colorscale , colorscale_center = self . param . colorscale_center , light_font = self . param . light_font , dark_font = self . param . dark_font , watch = True , ) if not self . colors : self . calc_colors ( data = self . data , colorscale = self . colorscale , colorscale_center = self . colorscale_center , light_font = self . light_font , dark_font = self . dark_font , ) def calc_colors ( self , data , colorscale , colorscale_center , light_font , dark_font ): colors , fonts = util . table_colors ( data = data , colorscale = colorscale , colorscale_center = colorscale_center , light_font = light_font , dark_font = dark_font , ) self . colors = colors . tolist () self . font_colors = fonts . tolist () # This is required to trigger an update since we're using jinja2 templating. self . n_color += 1 _template = r \"\"\" <table id=\"cal-data\" class=\"cal-data\"> <tbody id=\"cal-data-body\" onmouseleave=\"${script('onmouseleave')}\"> <tr id=\"cal-data-row-0\"> <th id=\"cal-data-0-0\" class=\"cal-data-name\" { % i f axis_breakpoints|length %} colspan=\"{{axis_breakpoints[0]|length + axis_breakpoints|length - 1}}\" { % e ndif %} > {{table_name}} </th> </tr> <tr id=\"cal-data-row-1\"> { % f or axis_breakpoint in axis_breakpoints|reverse %} <th id=\"cal-data-1-{{loop.index0}}\" class=\"cal-data-axis-name-{{loop.index0}}\" { % i f loop.index0 == axis_breakpoints|length-1 %} colspan=\"{{axis_breakpoint|length}}\" { % e lse %} rowspan=2 { % e ndif %} > {{axis_names[axis_breakpoints|length-loop.index0-1]}} </th> { % e ndfor %} </tr> <tr id=\"cal-data-row-2\"> { % f or val in axis_breakpoints[0] %} <td id=\"cal-data-2-{{loop.index0+axis_breakpoints|length-1}}\" class=\"cal-data-axis0\" contenteditable={{ editable|string }} { % i f editable %} onfocus=\"${script('focus')}\" onfocusout=\"${script('focus_out')}\" onkeydown=\"${script('tbl_keydown')}\" onkeypress=\"${script('keypress')}\" onkeyup=\"${script('keyup')}\" onmouseup=\"${script('onmouseup')}\" onmousedown=\"${script('onmousedown')}\" onmouseenter=\"${script('onmouseenter')}\" { % e ndif %} > {{\" %0.*f \" % (axis_precisions[0],val)}} </td> { % e ndfor %} </tr> { % i f axis_breakpoints|length > 1 %} { % f or row in range(data|length) %} { % s et outer_loop=loop %} <tr id=\"cal-data-row-{{outer_loop.index0+3}}\"> { % i f axis_breakpoints[1]|length %} <td id=\"cal-data-{{outer_loop.index0+3}}-0\" contenteditable={{ editable|string }} class=\"cal-data-axis1\" { % i f editable %} onfocus=\"${script('focus')}\" onfocusout=\"${script('focus_out')}\" onkeydown=\"${script('tbl_keydown')}\" onkeypress=\"${script('keypress')}\" onkeyup=\"${script('keyup')}\" onmouseup=\"${script('onmouseup')}\" onmousedown=\"${script('onmousedown')}\" onmouseenter=\"${script('onmouseenter')}\" { % e ndif %} > {{\" %0.*f \" % (axis_precisions[1],axis_breakpoints[1][loop.index0])}} </td> { % e ndif %} { % f or col in range(data[0]|length) %} <td id=\"cal-data-{{outer_loop.index0+3}}-{{loop.index0+1}}\" contenteditable={{ editable|string }} class=\"cal-data-data{{ ' locked' if locked[outer_loop.index0][loop.index0] }}\" { % i f editable %} onfocus=\"${script('focus')}\" onfocusout=\"${script('focus_out')}\" onkeydown=\"${script('tbl_keydown')}\" onkeypress=\"${script('keypress')}\" onkeyup=\"${script('keyup')}\" onmousedown=\"${script('onmousedown')}\" onmouseenter=\"${script('onmouseenter')}\" onmouseup=\"${script('onmouseup')}\" { % e ndif %} { % i f colors %} style=\" background-color: {{ colors[outer_loop.index0][loop.index0] }}; color: {{ font_colors[outer_loop.index0][loop.index0] }}; \" { % e ndif %} > {{ \" %0.*f \" % (data_precision,data[outer_loop.index0][loop.index0])}} </td> { % e ndfor %} </tr> { % e ndfor %} { % e lse %} <tr id=\"cal-data-row-3\"> { % f or col in range(data|length) %} <td id=\"cal-data-3-{{loop.index0}}\" contenteditable={{ editable|string }} class=\"cal-data-data{{ ' locked' if locked[loop.index0] }}\" { % i f editable %} onfocus=\"${script('focus')}\" onfocusout=\"${script('focus_out')}\" onkeydown=\"${script('tbl_keydown')}\" onkeypress=\"${script('keypress')}\" onkeyup=\"${script('keyup')}\" onmouseup=\"${script('onmouseup')}\" onmousedown=\"${script('onmousedown')}\" onmouseenter=\"${script('onmouseenter')}\" { % e ndif %} { % i f colors %} style=\" background-color: {{ colors[loop.index0] }}; color: {{ font_colors[loop.index0] }}; \" { % e ndif %} > {{ \" %0.*f \" % (data_precision,data[loop.index0])}} </td> { % e ndfor %} </tr> { % e ndif %} </tbody> </table> \"\"\" __init__ ( ** kwargs ) Initiate and Update Colors Source code in ccg\\ui\\panel.py 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 def __init__ ( self , ** kwargs ): \"\"\"Initiate and Update Colors\"\"\" super () . __init__ ( ** kwargs ) self . colors_bind = pn . bind ( self . calc_colors , data = self . param . data , colorscale = self . param . colorscale , colorscale_center = self . param . colorscale_center , light_font = self . param . light_font , dark_font = self . param . dark_font , watch = True , ) if not self . colors : self . calc_colors ( data = self . data , colorscale = self . colorscale , colorscale_center = self . colorscale_center , light_font = self . light_font , dark_font = self . dark_font , ) text_to_scripts ( filename ) Returns a _scripts dictionary for ReactiveHTML based on a string Args: filename (str): The js script Returns: Dict: The output _scripts Example: txt=''' ... render=()=>{ ... console.log(data) ... } ... value=()=>{ ... my_func(value) ... } ... ''' text_to_scripts(txt) {'render': 'console.log(data)', 'value': 'my_func(value)'} Note: The script must be in the following format: Based on MarcSkovMarksen's suggestions for ReactiveHTML Scripts. Source code in ccg\\ui\\panel.py 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 def text_to_scripts ( filename : Path ) -> dict : \"\"\"Returns a `_scripts` dictionary for ReactiveHTML based on a string Args: filename (str): The js script Returns: Dict: The output `_scripts` Example: >>> txt=''' ... render=()=>{ ... console.log(data) ... } ... value=()=>{ ... my_func(value) ... } ... ''' >>> text_to_scripts(txt) {'render': 'console.log(data)', 'value': 'my_func(value)'} Note: The script must be in the following format: Based on MarcSkovMarksen's suggestions for ReactiveHTML Scripts. \"\"\" tic = datetime . datetime . now () with open ( Path ( filename ), mode = \"r\" , encoding = \"utf-8\" ) as f : text = f . read () lines = text . split ( \" \\n \" ) scripts = {} key = \"\" value = \"\" for line in lines : if key : if line == \"};\" : scripts [ key ] = _clean_script ( value ) key = value = \"\" else : value += line + \" \\n \" else : if ( line and not line [ 0 ] == \" \" and line . endswith ( \") => {\" ) and \"= (\" in line ): key = line . split ( \"=\" )[ 0 ] . strip () toc = datetime . datetime . now () - tic _LOGGER . debug ( \"Text to Scripts in %.3f \" , toc . total_seconds ()) return scripts","title":"panel"},{"location":"reference/ccg/ui/panel/#ccg.ui.panel.CalData","text":"Class to contain cal data and its handlers. Source code in ccg\\ui\\panel.py 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 class CalData : \"\"\"Class to contain cal data and its handlers.\"\"\" def __init__ ( self , data : Tbl | None = None ): self . table_data = data if self . table_data is not None : self . widget = pn . Column ( sizing_mode = \"stretch_width\" , css_classes = [ \"cdata\" ], name = data . name ) else : self . widget = pn . Column ( sizing_mode = \"stretch_width\" , css_classes = [ \"cdata\" ]) self . additional_gate : GateColl | None = None # self.fig.fig = None # self.plt_widget = pn.pane.Plotly( # self.fig.fig, # height=600, # width_policy=\"fit\", # sizing_mode=\"stretch_width\", # css_classes=[\"plot\"], # align=(\"start\", \"center\"), # link_figure=False, # ) self . build_panel_widget () def build_panel_widget ( self ) -> pn . Column : \"\"\"Build CalData widget for param.\"\"\" tic = datetime . datetime . now () res = self . widget if self . table_data is not None : # tic = datetime.datetime.now() # res.name = self.table_data.name # Can't modify name, need to decide if its ok to init with None prec_args = self . build_prec_args () assert isinstance ( prec_args , dict ) self . cdata = CalDataTbl ( name = self . table_data . name , table_name = f \" { self . table_data . name } [ { self . table_data . unit } ]\" , data = self . table_data . data . T . tolist (), colorscale = \"RdBu\" , ** prec_args , ) prec_args [ \"data_precision\" ] = 1 self . count = CalDataTbl ( name = \"Count\" , table_name = \"Count [samples]\" , data = self . table_data . count . T . tolist (), editable = False , colorscale = \"Blues\" , ** prec_args , ) prec_args [ \"data_precision\" ] = 2 self . delta_perc = CalDataTbl ( name = \"Delta %\" , table_name = \"Delta (current/orig-1) [%]\" , data = self . table_data . delta_perc . T . tolist (), editable = False , colorscale = \"RdBu\" , colorscale_center = 0 , ** prec_args , ) self . cdata . param . watch ( self . update_axes , [ \"axis_breakpoints\" ]) self . cdata . param . watch ( self . update_table_data , [ \"data\" ]) self . cdata . param . watch ( self . highlight_selected , [ \"selected_cells\" ]) self . cdata . param . watch ( self . undo , [ \"undo\" ]) self . cdata . param . watch ( self . reset , [ \"reset\" ]) toc = datetime . datetime . now () - tic _LOGGER . debug ( \"caldatas in %.3f \" , toc . total_seconds ()) tic = datetime . datetime . now () plt = plotgo . Plot ( self . table_data ) self . fig = plt self . plt_widget = pn . pane . Plotly ( self . fig . fig , height = 600 , width_policy = \"fit\" , sizing_mode = \"stretch_width\" , css_classes = [ \"plot\" ], align = ( \"start\" , \"center\" ), link_figure = False , ) toc = datetime . datetime . now () - tic _LOGGER . debug ( \"Built plot in %.3f \" , toc . total_seconds ()) tic = datetime . datetime . now () # self.plt_widget.param.watch( # self.plot_click, [\"click_data\"], onlychanged=False # ) self . f_orig = pn . widgets . FloatSlider ( name = \"Damping Factor\" , start = 0 , end = 1 , step = 0.01 , value = self . table_data . f_orig , ) self . smoothing = [] for j in range ( self . table_data . n_dim ): self . smoothing . append ( pn . widgets . FloatSlider ( name = f \" { self . table_data . axes [ j ] . name } Smoothing\" , start = 0 , end = 1 , step = 0.01 , value = self . table_data . f_smooth [ j ], ) ) self . fit_button = pn . widgets . Button ( name = \"Fit\" , disabled = True ) self . commit_button = pn . widgets . Button ( name = \"Commit\" , disabled = False ) self . color_sig = pn . widgets . MultiChoice ( name = \"Scatter Data Color Source:\" , delete_button = True , max_items = 1 , placeholder = \"Select a signal name or `Relative Density` for color axis\" , # doesnt seem to work ) self . additional_gate_path = pn . widgets . TextInput ( name = \"Table Specific Gate Config File\" , placeholder = \"Gate config filename...\" , ) self . additional_gate_path . param . watch ( self . load_additional_gate , [ \"value\" ]) self . tabs = pn . Tabs ( self . cdata , self . delta_perc , self . count , dynamic = False , ) self . tabs . param . watch ( self . changed_tabs , [ \"active\" ]) res . extend ( [ pn . Row ( self . tabs , pn . Column ( self . f_orig , * self . smoothing , self . fit_button , self . commit_button , self . color_sig , self . additional_gate_path , width = 280 , ), sizing_mode = \"stretch_width\" , ), self . plt_widget , # self.plt_widget.controls(jslink=True), ] ) self . fit_button . on_click ( self . fit_data ) self . commit_button . on_click ( self . commit_fit ) # toc = datetime.datetime.now() - tic # _LOGGER.debug(\"Built cal_data widget in %.3f\", toc.total_seconds()) toc = datetime . datetime . now () - tic _LOGGER . debug ( \"finished cal_data widget in %.3f \" , toc . total_seconds ()) return res def build_prec_args ( self ): \"\"\"Build the prec_args dictionary for CalDataTbl.\"\"\" if self . table_data is not None : axes_data = self . table_data . axes prec_args = { \"axis_names\" : [ f \" { axis . name } [ { axis . unit } ]\" for axis in axes_data ], \"axis_breakpoints\" : [ axis . data . tolist () for axis in axes_data ], \"axis_precisions\" : [ axis . precision for axis in axes_data ], \"data_precision\" : self . table_data . precision , \"locked\" : self . table_data . locked . T . tolist (), } return prec_args @property def row_off ( self ) -> int | None : \"\"\"Row offset for cal data table\"\"\" if self . table_data is None : return None if self . table_data . n_dim in ( 2 , 1 ): return 3 if self . table_data . n_dim == 3 : raise NotImplementedError ( \"3d table data not implemented\" ) elif self . table_data . n_dim == 0 : return 1 else : return None @property def col_off ( self ) -> int | None : \"\"\"Column offset for cal data table\"\"\" if self . table_data is None : return None if self . table_data . n_dim == 2 : return 1 if self . table_data . n_dim in ( 1 , 0 ): return 0 else : return None def load_additional_gate ( self , event : param . parameterized . Event | None = None ): \"\"\"Load a table specific gate config\"\"\" if event is not None : try : file_path = Path ( event . new ) if file_path and str ( file_path ) != \".\" : self . additional_gate = gatecoll_from_file ( file_path ) else : self . additional_gate = None event . obj . name = \"Table Specific Gate Config File\" event . obj . styles = { \"background\" : None } except OSError : event . obj . name = \"Invalid File Name\" event . obj . styles = { \"background\" : \"#e03838\" } self . additional_gate = None def undo ( self , event : param . parameterized . Event ): \"\"\"Undo last change to table.\"\"\" if event . new : self . table_data . undo () if self . table_data . n_dim == 2 : self . cdata . axis_breakpoints [ 1 ] = self . table_data . axes [ 1 ] . data . tolist () if self . table_data . n_dim > 0 : self . cdata . axis_breakpoints [ 0 ] = self . table_data . axes [ 0 ] . data . tolist () self . cdata . undo = False self . update_all_tables () self . update_table_plot () def reset ( self , event : param . parameterized . Event ): \"\"\"Reset selected cells to orig.\"\"\" if event . new : axis0_edit = False axis1_edit = False data_edit = False self . table_data . snapshot () # Take snapshot before making changes. # print(\"selected cell = \", self.cdata.selected_cells) for cell in self . cdata . selected_cells : if cell [ \"row\" ] < self . row_off : # This is axis0 axis0_edit = True self . table_data . axes [ 0 ][ cell [ \"col\" ] - self . col_off ] = ( self . table_data . _archive [ \"orig\" ][ - 1 ] . axes [ 0 ][ cell [ \"col\" ] - self . col_off ] ) elif cell [ \"col\" ] < self . col_off : # This is axis1 axis1_edit = True self . table_data . axes [ 1 ][ cell [ \"row\" ] - self . row_off ] = ( self . table_data . _archive [ \"orig\" ][ - 1 ] . axes [ 1 ][ cell [ \"row\" ] - self . row_off ] ) else : data_edit = True if self . table_data . n_dim == 2 : self . table_data . data [ cell [ \"col\" ] - self . col_off , cell [ \"row\" ] - self . row_off ] = self . table_data . _archive [ \"orig\" ][ - 1 ] . data [ cell [ \"col\" ] - self . col_off , cell [ \"row\" ] - self . row_off ] else : self . table_data . data [ cell [ \"col\" ] - self . col_off ] = ( self . table_data . _archive [ \"orig\" ][ - 1 ] . data [ cell [ \"col\" ] - self . col_off ] ) if axis0_edit : self . cdata . axis_breakpoints [ 0 ] = self . table_data . axes [ 0 ] . data . tolist () # To trigger interpolation self . table_data . axes [ 0 ] = self . table_data . axes [ 0 ] data_edit = True if axis1_edit : self . cdata . axis_breakpoints [ 1 ] = self . table_data . axes [ 1 ] . data . tolist () # To trigger interpolation self . table_data . axes [ 1 ] = self . table_data . axes [ 1 ] data_edit = True if data_edit : self . cdata . data = self . table_data . data . T . tolist () self . cdata . reset = False self . update_all_tables () self . update_table_plot () def changed_tabs ( self , event : param . parameterized . Event ): if event . old == 0 : self . cdata . selected_cells = [] def update_axes ( self , event : param . parameterized . Event ): \"\"\"handle updates to axes\"\"\" if not event . obj . undo and not event . obj . reset : new_axes_data = event . new for index , axis in enumerate ( new_axes_data ): self . table_data . axes [ index ] . data = np . array ( axis , dtype = self . table_data . axes [ index ] . data . dtype ) self . update_all_tables () self . update_table_plot () def update_table_plot ( self , _ : param . parameterized . Event = None ): \"\"\"Update table traces in plot.\"\"\" tic = datetime . datetime . now () if self . table_data . n_dim == 2 : keys = [ \"x\" , \"y\" , \"z\" ] ntrace = 4 elif self . table_data . n_dim == 1 : keys = [ \"x\" , \"y\" ] ntrace = 2 else : keys = [ \"y\" ] ntrace = 2 tmptrc = self . fig . build_traces_from_tbl ( self . table_data ) # with self.fig.fig.batch_update(): for i in range ( ntrace ): # 4 table traces newdata = { key : tmptrc [ i ][ key ] for key in keys } self . fig . fig . update_traces ( newdata , selector = i , overwrite = False ) self . plt_widget . param . trigger ( \"object\" ) toc = datetime . datetime . now () - tic _LOGGER . debug ( \"Update %s plot in %.3f \" , self . table_data . name , toc . total_seconds () ) def update_plot ( self , _ : param . parameterized . Event = None ): \"\"\"Updates the whole plot\"\"\" if isinstance ( self . fig , plotgo . Plot ): tmptrc = self . fig . build_traces_from_tbl ( self . table_data ) n = 0 for i , _ in enumerate ( self . fig . fig . data ): self . fig . fig . update_traces ( tmptrc [ i ], selector = i ) n = i for i in range ( n + 1 , len ( tmptrc )): self . fig . fig . add_trace ( tmptrc [ i ]) event = DummyEvent ( old = [], new = self . cdata . selected_cells ) self . highlight_selected ( event ) else : util . merge_dict ( self . fig , Plot ( self . table_data ) . to_dict ()) event = DummyEvent ( old = [], new = self . cdata . selected_cells ) self . highlight_selected ( event ) def plot_click ( self , event : param . parameterized . Event ): \"\"\"Plot Clicked\"\"\" n = event . new [ \"points\" ][ 0 ][ \"curveNumber\" ] if n == 2 : x = event . new [ \"points\" ][ 0 ][ \"x\" ] y = event . new [ \"points\" ][ 0 ][ \"y\" ] xind = np . where ( self . table_data . axes [ 0 ] . data == x )[ 0 ] yind = np . where ( self . table_data . axes [ 1 ] . data == y )[ 0 ] row = yind [ 0 ] + 3 col = xind [ 0 ] + 1 idn = f \"cal-data- { row } - { col } - { self . cdata . idn } \" active_cell = { \"row\" : row , \"col\" : col , \"id\" : idn } self . cdata . active_cell = active_cell self . cdata . n_cell = self . cdata . n_cell + 1 def highlight_selected ( self , event : param . parameterized . Event ): \"\"\"This will updated the plt trace to highlight the selected cells from event.obj.selected_cells\"\"\" tic = datetime . datetime . now () if self . table_data . n_dim == 2 : trcnum = 3 else : trcnum = 1 old_inds , new_inds = self . find_highlight_inds ( event ) tmp = self . build_selction_update ( old_selected = old_inds , selected = new_inds , trace_num = trcnum ) # with self.fig.fig.batch_update(): self . fig . fig . update_traces ( ** tmp ) self . plt_widget . param . trigger ( \"object\" ) toc = datetime . datetime . now () - tic _LOGGER . debug ( \"Update %s plot selection in %.3f \" , self . table_data . name , toc . total_seconds (), ) def find_highlight_inds ( self , event : param . parameterized . Event ): \"\"\"Finds indices for highlighting func\"\"\" old_inds = [] new_inds = [] if event : new_rows = [] new_cols = [] ndim = self . table_data . n_dim for cell in event . new : row_offset = cell [ \"row\" ] - self . row_off col_offset = cell [ \"col\" ] - self . col_off if row_offset == - 1 : if ndim == 2 : new_rows . extend ( range ( len ( self . table_data . axes [ 1 ]))) new_cols . extend ([ col_offset ] * len ( self . table_data . axes [ 1 ])) else : new_rows . append ( 0 ) new_cols . append ( col_offset ) elif col_offset == - 1 : new_rows . extend ([ row_offset ] * len ( self . table_data . axes [ 0 ])) new_cols . extend ( range ( len ( self . table_data . axes [ 0 ]))) else : new_rows . append ( row_offset ) new_cols . append ( col_offset ) old_rows = [] old_cols = [] for cell in event . old : row_offset = cell [ \"row\" ] - self . row_off col_offset = cell [ \"col\" ] - self . col_off if row_offset == - 1 : if ndim == 2 : old_rows . extend ( range ( len ( self . table_data . axes [ 1 ]))) old_cols . extend ([ col_offset ] * len ( self . table_data . axes [ 1 ])) else : old_rows . append ( 0 ) old_cols . append ( col_offset ) elif col_offset == - 1 : old_rows . extend ([ row_offset ] * len ( self . table_data . axes [ 0 ])) old_cols . extend ( range ( len ( self . table_data . axes [ 0 ]))) else : old_rows . append ( row_offset ) old_cols . append ( col_offset ) if ( np . all ( np . greater_equal ( new_rows , 0 )) and np . all ( np . greater_equal ( new_cols , 0 )) and ( len ( old_cols ) + len ( new_cols )) > 0 ): shp = tuple ( x + 1 for x in self . table_data . axes . table_shape ) if ndim < 2 : shp = self . table_data . axes . table_shape if old_rows : if ndim == 0 : old_inds = [ 0 ] elif ndim == 2 : old_inds = np . concatenate ( ( old_inds , np . ravel_multi_index ( ( old_cols , old_rows ), shp [:: - 1 ], order = \"f\" ) + np . prod ( shp ) - shp [ 0 ], ) ) else : old_inds = np . ravel_multi_index ( ( old_rows , old_cols ), shp , order = \"f\" ) # New Inds if new_rows : if ndim == 0 : new_inds = [ 0 ] elif ndim == 2 : new_inds = np . concatenate ( ( new_inds , np . ravel_multi_index ( ( new_cols , new_rows ), shp [:: - 1 ], order = \"f\" ) + np . prod ( shp ) - shp [ 0 ], ) ) else : new_inds = np . ravel_multi_index ( ( new_rows , new_cols ), shp , order = \"f\" ) return old_inds , new_inds def build_selction_update ( self , old_selected : list | npt . NDArray = None , selected : list | npt . NDArray = None , trace_num : int = 0 , ): \"\"\"Build update for selection\"\"\" # Can't use selectedpoints... argh if selected is None : selected = [] if old_selected is None : old_selected = [] trc = self . fig . fig . data [ trace_num ] color = np . copy ( np . atleast_1d ( trc [ \"marker\" ][ \"color\" ])) # so it knows to update size = np . copy ( np . atleast_1d ( trc [ \"marker\" ][ \"size\" ])) if not isinstance ( color , ( list , np . ndarray )) or len ( color ) != len ( trc [ \"y\" ]): color = np . array ([ color ] * len ( trc [ \"y\" ])) if not isinstance ( size , ( list , np . ndarray )) or len ( size ) != len ( trc [ \"y\" ]): size = np . array ([ size ] * len ( trc [ \"y\" ])) # reset old selection first # reset old if not in new for ind in old_selected : if ind not in selected : ind = int ( ind ) color [ ind ] = util . shift_lightness ( str ( color [ ind ]), 1 / 1.8 ) size [ ind ] = size [ ind ] / 2 # set new if not in old for ind in selected : if ind not in old_selected : ind = int ( ind ) color [ ind ] = util . shift_lightness ( str ( color [ ind ]), 1.8 ) size [ ind ] = size [ ind ] * 2 return { \"marker\" : { \"color\" : color , \"size\" : size }, \"selector\" : trace_num , } def update_all_tables ( self ): \"\"\"Update all the tables.\"\"\" self . cdata . data = self . table_data . data . T . tolist () # self.cdata.update_colors() self . cdata . n_data += 1 self . update_delta_table () self . count . data = self . table_data . count . T . tolist () self . count . axis_breakpoints = self . cdata . axis_breakpoints # self.count.update_colors() self . count . n_data += 1 def update_delta_table ( self ): \"\"\"Update all the tables.\"\"\" self . delta_perc . data = self . table_data . delta_perc . T . tolist () self . delta_perc . axis_breakpoints = self . cdata . axis_breakpoints # self.delta_perc.update_colors() self . delta_perc . n_data += 1 def update_table_data ( self , event : param . parameterized . Event ): \"\"\"Update the table data if changes from client.\"\"\" self . table_data . data = np . array ( event . new , dtype = self . table_data . dtype ) . T self . cdata . n_data += 1 # self.cdata.update_colors() # self.cdata.n_color += 1 self . update_delta_table () self . update_table_plot ( event ) def fit_data ( self , _ : param . parameterized . Event , block_update = False ): \"\"\"fit param to scatter data.\"\"\" if self . table_data and self . table_data . scatter_data [ 0 ] is not None : self . table_data . data = self . table_data . orig . data self . table_data . locked = np . array ( self . cdata . locked ) . T self . table_data . f_orig = self . f_orig . value self . table_data . f_smooth = [ f . value for f in self . smoothing ] self . table_data . fit ( saturate = True ) if not block_update : self . update_all_tables () self . update_table_plot () def commit_fit ( self , _ : param . parameterized . Event | None = None ): \"\"\"commit current value to orig\"\"\" if self . table_data : self . table_data . snapshot ( \"orig\" ) self . update_delta_table () self . update_table_plot ()","title":"CalData"},{"location":"reference/ccg/ui/panel/#ccg.ui.panel.CalData.col_off","text":"Column offset for cal data table","title":"col_off"},{"location":"reference/ccg/ui/panel/#ccg.ui.panel.CalData.row_off","text":"Row offset for cal data table","title":"row_off"},{"location":"reference/ccg/ui/panel/#ccg.ui.panel.CalData.build_panel_widget","text":"Build CalData widget for param. Source code in ccg\\ui\\panel.py 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 def build_panel_widget ( self ) -> pn . Column : \"\"\"Build CalData widget for param.\"\"\" tic = datetime . datetime . now () res = self . widget if self . table_data is not None : # tic = datetime.datetime.now() # res.name = self.table_data.name # Can't modify name, need to decide if its ok to init with None prec_args = self . build_prec_args () assert isinstance ( prec_args , dict ) self . cdata = CalDataTbl ( name = self . table_data . name , table_name = f \" { self . table_data . name } [ { self . table_data . unit } ]\" , data = self . table_data . data . T . tolist (), colorscale = \"RdBu\" , ** prec_args , ) prec_args [ \"data_precision\" ] = 1 self . count = CalDataTbl ( name = \"Count\" , table_name = \"Count [samples]\" , data = self . table_data . count . T . tolist (), editable = False , colorscale = \"Blues\" , ** prec_args , ) prec_args [ \"data_precision\" ] = 2 self . delta_perc = CalDataTbl ( name = \"Delta %\" , table_name = \"Delta (current/orig-1) [%]\" , data = self . table_data . delta_perc . T . tolist (), editable = False , colorscale = \"RdBu\" , colorscale_center = 0 , ** prec_args , ) self . cdata . param . watch ( self . update_axes , [ \"axis_breakpoints\" ]) self . cdata . param . watch ( self . update_table_data , [ \"data\" ]) self . cdata . param . watch ( self . highlight_selected , [ \"selected_cells\" ]) self . cdata . param . watch ( self . undo , [ \"undo\" ]) self . cdata . param . watch ( self . reset , [ \"reset\" ]) toc = datetime . datetime . now () - tic _LOGGER . debug ( \"caldatas in %.3f \" , toc . total_seconds ()) tic = datetime . datetime . now () plt = plotgo . Plot ( self . table_data ) self . fig = plt self . plt_widget = pn . pane . Plotly ( self . fig . fig , height = 600 , width_policy = \"fit\" , sizing_mode = \"stretch_width\" , css_classes = [ \"plot\" ], align = ( \"start\" , \"center\" ), link_figure = False , ) toc = datetime . datetime . now () - tic _LOGGER . debug ( \"Built plot in %.3f \" , toc . total_seconds ()) tic = datetime . datetime . now () # self.plt_widget.param.watch( # self.plot_click, [\"click_data\"], onlychanged=False # ) self . f_orig = pn . widgets . FloatSlider ( name = \"Damping Factor\" , start = 0 , end = 1 , step = 0.01 , value = self . table_data . f_orig , ) self . smoothing = [] for j in range ( self . table_data . n_dim ): self . smoothing . append ( pn . widgets . FloatSlider ( name = f \" { self . table_data . axes [ j ] . name } Smoothing\" , start = 0 , end = 1 , step = 0.01 , value = self . table_data . f_smooth [ j ], ) ) self . fit_button = pn . widgets . Button ( name = \"Fit\" , disabled = True ) self . commit_button = pn . widgets . Button ( name = \"Commit\" , disabled = False ) self . color_sig = pn . widgets . MultiChoice ( name = \"Scatter Data Color Source:\" , delete_button = True , max_items = 1 , placeholder = \"Select a signal name or `Relative Density` for color axis\" , # doesnt seem to work ) self . additional_gate_path = pn . widgets . TextInput ( name = \"Table Specific Gate Config File\" , placeholder = \"Gate config filename...\" , ) self . additional_gate_path . param . watch ( self . load_additional_gate , [ \"value\" ]) self . tabs = pn . Tabs ( self . cdata , self . delta_perc , self . count , dynamic = False , ) self . tabs . param . watch ( self . changed_tabs , [ \"active\" ]) res . extend ( [ pn . Row ( self . tabs , pn . Column ( self . f_orig , * self . smoothing , self . fit_button , self . commit_button , self . color_sig , self . additional_gate_path , width = 280 , ), sizing_mode = \"stretch_width\" , ), self . plt_widget , # self.plt_widget.controls(jslink=True), ] ) self . fit_button . on_click ( self . fit_data ) self . commit_button . on_click ( self . commit_fit ) # toc = datetime.datetime.now() - tic # _LOGGER.debug(\"Built cal_data widget in %.3f\", toc.total_seconds()) toc = datetime . datetime . now () - tic _LOGGER . debug ( \"finished cal_data widget in %.3f \" , toc . total_seconds ()) return res","title":"build_panel_widget"},{"location":"reference/ccg/ui/panel/#ccg.ui.panel.CalData.build_prec_args","text":"Build the prec_args dictionary for CalDataTbl. Source code in ccg\\ui\\panel.py 523 524 525 526 527 528 529 530 531 532 533 534 535 536 def build_prec_args ( self ): \"\"\"Build the prec_args dictionary for CalDataTbl.\"\"\" if self . table_data is not None : axes_data = self . table_data . axes prec_args = { \"axis_names\" : [ f \" { axis . name } [ { axis . unit } ]\" for axis in axes_data ], \"axis_breakpoints\" : [ axis . data . tolist () for axis in axes_data ], \"axis_precisions\" : [ axis . precision for axis in axes_data ], \"data_precision\" : self . table_data . precision , \"locked\" : self . table_data . locked . T . tolist (), } return prec_args","title":"build_prec_args"},{"location":"reference/ccg/ui/panel/#ccg.ui.panel.CalData.build_selction_update","text":"Build update for selection Source code in ccg\\ui\\panel.py 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 def build_selction_update ( self , old_selected : list | npt . NDArray = None , selected : list | npt . NDArray = None , trace_num : int = 0 , ): \"\"\"Build update for selection\"\"\" # Can't use selectedpoints... argh if selected is None : selected = [] if old_selected is None : old_selected = [] trc = self . fig . fig . data [ trace_num ] color = np . copy ( np . atleast_1d ( trc [ \"marker\" ][ \"color\" ])) # so it knows to update size = np . copy ( np . atleast_1d ( trc [ \"marker\" ][ \"size\" ])) if not isinstance ( color , ( list , np . ndarray )) or len ( color ) != len ( trc [ \"y\" ]): color = np . array ([ color ] * len ( trc [ \"y\" ])) if not isinstance ( size , ( list , np . ndarray )) or len ( size ) != len ( trc [ \"y\" ]): size = np . array ([ size ] * len ( trc [ \"y\" ])) # reset old selection first # reset old if not in new for ind in old_selected : if ind not in selected : ind = int ( ind ) color [ ind ] = util . shift_lightness ( str ( color [ ind ]), 1 / 1.8 ) size [ ind ] = size [ ind ] / 2 # set new if not in old for ind in selected : if ind not in old_selected : ind = int ( ind ) color [ ind ] = util . shift_lightness ( str ( color [ ind ]), 1.8 ) size [ ind ] = size [ ind ] * 2 return { \"marker\" : { \"color\" : color , \"size\" : size }, \"selector\" : trace_num , }","title":"build_selction_update"},{"location":"reference/ccg/ui/panel/#ccg.ui.panel.CalData.commit_fit","text":"commit current value to orig Source code in ccg\\ui\\panel.py 928 929 930 931 932 933 def commit_fit ( self , _ : param . parameterized . Event | None = None ): \"\"\"commit current value to orig\"\"\" if self . table_data : self . table_data . snapshot ( \"orig\" ) self . update_delta_table () self . update_table_plot ()","title":"commit_fit"},{"location":"reference/ccg/ui/panel/#ccg.ui.panel.CalData.find_highlight_inds","text":"Finds indices for highlighting func Source code in ccg\\ui\\panel.py 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 def find_highlight_inds ( self , event : param . parameterized . Event ): \"\"\"Finds indices for highlighting func\"\"\" old_inds = [] new_inds = [] if event : new_rows = [] new_cols = [] ndim = self . table_data . n_dim for cell in event . new : row_offset = cell [ \"row\" ] - self . row_off col_offset = cell [ \"col\" ] - self . col_off if row_offset == - 1 : if ndim == 2 : new_rows . extend ( range ( len ( self . table_data . axes [ 1 ]))) new_cols . extend ([ col_offset ] * len ( self . table_data . axes [ 1 ])) else : new_rows . append ( 0 ) new_cols . append ( col_offset ) elif col_offset == - 1 : new_rows . extend ([ row_offset ] * len ( self . table_data . axes [ 0 ])) new_cols . extend ( range ( len ( self . table_data . axes [ 0 ]))) else : new_rows . append ( row_offset ) new_cols . append ( col_offset ) old_rows = [] old_cols = [] for cell in event . old : row_offset = cell [ \"row\" ] - self . row_off col_offset = cell [ \"col\" ] - self . col_off if row_offset == - 1 : if ndim == 2 : old_rows . extend ( range ( len ( self . table_data . axes [ 1 ]))) old_cols . extend ([ col_offset ] * len ( self . table_data . axes [ 1 ])) else : old_rows . append ( 0 ) old_cols . append ( col_offset ) elif col_offset == - 1 : old_rows . extend ([ row_offset ] * len ( self . table_data . axes [ 0 ])) old_cols . extend ( range ( len ( self . table_data . axes [ 0 ]))) else : old_rows . append ( row_offset ) old_cols . append ( col_offset ) if ( np . all ( np . greater_equal ( new_rows , 0 )) and np . all ( np . greater_equal ( new_cols , 0 )) and ( len ( old_cols ) + len ( new_cols )) > 0 ): shp = tuple ( x + 1 for x in self . table_data . axes . table_shape ) if ndim < 2 : shp = self . table_data . axes . table_shape if old_rows : if ndim == 0 : old_inds = [ 0 ] elif ndim == 2 : old_inds = np . concatenate ( ( old_inds , np . ravel_multi_index ( ( old_cols , old_rows ), shp [:: - 1 ], order = \"f\" ) + np . prod ( shp ) - shp [ 0 ], ) ) else : old_inds = np . ravel_multi_index ( ( old_rows , old_cols ), shp , order = \"f\" ) # New Inds if new_rows : if ndim == 0 : new_inds = [ 0 ] elif ndim == 2 : new_inds = np . concatenate ( ( new_inds , np . ravel_multi_index ( ( new_cols , new_rows ), shp [:: - 1 ], order = \"f\" ) + np . prod ( shp ) - shp [ 0 ], ) ) else : new_inds = np . ravel_multi_index ( ( new_rows , new_cols ), shp , order = \"f\" ) return old_inds , new_inds","title":"find_highlight_inds"},{"location":"reference/ccg/ui/panel/#ccg.ui.panel.CalData.fit_data","text":"fit param to scatter data. Source code in ccg\\ui\\panel.py 915 916 917 918 919 920 921 922 923 924 925 926 def fit_data ( self , _ : param . parameterized . Event , block_update = False ): \"\"\"fit param to scatter data.\"\"\" if self . table_data and self . table_data . scatter_data [ 0 ] is not None : self . table_data . data = self . table_data . orig . data self . table_data . locked = np . array ( self . cdata . locked ) . T self . table_data . f_orig = self . f_orig . value self . table_data . f_smooth = [ f . value for f in self . smoothing ] self . table_data . fit ( saturate = True ) if not block_update : self . update_all_tables () self . update_table_plot ()","title":"fit_data"},{"location":"reference/ccg/ui/panel/#ccg.ui.panel.CalData.highlight_selected","text":"This will updated the plt trace to highlight the selected cells from event.obj.selected_cells Source code in ccg\\ui\\panel.py 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 def highlight_selected ( self , event : param . parameterized . Event ): \"\"\"This will updated the plt trace to highlight the selected cells from event.obj.selected_cells\"\"\" tic = datetime . datetime . now () if self . table_data . n_dim == 2 : trcnum = 3 else : trcnum = 1 old_inds , new_inds = self . find_highlight_inds ( event ) tmp = self . build_selction_update ( old_selected = old_inds , selected = new_inds , trace_num = trcnum ) # with self.fig.fig.batch_update(): self . fig . fig . update_traces ( ** tmp ) self . plt_widget . param . trigger ( \"object\" ) toc = datetime . datetime . now () - tic _LOGGER . debug ( \"Update %s plot selection in %.3f \" , self . table_data . name , toc . total_seconds (), )","title":"highlight_selected"},{"location":"reference/ccg/ui/panel/#ccg.ui.panel.CalData.load_additional_gate","text":"Load a table specific gate config Source code in ccg\\ui\\panel.py 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 def load_additional_gate ( self , event : param . parameterized . Event | None = None ): \"\"\"Load a table specific gate config\"\"\" if event is not None : try : file_path = Path ( event . new ) if file_path and str ( file_path ) != \".\" : self . additional_gate = gatecoll_from_file ( file_path ) else : self . additional_gate = None event . obj . name = \"Table Specific Gate Config File\" event . obj . styles = { \"background\" : None } except OSError : event . obj . name = \"Invalid File Name\" event . obj . styles = { \"background\" : \"#e03838\" } self . additional_gate = None","title":"load_additional_gate"},{"location":"reference/ccg/ui/panel/#ccg.ui.panel.CalData.plot_click","text":"Plot Clicked Source code in ccg\\ui\\panel.py 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 def plot_click ( self , event : param . parameterized . Event ): \"\"\"Plot Clicked\"\"\" n = event . new [ \"points\" ][ 0 ][ \"curveNumber\" ] if n == 2 : x = event . new [ \"points\" ][ 0 ][ \"x\" ] y = event . new [ \"points\" ][ 0 ][ \"y\" ] xind = np . where ( self . table_data . axes [ 0 ] . data == x )[ 0 ] yind = np . where ( self . table_data . axes [ 1 ] . data == y )[ 0 ] row = yind [ 0 ] + 3 col = xind [ 0 ] + 1 idn = f \"cal-data- { row } - { col } - { self . cdata . idn } \" active_cell = { \"row\" : row , \"col\" : col , \"id\" : idn } self . cdata . active_cell = active_cell self . cdata . n_cell = self . cdata . n_cell + 1","title":"plot_click"},{"location":"reference/ccg/ui/panel/#ccg.ui.panel.CalData.reset","text":"Reset selected cells to orig. Source code in ccg\\ui\\panel.py 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 def reset ( self , event : param . parameterized . Event ): \"\"\"Reset selected cells to orig.\"\"\" if event . new : axis0_edit = False axis1_edit = False data_edit = False self . table_data . snapshot () # Take snapshot before making changes. # print(\"selected cell = \", self.cdata.selected_cells) for cell in self . cdata . selected_cells : if cell [ \"row\" ] < self . row_off : # This is axis0 axis0_edit = True self . table_data . axes [ 0 ][ cell [ \"col\" ] - self . col_off ] = ( self . table_data . _archive [ \"orig\" ][ - 1 ] . axes [ 0 ][ cell [ \"col\" ] - self . col_off ] ) elif cell [ \"col\" ] < self . col_off : # This is axis1 axis1_edit = True self . table_data . axes [ 1 ][ cell [ \"row\" ] - self . row_off ] = ( self . table_data . _archive [ \"orig\" ][ - 1 ] . axes [ 1 ][ cell [ \"row\" ] - self . row_off ] ) else : data_edit = True if self . table_data . n_dim == 2 : self . table_data . data [ cell [ \"col\" ] - self . col_off , cell [ \"row\" ] - self . row_off ] = self . table_data . _archive [ \"orig\" ][ - 1 ] . data [ cell [ \"col\" ] - self . col_off , cell [ \"row\" ] - self . row_off ] else : self . table_data . data [ cell [ \"col\" ] - self . col_off ] = ( self . table_data . _archive [ \"orig\" ][ - 1 ] . data [ cell [ \"col\" ] - self . col_off ] ) if axis0_edit : self . cdata . axis_breakpoints [ 0 ] = self . table_data . axes [ 0 ] . data . tolist () # To trigger interpolation self . table_data . axes [ 0 ] = self . table_data . axes [ 0 ] data_edit = True if axis1_edit : self . cdata . axis_breakpoints [ 1 ] = self . table_data . axes [ 1 ] . data . tolist () # To trigger interpolation self . table_data . axes [ 1 ] = self . table_data . axes [ 1 ] data_edit = True if data_edit : self . cdata . data = self . table_data . data . T . tolist () self . cdata . reset = False self . update_all_tables () self . update_table_plot ()","title":"reset"},{"location":"reference/ccg/ui/panel/#ccg.ui.panel.CalData.undo","text":"Undo last change to table. Source code in ccg\\ui\\panel.py 581 582 583 584 585 586 587 588 589 590 591 592 def undo ( self , event : param . parameterized . Event ): \"\"\"Undo last change to table.\"\"\" if event . new : self . table_data . undo () if self . table_data . n_dim == 2 : self . cdata . axis_breakpoints [ 1 ] = self . table_data . axes [ 1 ] . data . tolist () if self . table_data . n_dim > 0 : self . cdata . axis_breakpoints [ 0 ] = self . table_data . axes [ 0 ] . data . tolist () self . cdata . undo = False self . update_all_tables () self . update_table_plot ()","title":"undo"},{"location":"reference/ccg/ui/panel/#ccg.ui.panel.CalData.update_all_tables","text":"Update all the tables. Source code in ccg\\ui\\panel.py 888 889 890 891 892 893 894 895 896 897 def update_all_tables ( self ): \"\"\"Update all the tables.\"\"\" self . cdata . data = self . table_data . data . T . tolist () # self.cdata.update_colors() self . cdata . n_data += 1 self . update_delta_table () self . count . data = self . table_data . count . T . tolist () self . count . axis_breakpoints = self . cdata . axis_breakpoints # self.count.update_colors() self . count . n_data += 1","title":"update_all_tables"},{"location":"reference/ccg/ui/panel/#ccg.ui.panel.CalData.update_axes","text":"handle updates to axes Source code in ccg\\ui\\panel.py 655 656 657 658 659 660 661 662 663 664 665 def update_axes ( self , event : param . parameterized . Event ): \"\"\"handle updates to axes\"\"\" if not event . obj . undo and not event . obj . reset : new_axes_data = event . new for index , axis in enumerate ( new_axes_data ): self . table_data . axes [ index ] . data = np . array ( axis , dtype = self . table_data . axes [ index ] . data . dtype ) self . update_all_tables () self . update_table_plot ()","title":"update_axes"},{"location":"reference/ccg/ui/panel/#ccg.ui.panel.CalData.update_delta_table","text":"Update all the tables. Source code in ccg\\ui\\panel.py 899 900 901 902 903 904 def update_delta_table ( self ): \"\"\"Update all the tables.\"\"\" self . delta_perc . data = self . table_data . delta_perc . T . tolist () self . delta_perc . axis_breakpoints = self . cdata . axis_breakpoints # self.delta_perc.update_colors() self . delta_perc . n_data += 1","title":"update_delta_table"},{"location":"reference/ccg/ui/panel/#ccg.ui.panel.CalData.update_plot","text":"Updates the whole plot Source code in ccg\\ui\\panel.py 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 def update_plot ( self , _ : param . parameterized . Event = None ): \"\"\"Updates the whole plot\"\"\" if isinstance ( self . fig , plotgo . Plot ): tmptrc = self . fig . build_traces_from_tbl ( self . table_data ) n = 0 for i , _ in enumerate ( self . fig . fig . data ): self . fig . fig . update_traces ( tmptrc [ i ], selector = i ) n = i for i in range ( n + 1 , len ( tmptrc )): self . fig . fig . add_trace ( tmptrc [ i ]) event = DummyEvent ( old = [], new = self . cdata . selected_cells ) self . highlight_selected ( event ) else : util . merge_dict ( self . fig , Plot ( self . table_data ) . to_dict ()) event = DummyEvent ( old = [], new = self . cdata . selected_cells ) self . highlight_selected ( event )","title":"update_plot"},{"location":"reference/ccg/ui/panel/#ccg.ui.panel.CalData.update_table_data","text":"Update the table data if changes from client. Source code in ccg\\ui\\panel.py 906 907 908 909 910 911 912 913 def update_table_data ( self , event : param . parameterized . Event ): \"\"\"Update the table data if changes from client.\"\"\" self . table_data . data = np . array ( event . new , dtype = self . table_data . dtype ) . T self . cdata . n_data += 1 # self.cdata.update_colors() # self.cdata.n_color += 1 self . update_delta_table () self . update_table_plot ( event )","title":"update_table_data"},{"location":"reference/ccg/ui/panel/#ccg.ui.panel.CalData.update_table_plot","text":"Update table traces in plot. Source code in ccg\\ui\\panel.py 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 def update_table_plot ( self , _ : param . parameterized . Event = None ): \"\"\"Update table traces in plot.\"\"\" tic = datetime . datetime . now () if self . table_data . n_dim == 2 : keys = [ \"x\" , \"y\" , \"z\" ] ntrace = 4 elif self . table_data . n_dim == 1 : keys = [ \"x\" , \"y\" ] ntrace = 2 else : keys = [ \"y\" ] ntrace = 2 tmptrc = self . fig . build_traces_from_tbl ( self . table_data ) # with self.fig.fig.batch_update(): for i in range ( ntrace ): # 4 table traces newdata = { key : tmptrc [ i ][ key ] for key in keys } self . fig . fig . update_traces ( newdata , selector = i , overwrite = False ) self . plt_widget . param . trigger ( \"object\" ) toc = datetime . datetime . now () - tic _LOGGER . debug ( \"Update %s plot in %.3f \" , self . table_data . name , toc . total_seconds () )","title":"update_table_plot"},{"location":"reference/ccg/ui/panel/#ccg.ui.panel.CalDataTabs","text":"A class to manage tabbed widgets of CalDatas. Attributes: tabs ( dict [ str , CalData ] ) \u2013 A dictionary mapping tab names to CalData objects. widget ( Tabs ) \u2013 A Panel Tabs object that contains the tabbed widgets. Methods: __init__ \u2013 Initializes the CalDataTabs object. update_tabs \u2013 Updates the tabs with a new set of Tbls objects. _set_no_cal_loaded \u2013 Sets the widget to display a \"No Cal Loaded\" message. Source code in ccg\\ui\\panel.py 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 class CalDataTabs : \"\"\" A class to manage tabbed widgets of CalDatas. Attributes ---------- tabs : dict[str, CalData] A dictionary mapping tab names to CalData objects. widget : pn.Tabs A Panel Tabs object that contains the tabbed widgets. Methods ------- __init__(tbls: Tbls | None = None): Initializes the CalDataTabs object. update_tabs(tbls: Tbls): Updates the tabs with a new set of Tbls objects. _set_no_cal_loaded(): Sets the widget to display a \"No Cal Loaded\" message. \"\"\" def __init__ ( self , tbls : Tbls | None = None ): self . tabs : dict [ str , CalData ] = {} self . widget = pn . Tabs ( dynamic = True , tabs_location = \"left\" , css_classes = [ \"tabs-left\" ], align = \"center\" , sizing_mode = \"stretch_width\" , ) if tbls : self . update_tabs ( tbls ) else : self . _set_no_cal_loaded () self . widget . param . watch ( self . update_active_tabs , [ \"active\" ]) def update_tabs ( self , tbls : Tbls ): \"\"\" Updates the tabs with a new set of Tbls objects. Parameters ---------- tbls : Tbls A Tbls object containing the new tabs to add. \"\"\" self . widget . clear () # Clear the existing widget for tbl in tbls : cdata = CalData ( tbl ) self . tabs [ tbl . name ] = cdata if len ( tbl . name ) > 32 : # TODO: Check if this hurts the update_active_tabs name = \"...\" + tbl . name [ - 28 :] else : name = tbl . name self . widget . append (( name , cdata . widget )) def _set_no_cal_loaded ( self ): try : self . widget [:] = [ pn . Column ( pn . Spacer ( height = 0 ), pn . pane . SVG ( \"CCG_logo_full_darkbg.svg\" , alt_text = \"Competition Controls Group logo.\" , link_url = \"competitioncontrols.com\" , width = 800 , align = \"center\" , ), sizing_mode = \"stretch_width\" , name = \"No Cal Loaded\" , ) ] except OSError : pass def update_active_tabs ( self , event : param . parameterized . Event | None = None ): \"\"\"hack to update table on active\"\"\" name = self . widget . objects [ event . new ] . name self . tabs [ name ] . update_all_tables () self . tabs [ name ] . update_table_plot () oldname = self . widget . objects [ event . old ] . name self . tabs [ oldname ] . cdata . selected_cells = [] def __getitem__ ( self , key ): \"\"\"getitem\"\"\" if isinstance ( key , int ): return list ( self . tabs . values ())[ key ] return self . tabs [ key ] def __len__ ( self ): \"\"\"len\"\"\" return len ( self . tabs )","title":"CalDataTabs"},{"location":"reference/ccg/ui/panel/#ccg.ui.panel.CalDataTabs.__getitem__","text":"getitem Source code in ccg\\ui\\panel.py 1019 1020 1021 1022 1023 def __getitem__ ( self , key ): \"\"\"getitem\"\"\" if isinstance ( key , int ): return list ( self . tabs . values ())[ key ] return self . tabs [ key ]","title":"__getitem__"},{"location":"reference/ccg/ui/panel/#ccg.ui.panel.CalDataTabs.__len__","text":"len Source code in ccg\\ui\\panel.py 1025 1026 1027 def __len__ ( self ): \"\"\"len\"\"\" return len ( self . tabs )","title":"__len__"},{"location":"reference/ccg/ui/panel/#ccg.ui.panel.CalDataTabs.update_active_tabs","text":"hack to update table on active Source code in ccg\\ui\\panel.py 1011 1012 1013 1014 1015 1016 1017 def update_active_tabs ( self , event : param . parameterized . Event | None = None ): \"\"\"hack to update table on active\"\"\" name = self . widget . objects [ event . new ] . name self . tabs [ name ] . update_all_tables () self . tabs [ name ] . update_table_plot () oldname = self . widget . objects [ event . old ] . name self . tabs [ oldname ] . cdata . selected_cells = []","title":"update_active_tabs"},{"location":"reference/ccg/ui/panel/#ccg.ui.panel.CalDataTabs.update_tabs","text":"Updates the tabs with a new set of Tbls objects. Parameters: tbls ( Tbls ) \u2013 A Tbls object containing the new tabs to add. Source code in ccg\\ui\\panel.py 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 def update_tabs ( self , tbls : Tbls ): \"\"\" Updates the tabs with a new set of Tbls objects. Parameters ---------- tbls : Tbls A Tbls object containing the new tabs to add. \"\"\" self . widget . clear () # Clear the existing widget for tbl in tbls : cdata = CalData ( tbl ) self . tabs [ tbl . name ] = cdata if len ( tbl . name ) > 32 : # TODO: Check if this hurts the update_active_tabs name = \"...\" + tbl . name [ - 28 :] else : name = tbl . name self . widget . append (( name , cdata . widget ))","title":"update_tabs"},{"location":"reference/ccg/ui/panel/#ccg.ui.panel.CalDataTbl","text":"Bases: ReactiveHTML Base class for custom table data control. Source code in ccg\\ui\\panel.py 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 class CalDataTbl ( pn . reactive . ReactiveHTML ): \"\"\"Base class for custom table data control.\"\"\" table_name = param . String ( doc = \"Param Name.\" ) axis_names = param . List ( doc = \"Axis Names.\" , default = []) axis_breakpoints = param . List ( doc = \"Axis Breakpoints.\" , default = []) axis_precisions = param . List ( doc = \"Axis Precisions.\" , default = []) data = param . List ( doc = \"Param Data.\" ) data_precision = param . Integer ( default = 1 , doc = \"Data Precision\" ) n_data = param . Integer ( default = 0 , doc = \"Flag to indicate update from python.\" ) n_color = param . Integer ( default = 0 , doc = \"Flag to indicate update from python.\" ) active_cell = param . Dict ( doc = \"Active Cell\" ) n_cell = param . Integer ( default = 0 , doc = \"Flag to indicate update from python.\" ) selected_cells = param . List ( doc = \"Selected Cells\" , default = []) locked = param . List ( doc = \"Locked Cells\" ) idn = param . String ( default = \"\" , doc = \"table id\" ) undo = param . Boolean ( default = False , doc = \"flag for python undo\" ) reset = param . Boolean ( default = False , doc = \"flag for python reset of selected cells\" ) editable = param . Boolean ( default = True , doc = \"flag for if table is editable\" ) colorscale = param . String ( default = \"Turbo\" , doc = \"Colorscale for table cell colors\" ) colorscale_center = param . Number ( default = None , doc = \"Center colorscale around this value\" ) light_font = param . String ( default = \"#e5e5e5\" , doc = \"Colorscale for table cell colors\" ) dark_font = param . String ( default = \"#434343\" , doc = \"Colorscale for table cell colors\" ) colors = param . List ( doc = \"Cell colors.\" ) font_colors = param . List ( doc = \"Font colors.\" ) _scripts = text_to_scripts ( Path ( __file__ ) . parent . joinpath ( \"caldata_scripts.js\" )) def __init__ ( self , ** kwargs ): \"\"\"Initiate and Update Colors\"\"\" super () . __init__ ( ** kwargs ) self . colors_bind = pn . bind ( self . calc_colors , data = self . param . data , colorscale = self . param . colorscale , colorscale_center = self . param . colorscale_center , light_font = self . param . light_font , dark_font = self . param . dark_font , watch = True , ) if not self . colors : self . calc_colors ( data = self . data , colorscale = self . colorscale , colorscale_center = self . colorscale_center , light_font = self . light_font , dark_font = self . dark_font , ) def calc_colors ( self , data , colorscale , colorscale_center , light_font , dark_font ): colors , fonts = util . table_colors ( data = data , colorscale = colorscale , colorscale_center = colorscale_center , light_font = light_font , dark_font = dark_font , ) self . colors = colors . tolist () self . font_colors = fonts . tolist () # This is required to trigger an update since we're using jinja2 templating. self . n_color += 1 _template = r \"\"\" <table id=\"cal-data\" class=\"cal-data\"> <tbody id=\"cal-data-body\" onmouseleave=\"${script('onmouseleave')}\"> <tr id=\"cal-data-row-0\"> <th id=\"cal-data-0-0\" class=\"cal-data-name\" { % i f axis_breakpoints|length %} colspan=\"{{axis_breakpoints[0]|length + axis_breakpoints|length - 1}}\" { % e ndif %} > {{table_name}} </th> </tr> <tr id=\"cal-data-row-1\"> { % f or axis_breakpoint in axis_breakpoints|reverse %} <th id=\"cal-data-1-{{loop.index0}}\" class=\"cal-data-axis-name-{{loop.index0}}\" { % i f loop.index0 == axis_breakpoints|length-1 %} colspan=\"{{axis_breakpoint|length}}\" { % e lse %} rowspan=2 { % e ndif %} > {{axis_names[axis_breakpoints|length-loop.index0-1]}} </th> { % e ndfor %} </tr> <tr id=\"cal-data-row-2\"> { % f or val in axis_breakpoints[0] %} <td id=\"cal-data-2-{{loop.index0+axis_breakpoints|length-1}}\" class=\"cal-data-axis0\" contenteditable={{ editable|string }} { % i f editable %} onfocus=\"${script('focus')}\" onfocusout=\"${script('focus_out')}\" onkeydown=\"${script('tbl_keydown')}\" onkeypress=\"${script('keypress')}\" onkeyup=\"${script('keyup')}\" onmouseup=\"${script('onmouseup')}\" onmousedown=\"${script('onmousedown')}\" onmouseenter=\"${script('onmouseenter')}\" { % e ndif %} > {{\" %0.*f \" % (axis_precisions[0],val)}} </td> { % e ndfor %} </tr> { % i f axis_breakpoints|length > 1 %} { % f or row in range(data|length) %} { % s et outer_loop=loop %} <tr id=\"cal-data-row-{{outer_loop.index0+3}}\"> { % i f axis_breakpoints[1]|length %} <td id=\"cal-data-{{outer_loop.index0+3}}-0\" contenteditable={{ editable|string }} class=\"cal-data-axis1\" { % i f editable %} onfocus=\"${script('focus')}\" onfocusout=\"${script('focus_out')}\" onkeydown=\"${script('tbl_keydown')}\" onkeypress=\"${script('keypress')}\" onkeyup=\"${script('keyup')}\" onmouseup=\"${script('onmouseup')}\" onmousedown=\"${script('onmousedown')}\" onmouseenter=\"${script('onmouseenter')}\" { % e ndif %} > {{\" %0.*f \" % (axis_precisions[1],axis_breakpoints[1][loop.index0])}} </td> { % e ndif %} { % f or col in range(data[0]|length) %} <td id=\"cal-data-{{outer_loop.index0+3}}-{{loop.index0+1}}\" contenteditable={{ editable|string }} class=\"cal-data-data{{ ' locked' if locked[outer_loop.index0][loop.index0] }}\" { % i f editable %} onfocus=\"${script('focus')}\" onfocusout=\"${script('focus_out')}\" onkeydown=\"${script('tbl_keydown')}\" onkeypress=\"${script('keypress')}\" onkeyup=\"${script('keyup')}\" onmousedown=\"${script('onmousedown')}\" onmouseenter=\"${script('onmouseenter')}\" onmouseup=\"${script('onmouseup')}\" { % e ndif %} { % i f colors %} style=\" background-color: {{ colors[outer_loop.index0][loop.index0] }}; color: {{ font_colors[outer_loop.index0][loop.index0] }}; \" { % e ndif %} > {{ \" %0.*f \" % (data_precision,data[outer_loop.index0][loop.index0])}} </td> { % e ndfor %} </tr> { % e ndfor %} { % e lse %} <tr id=\"cal-data-row-3\"> { % f or col in range(data|length) %} <td id=\"cal-data-3-{{loop.index0}}\" contenteditable={{ editable|string }} class=\"cal-data-data{{ ' locked' if locked[loop.index0] }}\" { % i f editable %} onfocus=\"${script('focus')}\" onfocusout=\"${script('focus_out')}\" onkeydown=\"${script('tbl_keydown')}\" onkeypress=\"${script('keypress')}\" onkeyup=\"${script('keyup')}\" onmouseup=\"${script('onmouseup')}\" onmousedown=\"${script('onmousedown')}\" onmouseenter=\"${script('onmouseenter')}\" { % e ndif %} { % i f colors %} style=\" background-color: {{ colors[loop.index0] }}; color: {{ font_colors[loop.index0] }}; \" { % e ndif %} > {{ \" %0.*f \" % (data_precision,data[loop.index0])}} </td> { % e ndfor %} </tr> { % e ndif %} </tbody> </table> \"\"\"","title":"CalDataTbl"},{"location":"reference/ccg/ui/panel/#ccg.ui.panel.CalDataTbl.__init__","text":"Initiate and Update Colors Source code in ccg\\ui\\panel.py 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 def __init__ ( self , ** kwargs ): \"\"\"Initiate and Update Colors\"\"\" super () . __init__ ( ** kwargs ) self . colors_bind = pn . bind ( self . calc_colors , data = self . param . data , colorscale = self . param . colorscale , colorscale_center = self . param . colorscale_center , light_font = self . param . light_font , dark_font = self . param . dark_font , watch = True , ) if not self . colors : self . calc_colors ( data = self . data , colorscale = self . colorscale , colorscale_center = self . colorscale_center , light_font = self . light_font , dark_font = self . dark_font , )","title":"__init__"},{"location":"reference/ccg/ui/panel/#ccg.ui.panel.text_to_scripts","text":"Returns a _scripts dictionary for ReactiveHTML based on a string Args: filename (str): The js script Returns: Dict: The output _scripts Example: txt=''' ... render=()=>{ ... console.log(data) ... } ... value=()=>{ ... my_func(value) ... } ... ''' text_to_scripts(txt) {'render': 'console.log(data)', 'value': 'my_func(value)'} Note: The script must be in the following format: Based on MarcSkovMarksen's suggestions for ReactiveHTML Scripts. Source code in ccg\\ui\\panel.py 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 def text_to_scripts ( filename : Path ) -> dict : \"\"\"Returns a `_scripts` dictionary for ReactiveHTML based on a string Args: filename (str): The js script Returns: Dict: The output `_scripts` Example: >>> txt=''' ... render=()=>{ ... console.log(data) ... } ... value=()=>{ ... my_func(value) ... } ... ''' >>> text_to_scripts(txt) {'render': 'console.log(data)', 'value': 'my_func(value)'} Note: The script must be in the following format: Based on MarcSkovMarksen's suggestions for ReactiveHTML Scripts. \"\"\" tic = datetime . datetime . now () with open ( Path ( filename ), mode = \"r\" , encoding = \"utf-8\" ) as f : text = f . read () lines = text . split ( \" \\n \" ) scripts = {} key = \"\" value = \"\" for line in lines : if key : if line == \"};\" : scripts [ key ] = _clean_script ( value ) key = value = \"\" else : value += line + \" \\n \" else : if ( line and not line [ 0 ] == \" \" and line . endswith ( \") => {\" ) and \"= (\" in line ): key = line . split ( \"=\" )[ 0 ] . strip () toc = datetime . datetime . now () - tic _LOGGER . debug ( \"Text to Scripts in %.3f \" , toc . total_seconds ()) return scripts","title":"text_to_scripts"},{"location":"reference/ccg/ui/plot/","text":"Plot Class to generate Plotly plots. Source code in ccg\\ui\\plot.py 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 class Plot : \"\"\"Class to generate Plotly plots.\"\"\" # Plot Colors # https://www.behance.net/gallery/84533571/Above-the-Allgaeu # THEME1 = \"#010A26\" # THEME2 = \"#283040\" # THEME3 = \"#6D7B8C\" # THEME4 = \"#8A99A6\" # THEME5 = \"#6B734F\" THEME1 = \"#011726\" THEME2 = \"#353837\" THEME3 = \"#656b72\" THEME4 = \"#8f979e\" THEME5 = \"#6B734F\" WHITE = \"#e3ecff\" BLACK = \"#111c24\" GREY1 = \"#333533\" TRACES = [ \"#4ea7fa\" , \"#bcfa35\" , \"#FA2341\" , \"#923df3\" , \"#315dee\" , \"#0fbd26\" , \"#ff90a8\" , \"#ee31ee\" , \"#bdccdd\" , \"#22f31a\" , \"#fffc43\" , \"#ff8615\" , ] # TODO: Add more colors n_colors = len ( TRACES ) TURBO = [ [ 0.000 , \"#30123b\" ], [ 0.071 , \"#4145ab\" ], [ 0.143 , \"#4675ed\" ], [ 0.214 , \"#39a2fc\" ], [ 0.286 , \"#1bcfd4\" ], [ 0.357 , \"#24eca6\" ], [ 0.429 , \"#61fc6c\" ], [ 0.500 , \"#a4fc3b\" ], [ 0.571 , \"#d1e834\" ], [ 0.643 , \"#f3c63a\" ], [ 0.714 , \"#fe9b2d\" ], [ 0.786 , \"#f36315\" ], [ 0.857 , \"#d93806\" ], [ 0.929 , \"#b11901\" ], [ 1.000 , \"#7a0402\" ], ] LINESHAPE = { None : \"linear\" , ccg . util . InterpMethod . LINEAR : \"linear\" , ccg . util . InterpMethod . ZOH : \"hv\" , ccg . util . InterpMethod . NEAREST : \"hvh\" , } frange = 4 # Factor of range for combining y axes fpos = 0.06 # Factor of position for multi y axes compat_types = [ ( \"i\" , \"f\" , \"u\" ), ( \"U\" , \"S\" ), ( \"b\" ,), ( \"O\" ,), ] _copy_button = { \"name\" : \"toClipboard\" , \"title\" : \"Copy to clipboard\" , \"icon\" : { \"path\" : \"M102.17,29.66A3,3,0,0,0,100,26.79L73.62,1.1A3,3,0,0,0,71.31,0h-46a5.36,5.36,0,0,0-5.36,5.36V20.41H5.36A5.36,5.36,0,0,0,0,25.77v91.75a5.36,5.36,0,0,0,5.36,5.36H76.9a5.36,5.36,0,0,0,5.33-5.36v-15H96.82a5.36,5.36,0,0,0,5.33-5.36q0-33.73,0-67.45ZM25.91,20.41V6h42.4V30.24a3,3,0,0,0,3,3H96.18q0,31.62,0,63.24h-14l0-46.42a3,3,0,0,0-2.17-2.87L53.69,21.51a2.93,2.93,0,0,0-2.3-1.1ZM54.37,30.89,72.28,47.67H54.37V30.89ZM6,116.89V26.37h42.4V50.65a3,3,0,0,0,3,3H76.26q0,31.64,0,63.24ZM17.33,69.68a2.12,2.12,0,0,1,1.59-.74H54.07a2.14,2.14,0,0,1,1.6.73,2.54,2.54,0,0,1,.63,1.7,2.57,2.57,0,0,1-.64,1.7,2.16,2.16,0,0,1-1.59.74H18.92a2.15,2.15,0,0,1-1.6-.73,2.59,2.59,0,0,1,0-3.4Zm0,28.94a2.1,2.1,0,0,1,1.58-.74H63.87a2.12,2.12,0,0,1,1.59.74,2.57,2.57,0,0,1,.64,1.7,2.54,2.54,0,0,1-.63,1.7,2.14,2.14,0,0,1-1.6.73H18.94a2.13,2.13,0,0,1-1.59-.73,2.56,2.56,0,0,1,0-3.4ZM63.87,83.41a2.12,2.12,0,0,1,1.59.74,2.59,2.59,0,0,1,0,3.4,2.13,2.13,0,0,1-1.6.72H18.94a2.12,2.12,0,0,1-1.59-.72,2.55,2.55,0,0,1-.64-1.71,2.5,2.5,0,0,1,.65-1.69,2.1,2.1,0,0,1,1.58-.74ZM17.33,55.2a2.15,2.15,0,0,1,1.59-.73H39.71a2.13,2.13,0,0,1,1.6.72,2.61,2.61,0,0,1,0,3.41,2.15,2.15,0,0,1-1.59.73H18.92a2.14,2.14,0,0,1-1.6-.72,2.61,2.61,0,0,1,0-3.41Zm0-14.47A2.13,2.13,0,0,1,18.94,40H30.37a2.12,2.12,0,0,1,1.59.72,2.61,2.61,0,0,1,0,3.41,2.13,2.13,0,0,1-1.58.73H18.94a2.16,2.16,0,0,1-1.59-.72,2.57,2.57,0,0,1-.64-1.71,2.54,2.54,0,0,1,.65-1.7ZM74.3,10.48,92.21,27.26H74.3V10.48Z\" , \"transform\" : \"scale(0.12)\" , }, \"click\" : \"plotly_clip\" , } _copyfunc = \"function plotly_clip(gd) {Plotly.toImage(gd, { format: 'png', width: 2100, height: 900 }).then(async function (url) {try {const data = await fetch(url);const blob = await data.blob();await navigator.clipboard.write([new ClipboardItem({[blob.type]: blob})]);console.log('Image copied.');} catch (err) {console.error(err.name, err.message);}});}\" config = { \"scrollZoom\" : True , \"edits\" : { \"legendPosition\" : True }, \"displaylogo\" : False , \"modeBarButtons\" : [ [ _copy_button , \"toImage\" , \"zoom2d\" , \"pan2d\" , \"resetScale2d\" ] ], } _scene_axis = { \"backgroundcolor\" : THEME4 , \"color\" : WHITE , \"gridcolor\" : THEME3 , \"showline\" : True , \"showgrid\" : True , \"ticks\" : \"outside\" , \"mirror\" : True , } _plt_layout = { \"title\" : { \"text\" : \"Data Plot\" , \"font\" : { \"size\" : 24 }, \"x\" : 0.5 , \"xanchor\" : \"center\" , }, \"legend\" : { \"bgcolor\" : THEME3 , \"bordercolor\" : THEME4 , \"borderwidth\" : 1 , \"xanchor\" : \"left\" , \"yanchor\" : \"top\" , \"x\" : 1.02 , \"y\" : 1 , }, \"showlegend\" : True , \"hovermode\" : \"closest\" , \"margin\" : { \"autoexpand\" : True , \"b\" : 80 , \"l\" : 80 , \"r\" : 80 , \"t\" : 80 , \"pad\" : 0 }, \"xaxis1\" : { \"color\" : WHITE , \"gridcolor\" : THEME4 , \"showline\" : True , \"spikesnap\" : \"hovered data\" , \"spikemode\" : \"across+marker\" , \"spikedash\" : \"solid\" , \"spikethickness\" : 1 , \"ticks\" : \"outside\" , \"zerolinecolor\" : THEME4 , \"zerolinewidth\" : 2 , \"mirror\" : True , }, \"paper_bgcolor\" : THEME2 , \"plot_bgcolor\" : GREY1 , \"font\" : { \"color\" : WHITE , \"family\" : 'Consolas, \"Courier New\", monospace' }, \"clickmode\" : \"event+select\" , \"colorway\" : TRACES , \"selectdirection\" : \"any\" , \"autosize\" : True , \"uirevision\" : True , # \"transition\": {\"duration\": 500, \"easing\": \"cubic-in-out\"}, } def __init__ ( self , data : Frame | Sig | Tbl = None , name : str = None , plot_prep = True ): self . traces : list [ dict ] = [] self . nyaxes = 0 self . ntrace = - 1 self . n_cond = 0 # For use in gate diag plots self . n_col = 0 # For use in gate diag plots self . yaxes : dict [ str , dict ] = {} self . plt_layout = copy . deepcopy ( self . _plt_layout ) self . plot_prep = plot_prep # Build traces if isinstance ( data , Frame ): for sig in data : self . append_trace_from_sig ( sig ) elif isinstance ( data , Sig ): self . append_trace_from_sig ( data ) elif isinstance ( data , Tbl ): self . append_trace_from_tbl ( data ) elif isinstance ( data , ScatterData ): self . append_trace_from_scatter ( data ) elif data is None : pass else : raise NotImplementedError ( f \"Plot not implemented for { type ( data ) } \" ) if name is None : if data is None or data . name is None : name = \"CCG Data\" else : name = data . name self . plt_layout [ \"title\" ][ \"text\" ] = name def update_axis ( self , axis : str = \"xaxis1\" , title : str = None , unit : str = None , min_range : float = None , max_range : float = None , ): \"\"\"Update axis info.\"\"\" if title is not None : if unit is not None : ccg . util . merge_dict ( self . plt_layout , { axis : { \"title\" : { \"text\" : f \" { title } [ { unit } ]\" }}} ) else : ccg . util . merge_dict ( self . plt_layout , { axis : { \"title\" : { \"text\" : f \" { title } \" }}} ) ccg . util . merge_dict ( self . plt_layout , { axis : { \"range\" : [ min_range , max_range ]}}) def build_trace ( self , x : npt . NDArray , y : npt . NDArray , signame : str = None , sigunit : str = None , connect_gaps : bool = None , yaxis : str = None , color : int = None , ): \"\"\"Build Trace for plotly.\"\"\" ntrace = self . ntrace + 1 if color is None : color = ntrace yaxis = self . find_yaxis ( Sig ( data = y , tline = TLine ( x ), name = signame , unit = sigunit ), yaxis = yaxis ) # TODO: Implement find_yaxis for non sigs sigunit = \"\" if sigunit is None else sigunit trace = { \"type\" : \"scattergl\" , \"y\" : y , \"x\" : x , \"name\" : f \" { signame } [ { sigunit } ]\" , \"mode\" : \"markers+lines\" , \"hovertemplate\" : \"\"\"Value: % {y:.2f} % {yaxis.title.text} <br> X: % {x:.2f} % {xaxis.title.text} \"\"\" , \"yaxis\" : yaxis , \"opacity\" : 1 , \"connectgaps\" : bool ( connect_gaps ), \"marker\" : { \"size\" : [ 2 ] * len ( y ), \"line\" : { \"color\" : ccg . util . max_contrast ( self . _plt_layout [ \"plot_bgcolor\" ], ccg . util . shift_lightness ( self . TRACES [ color % self . n_colors ], 1.4 ), ccg . util . shift_lightness ( self . TRACES [ color % self . n_colors ], 0.4 ), ), \"width\" : 1 , }, }, \"line\" : { \"width\" : 1 , \"color\" : self . TRACES [ color % self . n_colors ], }, } return trace def build_trace_from_sig ( self , sig : Sig , color : int = None , yaxis : str = None ): \"\"\"Build Trace for plotly from a Sig.\"\"\" ntrace = self . ntrace + 1 if color is None : color = ntrace if self . plot_prep : sig = sig . plot_prep () yaxis = self . find_yaxis ( sig , yaxis ) unit = \"\" if sig . unit is None else sig . unit if sig . tline [ 0 ] < 32000000 : # apprx 1yr from epoch # assume this is an elapsed time instead x = sig . tline . unix hov_temp = \"\"\" Value: % {y:.2f} % {yaxis.title.text} <br> Time: % {x:.3f} [s]\"\"\" self . update_axis ( axis = \"xaxis1\" , title = \"Elapsed Time\" , unit = \"S\" ) else : x = sig . tline . iso hov_temp = \"\"\" Value: % {y:.2f} % {yaxis.title.text} <br> Time: %{x|%H:%M:%S.%L}\"\"\" self . update_axis ( axis = \"xaxis1\" , title = \"Date and Time\" ) if sig . nsamples > 100000 : hov = \"skip\" # Disable hover since its too slow hov_temp = \"\" else : hov = \"all\" trace = { \"type\" : \"scattergl\" , \"y\" : sig . data , \"x\" : x , \"name\" : f \" { sig . name } [ { unit } ]\" , \"mode\" : \"markers+lines\" , \"hovertemplate\" : hov_temp , \"hoverinfo\" : hov , \"yaxis\" : yaxis , \"opacity\" : 1 , \"connectgaps\" : bool ( sig . connect_gaps ), # should work if connect_gaps is None \"marker\" : { # \"color\": TRACES[self.ntrace], \"size\" : [ 2 ] * len ( x ), \"line\" : { \"color\" : ccg . util . max_contrast ( self . _plt_layout [ \"plot_bgcolor\" ], ccg . util . shift_lightness ( self . TRACES [ color % self . n_colors ], 1.4 ), ccg . util . shift_lightness ( self . TRACES [ color % self . n_colors ], 0.4 ), ), \"width\" : 1 , }, }, \"line\" : { \"width\" : 1 , \"shape\" : self . LINESHAPE [ sig . interp_method ], \"color\" : self . TRACES [ color % self . n_colors ], }, } if sig . base_data is not None : ccg . util . merge_dict ( trace , { \"text\" : sig . base_data , \"hovertemplate\" : \"\"\"Value: % {text} <br> Time: %{x|%H:%M:%S.%L}\"\"\" , }, ) return trace def build_traces_from_tbl ( self , tbl : Tbl , color : int = None ) -> list [ dict ]: \"\"\"build trace from table.\"\"\" ntrace = 1 # self.ntrace+1 Does it make sense to deal with multiple tbls in 1 plot? if tbl . unit is not None : unit = f \" [ { tbl . unit } ]\" else : unit = \"\" if tbl . n_dim == 2 : traces = self . build_2d_traces ( tbl , color , ntrace , unit ) elif tbl . n_dim == 1 : traces = self . build_1d_traces ( tbl , color , ntrace , unit ) elif tbl . n_dim == 0 : traces = self . build_0d_traces ( tbl , color , ntrace , unit ) else : raise NotImplementedError ( f \"Plot not implemented for n_dim = { tbl . n_dim } \" ) return traces def build_traces_from_scatter ( self , scatter : ScatterData ): \"\"\"Builds scatter data traces\"\"\" # TODO: Implement support for more than 1 scatter if scatter is not None : return [ self . build_scatter_trace ( scatter = scatter )] def build_0d_traces ( self , param : Tbl , color : int , ntrace : int , unit : str ): \"\"\"Build traces for 0d param\"\"\" traces = [] yaxis = f \"y { self . nyaxes + 1 } \" hov_temp = ( f \"\"\" { param . name } : % {{ y:. { param . precision } f }} [ { unit } ]<extra></extra>\"\"\" ) try : tmp_trc = { \"type\" : \"scattergl\" , \"y\" : param . orig . data , \"name\" : param . orig . name , \"mode\" : \"markers\" , \"yaxis\" : yaxis , \"opacity\" : 1 , \"hovertemplate\" : hov_temp , \"marker\" : { \"size\" : 8 , \"color\" : self . TRACES [ ntrace % self . n_colors ], \"line\" : { \"color\" : ccg . util . max_contrast ( self . _plt_layout [ \"plot_bgcolor\" ], ccg . util . shift_lightness ( self . TRACES [ ntrace % self . n_colors ], 1.4 ), ccg . util . shift_lightness ( self . TRACES [ ntrace % self . n_colors ], 0.4 ), ), \"width\" : 1 , }, }, \"hoverlabel\" : { \"bgcolor\" : self . TRACES [ ntrace % self . n_colors ]}, \"showlegend\" : True , \"legendgroup\" : f \" { param . orig . name } _ { ntrace } \" , } traces . append ( tmp_trc ) ntrace += 1 except KeyError : pass if color is None : color = ntrace tmp_trc = { \"type\" : \"scattergl\" , \"y\" : param . data , \"name\" : param . name , \"mode\" : \"markers\" , \"hovertemplate\" : hov_temp , \"opacity\" : 1 , \"marker\" : { \"size\" : 8 , \"color\" : self . TRACES [ color % self . n_colors ], \"line\" : { \"color\" : ccg . util . max_contrast ( self . _plt_layout [ \"plot_bgcolor\" ], ccg . util . shift_lightness ( self . TRACES [ color % self . n_colors ], 1.4 ), ccg . util . shift_lightness ( self . TRACES [ color % self . n_colors ], 0.4 ), ), \"width\" : 1 , }, }, \"hoverlabel\" : { \"bgcolor\" : self . TRACES [ color % self . n_colors ]}, \"showlegend\" : True , \"legendgroup\" : f \" { param . name } _ { ntrace } \" , } traces . append ( tmp_trc ) ntrace += 1 nscatter = 0 for scatter in param . scatter_data : if scatter is not None : # plot the scatter data as well. nscatter += 1 tmp_trc = self . build_scatter_trace ( scatter = scatter , param = param , ntrace = ntrace , nscatter = nscatter ) traces . append ( tmp_trc ) ntrace += 1 self . yaxes [ yaxis ] = { \"unit\" : param . unit , \"min\" : param . data_range [ 0 ], \"max\" : param . data_range [ 1 ], \"dtype\" : self . compat_types [ np . where ([ param . data . dtype . kind in t for t in self . compat_types ])[ 0 ][ 0 ] # r-worded way to get the index of the match ], \"color\" : self . WHITE , \"fixed_range\" : False , } return traces def build_1d_traces ( self , param : Tbl , color : int , ntrace : int , unit : str ): \"\"\"Build traces for 1d param\"\"\" traces = [] yaxis = f \"y { self . nyaxes + 1 } \" hov_temp = f \"\"\" { param . name } : % {{ y:. { param . precision } f }} [ { unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } f }} [ { param . axes [ 0 ] . unit } ]<extra></extra>\"\"\" try : tmp_trc = { \"type\" : \"scattergl\" , \"y\" : param . orig . data , \"x\" : param . orig . axes [ 0 ] . data , \"name\" : param . orig . name , \"mode\" : \"markers+lines\" , \"yaxis\" : yaxis , \"opacity\" : 1 , \"hovertemplate\" : hov_temp , \"marker\" : { \"size\" : np . array ([ 10 ] * param . orig . data . size ), \"color\" : self . TRACES [ ntrace % self . n_colors ], \"line\" : { \"color\" : ccg . util . max_contrast ( self . _plt_layout [ \"plot_bgcolor\" ], ccg . util . shift_lightness ( self . TRACES [ ntrace % self . n_colors ], 1.4 ), ccg . util . shift_lightness ( self . TRACES [ ntrace % self . n_colors ], 0.4 ), ), \"width\" : 1 , }, }, \"line\" : { \"width\" : 1 , \"shape\" : self . LINESHAPE [ param . orig . axes [ 0 ] . interp_method ], \"color\" : self . TRACES [ ntrace % self . n_colors ], }, \"hoverlabel\" : { \"bgcolor\" : self . TRACES [ ntrace % self . n_colors ]}, \"showlegend\" : True , \"legendgroup\" : f \" { param . orig . name } _ { ntrace } \" , } traces . append ( tmp_trc ) ntrace += 1 except KeyError : pass if color is None : color = ntrace tmp_trc = { \"type\" : \"scattergl\" , \"y\" : param . data , \"x\" : param . axes [ 0 ] . data , \"name\" : param . name , \"mode\" : \"markers+lines\" , \"hovertemplate\" : hov_temp , \"opacity\" : 1 , \"marker\" : { \"size\" : np . array ([ 10 ] * param . data . size ), \"color\" : self . TRACES [ color % self . n_colors ], \"line\" : { \"color\" : ccg . util . max_contrast ( self . _plt_layout [ \"plot_bgcolor\" ], ccg . util . shift_lightness ( self . TRACES [ color % self . n_colors ], 1.4 ), ccg . util . shift_lightness ( self . TRACES [ color % self . n_colors ], 0.4 ), ), \"width\" : 1 , }, }, \"line\" : { \"width\" : 1 , \"shape\" : self . LINESHAPE [ param . axes [ 0 ] . interp_method ], \"color\" : self . TRACES [ color % self . n_colors ], }, \"hoverlabel\" : { \"bgcolor\" : self . TRACES [ color % self . n_colors ]}, \"showlegend\" : True , \"legendgroup\" : f \" { param . name } _ { ntrace } \" , } traces . append ( tmp_trc ) ntrace += 1 nscatter = 0 for scatter in param . scatter_data : if scatter is not None : # plot the scatter data as well. nscatter += 1 tmp_trc = self . build_scatter_trace ( scatter = scatter , param = param , ntrace = ntrace , nscatter = nscatter ) traces . append ( tmp_trc ) ntrace += 1 self . yaxes [ yaxis ] = { \"unit\" : param . unit , \"min\" : param . data_range [ 0 ], \"max\" : param . data_range [ 1 ], \"dtype\" : self . compat_types [ np . where ([ param . data . dtype . kind in t for t in self . compat_types ])[ 0 ][ 0 ] # r-worded way to get the index of the match ], \"color\" : self . WHITE , \"fixed_range\" : False , } return traces def build_2d_traces ( self , param : Tbl , color : int , ntrace : int , unit : str ): \"\"\"build traces from 2d param\"\"\" traces = [] try : traces . extend ( self . build_surf_traces ( param . orig , ntrace - 1 , ntrace , unit , visible = True ) ) ntrace += 1 except KeyError : pass if color is None : color = ntrace - 1 traces . extend ( self . build_surf_traces ( param , color , ntrace , unit )) ntrace += 1 nscatter = 0 for scatter in param . scatter_data : if scatter is not None : # plot the scatter data as well. nscatter += 1 tmp_trc = self . build_scatter_trace ( scatter = scatter , param = param , ntrace = ntrace , nscatter = nscatter ) traces . append ( tmp_trc ) ntrace += 1 xaxis = copy . deepcopy ( self . _scene_axis ) xaxis . update ( { \"title\" : { \"text\" : f \" { param . axes [ 0 ] . name } [ { param . axes [ 0 ] . unit } ]\" }} ) yaxis = copy . deepcopy ( self . _scene_axis ) yaxis . update ( { \"title\" : { \"text\" : f \" { param . axes [ 1 ] . name } [ { param . axes [ 1 ] . unit } ]\" }} ) zaxis = copy . deepcopy ( self . _scene_axis ) zaxis . update ({ \"title\" : { \"text\" : f \" { param . name } [ { param . unit } ]\" }}) scene = { \"scene\" : { \"xaxis\" : xaxis , \"yaxis\" : yaxis , \"zaxis\" : zaxis , \"camera\" : { \"eye\" : { \"x\" : - 1.25 , \"y\" : - 1.25 , \"z\" : 1.1 }}, } } ccg . util . merge_dict ( self . plt_layout , scene ) return traces def build_scatter_trace ( self , scatter : ScatterData , param : Tbl = None , ntrace : int = 1 , nscatter : int = 1 , ): \"\"\"Builds a scatter trace. ntrace and nscatter are counters for color increments\"\"\" ndim = scatter . ndim tmp_trc = { \"name\" : scatter . name , \"mode\" : \"markers\" , \"opacity\" : 1 , \"marker\" : { \"size\" : 3 , \"color\" : self . TRACES [ ntrace % self . n_colors ], \"colorscale\" : [ [ 0 , self . TRACES [ ntrace % self . n_colors ]], [ 1 , self . TRACES [ ntrace % self . n_colors ]], ], \"showscale\" : False , }, \"hoverlabel\" : { \"bgcolor\" : self . TRACES [ ntrace % self . n_colors ]}, \"showlegend\" : True , \"legendgroup\" : f \" { scatter . name } _ { ntrace } \" , } if scatter . color is not None : tmp = { \"marker\" : { \"color\" : scatter . color , \"colorscale\" : self . TURBO , \"colorbar\" : { \"bgcolor\" : self . THEME3 , \"bordercolor\" : self . THEME4 , \"borderwidth\" : 1 , \"title\" : { \"text\" : f \" { scatter . color_label } [ { scatter . color_unit } ]\" , \"side\" : \"right\" , }, \"x\" : 0 , }, \"showscale\" : True , }, \"text\" : np . round ( scatter . color , scatter . color_precision ), } if scatter . color_range is not None : ccg . util . merge_dict ( tmp , { \"marker\" : { \"cmin\" : scatter . color_range [ 0 ], \"cmax\" : scatter . color_range [ 1 ], } }, ) # Need to move legend to clear color bar. tmp_lgnd = { \"legend\" : { \"xanchor\" : \"right\" , \"yanchor\" : \"top\" , \"x\" : 1 , \"y\" : 1 , }, } ccg . util . merge_dict ( self . plt_layout , tmp_lgnd ) ccg . util . merge_dict ( tmp_trc , tmp ) if ndim == 2 : if param is not None : if scatter . color is not None : hov_temp = f \"\"\" { scatter . name } : % {{ z:. { param . precision } f }} [ { param . unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } f }} [ { param . axes [ 0 ] . unit } ]<br> { param . axes [ 1 ] . name } : % {{ y:. { param . axes [ 1 ] . precision } f }} [ { param . axes [ 1 ] . unit } ]<br> { scatter . color_label } : % {{ marker.color:. { scatter . color_precision } f }} [ { scatter . color_unit } ] <extra></extra>\"\"\" else : hov_temp = f \"\"\" { scatter . name } : % {{ z:. { param . precision } d }} [ { param . unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } d }} [ { param . axes [ 0 ] . unit } ]<br> { param . axes [ 1 ] . name } : % {{ y:. { param . axes [ 1 ] . precision } d }} [ { param . axes [ 1 ] . unit } ] <extra></extra>\"\"\" else : if scatter . color is not None : hov_temp = \"\" tmp = { \"type\" : \"scatter3d\" , \"x\" : scatter . data [ 0 ], \"y\" : scatter . data [ 1 ], \"z\" : scatter . data [ 2 ], \"hovertemplate\" : hov_temp , } elif ndim == 1 : if param is not None : if scatter . color is not None : hov_temp = f \"\"\" { scatter . name } : % {{ y:. { param . precision } f }} [ { param . unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } f }} [ { param . axes [ 0 ] . unit } ]<br> { scatter . color_label } : % {{ marker.color:. { scatter . color_precision } f }} [ { scatter . color_unit } ] <extra></extra>\"\"\" else : hov_temp = f \"\"\" { scatter . name } : % {{ y:. { param . precision } d }} [ { param . unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } d }} [ { param . axes [ 0 ] . unit } ]<br> <extra></extra>\"\"\" else : hov_temp = \"\" tmp = { \"type\" : \"scattergl\" , \"x\" : scatter . data [ 0 ], \"y\" : scatter . data [ 1 ], \"hovertemplate\" : hov_temp , } elif ndim == 0 : if param is not None : if scatter . color is not None : hov_temp = f \"\"\" { scatter . name } : % {{ y:. { param . precision } f }} [ { param . unit } ]<br> { scatter . color_label } : % {{ marker.color:. { scatter . color_precision } f }} [ { scatter . color_unit } ] <extra></extra>\"\"\" else : hov_temp = f \"\"\" { scatter . name } : % {{ y:. { param . precision } d }} [ { param . unit } ]<br> <extra></extra>\"\"\" else : hov_temp = \"\" tmp = { \"type\" : \"scattergl\" , \"x\" : scatter . data [ 0 ] * 0 , \"y\" : scatter . data [ 1 ], \"hovertemplate\" : hov_temp , } else : raise NotImplementedError ccg . util . merge_dict ( tmp_trc , tmp ) if nscatter > 1 : ccg . util . merge_dict ( tmp_trc , { \"visible\" : \"legendonly\" }) return tmp_trc def build_surf_traces ( self , param : Tbl , color : int , ntrace : int , unit : str , visible : bool = True , ): \"\"\"Build 2d surface trace\"\"\" if not visible : visible = \"legendonly\" hov_temp = f \"\"\" { param . name } : % {{ z:. { param . precision } f }} [ { param . unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } f }} [ { param . axes [ 0 ] . unit } ]<br> { param . axes [ 1 ] . name } : % {{ y:. { param . axes [ 1 ] . precision } f }} [ { param . axes [ 1 ] . unit } ] <extra></extra>\"\"\" x , y = np . meshgrid ( param . axes [ 0 ] . data , param . axes [ 1 ] . data ) x = np . concatenate (( x , x [ - 1 , np . newaxis ])) y = np . concatenate (( y , y [ - 1 , np . newaxis ])) z = np . concatenate (( param . data . T , param . data . T [ - 1 , np . newaxis ] * np . NaN )) i = x . flatten ( \"F\" ) j = y . flatten ( \"F\" ) k = z . flatten ( \"F\" ) y , x = np . meshgrid ( param . axes [ 1 ] . data , param . axes [ 0 ] . data ) x = np . concatenate (( x , x [ - 1 , np . newaxis ])) y = np . concatenate (( y , y [ - 1 , np . newaxis ])) z = np . concatenate (( param . data , param . data [ - 1 , np . newaxis ] * np . NaN )) i = np . concatenate (( i , x . flatten ( \"F\" ))) j = np . concatenate (( j , y . flatten ( \"F\" ))) k = np . concatenate (( k , z . flatten ( \"F\" ))) traces = [ { \"type\" : \"surface\" , \"x\" : param . axes [ 0 ] . data , \"y\" : param . axes [ 1 ] . data , \"z\" : param . data . T , \"name\" : f \" { param . name }{ unit } \" , \"hovertemplate\" : hov_temp , \"hoverlabel\" : { \"bgcolor\" : self . TRACES [ color % self . n_colors ]}, \"opacity\" : 0.5 , \"colorscale\" : [ [ 0 , self . TRACES [ color % self . n_colors ]], [ 1 , self . TRACES [ color % self . n_colors ]], ], \"showlegend\" : True , \"legendgroup\" : f \" { param . name } _ { ntrace } \" , \"showscale\" : False , \"visible\" : visible , }, { \"type\" : \"scatter3d\" , \"x\" : i , \"y\" : j , \"z\" : k , \"name\" : f \" { param . name }{ unit } \" , \"hoverinfo\" : \"skip\" , \"opacity\" : 1 , \"marker\" : { \"color\" : np . array ([ self . TRACES [ color % self . n_colors ]] * len ( i )), \"size\" : np . array ([ 10 ] * len ( i )), # \"line\": { # \"color\": ccg.util.max_contrast( # self.TRACES[color % self.n_colors], # ccg.util.shift_lightness( # self.TRACES[color % self.n_colors], 1.4 # ), # ccg.util.shift_lightness( # self.TRACES[color % self.n_colors], 0.4 # ), # ), # \"width\": 1, # }, }, \"line\" : { \"color\" : ccg . util . max_contrast ( self . TRACES [ color % self . n_colors ], ccg . util . shift_lightness ( self . TRACES [ color % self . n_colors ], 1.4 ), ccg . util . shift_lightness ( self . TRACES [ color % self . n_colors ], 0.4 ), ), \"width\" : 2 , }, \"showlegend\" : False , \"legendgroup\" : f \" { param . name } _ { ntrace } \" , \"connectgaps\" : False , \"visible\" : visible , }, ] return traces def find_yaxis ( self , sig : Sig , yaxis : str = None ): \"\"\"Check for matching y axes.\"\"\" if sig . data_range is not None : sig_min = sig . data_range [ 0 ] sig_max = sig . data_range [ 1 ] fixed_range = True else : sig_min = sig . min sig_max = sig . max fixed_range = False if yaxis is not None : if yaxis in self . yaxes : try : if \"U\" in self . yaxes [ yaxis ][ \"dtype\" ]: # its a string type so no scaling info self . yaxes [ yaxis ][ \"color\" ] = self . WHITE # change to grey for multi return yaxis yrange = self . yaxes [ yaxis ][ \"max\" ] - self . yaxes [ yaxis ][ \"min\" ] sigrange = sig_max - sig_min if yrange == 0 : yrange = self . yaxes [ yaxis ][ \"min\" ] self . yaxes [ yaxis ][ \"color\" ] = self . WHITE # change to grey for multi # Should we update the max and min here? could let it expand to inf... # Maybe an average? if fixed_range : self . yaxes [ yaxis ][ \"fixed_range\" ] = fixed_range self . yaxes [ yaxis ][ \"min\" ] = ( self . yaxes [ yaxis ][ \"min\" ] + sig_min ) / 2 self . yaxes [ yaxis ][ \"max\" ] = ( self . yaxes [ yaxis ][ \"max\" ] + sig_max ) / 2 return yaxis except TypeError : # For the case of dtype=obj and not compat pass else : self . nyaxes += 1 self . yaxes [ yaxis ] = { \"unit\" : sig . unit , \"min\" : sig_min , \"max\" : sig_max , \"dtype\" : self . compat_types [ np . where ([ sig . data . dtype . kind in t for t in self . compat_types ])[ 0 ][ 0 ] # r-worded way to get the index of the match ], \"color\" : ccg . util . max_contrast ( self . THEME2 , ccg . util . shift_lightness ( self . TRACES [( self . ntrace + 1 ) % self . n_colors ], 1.4 ), ccg . util . shift_lightness ( self . TRACES [( self . ntrace + 1 ) % self . n_colors ], 0.4 ), ), \"fixed_range\" : fixed_range , } return yaxis else : if self . nyaxes > 0 : for yaxis , yaxis_def in self . yaxes . items (): if ( sig . data . dtype . kind in yaxis_def [ \"dtype\" ] and yaxis_def [ \"unit\" ] == sig . unit ): try : if \"U\" in yaxis_def [ \"dtype\" ]: # its a string type so no scaling info yaxis_def [ \"color\" ] = ( self . WHITE ) # change to grey for multi return yaxis yrange = yaxis_def [ \"max\" ] - yaxis_def [ \"min\" ] sigrange = sig_max - sig_min if yrange == 0 : yrange = yaxis_def [ \"min\" ] if ( sig_min > yaxis_def [ \"min\" ] - ( yrange * self . frange / 2 ) and sig_max < yaxis_def [ \"max\" ] + ( yrange * self . frange / 2 ) and sigrange < yrange * self . frange and sigrange > yrange / self . frange ): yaxis_def [ \"color\" ] = ( self . WHITE ) # change to grey for multi # Should we update the max and min here? could let it expand to inf... # Maybe an average? if fixed_range : yaxis_def [ \"fixed_range\" ] = fixed_range yaxis_def [ \"min\" ] = ( yaxis_def [ \"min\" ] + sig_min ) / 2 yaxis_def [ \"max\" ] = ( yaxis_def [ \"max\" ] + sig_max ) / 2 return yaxis except TypeError : # For the case of dtype=obj and not compat pass self . nyaxes += 1 yaxis = f \"y { self . nyaxes } \" self . yaxes [ yaxis ] = { \"unit\" : sig . unit , \"min\" : sig_min , \"max\" : sig_max , \"dtype\" : self . compat_types [ np . where ([ sig . data . dtype . kind in t for t in self . compat_types ])[ 0 ][ 0 ] # r-worded way to get the index of the match ], \"color\" : ccg . util . max_contrast ( self . THEME2 , ccg . util . shift_lightness ( self . TRACES [( self . ntrace + 1 ) % self . n_colors ], 1.4 ), ccg . util . shift_lightness ( self . TRACES [( self . ntrace + 1 ) % self . n_colors ], 0.4 ), ), \"fixed_range\" : fixed_range , } return yaxis def build_yaxes ( self ): \"\"\"Build yaxes element for layout.\"\"\" # tic = datetime.now() yaxes : dict [ str , dict ] = {} domain_min = 1 domain_min_name = \"y1\" # TODO: Handle domains better... for i , ( y_name , yaxis ) in enumerate ( self . yaxes . items ()): yaxis_tmp = copy . deepcopy ( yaxis ) # Since we will remove stuff from this later... name = y_name . replace ( \"y\" , \"yaxis\" ) if ( i % 2 ) == 0 : side = \"left\" pos = round ( i / 2 + 0.001 ) * self . fpos else : side = \"right\" pos = 1 - round ( i / 2 - 0.001 + 1 ) * self . fpos unit = yaxis_tmp . pop ( \"unit\" ) # Pop since its not a standard. _ = yaxis_tmp . pop ( \"dtype\" ) # not needed here data_range = [ yaxis_tmp . pop ( \"min\" ), yaxis_tmp . pop ( \"max\" )] if not yaxis_tmp . pop ( \"fixed_range\" ): data_range = False # Not sure im ready to use this yet. title = \"\" if unit is None else f \"[ { unit } ]\" ccg . util . merge_dict ( yaxes , { name : { \"title\" : { \"text\" : title }, \"overlaying\" : \"y1\" , \"anchor\" : \"x1\" , \"position\" : pos , \"color\" : yaxis_tmp [ \"color\" ], \"gridcolor\" : yaxis_tmp [ \"color\" ], \"showgrid\" : True , \"showline\" : True , \"mirror\" : True , \"side\" : side , \"spikesnap\" : \"hovered data\" , \"spikemode\" : \"across+marker\" , \"spikedash\" : \"solid\" , \"spikethickness\" : 1 , \"ticks\" : \"outside\" , \"ticklen\" : 3 , \"zerolinecolor\" : yaxis_tmp [ \"color\" ], \"zerolinewidth\" : 2 , } }, ) ccg . util . merge_dict ( yaxes [ name ], yaxis_tmp ) if data_range : ccg . util . merge_dict ( yaxes [ name ], { \"range\" : data_range , }, ) if i > 0 : del yaxes [ f \"yaxis { i } \" ][ \"anchor\" ] # to allow spacing multiple if \"domain\" in yaxis_tmp : if yaxis_tmp [ \"domain\" ][ 0 ] < domain_min : domain_min = yaxis_tmp [ \"domain\" ][ 0 ] domain_min_name = y_name if not yaxes : return del yaxes [ \"yaxis1\" ][ \"overlaying\" ] # to allow hover to work try : # TODO: Improve this for more domains del yaxes [ domain_min_name . replace ( \"y\" , \"yaxis\" )][ \"overlaying\" ] except KeyError : pass ccg . util . merge_dict ( self . plt_layout , yaxes ) self . plt_layout [ \"xaxis1\" ][ \"domain\" ] = [ ( round (( self . nyaxes ) / 2 + 0.001 ) - 1 ) * self . fpos , 1 - round ( self . nyaxes / 2 - 0.001 ) * self . fpos , ] # +0.001 since python is r-worded self . plt_layout [ \"xaxis1\" ][ \"anchor\" ] = domain_min_name # toc = datetime.now() - tic # _LOGGER.debug( # \"build %s yaxes in %.3f\", # self.plt_layout[\"title\"][\"text\"], # toc.total_seconds(), # ) def append_trace_from_sig ( self , sig : Sig , yaxis : str = None , color : int = None ): \"\"\"Build trace from sig and append to traces.\"\"\" try : trace = self . build_trace_from_sig ( sig , yaxis = yaxis , color = color ) self . append_trace ( trace ) except NotImplementedError as err : _LOGGER . warning ( \" %s . Skipped %s .\" , err , sig . name ) def append_trace_from_tbl ( self , tbl : Tbl ): \"\"\"build trace from table and append\"\"\" try : trace = self . build_traces_from_tbl ( tbl ) self . append_trace ( trace ) except ( NotImplementedError , KeyError ) as err : _LOGGER . warning ( \" %s . Skipped %s .\" , err , tbl . name ) def append_trace_from_scatter ( self , scatter : ScatterData ): \"\"\"build trace from Scatter and append\"\"\" try : trace = self . build_traces_from_scatter ( scatter ) self . append_trace ( trace ) except ( NotImplementedError , KeyError ) as err : _LOGGER . warning ( \" %s . Skipped %s .\" , err , scatter . name ) def append_trace ( self , trace : dict | list [ dict ]): \"Append trace to traces.\" if isinstance ( trace , list ): self . traces . extend ( trace ) else : self . traces . append ( trace ) self . ntrace += 1 # profile def to_html ( self ) -> str : \"\"\"Generate the HTML string for plot.\"\"\" tic = datetime . now () self . build_yaxes () fig = go . Figure ( data = self . traces , layout = self . plt_layout ) html_str : str = pio . to_html ( fig = fig , validate = True , config = self . config , ) html_str = html_str . replace ( json . dumps ( self . _copy_button [ \"click\" ]), self . _copyfunc ) toc = datetime . now () - tic _LOGGER . debug ( \"Generated plot HTML in %.3f [s]\" , toc . total_seconds ()) return html_str def to_file ( self , filename : Path | str = None ) -> Path : if filename is None : if \"name\" in self . traces [ 0 ] . keys (): filename = Path ( f ' { self . traces [ 0 ][ \"name\" ] } .html' ) else : filename = Path ( \"plt.html\" ) with open ( filename , \"w\" , encoding = \"utf-8\" ) as f : f . write ( self . to_html ()) return filename def to_fig ( self ) -> tuple [ go . Figure , dict ]: \"\"\"Return the plotly figure and config dict.\"\"\" self . build_yaxes () fig = go . Figure ( data = self . traces , layout = self . plt_layout ) return fig , self . config def to_dict ( self ) -> dict : \"\"\"Return dictionary of plot\"\"\" self . build_yaxes () return { \"data\" : self . traces , \"layout\" : self . plt_layout } def plot ( self ): \"\"\"Plot.\"\"\" # fig = go.Figure(data=self.traces, layout=self.plt_layout) # fig.show() html_str = self . to_html () pbr . open_html_in_browser ( html_str ) def save ( self , filename : str , open_after : bool = False ): \"\"\"Save HTML.\"\"\" html_str = self . to_html () path = Path ( filename ) path . write_text ( html_str , encoding = \"utf-8\" ) if open_after : url = path . absolute () . as_uri () webbrowser . open ( url ) def to_image ( self , img_format : str = \"svg\" , width : int = None , height : int = None , as_b64 : bool = False , ) -> bytes : \"\"\"Return image bytes.\"\"\" self . build_yaxes () fig = go . Figure ( data = self . traces , layout = self . plt_layout ) res = pio . to_image ( fig = fig , format = img_format , width = width , height = height ) if as_b64 : res = b64encode ( res ) return res def export2pdf ( self , filename : str | Path , width : int = None , height : int = None ): \"\"\"Export plot to PDF.\"\"\" self . build_yaxes () fig = go . Figure ( data = self . traces , layout = self . plt_layout ) pio . write_image ( fig = fig , file = filename , format = \"pdf\" , width = width , height = height ) append_trace ( trace ) Append trace to traces. Source code in ccg\\ui\\plot.py 1320 1321 1322 1323 1324 1325 1326 def append_trace ( self , trace : dict | list [ dict ]): \"Append trace to traces.\" if isinstance ( trace , list ): self . traces . extend ( trace ) else : self . traces . append ( trace ) self . ntrace += 1 append_trace_from_scatter ( scatter ) build trace from Scatter and append Source code in ccg\\ui\\plot.py 1312 1313 1314 1315 1316 1317 1318 def append_trace_from_scatter ( self , scatter : ScatterData ): \"\"\"build trace from Scatter and append\"\"\" try : trace = self . build_traces_from_scatter ( scatter ) self . append_trace ( trace ) except ( NotImplementedError , KeyError ) as err : _LOGGER . warning ( \" %s . Skipped %s .\" , err , scatter . name ) append_trace_from_sig ( sig , yaxis = None , color = None ) Build trace from sig and append to traces. Source code in ccg\\ui\\plot.py 1296 1297 1298 1299 1300 1301 1302 def append_trace_from_sig ( self , sig : Sig , yaxis : str = None , color : int = None ): \"\"\"Build trace from sig and append to traces.\"\"\" try : trace = self . build_trace_from_sig ( sig , yaxis = yaxis , color = color ) self . append_trace ( trace ) except NotImplementedError as err : _LOGGER . warning ( \" %s . Skipped %s .\" , err , sig . name ) append_trace_from_tbl ( tbl ) build trace from table and append Source code in ccg\\ui\\plot.py 1304 1305 1306 1307 1308 1309 1310 def append_trace_from_tbl ( self , tbl : Tbl ): \"\"\"build trace from table and append\"\"\" try : trace = self . build_traces_from_tbl ( tbl ) self . append_trace ( trace ) except ( NotImplementedError , KeyError ) as err : _LOGGER . warning ( \" %s . Skipped %s .\" , err , tbl . name ) build_0d_traces ( param , color , ntrace , unit ) Build traces for 0d param Source code in ccg\\ui\\plot.py 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 def build_0d_traces ( self , param : Tbl , color : int , ntrace : int , unit : str ): \"\"\"Build traces for 0d param\"\"\" traces = [] yaxis = f \"y { self . nyaxes + 1 } \" hov_temp = ( f \"\"\" { param . name } : % {{ y:. { param . precision } f }} [ { unit } ]<extra></extra>\"\"\" ) try : tmp_trc = { \"type\" : \"scattergl\" , \"y\" : param . orig . data , \"name\" : param . orig . name , \"mode\" : \"markers\" , \"yaxis\" : yaxis , \"opacity\" : 1 , \"hovertemplate\" : hov_temp , \"marker\" : { \"size\" : 8 , \"color\" : self . TRACES [ ntrace % self . n_colors ], \"line\" : { \"color\" : ccg . util . max_contrast ( self . _plt_layout [ \"plot_bgcolor\" ], ccg . util . shift_lightness ( self . TRACES [ ntrace % self . n_colors ], 1.4 ), ccg . util . shift_lightness ( self . TRACES [ ntrace % self . n_colors ], 0.4 ), ), \"width\" : 1 , }, }, \"hoverlabel\" : { \"bgcolor\" : self . TRACES [ ntrace % self . n_colors ]}, \"showlegend\" : True , \"legendgroup\" : f \" { param . orig . name } _ { ntrace } \" , } traces . append ( tmp_trc ) ntrace += 1 except KeyError : pass if color is None : color = ntrace tmp_trc = { \"type\" : \"scattergl\" , \"y\" : param . data , \"name\" : param . name , \"mode\" : \"markers\" , \"hovertemplate\" : hov_temp , \"opacity\" : 1 , \"marker\" : { \"size\" : 8 , \"color\" : self . TRACES [ color % self . n_colors ], \"line\" : { \"color\" : ccg . util . max_contrast ( self . _plt_layout [ \"plot_bgcolor\" ], ccg . util . shift_lightness ( self . TRACES [ color % self . n_colors ], 1.4 ), ccg . util . shift_lightness ( self . TRACES [ color % self . n_colors ], 0.4 ), ), \"width\" : 1 , }, }, \"hoverlabel\" : { \"bgcolor\" : self . TRACES [ color % self . n_colors ]}, \"showlegend\" : True , \"legendgroup\" : f \" { param . name } _ { ntrace } \" , } traces . append ( tmp_trc ) ntrace += 1 nscatter = 0 for scatter in param . scatter_data : if scatter is not None : # plot the scatter data as well. nscatter += 1 tmp_trc = self . build_scatter_trace ( scatter = scatter , param = param , ntrace = ntrace , nscatter = nscatter ) traces . append ( tmp_trc ) ntrace += 1 self . yaxes [ yaxis ] = { \"unit\" : param . unit , \"min\" : param . data_range [ 0 ], \"max\" : param . data_range [ 1 ], \"dtype\" : self . compat_types [ np . where ([ param . data . dtype . kind in t for t in self . compat_types ])[ 0 ][ 0 ] # r-worded way to get the index of the match ], \"color\" : self . WHITE , \"fixed_range\" : False , } return traces build_1d_traces ( param , color , ntrace , unit ) Build traces for 1d param Source code in ccg\\ui\\plot.py 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 def build_1d_traces ( self , param : Tbl , color : int , ntrace : int , unit : str ): \"\"\"Build traces for 1d param\"\"\" traces = [] yaxis = f \"y { self . nyaxes + 1 } \" hov_temp = f \"\"\" { param . name } : % {{ y:. { param . precision } f }} [ { unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } f }} [ { param . axes [ 0 ] . unit } ]<extra></extra>\"\"\" try : tmp_trc = { \"type\" : \"scattergl\" , \"y\" : param . orig . data , \"x\" : param . orig . axes [ 0 ] . data , \"name\" : param . orig . name , \"mode\" : \"markers+lines\" , \"yaxis\" : yaxis , \"opacity\" : 1 , \"hovertemplate\" : hov_temp , \"marker\" : { \"size\" : np . array ([ 10 ] * param . orig . data . size ), \"color\" : self . TRACES [ ntrace % self . n_colors ], \"line\" : { \"color\" : ccg . util . max_contrast ( self . _plt_layout [ \"plot_bgcolor\" ], ccg . util . shift_lightness ( self . TRACES [ ntrace % self . n_colors ], 1.4 ), ccg . util . shift_lightness ( self . TRACES [ ntrace % self . n_colors ], 0.4 ), ), \"width\" : 1 , }, }, \"line\" : { \"width\" : 1 , \"shape\" : self . LINESHAPE [ param . orig . axes [ 0 ] . interp_method ], \"color\" : self . TRACES [ ntrace % self . n_colors ], }, \"hoverlabel\" : { \"bgcolor\" : self . TRACES [ ntrace % self . n_colors ]}, \"showlegend\" : True , \"legendgroup\" : f \" { param . orig . name } _ { ntrace } \" , } traces . append ( tmp_trc ) ntrace += 1 except KeyError : pass if color is None : color = ntrace tmp_trc = { \"type\" : \"scattergl\" , \"y\" : param . data , \"x\" : param . axes [ 0 ] . data , \"name\" : param . name , \"mode\" : \"markers+lines\" , \"hovertemplate\" : hov_temp , \"opacity\" : 1 , \"marker\" : { \"size\" : np . array ([ 10 ] * param . data . size ), \"color\" : self . TRACES [ color % self . n_colors ], \"line\" : { \"color\" : ccg . util . max_contrast ( self . _plt_layout [ \"plot_bgcolor\" ], ccg . util . shift_lightness ( self . TRACES [ color % self . n_colors ], 1.4 ), ccg . util . shift_lightness ( self . TRACES [ color % self . n_colors ], 0.4 ), ), \"width\" : 1 , }, }, \"line\" : { \"width\" : 1 , \"shape\" : self . LINESHAPE [ param . axes [ 0 ] . interp_method ], \"color\" : self . TRACES [ color % self . n_colors ], }, \"hoverlabel\" : { \"bgcolor\" : self . TRACES [ color % self . n_colors ]}, \"showlegend\" : True , \"legendgroup\" : f \" { param . name } _ { ntrace } \" , } traces . append ( tmp_trc ) ntrace += 1 nscatter = 0 for scatter in param . scatter_data : if scatter is not None : # plot the scatter data as well. nscatter += 1 tmp_trc = self . build_scatter_trace ( scatter = scatter , param = param , ntrace = ntrace , nscatter = nscatter ) traces . append ( tmp_trc ) ntrace += 1 self . yaxes [ yaxis ] = { \"unit\" : param . unit , \"min\" : param . data_range [ 0 ], \"max\" : param . data_range [ 1 ], \"dtype\" : self . compat_types [ np . where ([ param . data . dtype . kind in t for t in self . compat_types ])[ 0 ][ 0 ] # r-worded way to get the index of the match ], \"color\" : self . WHITE , \"fixed_range\" : False , } return traces build_2d_traces ( param , color , ntrace , unit ) build traces from 2d param Source code in ccg\\ui\\plot.py 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 def build_2d_traces ( self , param : Tbl , color : int , ntrace : int , unit : str ): \"\"\"build traces from 2d param\"\"\" traces = [] try : traces . extend ( self . build_surf_traces ( param . orig , ntrace - 1 , ntrace , unit , visible = True ) ) ntrace += 1 except KeyError : pass if color is None : color = ntrace - 1 traces . extend ( self . build_surf_traces ( param , color , ntrace , unit )) ntrace += 1 nscatter = 0 for scatter in param . scatter_data : if scatter is not None : # plot the scatter data as well. nscatter += 1 tmp_trc = self . build_scatter_trace ( scatter = scatter , param = param , ntrace = ntrace , nscatter = nscatter ) traces . append ( tmp_trc ) ntrace += 1 xaxis = copy . deepcopy ( self . _scene_axis ) xaxis . update ( { \"title\" : { \"text\" : f \" { param . axes [ 0 ] . name } [ { param . axes [ 0 ] . unit } ]\" }} ) yaxis = copy . deepcopy ( self . _scene_axis ) yaxis . update ( { \"title\" : { \"text\" : f \" { param . axes [ 1 ] . name } [ { param . axes [ 1 ] . unit } ]\" }} ) zaxis = copy . deepcopy ( self . _scene_axis ) zaxis . update ({ \"title\" : { \"text\" : f \" { param . name } [ { param . unit } ]\" }}) scene = { \"scene\" : { \"xaxis\" : xaxis , \"yaxis\" : yaxis , \"zaxis\" : zaxis , \"camera\" : { \"eye\" : { \"x\" : - 1.25 , \"y\" : - 1.25 , \"z\" : 1.1 }}, } } ccg . util . merge_dict ( self . plt_layout , scene ) return traces build_scatter_trace ( scatter , param = None , ntrace = 1 , nscatter = 1 ) Builds a scatter trace. ntrace and nscatter are counters for color increments Source code in ccg\\ui\\plot.py 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 def build_scatter_trace ( self , scatter : ScatterData , param : Tbl = None , ntrace : int = 1 , nscatter : int = 1 , ): \"\"\"Builds a scatter trace. ntrace and nscatter are counters for color increments\"\"\" ndim = scatter . ndim tmp_trc = { \"name\" : scatter . name , \"mode\" : \"markers\" , \"opacity\" : 1 , \"marker\" : { \"size\" : 3 , \"color\" : self . TRACES [ ntrace % self . n_colors ], \"colorscale\" : [ [ 0 , self . TRACES [ ntrace % self . n_colors ]], [ 1 , self . TRACES [ ntrace % self . n_colors ]], ], \"showscale\" : False , }, \"hoverlabel\" : { \"bgcolor\" : self . TRACES [ ntrace % self . n_colors ]}, \"showlegend\" : True , \"legendgroup\" : f \" { scatter . name } _ { ntrace } \" , } if scatter . color is not None : tmp = { \"marker\" : { \"color\" : scatter . color , \"colorscale\" : self . TURBO , \"colorbar\" : { \"bgcolor\" : self . THEME3 , \"bordercolor\" : self . THEME4 , \"borderwidth\" : 1 , \"title\" : { \"text\" : f \" { scatter . color_label } [ { scatter . color_unit } ]\" , \"side\" : \"right\" , }, \"x\" : 0 , }, \"showscale\" : True , }, \"text\" : np . round ( scatter . color , scatter . color_precision ), } if scatter . color_range is not None : ccg . util . merge_dict ( tmp , { \"marker\" : { \"cmin\" : scatter . color_range [ 0 ], \"cmax\" : scatter . color_range [ 1 ], } }, ) # Need to move legend to clear color bar. tmp_lgnd = { \"legend\" : { \"xanchor\" : \"right\" , \"yanchor\" : \"top\" , \"x\" : 1 , \"y\" : 1 , }, } ccg . util . merge_dict ( self . plt_layout , tmp_lgnd ) ccg . util . merge_dict ( tmp_trc , tmp ) if ndim == 2 : if param is not None : if scatter . color is not None : hov_temp = f \"\"\" { scatter . name } : % {{ z:. { param . precision } f }} [ { param . unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } f }} [ { param . axes [ 0 ] . unit } ]<br> { param . axes [ 1 ] . name } : % {{ y:. { param . axes [ 1 ] . precision } f }} [ { param . axes [ 1 ] . unit } ]<br> { scatter . color_label } : % {{ marker.color:. { scatter . color_precision } f }} [ { scatter . color_unit } ] <extra></extra>\"\"\" else : hov_temp = f \"\"\" { scatter . name } : % {{ z:. { param . precision } d }} [ { param . unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } d }} [ { param . axes [ 0 ] . unit } ]<br> { param . axes [ 1 ] . name } : % {{ y:. { param . axes [ 1 ] . precision } d }} [ { param . axes [ 1 ] . unit } ] <extra></extra>\"\"\" else : if scatter . color is not None : hov_temp = \"\" tmp = { \"type\" : \"scatter3d\" , \"x\" : scatter . data [ 0 ], \"y\" : scatter . data [ 1 ], \"z\" : scatter . data [ 2 ], \"hovertemplate\" : hov_temp , } elif ndim == 1 : if param is not None : if scatter . color is not None : hov_temp = f \"\"\" { scatter . name } : % {{ y:. { param . precision } f }} [ { param . unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } f }} [ { param . axes [ 0 ] . unit } ]<br> { scatter . color_label } : % {{ marker.color:. { scatter . color_precision } f }} [ { scatter . color_unit } ] <extra></extra>\"\"\" else : hov_temp = f \"\"\" { scatter . name } : % {{ y:. { param . precision } d }} [ { param . unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } d }} [ { param . axes [ 0 ] . unit } ]<br> <extra></extra>\"\"\" else : hov_temp = \"\" tmp = { \"type\" : \"scattergl\" , \"x\" : scatter . data [ 0 ], \"y\" : scatter . data [ 1 ], \"hovertemplate\" : hov_temp , } elif ndim == 0 : if param is not None : if scatter . color is not None : hov_temp = f \"\"\" { scatter . name } : % {{ y:. { param . precision } f }} [ { param . unit } ]<br> { scatter . color_label } : % {{ marker.color:. { scatter . color_precision } f }} [ { scatter . color_unit } ] <extra></extra>\"\"\" else : hov_temp = f \"\"\" { scatter . name } : % {{ y:. { param . precision } d }} [ { param . unit } ]<br> <extra></extra>\"\"\" else : hov_temp = \"\" tmp = { \"type\" : \"scattergl\" , \"x\" : scatter . data [ 0 ] * 0 , \"y\" : scatter . data [ 1 ], \"hovertemplate\" : hov_temp , } else : raise NotImplementedError ccg . util . merge_dict ( tmp_trc , tmp ) if nscatter > 1 : ccg . util . merge_dict ( tmp_trc , { \"visible\" : \"legendonly\" }) return tmp_trc build_surf_traces ( param , color , ntrace , unit , visible = True ) Build 2d surface trace Source code in ccg\\ui\\plot.py 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 def build_surf_traces ( self , param : Tbl , color : int , ntrace : int , unit : str , visible : bool = True , ): \"\"\"Build 2d surface trace\"\"\" if not visible : visible = \"legendonly\" hov_temp = f \"\"\" { param . name } : % {{ z:. { param . precision } f }} [ { param . unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } f }} [ { param . axes [ 0 ] . unit } ]<br> { param . axes [ 1 ] . name } : % {{ y:. { param . axes [ 1 ] . precision } f }} [ { param . axes [ 1 ] . unit } ] <extra></extra>\"\"\" x , y = np . meshgrid ( param . axes [ 0 ] . data , param . axes [ 1 ] . data ) x = np . concatenate (( x , x [ - 1 , np . newaxis ])) y = np . concatenate (( y , y [ - 1 , np . newaxis ])) z = np . concatenate (( param . data . T , param . data . T [ - 1 , np . newaxis ] * np . NaN )) i = x . flatten ( \"F\" ) j = y . flatten ( \"F\" ) k = z . flatten ( \"F\" ) y , x = np . meshgrid ( param . axes [ 1 ] . data , param . axes [ 0 ] . data ) x = np . concatenate (( x , x [ - 1 , np . newaxis ])) y = np . concatenate (( y , y [ - 1 , np . newaxis ])) z = np . concatenate (( param . data , param . data [ - 1 , np . newaxis ] * np . NaN )) i = np . concatenate (( i , x . flatten ( \"F\" ))) j = np . concatenate (( j , y . flatten ( \"F\" ))) k = np . concatenate (( k , z . flatten ( \"F\" ))) traces = [ { \"type\" : \"surface\" , \"x\" : param . axes [ 0 ] . data , \"y\" : param . axes [ 1 ] . data , \"z\" : param . data . T , \"name\" : f \" { param . name }{ unit } \" , \"hovertemplate\" : hov_temp , \"hoverlabel\" : { \"bgcolor\" : self . TRACES [ color % self . n_colors ]}, \"opacity\" : 0.5 , \"colorscale\" : [ [ 0 , self . TRACES [ color % self . n_colors ]], [ 1 , self . TRACES [ color % self . n_colors ]], ], \"showlegend\" : True , \"legendgroup\" : f \" { param . name } _ { ntrace } \" , \"showscale\" : False , \"visible\" : visible , }, { \"type\" : \"scatter3d\" , \"x\" : i , \"y\" : j , \"z\" : k , \"name\" : f \" { param . name }{ unit } \" , \"hoverinfo\" : \"skip\" , \"opacity\" : 1 , \"marker\" : { \"color\" : np . array ([ self . TRACES [ color % self . n_colors ]] * len ( i )), \"size\" : np . array ([ 10 ] * len ( i )), # \"line\": { # \"color\": ccg.util.max_contrast( # self.TRACES[color % self.n_colors], # ccg.util.shift_lightness( # self.TRACES[color % self.n_colors], 1.4 # ), # ccg.util.shift_lightness( # self.TRACES[color % self.n_colors], 0.4 # ), # ), # \"width\": 1, # }, }, \"line\" : { \"color\" : ccg . util . max_contrast ( self . TRACES [ color % self . n_colors ], ccg . util . shift_lightness ( self . TRACES [ color % self . n_colors ], 1.4 ), ccg . util . shift_lightness ( self . TRACES [ color % self . n_colors ], 0.4 ), ), \"width\" : 2 , }, \"showlegend\" : False , \"legendgroup\" : f \" { param . name } _ { ntrace } \" , \"connectgaps\" : False , \"visible\" : visible , }, ] return traces build_trace ( x , y , signame = None , sigunit = None , connect_gaps = None , yaxis = None , color = None ) Build Trace for plotly. Source code in ccg\\ui\\plot.py 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 def build_trace ( self , x : npt . NDArray , y : npt . NDArray , signame : str = None , sigunit : str = None , connect_gaps : bool = None , yaxis : str = None , color : int = None , ): \"\"\"Build Trace for plotly.\"\"\" ntrace = self . ntrace + 1 if color is None : color = ntrace yaxis = self . find_yaxis ( Sig ( data = y , tline = TLine ( x ), name = signame , unit = sigunit ), yaxis = yaxis ) # TODO: Implement find_yaxis for non sigs sigunit = \"\" if sigunit is None else sigunit trace = { \"type\" : \"scattergl\" , \"y\" : y , \"x\" : x , \"name\" : f \" { signame } [ { sigunit } ]\" , \"mode\" : \"markers+lines\" , \"hovertemplate\" : \"\"\"Value: % {y:.2f} % {yaxis.title.text} <br> X: % {x:.2f} % {xaxis.title.text} \"\"\" , \"yaxis\" : yaxis , \"opacity\" : 1 , \"connectgaps\" : bool ( connect_gaps ), \"marker\" : { \"size\" : [ 2 ] * len ( y ), \"line\" : { \"color\" : ccg . util . max_contrast ( self . _plt_layout [ \"plot_bgcolor\" ], ccg . util . shift_lightness ( self . TRACES [ color % self . n_colors ], 1.4 ), ccg . util . shift_lightness ( self . TRACES [ color % self . n_colors ], 0.4 ), ), \"width\" : 1 , }, }, \"line\" : { \"width\" : 1 , \"color\" : self . TRACES [ color % self . n_colors ], }, } return trace build_trace_from_sig ( sig , color = None , yaxis = None ) Build Trace for plotly from a Sig. Source code in ccg\\ui\\plot.py 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 def build_trace_from_sig ( self , sig : Sig , color : int = None , yaxis : str = None ): \"\"\"Build Trace for plotly from a Sig.\"\"\" ntrace = self . ntrace + 1 if color is None : color = ntrace if self . plot_prep : sig = sig . plot_prep () yaxis = self . find_yaxis ( sig , yaxis ) unit = \"\" if sig . unit is None else sig . unit if sig . tline [ 0 ] < 32000000 : # apprx 1yr from epoch # assume this is an elapsed time instead x = sig . tline . unix hov_temp = \"\"\" Value: % {y:.2f} % {yaxis.title.text} <br> Time: % {x:.3f} [s]\"\"\" self . update_axis ( axis = \"xaxis1\" , title = \"Elapsed Time\" , unit = \"S\" ) else : x = sig . tline . iso hov_temp = \"\"\" Value: % {y:.2f} % {yaxis.title.text} <br> Time: %{x|%H:%M:%S.%L}\"\"\" self . update_axis ( axis = \"xaxis1\" , title = \"Date and Time\" ) if sig . nsamples > 100000 : hov = \"skip\" # Disable hover since its too slow hov_temp = \"\" else : hov = \"all\" trace = { \"type\" : \"scattergl\" , \"y\" : sig . data , \"x\" : x , \"name\" : f \" { sig . name } [ { unit } ]\" , \"mode\" : \"markers+lines\" , \"hovertemplate\" : hov_temp , \"hoverinfo\" : hov , \"yaxis\" : yaxis , \"opacity\" : 1 , \"connectgaps\" : bool ( sig . connect_gaps ), # should work if connect_gaps is None \"marker\" : { # \"color\": TRACES[self.ntrace], \"size\" : [ 2 ] * len ( x ), \"line\" : { \"color\" : ccg . util . max_contrast ( self . _plt_layout [ \"plot_bgcolor\" ], ccg . util . shift_lightness ( self . TRACES [ color % self . n_colors ], 1.4 ), ccg . util . shift_lightness ( self . TRACES [ color % self . n_colors ], 0.4 ), ), \"width\" : 1 , }, }, \"line\" : { \"width\" : 1 , \"shape\" : self . LINESHAPE [ sig . interp_method ], \"color\" : self . TRACES [ color % self . n_colors ], }, } if sig . base_data is not None : ccg . util . merge_dict ( trace , { \"text\" : sig . base_data , \"hovertemplate\" : \"\"\"Value: % {text} <br> Time: %{x|%H:%M:%S.%L}\"\"\" , }, ) return trace build_traces_from_scatter ( scatter ) Builds scatter data traces Source code in ccg\\ui\\plot.py 579 580 581 582 583 def build_traces_from_scatter ( self , scatter : ScatterData ): \"\"\"Builds scatter data traces\"\"\" # TODO: Implement support for more than 1 scatter if scatter is not None : return [ self . build_scatter_trace ( scatter = scatter )] build_traces_from_tbl ( tbl , color = None ) build trace from table. Source code in ccg\\ui\\plot.py 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 def build_traces_from_tbl ( self , tbl : Tbl , color : int = None ) -> list [ dict ]: \"\"\"build trace from table.\"\"\" ntrace = 1 # self.ntrace+1 Does it make sense to deal with multiple tbls in 1 plot? if tbl . unit is not None : unit = f \" [ { tbl . unit } ]\" else : unit = \"\" if tbl . n_dim == 2 : traces = self . build_2d_traces ( tbl , color , ntrace , unit ) elif tbl . n_dim == 1 : traces = self . build_1d_traces ( tbl , color , ntrace , unit ) elif tbl . n_dim == 0 : traces = self . build_0d_traces ( tbl , color , ntrace , unit ) else : raise NotImplementedError ( f \"Plot not implemented for n_dim = { tbl . n_dim } \" ) return traces build_yaxes () Build yaxes element for layout. Source code in ccg\\ui\\plot.py 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 def build_yaxes ( self ): \"\"\"Build yaxes element for layout.\"\"\" # tic = datetime.now() yaxes : dict [ str , dict ] = {} domain_min = 1 domain_min_name = \"y1\" # TODO: Handle domains better... for i , ( y_name , yaxis ) in enumerate ( self . yaxes . items ()): yaxis_tmp = copy . deepcopy ( yaxis ) # Since we will remove stuff from this later... name = y_name . replace ( \"y\" , \"yaxis\" ) if ( i % 2 ) == 0 : side = \"left\" pos = round ( i / 2 + 0.001 ) * self . fpos else : side = \"right\" pos = 1 - round ( i / 2 - 0.001 + 1 ) * self . fpos unit = yaxis_tmp . pop ( \"unit\" ) # Pop since its not a standard. _ = yaxis_tmp . pop ( \"dtype\" ) # not needed here data_range = [ yaxis_tmp . pop ( \"min\" ), yaxis_tmp . pop ( \"max\" )] if not yaxis_tmp . pop ( \"fixed_range\" ): data_range = False # Not sure im ready to use this yet. title = \"\" if unit is None else f \"[ { unit } ]\" ccg . util . merge_dict ( yaxes , { name : { \"title\" : { \"text\" : title }, \"overlaying\" : \"y1\" , \"anchor\" : \"x1\" , \"position\" : pos , \"color\" : yaxis_tmp [ \"color\" ], \"gridcolor\" : yaxis_tmp [ \"color\" ], \"showgrid\" : True , \"showline\" : True , \"mirror\" : True , \"side\" : side , \"spikesnap\" : \"hovered data\" , \"spikemode\" : \"across+marker\" , \"spikedash\" : \"solid\" , \"spikethickness\" : 1 , \"ticks\" : \"outside\" , \"ticklen\" : 3 , \"zerolinecolor\" : yaxis_tmp [ \"color\" ], \"zerolinewidth\" : 2 , } }, ) ccg . util . merge_dict ( yaxes [ name ], yaxis_tmp ) if data_range : ccg . util . merge_dict ( yaxes [ name ], { \"range\" : data_range , }, ) if i > 0 : del yaxes [ f \"yaxis { i } \" ][ \"anchor\" ] # to allow spacing multiple if \"domain\" in yaxis_tmp : if yaxis_tmp [ \"domain\" ][ 0 ] < domain_min : domain_min = yaxis_tmp [ \"domain\" ][ 0 ] domain_min_name = y_name if not yaxes : return del yaxes [ \"yaxis1\" ][ \"overlaying\" ] # to allow hover to work try : # TODO: Improve this for more domains del yaxes [ domain_min_name . replace ( \"y\" , \"yaxis\" )][ \"overlaying\" ] except KeyError : pass ccg . util . merge_dict ( self . plt_layout , yaxes ) self . plt_layout [ \"xaxis1\" ][ \"domain\" ] = [ ( round (( self . nyaxes ) / 2 + 0.001 ) - 1 ) * self . fpos , 1 - round ( self . nyaxes / 2 - 0.001 ) * self . fpos , ] # +0.001 since python is r-worded self . plt_layout [ \"xaxis1\" ][ \"anchor\" ] = domain_min_name export2pdf ( filename , width = None , height = None ) Export plot to PDF. Source code in ccg\\ui\\plot.py 1399 1400 1401 1402 1403 1404 1405 def export2pdf ( self , filename : str | Path , width : int = None , height : int = None ): \"\"\"Export plot to PDF.\"\"\" self . build_yaxes () fig = go . Figure ( data = self . traces , layout = self . plt_layout ) pio . write_image ( fig = fig , file = filename , format = \"pdf\" , width = width , height = height ) find_yaxis ( sig , yaxis = None ) Check for matching y axes. Source code in ccg\\ui\\plot.py 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 def find_yaxis ( self , sig : Sig , yaxis : str = None ): \"\"\"Check for matching y axes.\"\"\" if sig . data_range is not None : sig_min = sig . data_range [ 0 ] sig_max = sig . data_range [ 1 ] fixed_range = True else : sig_min = sig . min sig_max = sig . max fixed_range = False if yaxis is not None : if yaxis in self . yaxes : try : if \"U\" in self . yaxes [ yaxis ][ \"dtype\" ]: # its a string type so no scaling info self . yaxes [ yaxis ][ \"color\" ] = self . WHITE # change to grey for multi return yaxis yrange = self . yaxes [ yaxis ][ \"max\" ] - self . yaxes [ yaxis ][ \"min\" ] sigrange = sig_max - sig_min if yrange == 0 : yrange = self . yaxes [ yaxis ][ \"min\" ] self . yaxes [ yaxis ][ \"color\" ] = self . WHITE # change to grey for multi # Should we update the max and min here? could let it expand to inf... # Maybe an average? if fixed_range : self . yaxes [ yaxis ][ \"fixed_range\" ] = fixed_range self . yaxes [ yaxis ][ \"min\" ] = ( self . yaxes [ yaxis ][ \"min\" ] + sig_min ) / 2 self . yaxes [ yaxis ][ \"max\" ] = ( self . yaxes [ yaxis ][ \"max\" ] + sig_max ) / 2 return yaxis except TypeError : # For the case of dtype=obj and not compat pass else : self . nyaxes += 1 self . yaxes [ yaxis ] = { \"unit\" : sig . unit , \"min\" : sig_min , \"max\" : sig_max , \"dtype\" : self . compat_types [ np . where ([ sig . data . dtype . kind in t for t in self . compat_types ])[ 0 ][ 0 ] # r-worded way to get the index of the match ], \"color\" : ccg . util . max_contrast ( self . THEME2 , ccg . util . shift_lightness ( self . TRACES [( self . ntrace + 1 ) % self . n_colors ], 1.4 ), ccg . util . shift_lightness ( self . TRACES [( self . ntrace + 1 ) % self . n_colors ], 0.4 ), ), \"fixed_range\" : fixed_range , } return yaxis else : if self . nyaxes > 0 : for yaxis , yaxis_def in self . yaxes . items (): if ( sig . data . dtype . kind in yaxis_def [ \"dtype\" ] and yaxis_def [ \"unit\" ] == sig . unit ): try : if \"U\" in yaxis_def [ \"dtype\" ]: # its a string type so no scaling info yaxis_def [ \"color\" ] = ( self . WHITE ) # change to grey for multi return yaxis yrange = yaxis_def [ \"max\" ] - yaxis_def [ \"min\" ] sigrange = sig_max - sig_min if yrange == 0 : yrange = yaxis_def [ \"min\" ] if ( sig_min > yaxis_def [ \"min\" ] - ( yrange * self . frange / 2 ) and sig_max < yaxis_def [ \"max\" ] + ( yrange * self . frange / 2 ) and sigrange < yrange * self . frange and sigrange > yrange / self . frange ): yaxis_def [ \"color\" ] = ( self . WHITE ) # change to grey for multi # Should we update the max and min here? could let it expand to inf... # Maybe an average? if fixed_range : yaxis_def [ \"fixed_range\" ] = fixed_range yaxis_def [ \"min\" ] = ( yaxis_def [ \"min\" ] + sig_min ) / 2 yaxis_def [ \"max\" ] = ( yaxis_def [ \"max\" ] + sig_max ) / 2 return yaxis except TypeError : # For the case of dtype=obj and not compat pass self . nyaxes += 1 yaxis = f \"y { self . nyaxes } \" self . yaxes [ yaxis ] = { \"unit\" : sig . unit , \"min\" : sig_min , \"max\" : sig_max , \"dtype\" : self . compat_types [ np . where ([ sig . data . dtype . kind in t for t in self . compat_types ])[ 0 ][ 0 ] # r-worded way to get the index of the match ], \"color\" : ccg . util . max_contrast ( self . THEME2 , ccg . util . shift_lightness ( self . TRACES [( self . ntrace + 1 ) % self . n_colors ], 1.4 ), ccg . util . shift_lightness ( self . TRACES [( self . ntrace + 1 ) % self . n_colors ], 0.4 ), ), \"fixed_range\" : fixed_range , } return yaxis plot () Plot. Source code in ccg\\ui\\plot.py 1368 1369 1370 1371 1372 1373 def plot ( self ): \"\"\"Plot.\"\"\" # fig = go.Figure(data=self.traces, layout=self.plt_layout) # fig.show() html_str = self . to_html () pbr . open_html_in_browser ( html_str ) save ( filename , open_after = False ) Save HTML. Source code in ccg\\ui\\plot.py 1375 1376 1377 1378 1379 1380 1381 1382 def save ( self , filename : str , open_after : bool = False ): \"\"\"Save HTML.\"\"\" html_str = self . to_html () path = Path ( filename ) path . write_text ( html_str , encoding = \"utf-8\" ) if open_after : url = path . absolute () . as_uri () webbrowser . open ( url ) to_dict () Return dictionary of plot Source code in ccg\\ui\\plot.py 1363 1364 1365 1366 def to_dict ( self ) -> dict : \"\"\"Return dictionary of plot\"\"\" self . build_yaxes () return { \"data\" : self . traces , \"layout\" : self . plt_layout } to_fig () Return the plotly figure and config dict. Source code in ccg\\ui\\plot.py 1357 1358 1359 1360 1361 def to_fig ( self ) -> tuple [ go . Figure , dict ]: \"\"\"Return the plotly figure and config dict.\"\"\" self . build_yaxes () fig = go . Figure ( data = self . traces , layout = self . plt_layout ) return fig , self . config to_html () Generate the HTML string for plot. Source code in ccg\\ui\\plot.py 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 def to_html ( self ) -> str : \"\"\"Generate the HTML string for plot.\"\"\" tic = datetime . now () self . build_yaxes () fig = go . Figure ( data = self . traces , layout = self . plt_layout ) html_str : str = pio . to_html ( fig = fig , validate = True , config = self . config , ) html_str = html_str . replace ( json . dumps ( self . _copy_button [ \"click\" ]), self . _copyfunc ) toc = datetime . now () - tic _LOGGER . debug ( \"Generated plot HTML in %.3f [s]\" , toc . total_seconds ()) return html_str to_image ( img_format = 'svg' , width = None , height = None , as_b64 = False ) Return image bytes. Source code in ccg\\ui\\plot.py 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 def to_image ( self , img_format : str = \"svg\" , width : int = None , height : int = None , as_b64 : bool = False , ) -> bytes : \"\"\"Return image bytes.\"\"\" self . build_yaxes () fig = go . Figure ( data = self . traces , layout = self . plt_layout ) res = pio . to_image ( fig = fig , format = img_format , width = width , height = height ) if as_b64 : res = b64encode ( res ) return res update_axis ( axis = 'xaxis1' , title = None , unit = None , min_range = None , max_range = None ) Update axis info. Source code in ccg\\ui\\plot.py 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 def update_axis ( self , axis : str = \"xaxis1\" , title : str = None , unit : str = None , min_range : float = None , max_range : float = None , ): \"\"\"Update axis info.\"\"\" if title is not None : if unit is not None : ccg . util . merge_dict ( self . plt_layout , { axis : { \"title\" : { \"text\" : f \" { title } [ { unit } ]\" }}} ) else : ccg . util . merge_dict ( self . plt_layout , { axis : { \"title\" : { \"text\" : f \" { title } \" }}} ) ccg . util . merge_dict ( self . plt_layout , { axis : { \"range\" : [ min_range , max_range ]}}) PlotConfig Plot configuration. Source code in ccg\\ui\\plot.py 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 class PlotConfig : \"\"\"Plot configuration.\"\"\" def __init__ ( self , name : str = None , traces : list [ dict ] = None , layout : dict = None , ): self . name = name if not isinstance ( traces , list ): traces = [ traces ] self . traces = traces self . layout = layout def to_dict ( self ): \"\"\"Returns a dictionary\"\"\" res = { \"name\" : self . name , \"traces\" : self . traces , \"layout\" : self . layout , } return res def __repr__ ( self ): \"\"\"repr.\"\"\" return json . dumps ( self . to_dict ()) __repr__ () repr. Source code in ccg\\ui\\plot.py 56 57 58 def __repr__ ( self ): \"\"\"repr.\"\"\" return json . dumps ( self . to_dict ()) to_dict () Returns a dictionary Source code in ccg\\ui\\plot.py 47 48 49 50 51 52 53 54 def to_dict ( self ): \"\"\"Returns a dictionary\"\"\" res = { \"name\" : self . name , \"traces\" : self . traces , \"layout\" : self . layout , } return res PlotConfigColl Collection of plot configurations. Source code in ccg\\ui\\plot.py 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 class PlotConfigColl : \"\"\"Collection of plot configurations.\"\"\" def __init__ ( self , plot_configs : list [ PlotConfig ] = None ): if not isinstance ( plot_configs , list ) and plot_configs is not None : plot_configs = [ plot_configs ] self . plot_configs = plot_configs def append ( self , plot : PlotConfig | list [ PlotConfig ]): \"\"\"append plot to collection.\"\"\" if not isinstance ( plot , list ): plot = [ plot ] if self . plot_configs is None : self . plot_configs = plot else : self . plot_configs . extend ( plot ) def build_plot ( self , frames : Frame | list [ Frame ]): \"\"\"build plot from plot config collection\"\"\" if not isinstance ( frames , list ): frames = [ frames ] plots = [] for plot_config in self . plot_configs : plot = Plot ( name = plot_config . name ) annot_list = [] annots = False n_annot = 0 if \"annotations\" in plot_config . layout : if any ( isinstance ( lyt [ \"x\" ], str ) or isinstance ( lyt [ \"y\" ], str ) for lyt in plot_config . layout [ \"annotations\" ] ): annots = plot_config . layout . pop ( \"annotations\" ) else : annot_list = plot_config . layout [ \"annotations\" ] for ref_trace in plot_config . traces : try : for frame in frames : trace = ref_trace group = { \"legendgroup\" : frame . name , \"legendgrouptitle\" : { \"text\" : frame . name }, } if \"x\" in trace : x = frame [ trace . pop ( \"x\" ) ] . data # pop out to not update later hov_temp = { \"hovertemplate\" : \"\"\"Y: % {y:.2f} % {yaxis.title.text} <br> X: % {x:.3f} % {xaxis.title.text} \"\"\" } else : if ( frame [ trace [ \"y\" ]] . tline [ 0 ] < 32000000 ): # apprx 1yr from epoch # assume this is an elapsed time instead x = frame [ trace [ \"y\" ]] . tline . unix hov_temp = { \"hovertemplate\" : \"\"\"Value: % {y:.2f} % {yaxis.title.text} <br> Time: % {x:.3f} % {xaxis.title.text} \"\"\" } else : x = frame [ trace [ \"y\" ]] . tline . iso hov_temp = { \"hovertemplate\" : \"\"\"Value: % {y:.2f} % {yaxis.title.text} <br> Time: %{x|%H:%M:%S.%L}\"\"\" } yname = trace [ \"y\" ] y = frame [ trace . pop ( \"y\" )] . data # pop out to not update later yaxis = trace [ \"yaxis\" ] if \"yaxis\" in trace else None plt_trace = plot . build_trace ( x = x , y = y , signame = yname , yaxis = yaxis ) ccg . util . merge_dict ( plt_trace , group ) ccg . util . merge_dict ( plt_trace , hov_temp ) ccg . util . merge_dict ( plt_trace , trace ) # Update with other settings in trace. plot . append_trace ( plt_trace ) if annots : # Calculate the annotation for note in annots : # pylint: disable=eval-used new_note = copy . deepcopy ( note ) if isinstance ( note [ \"x\" ], str ): txt = \"\" txt = re . findall ( r \"PARAM(?:\\.|\\[).*\" , note [ \"x\" ]) if txt : new_note [ \"x\" ] = eval ( txt [ 0 ] . replace ( \"PARAM\" , \"frame\" ) ) if isinstance ( note [ \"y\" ], str ): txt = \"\" txt = re . findall ( r \"PARAM(?:\\.|\\[).*\" , note [ \"y\" ]) if txt : new_note [ \"y\" ] = eval ( txt [ 0 ] . replace ( \"PARAM\" , \"frame\" ) ) # check text for fstring txt = \"\" txt = re . findall ( r \"f'.*'\" , note [ \"text\" ]) if txt : new_note [ \"text\" ] = eval ( txt [ 0 ] . replace ( \"PARAM\" , \"frame\" ) ) if \"ay\" in note : new_note [ \"ay\" ] = note [ \"ay\" ] * ( n_annot + 1 ) if \"arrowcolor\" not in note : new_note [ \"arrowcolor\" ] = plot . TRACES [ n_annot % len ( plot . TRACES ) ] if \"bordercolor\" not in note : new_note [ \"bordercolor\" ] = plot . TRACES [ n_annot % len ( plot . TRACES ) ] annot_list . append ( new_note ) n_annot += 1 except KeyError as err : _LOGGER . warning ( \" %s . Skipped %s .\" , err , \"trace\" ) layout = plot . plt_layout . copy () ccg . util . merge_dict ( layout , { \"annotations\" : annot_list }) # Need to extract y-axes from the layout since plot tools build the yaxes at the end tmp_yaxes = {} list_to_remove = [] for key in layout : if key . startswith ( \"yaxis\" ): tmp_yaxes [ key . replace ( \"yaxis\" , \"y\" )] = layout [ key ] list_to_remove . append ( key ) for key in list_to_remove : layout . pop ( key ) ccg . util . merge_dict ( plot . yaxes , tmp_yaxes ) ccg . util . merge_dict ( plot . plt_layout , layout ) plots . append ( plot ) return plots def to_dict ( self ) -> list [ dict ]: \"\"\"To dictionary.\"\"\" res = [] for plot in self . plot_configs : res . append ( plot . to_dict ()) return res def to_file ( self , filename : str | Path ): \"\"\"Save to file.\"\"\" if isinstance ( filename , str ): filename = Path ( filename ) coll = self . to_dict () with open ( filename . with_suffix ( \".plot_cfg.json\" ), \"w\" , encoding = \"utf8\" ) as file : json . dump ( coll , file , indent = 4 ) return filename . with_suffix ( \".plot_cfg.json\" ) def from_file ( self , filename : str | Path ) -> PlotConfigColl : \"\"\"Read from file.\"\"\" with open ( filename , \"r\" , encoding = \"utf8\" ) as file : data = json . load ( file ) plots = [] for plot in data : plots . append ( PlotConfig ( ** plot )) return PlotConfigColl ( plots ) def __iter__ ( self ): \"\"\"iter.\"\"\" return iter ( self . plot_configs ) def __repr__ ( self ): \"\"\"repr.\"\"\" return json . dumps ( self . to_dict ()) __iter__ () iter. Source code in ccg\\ui\\plot.py 227 228 229 def __iter__ ( self ): \"\"\"iter.\"\"\" return iter ( self . plot_configs ) __repr__ () repr. Source code in ccg\\ui\\plot.py 231 232 233 def __repr__ ( self ): \"\"\"repr.\"\"\" return json . dumps ( self . to_dict ()) append ( plot ) append plot to collection. Source code in ccg\\ui\\plot.py 69 70 71 72 73 74 75 76 77 def append ( self , plot : PlotConfig | list [ PlotConfig ]): \"\"\"append plot to collection.\"\"\" if not isinstance ( plot , list ): plot = [ plot ] if self . plot_configs is None : self . plot_configs = plot else : self . plot_configs . extend ( plot ) build_plot ( frames ) build plot from plot config collection Source code in ccg\\ui\\plot.py 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 def build_plot ( self , frames : Frame | list [ Frame ]): \"\"\"build plot from plot config collection\"\"\" if not isinstance ( frames , list ): frames = [ frames ] plots = [] for plot_config in self . plot_configs : plot = Plot ( name = plot_config . name ) annot_list = [] annots = False n_annot = 0 if \"annotations\" in plot_config . layout : if any ( isinstance ( lyt [ \"x\" ], str ) or isinstance ( lyt [ \"y\" ], str ) for lyt in plot_config . layout [ \"annotations\" ] ): annots = plot_config . layout . pop ( \"annotations\" ) else : annot_list = plot_config . layout [ \"annotations\" ] for ref_trace in plot_config . traces : try : for frame in frames : trace = ref_trace group = { \"legendgroup\" : frame . name , \"legendgrouptitle\" : { \"text\" : frame . name }, } if \"x\" in trace : x = frame [ trace . pop ( \"x\" ) ] . data # pop out to not update later hov_temp = { \"hovertemplate\" : \"\"\"Y: % {y:.2f} % {yaxis.title.text} <br> X: % {x:.3f} % {xaxis.title.text} \"\"\" } else : if ( frame [ trace [ \"y\" ]] . tline [ 0 ] < 32000000 ): # apprx 1yr from epoch # assume this is an elapsed time instead x = frame [ trace [ \"y\" ]] . tline . unix hov_temp = { \"hovertemplate\" : \"\"\"Value: % {y:.2f} % {yaxis.title.text} <br> Time: % {x:.3f} % {xaxis.title.text} \"\"\" } else : x = frame [ trace [ \"y\" ]] . tline . iso hov_temp = { \"hovertemplate\" : \"\"\"Value: % {y:.2f} % {yaxis.title.text} <br> Time: %{x|%H:%M:%S.%L}\"\"\" } yname = trace [ \"y\" ] y = frame [ trace . pop ( \"y\" )] . data # pop out to not update later yaxis = trace [ \"yaxis\" ] if \"yaxis\" in trace else None plt_trace = plot . build_trace ( x = x , y = y , signame = yname , yaxis = yaxis ) ccg . util . merge_dict ( plt_trace , group ) ccg . util . merge_dict ( plt_trace , hov_temp ) ccg . util . merge_dict ( plt_trace , trace ) # Update with other settings in trace. plot . append_trace ( plt_trace ) if annots : # Calculate the annotation for note in annots : # pylint: disable=eval-used new_note = copy . deepcopy ( note ) if isinstance ( note [ \"x\" ], str ): txt = \"\" txt = re . findall ( r \"PARAM(?:\\.|\\[).*\" , note [ \"x\" ]) if txt : new_note [ \"x\" ] = eval ( txt [ 0 ] . replace ( \"PARAM\" , \"frame\" ) ) if isinstance ( note [ \"y\" ], str ): txt = \"\" txt = re . findall ( r \"PARAM(?:\\.|\\[).*\" , note [ \"y\" ]) if txt : new_note [ \"y\" ] = eval ( txt [ 0 ] . replace ( \"PARAM\" , \"frame\" ) ) # check text for fstring txt = \"\" txt = re . findall ( r \"f'.*'\" , note [ \"text\" ]) if txt : new_note [ \"text\" ] = eval ( txt [ 0 ] . replace ( \"PARAM\" , \"frame\" ) ) if \"ay\" in note : new_note [ \"ay\" ] = note [ \"ay\" ] * ( n_annot + 1 ) if \"arrowcolor\" not in note : new_note [ \"arrowcolor\" ] = plot . TRACES [ n_annot % len ( plot . TRACES ) ] if \"bordercolor\" not in note : new_note [ \"bordercolor\" ] = plot . TRACES [ n_annot % len ( plot . TRACES ) ] annot_list . append ( new_note ) n_annot += 1 except KeyError as err : _LOGGER . warning ( \" %s . Skipped %s .\" , err , \"trace\" ) layout = plot . plt_layout . copy () ccg . util . merge_dict ( layout , { \"annotations\" : annot_list }) # Need to extract y-axes from the layout since plot tools build the yaxes at the end tmp_yaxes = {} list_to_remove = [] for key in layout : if key . startswith ( \"yaxis\" ): tmp_yaxes [ key . replace ( \"yaxis\" , \"y\" )] = layout [ key ] list_to_remove . append ( key ) for key in list_to_remove : layout . pop ( key ) ccg . util . merge_dict ( plot . yaxes , tmp_yaxes ) ccg . util . merge_dict ( plot . plt_layout , layout ) plots . append ( plot ) return plots from_file ( filename ) Read from file. Source code in ccg\\ui\\plot.py 218 219 220 221 222 223 224 225 def from_file ( self , filename : str | Path ) -> PlotConfigColl : \"\"\"Read from file.\"\"\" with open ( filename , \"r\" , encoding = \"utf8\" ) as file : data = json . load ( file ) plots = [] for plot in data : plots . append ( PlotConfig ( ** plot )) return PlotConfigColl ( plots ) to_dict () To dictionary. Source code in ccg\\ui\\plot.py 201 202 203 204 205 206 def to_dict ( self ) -> list [ dict ]: \"\"\"To dictionary.\"\"\" res = [] for plot in self . plot_configs : res . append ( plot . to_dict ()) return res to_file ( filename ) Save to file. Source code in ccg\\ui\\plot.py 208 209 210 211 212 213 214 215 216 def to_file ( self , filename : str | Path ): \"\"\"Save to file.\"\"\" if isinstance ( filename , str ): filename = Path ( filename ) coll = self . to_dict () with open ( filename . with_suffix ( \".plot_cfg.json\" ), \"w\" , encoding = \"utf8\" ) as file : json . dump ( coll , file , indent = 4 ) return filename . with_suffix ( \".plot_cfg.json\" ) build_collection_traces ( gate , frameorsig , tline = None , plot_def = None , andor = 'n/a' ) Build traces for gate collection. Source code in ccg\\ui\\plot.py 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 1613 1614 def build_collection_traces ( gate : GateColl , frameorsig : Frame | Sig , tline : TLine = None , plot_def : Plot = None , andor : str = \"n/a\" , ): \"\"\"Build traces for gate collection.\"\"\" if plot_def is None : plot_def = Plot () if tline is None : plt_tline = gate . get_combined_tline ( frameorsig ) else : plt_tline = tline valid_axis = \"y1\" if plt_tline . tstart < 32000000 : times = [ plt_tline . tstart , plt_tline . tend , ] else : times = [ plt_tline . tstart_iso , plt_tline . tend_iso , ] trace = { \"type\" : \"scattergl\" , \"y\" : np . array ([ np . nan , np . nan ]), \"x\" : times , \"name\" : f \" { andor } (\" , \"mode\" : \"none\" , \"legendgroup\" : \"collection\" + str ( plot_def . n_col ), } plot_def . append_trace ( trace ) plot_def . n_col += 1 for cond in gate . conds : build_gate_plot ( cond , frameorsig , tline , plot_def ) trace = { \"type\" : \"scattergl\" , \"y\" : np . array ([ np . nan , np . nan ]), \"x\" : times , \"name\" : \")\" , \"mode\" : \"none\" , \"legendgroup\" : \"collection\" + str ( plot_def . n_col ), } plot_def . append_trace ( trace ) # Result plot # res = Sig( # data=gate.valid(frameorsig, tline) # * (1.0 + (plot_def.n_col + plot_def.n_cond) * 0.1), # tline=tline, # name=\"Result\", # interp_method=InterpMethod.ZOH, # ) # res.data = res.data * (1.0 + (plot_def.n_col + plot_def.n_cond) * 0.1) t_en , t_dis = gate . edges ( frameorsig , tline ) if len ( t_en ) == 0 : t_dis = [ plt_tline [ 0 ], plt_tline [ - 1 ]] data = np . concatenate ( ( np . ones ( len ( t_en )) * ( 1.0 + ( plot_def . n_col + plot_def . n_cond ) * 0.1 ), np . zeros ( len ( t_dis )), ) ) times = np . concatenate (( t_en , t_dis )) res = Sig ( data = data , tline = TLine ( data = times ), name = \"Result\" , interp_method = ccg . util . InterpMethod . ZOH , connect_gaps = True , ) res . sort_tline () trace = plot_def . build_trace_from_sig ( res , yaxis = valid_axis , color = plot_def . n_col + plot_def . n_cond ) plot_def . append_trace ( trace ) plot_def . n_col += 1 build_gate_plot ( gate , frame , tline = None , def_plot = None ) Plot validity and timer signals. Source code in ccg\\ui\\plot.py 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 def build_gate_plot ( gate : GateColl | GateCond , frame : Frame , tline : TLine = None , def_plot : Plot = None , ) -> Plot : \"\"\"Plot validity and timer signals.\"\"\" from ccg.data.gating import GateCollAND , GateCollOR , GateCond res_stack_factor = 0.05 valid_axis = \"y1\" if def_plot is None : if frame . name is None : name = \"Gate Condition\" else : name = f \"Gate Condition for { frame . name } \" def_plot = Plot ( name = name ) if isinstance ( gate , GateCollOR ): andor = \"OR\" build_collection_traces ( gate , frame , tline , def_plot , andor ) elif isinstance ( gate , GateCollAND ): andor = \"AND\" build_collection_traces ( gate , frame , tline , def_plot , andor ) elif isinstance ( gate , GateCond ): res = Sig ( gate . validate ( frame , tline )) # Copy # scale result so they stack res . data = res . data + (( def_plot . n_col + def_plot . n_cond ) * res_stack_factor ) trace = def_plot . build_trace_from_sig ( res , color = def_plot . n_cond , yaxis = valid_axis ) trace . update ({ \"legendgroup\" : \"Cond\" + str ( def_plot . n_cond )}) def_plot . append_trace ( trace ) def_plot . yaxes [ valid_axis ] . update ({ \"domain\" : [ 0.8 , 1 ]}) trace = def_plot . build_trace_from_sig ( frame [ gate . signame ], color = def_plot . n_cond ) trace . update ( { \"legendgroup\" : f \"Cond { def_plot . n_cond } \" , \"legendgrouptitle\" : { \"text\" : f \" { gate . min_limit } < { gate . signame } < { gate . max_limit } [ { gate . unit } ]\" }, } ) yaxis = trace [ \"yaxis\" ] def_plot . append_trace ( trace ) def_plot . yaxes [ yaxis ] . update ( { \"domain\" : [ 0 , 0.7875 ], \"overlaying\" : \"y2\" , \"showgrid\" : False } ) limits = [] min_limit = ccg . util . convert_units ( gate . min_limit , gate . unit , frame [ gate . signame ] . unit ) max_limit = ccg . util . convert_units ( gate . max_limit , gate . unit , frame [ gate . signame ] . unit ) if gate . min_limit == np . NINF : sig_range = frame [ gate . signame ] . max - frame [ gate . signame ] . min limits . extend ([ frame [ gate . signame ] . min - 0.1 * sig_range ] * 2 ) else : limits . extend ([ min_limit ] * 2 ) if gate . max_limit == np . inf : sig_range = frame [ gate . signame ] . max - frame [ gate . signame ] . min limits . extend ([ frame [ gate . signame ] . max + 0.1 * sig_range ] * 2 ) else : limits . extend ([ max_limit ] * 2 ) if frame [ gate . signame ] . tstart < 32000000 : times = np . array ( [ frame [ gate . signame ] . tstart , frame [ gate . signame ] . tend , frame [ gate . signame ] . tend , frame [ gate . signame ] . tstart , ] ) else : times = np . array ( [ frame [ gate . signame ] . tstart_iso , frame [ gate . signame ] . tend_iso , frame [ gate . signame ] . tend_iso , frame [ gate . signame ] . tstart_iso , ] ) trace = def_plot . build_trace ( x = times , y = limits , signame = f \" { gate . signame } _limits\" , yaxis = yaxis , color = def_plot . n_cond , connect_gaps = False , ) tmp_color = ccg . util . hex_to_rgb ( trace [ \"line\" ][ \"color\" ]) tmp_color_str = f \"rgba( { tmp_color [ 0 ] } , { tmp_color [ 1 ] } , { tmp_color [ 2 ] } ,0.2)\" trace . update ( { \"fill\" : \"toself\" , \"legendgroup\" : \"Cond\" + str ( def_plot . n_cond ), \"fillcolor\" : tmp_color_str , } ) def_plot . append_trace ( trace ) if def_plot . yaxes [ yaxis ][ \"color\" ] != def_plot . THEME3 : def_plot . yaxes [ yaxis ][ \"color\" ] = ccg . util . max_contrast ( def_plot . TRACES [ def_plot . n_cond % def_plot . n_colors ], ccg . util . shift_lightness ( def_plot . TRACES [ def_plot . n_cond % def_plot . n_colors ], 1.4 ), ccg . util . shift_lightness ( def_plot . TRACES [ def_plot . n_cond % def_plot . n_colors ], 0.4 ), ) def_plot . n_cond += 1 return def_plot","title":"plot"},{"location":"reference/ccg/ui/plot/#ccg.ui.plot.Plot","text":"Class to generate Plotly plots. Source code in ccg\\ui\\plot.py 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 980 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 class Plot : \"\"\"Class to generate Plotly plots.\"\"\" # Plot Colors # https://www.behance.net/gallery/84533571/Above-the-Allgaeu # THEME1 = \"#010A26\" # THEME2 = \"#283040\" # THEME3 = \"#6D7B8C\" # THEME4 = \"#8A99A6\" # THEME5 = \"#6B734F\" THEME1 = \"#011726\" THEME2 = \"#353837\" THEME3 = \"#656b72\" THEME4 = \"#8f979e\" THEME5 = \"#6B734F\" WHITE = \"#e3ecff\" BLACK = \"#111c24\" GREY1 = \"#333533\" TRACES = [ \"#4ea7fa\" , \"#bcfa35\" , \"#FA2341\" , \"#923df3\" , \"#315dee\" , \"#0fbd26\" , \"#ff90a8\" , \"#ee31ee\" , \"#bdccdd\" , \"#22f31a\" , \"#fffc43\" , \"#ff8615\" , ] # TODO: Add more colors n_colors = len ( TRACES ) TURBO = [ [ 0.000 , \"#30123b\" ], [ 0.071 , \"#4145ab\" ], [ 0.143 , \"#4675ed\" ], [ 0.214 , \"#39a2fc\" ], [ 0.286 , \"#1bcfd4\" ], [ 0.357 , \"#24eca6\" ], [ 0.429 , \"#61fc6c\" ], [ 0.500 , \"#a4fc3b\" ], [ 0.571 , \"#d1e834\" ], [ 0.643 , \"#f3c63a\" ], [ 0.714 , \"#fe9b2d\" ], [ 0.786 , \"#f36315\" ], [ 0.857 , \"#d93806\" ], [ 0.929 , \"#b11901\" ], [ 1.000 , \"#7a0402\" ], ] LINESHAPE = { None : \"linear\" , ccg . util . InterpMethod . LINEAR : \"linear\" , ccg . util . InterpMethod . ZOH : \"hv\" , ccg . util . InterpMethod . NEAREST : \"hvh\" , } frange = 4 # Factor of range for combining y axes fpos = 0.06 # Factor of position for multi y axes compat_types = [ ( \"i\" , \"f\" , \"u\" ), ( \"U\" , \"S\" ), ( \"b\" ,), ( \"O\" ,), ] _copy_button = { \"name\" : \"toClipboard\" , \"title\" : \"Copy to clipboard\" , \"icon\" : { \"path\" : \"M102.17,29.66A3,3,0,0,0,100,26.79L73.62,1.1A3,3,0,0,0,71.31,0h-46a5.36,5.36,0,0,0-5.36,5.36V20.41H5.36A5.36,5.36,0,0,0,0,25.77v91.75a5.36,5.36,0,0,0,5.36,5.36H76.9a5.36,5.36,0,0,0,5.33-5.36v-15H96.82a5.36,5.36,0,0,0,5.33-5.36q0-33.73,0-67.45ZM25.91,20.41V6h42.4V30.24a3,3,0,0,0,3,3H96.18q0,31.62,0,63.24h-14l0-46.42a3,3,0,0,0-2.17-2.87L53.69,21.51a2.93,2.93,0,0,0-2.3-1.1ZM54.37,30.89,72.28,47.67H54.37V30.89ZM6,116.89V26.37h42.4V50.65a3,3,0,0,0,3,3H76.26q0,31.64,0,63.24ZM17.33,69.68a2.12,2.12,0,0,1,1.59-.74H54.07a2.14,2.14,0,0,1,1.6.73,2.54,2.54,0,0,1,.63,1.7,2.57,2.57,0,0,1-.64,1.7,2.16,2.16,0,0,1-1.59.74H18.92a2.15,2.15,0,0,1-1.6-.73,2.59,2.59,0,0,1,0-3.4Zm0,28.94a2.1,2.1,0,0,1,1.58-.74H63.87a2.12,2.12,0,0,1,1.59.74,2.57,2.57,0,0,1,.64,1.7,2.54,2.54,0,0,1-.63,1.7,2.14,2.14,0,0,1-1.6.73H18.94a2.13,2.13,0,0,1-1.59-.73,2.56,2.56,0,0,1,0-3.4ZM63.87,83.41a2.12,2.12,0,0,1,1.59.74,2.59,2.59,0,0,1,0,3.4,2.13,2.13,0,0,1-1.6.72H18.94a2.12,2.12,0,0,1-1.59-.72,2.55,2.55,0,0,1-.64-1.71,2.5,2.5,0,0,1,.65-1.69,2.1,2.1,0,0,1,1.58-.74ZM17.33,55.2a2.15,2.15,0,0,1,1.59-.73H39.71a2.13,2.13,0,0,1,1.6.72,2.61,2.61,0,0,1,0,3.41,2.15,2.15,0,0,1-1.59.73H18.92a2.14,2.14,0,0,1-1.6-.72,2.61,2.61,0,0,1,0-3.41Zm0-14.47A2.13,2.13,0,0,1,18.94,40H30.37a2.12,2.12,0,0,1,1.59.72,2.61,2.61,0,0,1,0,3.41,2.13,2.13,0,0,1-1.58.73H18.94a2.16,2.16,0,0,1-1.59-.72,2.57,2.57,0,0,1-.64-1.71,2.54,2.54,0,0,1,.65-1.7ZM74.3,10.48,92.21,27.26H74.3V10.48Z\" , \"transform\" : \"scale(0.12)\" , }, \"click\" : \"plotly_clip\" , } _copyfunc = \"function plotly_clip(gd) {Plotly.toImage(gd, { format: 'png', width: 2100, height: 900 }).then(async function (url) {try {const data = await fetch(url);const blob = await data.blob();await navigator.clipboard.write([new ClipboardItem({[blob.type]: blob})]);console.log('Image copied.');} catch (err) {console.error(err.name, err.message);}});}\" config = { \"scrollZoom\" : True , \"edits\" : { \"legendPosition\" : True }, \"displaylogo\" : False , \"modeBarButtons\" : [ [ _copy_button , \"toImage\" , \"zoom2d\" , \"pan2d\" , \"resetScale2d\" ] ], } _scene_axis = { \"backgroundcolor\" : THEME4 , \"color\" : WHITE , \"gridcolor\" : THEME3 , \"showline\" : True , \"showgrid\" : True , \"ticks\" : \"outside\" , \"mirror\" : True , } _plt_layout = { \"title\" : { \"text\" : \"Data Plot\" , \"font\" : { \"size\" : 24 }, \"x\" : 0.5 , \"xanchor\" : \"center\" , }, \"legend\" : { \"bgcolor\" : THEME3 , \"bordercolor\" : THEME4 , \"borderwidth\" : 1 , \"xanchor\" : \"left\" , \"yanchor\" : \"top\" , \"x\" : 1.02 , \"y\" : 1 , }, \"showlegend\" : True , \"hovermode\" : \"closest\" , \"margin\" : { \"autoexpand\" : True , \"b\" : 80 , \"l\" : 80 , \"r\" : 80 , \"t\" : 80 , \"pad\" : 0 }, \"xaxis1\" : { \"color\" : WHITE , \"gridcolor\" : THEME4 , \"showline\" : True , \"spikesnap\" : \"hovered data\" , \"spikemode\" : \"across+marker\" , \"spikedash\" : \"solid\" , \"spikethickness\" : 1 , \"ticks\" : \"outside\" , \"zerolinecolor\" : THEME4 , \"zerolinewidth\" : 2 , \"mirror\" : True , }, \"paper_bgcolor\" : THEME2 , \"plot_bgcolor\" : GREY1 , \"font\" : { \"color\" : WHITE , \"family\" : 'Consolas, \"Courier New\", monospace' }, \"clickmode\" : \"event+select\" , \"colorway\" : TRACES , \"selectdirection\" : \"any\" , \"autosize\" : True , \"uirevision\" : True , # \"transition\": {\"duration\": 500, \"easing\": \"cubic-in-out\"}, } def __init__ ( self , data : Frame | Sig | Tbl = None , name : str = None , plot_prep = True ): self . traces : list [ dict ] = [] self . nyaxes = 0 self . ntrace = - 1 self . n_cond = 0 # For use in gate diag plots self . n_col = 0 # For use in gate diag plots self . yaxes : dict [ str , dict ] = {} self . plt_layout = copy . deepcopy ( self . _plt_layout ) self . plot_prep = plot_prep # Build traces if isinstance ( data , Frame ): for sig in data : self . append_trace_from_sig ( sig ) elif isinstance ( data , Sig ): self . append_trace_from_sig ( data ) elif isinstance ( data , Tbl ): self . append_trace_from_tbl ( data ) elif isinstance ( data , ScatterData ): self . append_trace_from_scatter ( data ) elif data is None : pass else : raise NotImplementedError ( f \"Plot not implemented for { type ( data ) } \" ) if name is None : if data is None or data . name is None : name = \"CCG Data\" else : name = data . name self . plt_layout [ \"title\" ][ \"text\" ] = name def update_axis ( self , axis : str = \"xaxis1\" , title : str = None , unit : str = None , min_range : float = None , max_range : float = None , ): \"\"\"Update axis info.\"\"\" if title is not None : if unit is not None : ccg . util . merge_dict ( self . plt_layout , { axis : { \"title\" : { \"text\" : f \" { title } [ { unit } ]\" }}} ) else : ccg . util . merge_dict ( self . plt_layout , { axis : { \"title\" : { \"text\" : f \" { title } \" }}} ) ccg . util . merge_dict ( self . plt_layout , { axis : { \"range\" : [ min_range , max_range ]}}) def build_trace ( self , x : npt . NDArray , y : npt . NDArray , signame : str = None , sigunit : str = None , connect_gaps : bool = None , yaxis : str = None , color : int = None , ): \"\"\"Build Trace for plotly.\"\"\" ntrace = self . ntrace + 1 if color is None : color = ntrace yaxis = self . find_yaxis ( Sig ( data = y , tline = TLine ( x ), name = signame , unit = sigunit ), yaxis = yaxis ) # TODO: Implement find_yaxis for non sigs sigunit = \"\" if sigunit is None else sigunit trace = { \"type\" : \"scattergl\" , \"y\" : y , \"x\" : x , \"name\" : f \" { signame } [ { sigunit } ]\" , \"mode\" : \"markers+lines\" , \"hovertemplate\" : \"\"\"Value: % {y:.2f} % {yaxis.title.text} <br> X: % {x:.2f} % {xaxis.title.text} \"\"\" , \"yaxis\" : yaxis , \"opacity\" : 1 , \"connectgaps\" : bool ( connect_gaps ), \"marker\" : { \"size\" : [ 2 ] * len ( y ), \"line\" : { \"color\" : ccg . util . max_contrast ( self . _plt_layout [ \"plot_bgcolor\" ], ccg . util . shift_lightness ( self . TRACES [ color % self . n_colors ], 1.4 ), ccg . util . shift_lightness ( self . TRACES [ color % self . n_colors ], 0.4 ), ), \"width\" : 1 , }, }, \"line\" : { \"width\" : 1 , \"color\" : self . TRACES [ color % self . n_colors ], }, } return trace def build_trace_from_sig ( self , sig : Sig , color : int = None , yaxis : str = None ): \"\"\"Build Trace for plotly from a Sig.\"\"\" ntrace = self . ntrace + 1 if color is None : color = ntrace if self . plot_prep : sig = sig . plot_prep () yaxis = self . find_yaxis ( sig , yaxis ) unit = \"\" if sig . unit is None else sig . unit if sig . tline [ 0 ] < 32000000 : # apprx 1yr from epoch # assume this is an elapsed time instead x = sig . tline . unix hov_temp = \"\"\" Value: % {y:.2f} % {yaxis.title.text} <br> Time: % {x:.3f} [s]\"\"\" self . update_axis ( axis = \"xaxis1\" , title = \"Elapsed Time\" , unit = \"S\" ) else : x = sig . tline . iso hov_temp = \"\"\" Value: % {y:.2f} % {yaxis.title.text} <br> Time: %{x|%H:%M:%S.%L}\"\"\" self . update_axis ( axis = \"xaxis1\" , title = \"Date and Time\" ) if sig . nsamples > 100000 : hov = \"skip\" # Disable hover since its too slow hov_temp = \"\" else : hov = \"all\" trace = { \"type\" : \"scattergl\" , \"y\" : sig . data , \"x\" : x , \"name\" : f \" { sig . name } [ { unit } ]\" , \"mode\" : \"markers+lines\" , \"hovertemplate\" : hov_temp , \"hoverinfo\" : hov , \"yaxis\" : yaxis , \"opacity\" : 1 , \"connectgaps\" : bool ( sig . connect_gaps ), # should work if connect_gaps is None \"marker\" : { # \"color\": TRACES[self.ntrace], \"size\" : [ 2 ] * len ( x ), \"line\" : { \"color\" : ccg . util . max_contrast ( self . _plt_layout [ \"plot_bgcolor\" ], ccg . util . shift_lightness ( self . TRACES [ color % self . n_colors ], 1.4 ), ccg . util . shift_lightness ( self . TRACES [ color % self . n_colors ], 0.4 ), ), \"width\" : 1 , }, }, \"line\" : { \"width\" : 1 , \"shape\" : self . LINESHAPE [ sig . interp_method ], \"color\" : self . TRACES [ color % self . n_colors ], }, } if sig . base_data is not None : ccg . util . merge_dict ( trace , { \"text\" : sig . base_data , \"hovertemplate\" : \"\"\"Value: % {text} <br> Time: %{x|%H:%M:%S.%L}\"\"\" , }, ) return trace def build_traces_from_tbl ( self , tbl : Tbl , color : int = None ) -> list [ dict ]: \"\"\"build trace from table.\"\"\" ntrace = 1 # self.ntrace+1 Does it make sense to deal with multiple tbls in 1 plot? if tbl . unit is not None : unit = f \" [ { tbl . unit } ]\" else : unit = \"\" if tbl . n_dim == 2 : traces = self . build_2d_traces ( tbl , color , ntrace , unit ) elif tbl . n_dim == 1 : traces = self . build_1d_traces ( tbl , color , ntrace , unit ) elif tbl . n_dim == 0 : traces = self . build_0d_traces ( tbl , color , ntrace , unit ) else : raise NotImplementedError ( f \"Plot not implemented for n_dim = { tbl . n_dim } \" ) return traces def build_traces_from_scatter ( self , scatter : ScatterData ): \"\"\"Builds scatter data traces\"\"\" # TODO: Implement support for more than 1 scatter if scatter is not None : return [ self . build_scatter_trace ( scatter = scatter )] def build_0d_traces ( self , param : Tbl , color : int , ntrace : int , unit : str ): \"\"\"Build traces for 0d param\"\"\" traces = [] yaxis = f \"y { self . nyaxes + 1 } \" hov_temp = ( f \"\"\" { param . name } : % {{ y:. { param . precision } f }} [ { unit } ]<extra></extra>\"\"\" ) try : tmp_trc = { \"type\" : \"scattergl\" , \"y\" : param . orig . data , \"name\" : param . orig . name , \"mode\" : \"markers\" , \"yaxis\" : yaxis , \"opacity\" : 1 , \"hovertemplate\" : hov_temp , \"marker\" : { \"size\" : 8 , \"color\" : self . TRACES [ ntrace % self . n_colors ], \"line\" : { \"color\" : ccg . util . max_contrast ( self . _plt_layout [ \"plot_bgcolor\" ], ccg . util . shift_lightness ( self . TRACES [ ntrace % self . n_colors ], 1.4 ), ccg . util . shift_lightness ( self . TRACES [ ntrace % self . n_colors ], 0.4 ), ), \"width\" : 1 , }, }, \"hoverlabel\" : { \"bgcolor\" : self . TRACES [ ntrace % self . n_colors ]}, \"showlegend\" : True , \"legendgroup\" : f \" { param . orig . name } _ { ntrace } \" , } traces . append ( tmp_trc ) ntrace += 1 except KeyError : pass if color is None : color = ntrace tmp_trc = { \"type\" : \"scattergl\" , \"y\" : param . data , \"name\" : param . name , \"mode\" : \"markers\" , \"hovertemplate\" : hov_temp , \"opacity\" : 1 , \"marker\" : { \"size\" : 8 , \"color\" : self . TRACES [ color % self . n_colors ], \"line\" : { \"color\" : ccg . util . max_contrast ( self . _plt_layout [ \"plot_bgcolor\" ], ccg . util . shift_lightness ( self . TRACES [ color % self . n_colors ], 1.4 ), ccg . util . shift_lightness ( self . TRACES [ color % self . n_colors ], 0.4 ), ), \"width\" : 1 , }, }, \"hoverlabel\" : { \"bgcolor\" : self . TRACES [ color % self . n_colors ]}, \"showlegend\" : True , \"legendgroup\" : f \" { param . name } _ { ntrace } \" , } traces . append ( tmp_trc ) ntrace += 1 nscatter = 0 for scatter in param . scatter_data : if scatter is not None : # plot the scatter data as well. nscatter += 1 tmp_trc = self . build_scatter_trace ( scatter = scatter , param = param , ntrace = ntrace , nscatter = nscatter ) traces . append ( tmp_trc ) ntrace += 1 self . yaxes [ yaxis ] = { \"unit\" : param . unit , \"min\" : param . data_range [ 0 ], \"max\" : param . data_range [ 1 ], \"dtype\" : self . compat_types [ np . where ([ param . data . dtype . kind in t for t in self . compat_types ])[ 0 ][ 0 ] # r-worded way to get the index of the match ], \"color\" : self . WHITE , \"fixed_range\" : False , } return traces def build_1d_traces ( self , param : Tbl , color : int , ntrace : int , unit : str ): \"\"\"Build traces for 1d param\"\"\" traces = [] yaxis = f \"y { self . nyaxes + 1 } \" hov_temp = f \"\"\" { param . name } : % {{ y:. { param . precision } f }} [ { unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } f }} [ { param . axes [ 0 ] . unit } ]<extra></extra>\"\"\" try : tmp_trc = { \"type\" : \"scattergl\" , \"y\" : param . orig . data , \"x\" : param . orig . axes [ 0 ] . data , \"name\" : param . orig . name , \"mode\" : \"markers+lines\" , \"yaxis\" : yaxis , \"opacity\" : 1 , \"hovertemplate\" : hov_temp , \"marker\" : { \"size\" : np . array ([ 10 ] * param . orig . data . size ), \"color\" : self . TRACES [ ntrace % self . n_colors ], \"line\" : { \"color\" : ccg . util . max_contrast ( self . _plt_layout [ \"plot_bgcolor\" ], ccg . util . shift_lightness ( self . TRACES [ ntrace % self . n_colors ], 1.4 ), ccg . util . shift_lightness ( self . TRACES [ ntrace % self . n_colors ], 0.4 ), ), \"width\" : 1 , }, }, \"line\" : { \"width\" : 1 , \"shape\" : self . LINESHAPE [ param . orig . axes [ 0 ] . interp_method ], \"color\" : self . TRACES [ ntrace % self . n_colors ], }, \"hoverlabel\" : { \"bgcolor\" : self . TRACES [ ntrace % self . n_colors ]}, \"showlegend\" : True , \"legendgroup\" : f \" { param . orig . name } _ { ntrace } \" , } traces . append ( tmp_trc ) ntrace += 1 except KeyError : pass if color is None : color = ntrace tmp_trc = { \"type\" : \"scattergl\" , \"y\" : param . data , \"x\" : param . axes [ 0 ] . data , \"name\" : param . name , \"mode\" : \"markers+lines\" , \"hovertemplate\" : hov_temp , \"opacity\" : 1 , \"marker\" : { \"size\" : np . array ([ 10 ] * param . data . size ), \"color\" : self . TRACES [ color % self . n_colors ], \"line\" : { \"color\" : ccg . util . max_contrast ( self . _plt_layout [ \"plot_bgcolor\" ], ccg . util . shift_lightness ( self . TRACES [ color % self . n_colors ], 1.4 ), ccg . util . shift_lightness ( self . TRACES [ color % self . n_colors ], 0.4 ), ), \"width\" : 1 , }, }, \"line\" : { \"width\" : 1 , \"shape\" : self . LINESHAPE [ param . axes [ 0 ] . interp_method ], \"color\" : self . TRACES [ color % self . n_colors ], }, \"hoverlabel\" : { \"bgcolor\" : self . TRACES [ color % self . n_colors ]}, \"showlegend\" : True , \"legendgroup\" : f \" { param . name } _ { ntrace } \" , } traces . append ( tmp_trc ) ntrace += 1 nscatter = 0 for scatter in param . scatter_data : if scatter is not None : # plot the scatter data as well. nscatter += 1 tmp_trc = self . build_scatter_trace ( scatter = scatter , param = param , ntrace = ntrace , nscatter = nscatter ) traces . append ( tmp_trc ) ntrace += 1 self . yaxes [ yaxis ] = { \"unit\" : param . unit , \"min\" : param . data_range [ 0 ], \"max\" : param . data_range [ 1 ], \"dtype\" : self . compat_types [ np . where ([ param . data . dtype . kind in t for t in self . compat_types ])[ 0 ][ 0 ] # r-worded way to get the index of the match ], \"color\" : self . WHITE , \"fixed_range\" : False , } return traces def build_2d_traces ( self , param : Tbl , color : int , ntrace : int , unit : str ): \"\"\"build traces from 2d param\"\"\" traces = [] try : traces . extend ( self . build_surf_traces ( param . orig , ntrace - 1 , ntrace , unit , visible = True ) ) ntrace += 1 except KeyError : pass if color is None : color = ntrace - 1 traces . extend ( self . build_surf_traces ( param , color , ntrace , unit )) ntrace += 1 nscatter = 0 for scatter in param . scatter_data : if scatter is not None : # plot the scatter data as well. nscatter += 1 tmp_trc = self . build_scatter_trace ( scatter = scatter , param = param , ntrace = ntrace , nscatter = nscatter ) traces . append ( tmp_trc ) ntrace += 1 xaxis = copy . deepcopy ( self . _scene_axis ) xaxis . update ( { \"title\" : { \"text\" : f \" { param . axes [ 0 ] . name } [ { param . axes [ 0 ] . unit } ]\" }} ) yaxis = copy . deepcopy ( self . _scene_axis ) yaxis . update ( { \"title\" : { \"text\" : f \" { param . axes [ 1 ] . name } [ { param . axes [ 1 ] . unit } ]\" }} ) zaxis = copy . deepcopy ( self . _scene_axis ) zaxis . update ({ \"title\" : { \"text\" : f \" { param . name } [ { param . unit } ]\" }}) scene = { \"scene\" : { \"xaxis\" : xaxis , \"yaxis\" : yaxis , \"zaxis\" : zaxis , \"camera\" : { \"eye\" : { \"x\" : - 1.25 , \"y\" : - 1.25 , \"z\" : 1.1 }}, } } ccg . util . merge_dict ( self . plt_layout , scene ) return traces def build_scatter_trace ( self , scatter : ScatterData , param : Tbl = None , ntrace : int = 1 , nscatter : int = 1 , ): \"\"\"Builds a scatter trace. ntrace and nscatter are counters for color increments\"\"\" ndim = scatter . ndim tmp_trc = { \"name\" : scatter . name , \"mode\" : \"markers\" , \"opacity\" : 1 , \"marker\" : { \"size\" : 3 , \"color\" : self . TRACES [ ntrace % self . n_colors ], \"colorscale\" : [ [ 0 , self . TRACES [ ntrace % self . n_colors ]], [ 1 , self . TRACES [ ntrace % self . n_colors ]], ], \"showscale\" : False , }, \"hoverlabel\" : { \"bgcolor\" : self . TRACES [ ntrace % self . n_colors ]}, \"showlegend\" : True , \"legendgroup\" : f \" { scatter . name } _ { ntrace } \" , } if scatter . color is not None : tmp = { \"marker\" : { \"color\" : scatter . color , \"colorscale\" : self . TURBO , \"colorbar\" : { \"bgcolor\" : self . THEME3 , \"bordercolor\" : self . THEME4 , \"borderwidth\" : 1 , \"title\" : { \"text\" : f \" { scatter . color_label } [ { scatter . color_unit } ]\" , \"side\" : \"right\" , }, \"x\" : 0 , }, \"showscale\" : True , }, \"text\" : np . round ( scatter . color , scatter . color_precision ), } if scatter . color_range is not None : ccg . util . merge_dict ( tmp , { \"marker\" : { \"cmin\" : scatter . color_range [ 0 ], \"cmax\" : scatter . color_range [ 1 ], } }, ) # Need to move legend to clear color bar. tmp_lgnd = { \"legend\" : { \"xanchor\" : \"right\" , \"yanchor\" : \"top\" , \"x\" : 1 , \"y\" : 1 , }, } ccg . util . merge_dict ( self . plt_layout , tmp_lgnd ) ccg . util . merge_dict ( tmp_trc , tmp ) if ndim == 2 : if param is not None : if scatter . color is not None : hov_temp = f \"\"\" { scatter . name } : % {{ z:. { param . precision } f }} [ { param . unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } f }} [ { param . axes [ 0 ] . unit } ]<br> { param . axes [ 1 ] . name } : % {{ y:. { param . axes [ 1 ] . precision } f }} [ { param . axes [ 1 ] . unit } ]<br> { scatter . color_label } : % {{ marker.color:. { scatter . color_precision } f }} [ { scatter . color_unit } ] <extra></extra>\"\"\" else : hov_temp = f \"\"\" { scatter . name } : % {{ z:. { param . precision } d }} [ { param . unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } d }} [ { param . axes [ 0 ] . unit } ]<br> { param . axes [ 1 ] . name } : % {{ y:. { param . axes [ 1 ] . precision } d }} [ { param . axes [ 1 ] . unit } ] <extra></extra>\"\"\" else : if scatter . color is not None : hov_temp = \"\" tmp = { \"type\" : \"scatter3d\" , \"x\" : scatter . data [ 0 ], \"y\" : scatter . data [ 1 ], \"z\" : scatter . data [ 2 ], \"hovertemplate\" : hov_temp , } elif ndim == 1 : if param is not None : if scatter . color is not None : hov_temp = f \"\"\" { scatter . name } : % {{ y:. { param . precision } f }} [ { param . unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } f }} [ { param . axes [ 0 ] . unit } ]<br> { scatter . color_label } : % {{ marker.color:. { scatter . color_precision } f }} [ { scatter . color_unit } ] <extra></extra>\"\"\" else : hov_temp = f \"\"\" { scatter . name } : % {{ y:. { param . precision } d }} [ { param . unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } d }} [ { param . axes [ 0 ] . unit } ]<br> <extra></extra>\"\"\" else : hov_temp = \"\" tmp = { \"type\" : \"scattergl\" , \"x\" : scatter . data [ 0 ], \"y\" : scatter . data [ 1 ], \"hovertemplate\" : hov_temp , } elif ndim == 0 : if param is not None : if scatter . color is not None : hov_temp = f \"\"\" { scatter . name } : % {{ y:. { param . precision } f }} [ { param . unit } ]<br> { scatter . color_label } : % {{ marker.color:. { scatter . color_precision } f }} [ { scatter . color_unit } ] <extra></extra>\"\"\" else : hov_temp = f \"\"\" { scatter . name } : % {{ y:. { param . precision } d }} [ { param . unit } ]<br> <extra></extra>\"\"\" else : hov_temp = \"\" tmp = { \"type\" : \"scattergl\" , \"x\" : scatter . data [ 0 ] * 0 , \"y\" : scatter . data [ 1 ], \"hovertemplate\" : hov_temp , } else : raise NotImplementedError ccg . util . merge_dict ( tmp_trc , tmp ) if nscatter > 1 : ccg . util . merge_dict ( tmp_trc , { \"visible\" : \"legendonly\" }) return tmp_trc def build_surf_traces ( self , param : Tbl , color : int , ntrace : int , unit : str , visible : bool = True , ): \"\"\"Build 2d surface trace\"\"\" if not visible : visible = \"legendonly\" hov_temp = f \"\"\" { param . name } : % {{ z:. { param . precision } f }} [ { param . unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } f }} [ { param . axes [ 0 ] . unit } ]<br> { param . axes [ 1 ] . name } : % {{ y:. { param . axes [ 1 ] . precision } f }} [ { param . axes [ 1 ] . unit } ] <extra></extra>\"\"\" x , y = np . meshgrid ( param . axes [ 0 ] . data , param . axes [ 1 ] . data ) x = np . concatenate (( x , x [ - 1 , np . newaxis ])) y = np . concatenate (( y , y [ - 1 , np . newaxis ])) z = np . concatenate (( param . data . T , param . data . T [ - 1 , np . newaxis ] * np . NaN )) i = x . flatten ( \"F\" ) j = y . flatten ( \"F\" ) k = z . flatten ( \"F\" ) y , x = np . meshgrid ( param . axes [ 1 ] . data , param . axes [ 0 ] . data ) x = np . concatenate (( x , x [ - 1 , np . newaxis ])) y = np . concatenate (( y , y [ - 1 , np . newaxis ])) z = np . concatenate (( param . data , param . data [ - 1 , np . newaxis ] * np . NaN )) i = np . concatenate (( i , x . flatten ( \"F\" ))) j = np . concatenate (( j , y . flatten ( \"F\" ))) k = np . concatenate (( k , z . flatten ( \"F\" ))) traces = [ { \"type\" : \"surface\" , \"x\" : param . axes [ 0 ] . data , \"y\" : param . axes [ 1 ] . data , \"z\" : param . data . T , \"name\" : f \" { param . name }{ unit } \" , \"hovertemplate\" : hov_temp , \"hoverlabel\" : { \"bgcolor\" : self . TRACES [ color % self . n_colors ]}, \"opacity\" : 0.5 , \"colorscale\" : [ [ 0 , self . TRACES [ color % self . n_colors ]], [ 1 , self . TRACES [ color % self . n_colors ]], ], \"showlegend\" : True , \"legendgroup\" : f \" { param . name } _ { ntrace } \" , \"showscale\" : False , \"visible\" : visible , }, { \"type\" : \"scatter3d\" , \"x\" : i , \"y\" : j , \"z\" : k , \"name\" : f \" { param . name }{ unit } \" , \"hoverinfo\" : \"skip\" , \"opacity\" : 1 , \"marker\" : { \"color\" : np . array ([ self . TRACES [ color % self . n_colors ]] * len ( i )), \"size\" : np . array ([ 10 ] * len ( i )), # \"line\": { # \"color\": ccg.util.max_contrast( # self.TRACES[color % self.n_colors], # ccg.util.shift_lightness( # self.TRACES[color % self.n_colors], 1.4 # ), # ccg.util.shift_lightness( # self.TRACES[color % self.n_colors], 0.4 # ), # ), # \"width\": 1, # }, }, \"line\" : { \"color\" : ccg . util . max_contrast ( self . TRACES [ color % self . n_colors ], ccg . util . shift_lightness ( self . TRACES [ color % self . n_colors ], 1.4 ), ccg . util . shift_lightness ( self . TRACES [ color % self . n_colors ], 0.4 ), ), \"width\" : 2 , }, \"showlegend\" : False , \"legendgroup\" : f \" { param . name } _ { ntrace } \" , \"connectgaps\" : False , \"visible\" : visible , }, ] return traces def find_yaxis ( self , sig : Sig , yaxis : str = None ): \"\"\"Check for matching y axes.\"\"\" if sig . data_range is not None : sig_min = sig . data_range [ 0 ] sig_max = sig . data_range [ 1 ] fixed_range = True else : sig_min = sig . min sig_max = sig . max fixed_range = False if yaxis is not None : if yaxis in self . yaxes : try : if \"U\" in self . yaxes [ yaxis ][ \"dtype\" ]: # its a string type so no scaling info self . yaxes [ yaxis ][ \"color\" ] = self . WHITE # change to grey for multi return yaxis yrange = self . yaxes [ yaxis ][ \"max\" ] - self . yaxes [ yaxis ][ \"min\" ] sigrange = sig_max - sig_min if yrange == 0 : yrange = self . yaxes [ yaxis ][ \"min\" ] self . yaxes [ yaxis ][ \"color\" ] = self . WHITE # change to grey for multi # Should we update the max and min here? could let it expand to inf... # Maybe an average? if fixed_range : self . yaxes [ yaxis ][ \"fixed_range\" ] = fixed_range self . yaxes [ yaxis ][ \"min\" ] = ( self . yaxes [ yaxis ][ \"min\" ] + sig_min ) / 2 self . yaxes [ yaxis ][ \"max\" ] = ( self . yaxes [ yaxis ][ \"max\" ] + sig_max ) / 2 return yaxis except TypeError : # For the case of dtype=obj and not compat pass else : self . nyaxes += 1 self . yaxes [ yaxis ] = { \"unit\" : sig . unit , \"min\" : sig_min , \"max\" : sig_max , \"dtype\" : self . compat_types [ np . where ([ sig . data . dtype . kind in t for t in self . compat_types ])[ 0 ][ 0 ] # r-worded way to get the index of the match ], \"color\" : ccg . util . max_contrast ( self . THEME2 , ccg . util . shift_lightness ( self . TRACES [( self . ntrace + 1 ) % self . n_colors ], 1.4 ), ccg . util . shift_lightness ( self . TRACES [( self . ntrace + 1 ) % self . n_colors ], 0.4 ), ), \"fixed_range\" : fixed_range , } return yaxis else : if self . nyaxes > 0 : for yaxis , yaxis_def in self . yaxes . items (): if ( sig . data . dtype . kind in yaxis_def [ \"dtype\" ] and yaxis_def [ \"unit\" ] == sig . unit ): try : if \"U\" in yaxis_def [ \"dtype\" ]: # its a string type so no scaling info yaxis_def [ \"color\" ] = ( self . WHITE ) # change to grey for multi return yaxis yrange = yaxis_def [ \"max\" ] - yaxis_def [ \"min\" ] sigrange = sig_max - sig_min if yrange == 0 : yrange = yaxis_def [ \"min\" ] if ( sig_min > yaxis_def [ \"min\" ] - ( yrange * self . frange / 2 ) and sig_max < yaxis_def [ \"max\" ] + ( yrange * self . frange / 2 ) and sigrange < yrange * self . frange and sigrange > yrange / self . frange ): yaxis_def [ \"color\" ] = ( self . WHITE ) # change to grey for multi # Should we update the max and min here? could let it expand to inf... # Maybe an average? if fixed_range : yaxis_def [ \"fixed_range\" ] = fixed_range yaxis_def [ \"min\" ] = ( yaxis_def [ \"min\" ] + sig_min ) / 2 yaxis_def [ \"max\" ] = ( yaxis_def [ \"max\" ] + sig_max ) / 2 return yaxis except TypeError : # For the case of dtype=obj and not compat pass self . nyaxes += 1 yaxis = f \"y { self . nyaxes } \" self . yaxes [ yaxis ] = { \"unit\" : sig . unit , \"min\" : sig_min , \"max\" : sig_max , \"dtype\" : self . compat_types [ np . where ([ sig . data . dtype . kind in t for t in self . compat_types ])[ 0 ][ 0 ] # r-worded way to get the index of the match ], \"color\" : ccg . util . max_contrast ( self . THEME2 , ccg . util . shift_lightness ( self . TRACES [( self . ntrace + 1 ) % self . n_colors ], 1.4 ), ccg . util . shift_lightness ( self . TRACES [( self . ntrace + 1 ) % self . n_colors ], 0.4 ), ), \"fixed_range\" : fixed_range , } return yaxis def build_yaxes ( self ): \"\"\"Build yaxes element for layout.\"\"\" # tic = datetime.now() yaxes : dict [ str , dict ] = {} domain_min = 1 domain_min_name = \"y1\" # TODO: Handle domains better... for i , ( y_name , yaxis ) in enumerate ( self . yaxes . items ()): yaxis_tmp = copy . deepcopy ( yaxis ) # Since we will remove stuff from this later... name = y_name . replace ( \"y\" , \"yaxis\" ) if ( i % 2 ) == 0 : side = \"left\" pos = round ( i / 2 + 0.001 ) * self . fpos else : side = \"right\" pos = 1 - round ( i / 2 - 0.001 + 1 ) * self . fpos unit = yaxis_tmp . pop ( \"unit\" ) # Pop since its not a standard. _ = yaxis_tmp . pop ( \"dtype\" ) # not needed here data_range = [ yaxis_tmp . pop ( \"min\" ), yaxis_tmp . pop ( \"max\" )] if not yaxis_tmp . pop ( \"fixed_range\" ): data_range = False # Not sure im ready to use this yet. title = \"\" if unit is None else f \"[ { unit } ]\" ccg . util . merge_dict ( yaxes , { name : { \"title\" : { \"text\" : title }, \"overlaying\" : \"y1\" , \"anchor\" : \"x1\" , \"position\" : pos , \"color\" : yaxis_tmp [ \"color\" ], \"gridcolor\" : yaxis_tmp [ \"color\" ], \"showgrid\" : True , \"showline\" : True , \"mirror\" : True , \"side\" : side , \"spikesnap\" : \"hovered data\" , \"spikemode\" : \"across+marker\" , \"spikedash\" : \"solid\" , \"spikethickness\" : 1 , \"ticks\" : \"outside\" , \"ticklen\" : 3 , \"zerolinecolor\" : yaxis_tmp [ \"color\" ], \"zerolinewidth\" : 2 , } }, ) ccg . util . merge_dict ( yaxes [ name ], yaxis_tmp ) if data_range : ccg . util . merge_dict ( yaxes [ name ], { \"range\" : data_range , }, ) if i > 0 : del yaxes [ f \"yaxis { i } \" ][ \"anchor\" ] # to allow spacing multiple if \"domain\" in yaxis_tmp : if yaxis_tmp [ \"domain\" ][ 0 ] < domain_min : domain_min = yaxis_tmp [ \"domain\" ][ 0 ] domain_min_name = y_name if not yaxes : return del yaxes [ \"yaxis1\" ][ \"overlaying\" ] # to allow hover to work try : # TODO: Improve this for more domains del yaxes [ domain_min_name . replace ( \"y\" , \"yaxis\" )][ \"overlaying\" ] except KeyError : pass ccg . util . merge_dict ( self . plt_layout , yaxes ) self . plt_layout [ \"xaxis1\" ][ \"domain\" ] = [ ( round (( self . nyaxes ) / 2 + 0.001 ) - 1 ) * self . fpos , 1 - round ( self . nyaxes / 2 - 0.001 ) * self . fpos , ] # +0.001 since python is r-worded self . plt_layout [ \"xaxis1\" ][ \"anchor\" ] = domain_min_name # toc = datetime.now() - tic # _LOGGER.debug( # \"build %s yaxes in %.3f\", # self.plt_layout[\"title\"][\"text\"], # toc.total_seconds(), # ) def append_trace_from_sig ( self , sig : Sig , yaxis : str = None , color : int = None ): \"\"\"Build trace from sig and append to traces.\"\"\" try : trace = self . build_trace_from_sig ( sig , yaxis = yaxis , color = color ) self . append_trace ( trace ) except NotImplementedError as err : _LOGGER . warning ( \" %s . Skipped %s .\" , err , sig . name ) def append_trace_from_tbl ( self , tbl : Tbl ): \"\"\"build trace from table and append\"\"\" try : trace = self . build_traces_from_tbl ( tbl ) self . append_trace ( trace ) except ( NotImplementedError , KeyError ) as err : _LOGGER . warning ( \" %s . Skipped %s .\" , err , tbl . name ) def append_trace_from_scatter ( self , scatter : ScatterData ): \"\"\"build trace from Scatter and append\"\"\" try : trace = self . build_traces_from_scatter ( scatter ) self . append_trace ( trace ) except ( NotImplementedError , KeyError ) as err : _LOGGER . warning ( \" %s . Skipped %s .\" , err , scatter . name ) def append_trace ( self , trace : dict | list [ dict ]): \"Append trace to traces.\" if isinstance ( trace , list ): self . traces . extend ( trace ) else : self . traces . append ( trace ) self . ntrace += 1 # profile def to_html ( self ) -> str : \"\"\"Generate the HTML string for plot.\"\"\" tic = datetime . now () self . build_yaxes () fig = go . Figure ( data = self . traces , layout = self . plt_layout ) html_str : str = pio . to_html ( fig = fig , validate = True , config = self . config , ) html_str = html_str . replace ( json . dumps ( self . _copy_button [ \"click\" ]), self . _copyfunc ) toc = datetime . now () - tic _LOGGER . debug ( \"Generated plot HTML in %.3f [s]\" , toc . total_seconds ()) return html_str def to_file ( self , filename : Path | str = None ) -> Path : if filename is None : if \"name\" in self . traces [ 0 ] . keys (): filename = Path ( f ' { self . traces [ 0 ][ \"name\" ] } .html' ) else : filename = Path ( \"plt.html\" ) with open ( filename , \"w\" , encoding = \"utf-8\" ) as f : f . write ( self . to_html ()) return filename def to_fig ( self ) -> tuple [ go . Figure , dict ]: \"\"\"Return the plotly figure and config dict.\"\"\" self . build_yaxes () fig = go . Figure ( data = self . traces , layout = self . plt_layout ) return fig , self . config def to_dict ( self ) -> dict : \"\"\"Return dictionary of plot\"\"\" self . build_yaxes () return { \"data\" : self . traces , \"layout\" : self . plt_layout } def plot ( self ): \"\"\"Plot.\"\"\" # fig = go.Figure(data=self.traces, layout=self.plt_layout) # fig.show() html_str = self . to_html () pbr . open_html_in_browser ( html_str ) def save ( self , filename : str , open_after : bool = False ): \"\"\"Save HTML.\"\"\" html_str = self . to_html () path = Path ( filename ) path . write_text ( html_str , encoding = \"utf-8\" ) if open_after : url = path . absolute () . as_uri () webbrowser . open ( url ) def to_image ( self , img_format : str = \"svg\" , width : int = None , height : int = None , as_b64 : bool = False , ) -> bytes : \"\"\"Return image bytes.\"\"\" self . build_yaxes () fig = go . Figure ( data = self . traces , layout = self . plt_layout ) res = pio . to_image ( fig = fig , format = img_format , width = width , height = height ) if as_b64 : res = b64encode ( res ) return res def export2pdf ( self , filename : str | Path , width : int = None , height : int = None ): \"\"\"Export plot to PDF.\"\"\" self . build_yaxes () fig = go . Figure ( data = self . traces , layout = self . plt_layout ) pio . write_image ( fig = fig , file = filename , format = \"pdf\" , width = width , height = height )","title":"Plot"},{"location":"reference/ccg/ui/plot/#ccg.ui.plot.Plot.append_trace","text":"Append trace to traces. Source code in ccg\\ui\\plot.py 1320 1321 1322 1323 1324 1325 1326 def append_trace ( self , trace : dict | list [ dict ]): \"Append trace to traces.\" if isinstance ( trace , list ): self . traces . extend ( trace ) else : self . traces . append ( trace ) self . ntrace += 1","title":"append_trace"},{"location":"reference/ccg/ui/plot/#ccg.ui.plot.Plot.append_trace_from_scatter","text":"build trace from Scatter and append Source code in ccg\\ui\\plot.py 1312 1313 1314 1315 1316 1317 1318 def append_trace_from_scatter ( self , scatter : ScatterData ): \"\"\"build trace from Scatter and append\"\"\" try : trace = self . build_traces_from_scatter ( scatter ) self . append_trace ( trace ) except ( NotImplementedError , KeyError ) as err : _LOGGER . warning ( \" %s . Skipped %s .\" , err , scatter . name )","title":"append_trace_from_scatter"},{"location":"reference/ccg/ui/plot/#ccg.ui.plot.Plot.append_trace_from_sig","text":"Build trace from sig and append to traces. Source code in ccg\\ui\\plot.py 1296 1297 1298 1299 1300 1301 1302 def append_trace_from_sig ( self , sig : Sig , yaxis : str = None , color : int = None ): \"\"\"Build trace from sig and append to traces.\"\"\" try : trace = self . build_trace_from_sig ( sig , yaxis = yaxis , color = color ) self . append_trace ( trace ) except NotImplementedError as err : _LOGGER . warning ( \" %s . Skipped %s .\" , err , sig . name )","title":"append_trace_from_sig"},{"location":"reference/ccg/ui/plot/#ccg.ui.plot.Plot.append_trace_from_tbl","text":"build trace from table and append Source code in ccg\\ui\\plot.py 1304 1305 1306 1307 1308 1309 1310 def append_trace_from_tbl ( self , tbl : Tbl ): \"\"\"build trace from table and append\"\"\" try : trace = self . build_traces_from_tbl ( tbl ) self . append_trace ( trace ) except ( NotImplementedError , KeyError ) as err : _LOGGER . warning ( \" %s . Skipped %s .\" , err , tbl . name )","title":"append_trace_from_tbl"},{"location":"reference/ccg/ui/plot/#ccg.ui.plot.Plot.build_0d_traces","text":"Build traces for 0d param Source code in ccg\\ui\\plot.py 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 def build_0d_traces ( self , param : Tbl , color : int , ntrace : int , unit : str ): \"\"\"Build traces for 0d param\"\"\" traces = [] yaxis = f \"y { self . nyaxes + 1 } \" hov_temp = ( f \"\"\" { param . name } : % {{ y:. { param . precision } f }} [ { unit } ]<extra></extra>\"\"\" ) try : tmp_trc = { \"type\" : \"scattergl\" , \"y\" : param . orig . data , \"name\" : param . orig . name , \"mode\" : \"markers\" , \"yaxis\" : yaxis , \"opacity\" : 1 , \"hovertemplate\" : hov_temp , \"marker\" : { \"size\" : 8 , \"color\" : self . TRACES [ ntrace % self . n_colors ], \"line\" : { \"color\" : ccg . util . max_contrast ( self . _plt_layout [ \"plot_bgcolor\" ], ccg . util . shift_lightness ( self . TRACES [ ntrace % self . n_colors ], 1.4 ), ccg . util . shift_lightness ( self . TRACES [ ntrace % self . n_colors ], 0.4 ), ), \"width\" : 1 , }, }, \"hoverlabel\" : { \"bgcolor\" : self . TRACES [ ntrace % self . n_colors ]}, \"showlegend\" : True , \"legendgroup\" : f \" { param . orig . name } _ { ntrace } \" , } traces . append ( tmp_trc ) ntrace += 1 except KeyError : pass if color is None : color = ntrace tmp_trc = { \"type\" : \"scattergl\" , \"y\" : param . data , \"name\" : param . name , \"mode\" : \"markers\" , \"hovertemplate\" : hov_temp , \"opacity\" : 1 , \"marker\" : { \"size\" : 8 , \"color\" : self . TRACES [ color % self . n_colors ], \"line\" : { \"color\" : ccg . util . max_contrast ( self . _plt_layout [ \"plot_bgcolor\" ], ccg . util . shift_lightness ( self . TRACES [ color % self . n_colors ], 1.4 ), ccg . util . shift_lightness ( self . TRACES [ color % self . n_colors ], 0.4 ), ), \"width\" : 1 , }, }, \"hoverlabel\" : { \"bgcolor\" : self . TRACES [ color % self . n_colors ]}, \"showlegend\" : True , \"legendgroup\" : f \" { param . name } _ { ntrace } \" , } traces . append ( tmp_trc ) ntrace += 1 nscatter = 0 for scatter in param . scatter_data : if scatter is not None : # plot the scatter data as well. nscatter += 1 tmp_trc = self . build_scatter_trace ( scatter = scatter , param = param , ntrace = ntrace , nscatter = nscatter ) traces . append ( tmp_trc ) ntrace += 1 self . yaxes [ yaxis ] = { \"unit\" : param . unit , \"min\" : param . data_range [ 0 ], \"max\" : param . data_range [ 1 ], \"dtype\" : self . compat_types [ np . where ([ param . data . dtype . kind in t for t in self . compat_types ])[ 0 ][ 0 ] # r-worded way to get the index of the match ], \"color\" : self . WHITE , \"fixed_range\" : False , } return traces","title":"build_0d_traces"},{"location":"reference/ccg/ui/plot/#ccg.ui.plot.Plot.build_1d_traces","text":"Build traces for 1d param Source code in ccg\\ui\\plot.py 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 def build_1d_traces ( self , param : Tbl , color : int , ntrace : int , unit : str ): \"\"\"Build traces for 1d param\"\"\" traces = [] yaxis = f \"y { self . nyaxes + 1 } \" hov_temp = f \"\"\" { param . name } : % {{ y:. { param . precision } f }} [ { unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } f }} [ { param . axes [ 0 ] . unit } ]<extra></extra>\"\"\" try : tmp_trc = { \"type\" : \"scattergl\" , \"y\" : param . orig . data , \"x\" : param . orig . axes [ 0 ] . data , \"name\" : param . orig . name , \"mode\" : \"markers+lines\" , \"yaxis\" : yaxis , \"opacity\" : 1 , \"hovertemplate\" : hov_temp , \"marker\" : { \"size\" : np . array ([ 10 ] * param . orig . data . size ), \"color\" : self . TRACES [ ntrace % self . n_colors ], \"line\" : { \"color\" : ccg . util . max_contrast ( self . _plt_layout [ \"plot_bgcolor\" ], ccg . util . shift_lightness ( self . TRACES [ ntrace % self . n_colors ], 1.4 ), ccg . util . shift_lightness ( self . TRACES [ ntrace % self . n_colors ], 0.4 ), ), \"width\" : 1 , }, }, \"line\" : { \"width\" : 1 , \"shape\" : self . LINESHAPE [ param . orig . axes [ 0 ] . interp_method ], \"color\" : self . TRACES [ ntrace % self . n_colors ], }, \"hoverlabel\" : { \"bgcolor\" : self . TRACES [ ntrace % self . n_colors ]}, \"showlegend\" : True , \"legendgroup\" : f \" { param . orig . name } _ { ntrace } \" , } traces . append ( tmp_trc ) ntrace += 1 except KeyError : pass if color is None : color = ntrace tmp_trc = { \"type\" : \"scattergl\" , \"y\" : param . data , \"x\" : param . axes [ 0 ] . data , \"name\" : param . name , \"mode\" : \"markers+lines\" , \"hovertemplate\" : hov_temp , \"opacity\" : 1 , \"marker\" : { \"size\" : np . array ([ 10 ] * param . data . size ), \"color\" : self . TRACES [ color % self . n_colors ], \"line\" : { \"color\" : ccg . util . max_contrast ( self . _plt_layout [ \"plot_bgcolor\" ], ccg . util . shift_lightness ( self . TRACES [ color % self . n_colors ], 1.4 ), ccg . util . shift_lightness ( self . TRACES [ color % self . n_colors ], 0.4 ), ), \"width\" : 1 , }, }, \"line\" : { \"width\" : 1 , \"shape\" : self . LINESHAPE [ param . axes [ 0 ] . interp_method ], \"color\" : self . TRACES [ color % self . n_colors ], }, \"hoverlabel\" : { \"bgcolor\" : self . TRACES [ color % self . n_colors ]}, \"showlegend\" : True , \"legendgroup\" : f \" { param . name } _ { ntrace } \" , } traces . append ( tmp_trc ) ntrace += 1 nscatter = 0 for scatter in param . scatter_data : if scatter is not None : # plot the scatter data as well. nscatter += 1 tmp_trc = self . build_scatter_trace ( scatter = scatter , param = param , ntrace = ntrace , nscatter = nscatter ) traces . append ( tmp_trc ) ntrace += 1 self . yaxes [ yaxis ] = { \"unit\" : param . unit , \"min\" : param . data_range [ 0 ], \"max\" : param . data_range [ 1 ], \"dtype\" : self . compat_types [ np . where ([ param . data . dtype . kind in t for t in self . compat_types ])[ 0 ][ 0 ] # r-worded way to get the index of the match ], \"color\" : self . WHITE , \"fixed_range\" : False , } return traces","title":"build_1d_traces"},{"location":"reference/ccg/ui/plot/#ccg.ui.plot.Plot.build_2d_traces","text":"build traces from 2d param Source code in ccg\\ui\\plot.py 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 def build_2d_traces ( self , param : Tbl , color : int , ntrace : int , unit : str ): \"\"\"build traces from 2d param\"\"\" traces = [] try : traces . extend ( self . build_surf_traces ( param . orig , ntrace - 1 , ntrace , unit , visible = True ) ) ntrace += 1 except KeyError : pass if color is None : color = ntrace - 1 traces . extend ( self . build_surf_traces ( param , color , ntrace , unit )) ntrace += 1 nscatter = 0 for scatter in param . scatter_data : if scatter is not None : # plot the scatter data as well. nscatter += 1 tmp_trc = self . build_scatter_trace ( scatter = scatter , param = param , ntrace = ntrace , nscatter = nscatter ) traces . append ( tmp_trc ) ntrace += 1 xaxis = copy . deepcopy ( self . _scene_axis ) xaxis . update ( { \"title\" : { \"text\" : f \" { param . axes [ 0 ] . name } [ { param . axes [ 0 ] . unit } ]\" }} ) yaxis = copy . deepcopy ( self . _scene_axis ) yaxis . update ( { \"title\" : { \"text\" : f \" { param . axes [ 1 ] . name } [ { param . axes [ 1 ] . unit } ]\" }} ) zaxis = copy . deepcopy ( self . _scene_axis ) zaxis . update ({ \"title\" : { \"text\" : f \" { param . name } [ { param . unit } ]\" }}) scene = { \"scene\" : { \"xaxis\" : xaxis , \"yaxis\" : yaxis , \"zaxis\" : zaxis , \"camera\" : { \"eye\" : { \"x\" : - 1.25 , \"y\" : - 1.25 , \"z\" : 1.1 }}, } } ccg . util . merge_dict ( self . plt_layout , scene ) return traces","title":"build_2d_traces"},{"location":"reference/ccg/ui/plot/#ccg.ui.plot.Plot.build_scatter_trace","text":"Builds a scatter trace. ntrace and nscatter are counters for color increments Source code in ccg\\ui\\plot.py 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935 936 937 938 939 940 941 942 943 944 945 946 947 948 949 950 951 952 953 954 955 956 957 958 959 960 961 962 963 964 965 966 967 968 969 970 971 972 973 974 975 976 977 978 979 def build_scatter_trace ( self , scatter : ScatterData , param : Tbl = None , ntrace : int = 1 , nscatter : int = 1 , ): \"\"\"Builds a scatter trace. ntrace and nscatter are counters for color increments\"\"\" ndim = scatter . ndim tmp_trc = { \"name\" : scatter . name , \"mode\" : \"markers\" , \"opacity\" : 1 , \"marker\" : { \"size\" : 3 , \"color\" : self . TRACES [ ntrace % self . n_colors ], \"colorscale\" : [ [ 0 , self . TRACES [ ntrace % self . n_colors ]], [ 1 , self . TRACES [ ntrace % self . n_colors ]], ], \"showscale\" : False , }, \"hoverlabel\" : { \"bgcolor\" : self . TRACES [ ntrace % self . n_colors ]}, \"showlegend\" : True , \"legendgroup\" : f \" { scatter . name } _ { ntrace } \" , } if scatter . color is not None : tmp = { \"marker\" : { \"color\" : scatter . color , \"colorscale\" : self . TURBO , \"colorbar\" : { \"bgcolor\" : self . THEME3 , \"bordercolor\" : self . THEME4 , \"borderwidth\" : 1 , \"title\" : { \"text\" : f \" { scatter . color_label } [ { scatter . color_unit } ]\" , \"side\" : \"right\" , }, \"x\" : 0 , }, \"showscale\" : True , }, \"text\" : np . round ( scatter . color , scatter . color_precision ), } if scatter . color_range is not None : ccg . util . merge_dict ( tmp , { \"marker\" : { \"cmin\" : scatter . color_range [ 0 ], \"cmax\" : scatter . color_range [ 1 ], } }, ) # Need to move legend to clear color bar. tmp_lgnd = { \"legend\" : { \"xanchor\" : \"right\" , \"yanchor\" : \"top\" , \"x\" : 1 , \"y\" : 1 , }, } ccg . util . merge_dict ( self . plt_layout , tmp_lgnd ) ccg . util . merge_dict ( tmp_trc , tmp ) if ndim == 2 : if param is not None : if scatter . color is not None : hov_temp = f \"\"\" { scatter . name } : % {{ z:. { param . precision } f }} [ { param . unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } f }} [ { param . axes [ 0 ] . unit } ]<br> { param . axes [ 1 ] . name } : % {{ y:. { param . axes [ 1 ] . precision } f }} [ { param . axes [ 1 ] . unit } ]<br> { scatter . color_label } : % {{ marker.color:. { scatter . color_precision } f }} [ { scatter . color_unit } ] <extra></extra>\"\"\" else : hov_temp = f \"\"\" { scatter . name } : % {{ z:. { param . precision } d }} [ { param . unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } d }} [ { param . axes [ 0 ] . unit } ]<br> { param . axes [ 1 ] . name } : % {{ y:. { param . axes [ 1 ] . precision } d }} [ { param . axes [ 1 ] . unit } ] <extra></extra>\"\"\" else : if scatter . color is not None : hov_temp = \"\" tmp = { \"type\" : \"scatter3d\" , \"x\" : scatter . data [ 0 ], \"y\" : scatter . data [ 1 ], \"z\" : scatter . data [ 2 ], \"hovertemplate\" : hov_temp , } elif ndim == 1 : if param is not None : if scatter . color is not None : hov_temp = f \"\"\" { scatter . name } : % {{ y:. { param . precision } f }} [ { param . unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } f }} [ { param . axes [ 0 ] . unit } ]<br> { scatter . color_label } : % {{ marker.color:. { scatter . color_precision } f }} [ { scatter . color_unit } ] <extra></extra>\"\"\" else : hov_temp = f \"\"\" { scatter . name } : % {{ y:. { param . precision } d }} [ { param . unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } d }} [ { param . axes [ 0 ] . unit } ]<br> <extra></extra>\"\"\" else : hov_temp = \"\" tmp = { \"type\" : \"scattergl\" , \"x\" : scatter . data [ 0 ], \"y\" : scatter . data [ 1 ], \"hovertemplate\" : hov_temp , } elif ndim == 0 : if param is not None : if scatter . color is not None : hov_temp = f \"\"\" { scatter . name } : % {{ y:. { param . precision } f }} [ { param . unit } ]<br> { scatter . color_label } : % {{ marker.color:. { scatter . color_precision } f }} [ { scatter . color_unit } ] <extra></extra>\"\"\" else : hov_temp = f \"\"\" { scatter . name } : % {{ y:. { param . precision } d }} [ { param . unit } ]<br> <extra></extra>\"\"\" else : hov_temp = \"\" tmp = { \"type\" : \"scattergl\" , \"x\" : scatter . data [ 0 ] * 0 , \"y\" : scatter . data [ 1 ], \"hovertemplate\" : hov_temp , } else : raise NotImplementedError ccg . util . merge_dict ( tmp_trc , tmp ) if nscatter > 1 : ccg . util . merge_dict ( tmp_trc , { \"visible\" : \"legendonly\" }) return tmp_trc","title":"build_scatter_trace"},{"location":"reference/ccg/ui/plot/#ccg.ui.plot.Plot.build_surf_traces","text":"Build 2d surface trace Source code in ccg\\ui\\plot.py 981 982 983 984 985 986 987 988 989 990 991 992 993 994 995 996 997 998 999 1000 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 1073 1074 1075 def build_surf_traces ( self , param : Tbl , color : int , ntrace : int , unit : str , visible : bool = True , ): \"\"\"Build 2d surface trace\"\"\" if not visible : visible = \"legendonly\" hov_temp = f \"\"\" { param . name } : % {{ z:. { param . precision } f }} [ { param . unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } f }} [ { param . axes [ 0 ] . unit } ]<br> { param . axes [ 1 ] . name } : % {{ y:. { param . axes [ 1 ] . precision } f }} [ { param . axes [ 1 ] . unit } ] <extra></extra>\"\"\" x , y = np . meshgrid ( param . axes [ 0 ] . data , param . axes [ 1 ] . data ) x = np . concatenate (( x , x [ - 1 , np . newaxis ])) y = np . concatenate (( y , y [ - 1 , np . newaxis ])) z = np . concatenate (( param . data . T , param . data . T [ - 1 , np . newaxis ] * np . NaN )) i = x . flatten ( \"F\" ) j = y . flatten ( \"F\" ) k = z . flatten ( \"F\" ) y , x = np . meshgrid ( param . axes [ 1 ] . data , param . axes [ 0 ] . data ) x = np . concatenate (( x , x [ - 1 , np . newaxis ])) y = np . concatenate (( y , y [ - 1 , np . newaxis ])) z = np . concatenate (( param . data , param . data [ - 1 , np . newaxis ] * np . NaN )) i = np . concatenate (( i , x . flatten ( \"F\" ))) j = np . concatenate (( j , y . flatten ( \"F\" ))) k = np . concatenate (( k , z . flatten ( \"F\" ))) traces = [ { \"type\" : \"surface\" , \"x\" : param . axes [ 0 ] . data , \"y\" : param . axes [ 1 ] . data , \"z\" : param . data . T , \"name\" : f \" { param . name }{ unit } \" , \"hovertemplate\" : hov_temp , \"hoverlabel\" : { \"bgcolor\" : self . TRACES [ color % self . n_colors ]}, \"opacity\" : 0.5 , \"colorscale\" : [ [ 0 , self . TRACES [ color % self . n_colors ]], [ 1 , self . TRACES [ color % self . n_colors ]], ], \"showlegend\" : True , \"legendgroup\" : f \" { param . name } _ { ntrace } \" , \"showscale\" : False , \"visible\" : visible , }, { \"type\" : \"scatter3d\" , \"x\" : i , \"y\" : j , \"z\" : k , \"name\" : f \" { param . name }{ unit } \" , \"hoverinfo\" : \"skip\" , \"opacity\" : 1 , \"marker\" : { \"color\" : np . array ([ self . TRACES [ color % self . n_colors ]] * len ( i )), \"size\" : np . array ([ 10 ] * len ( i )), # \"line\": { # \"color\": ccg.util.max_contrast( # self.TRACES[color % self.n_colors], # ccg.util.shift_lightness( # self.TRACES[color % self.n_colors], 1.4 # ), # ccg.util.shift_lightness( # self.TRACES[color % self.n_colors], 0.4 # ), # ), # \"width\": 1, # }, }, \"line\" : { \"color\" : ccg . util . max_contrast ( self . TRACES [ color % self . n_colors ], ccg . util . shift_lightness ( self . TRACES [ color % self . n_colors ], 1.4 ), ccg . util . shift_lightness ( self . TRACES [ color % self . n_colors ], 0.4 ), ), \"width\" : 2 , }, \"showlegend\" : False , \"legendgroup\" : f \" { param . name } _ { ntrace } \" , \"connectgaps\" : False , \"visible\" : visible , }, ] return traces","title":"build_surf_traces"},{"location":"reference/ccg/ui/plot/#ccg.ui.plot.Plot.build_trace","text":"Build Trace for plotly. Source code in ccg\\ui\\plot.py 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 def build_trace ( self , x : npt . NDArray , y : npt . NDArray , signame : str = None , sigunit : str = None , connect_gaps : bool = None , yaxis : str = None , color : int = None , ): \"\"\"Build Trace for plotly.\"\"\" ntrace = self . ntrace + 1 if color is None : color = ntrace yaxis = self . find_yaxis ( Sig ( data = y , tline = TLine ( x ), name = signame , unit = sigunit ), yaxis = yaxis ) # TODO: Implement find_yaxis for non sigs sigunit = \"\" if sigunit is None else sigunit trace = { \"type\" : \"scattergl\" , \"y\" : y , \"x\" : x , \"name\" : f \" { signame } [ { sigunit } ]\" , \"mode\" : \"markers+lines\" , \"hovertemplate\" : \"\"\"Value: % {y:.2f} % {yaxis.title.text} <br> X: % {x:.2f} % {xaxis.title.text} \"\"\" , \"yaxis\" : yaxis , \"opacity\" : 1 , \"connectgaps\" : bool ( connect_gaps ), \"marker\" : { \"size\" : [ 2 ] * len ( y ), \"line\" : { \"color\" : ccg . util . max_contrast ( self . _plt_layout [ \"plot_bgcolor\" ], ccg . util . shift_lightness ( self . TRACES [ color % self . n_colors ], 1.4 ), ccg . util . shift_lightness ( self . TRACES [ color % self . n_colors ], 0.4 ), ), \"width\" : 1 , }, }, \"line\" : { \"width\" : 1 , \"color\" : self . TRACES [ color % self . n_colors ], }, } return trace","title":"build_trace"},{"location":"reference/ccg/ui/plot/#ccg.ui.plot.Plot.build_trace_from_sig","text":"Build Trace for plotly from a Sig. Source code in ccg\\ui\\plot.py 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 def build_trace_from_sig ( self , sig : Sig , color : int = None , yaxis : str = None ): \"\"\"Build Trace for plotly from a Sig.\"\"\" ntrace = self . ntrace + 1 if color is None : color = ntrace if self . plot_prep : sig = sig . plot_prep () yaxis = self . find_yaxis ( sig , yaxis ) unit = \"\" if sig . unit is None else sig . unit if sig . tline [ 0 ] < 32000000 : # apprx 1yr from epoch # assume this is an elapsed time instead x = sig . tline . unix hov_temp = \"\"\" Value: % {y:.2f} % {yaxis.title.text} <br> Time: % {x:.3f} [s]\"\"\" self . update_axis ( axis = \"xaxis1\" , title = \"Elapsed Time\" , unit = \"S\" ) else : x = sig . tline . iso hov_temp = \"\"\" Value: % {y:.2f} % {yaxis.title.text} <br> Time: %{x|%H:%M:%S.%L}\"\"\" self . update_axis ( axis = \"xaxis1\" , title = \"Date and Time\" ) if sig . nsamples > 100000 : hov = \"skip\" # Disable hover since its too slow hov_temp = \"\" else : hov = \"all\" trace = { \"type\" : \"scattergl\" , \"y\" : sig . data , \"x\" : x , \"name\" : f \" { sig . name } [ { unit } ]\" , \"mode\" : \"markers+lines\" , \"hovertemplate\" : hov_temp , \"hoverinfo\" : hov , \"yaxis\" : yaxis , \"opacity\" : 1 , \"connectgaps\" : bool ( sig . connect_gaps ), # should work if connect_gaps is None \"marker\" : { # \"color\": TRACES[self.ntrace], \"size\" : [ 2 ] * len ( x ), \"line\" : { \"color\" : ccg . util . max_contrast ( self . _plt_layout [ \"plot_bgcolor\" ], ccg . util . shift_lightness ( self . TRACES [ color % self . n_colors ], 1.4 ), ccg . util . shift_lightness ( self . TRACES [ color % self . n_colors ], 0.4 ), ), \"width\" : 1 , }, }, \"line\" : { \"width\" : 1 , \"shape\" : self . LINESHAPE [ sig . interp_method ], \"color\" : self . TRACES [ color % self . n_colors ], }, } if sig . base_data is not None : ccg . util . merge_dict ( trace , { \"text\" : sig . base_data , \"hovertemplate\" : \"\"\"Value: % {text} <br> Time: %{x|%H:%M:%S.%L}\"\"\" , }, ) return trace","title":"build_trace_from_sig"},{"location":"reference/ccg/ui/plot/#ccg.ui.plot.Plot.build_traces_from_scatter","text":"Builds scatter data traces Source code in ccg\\ui\\plot.py 579 580 581 582 583 def build_traces_from_scatter ( self , scatter : ScatterData ): \"\"\"Builds scatter data traces\"\"\" # TODO: Implement support for more than 1 scatter if scatter is not None : return [ self . build_scatter_trace ( scatter = scatter )]","title":"build_traces_from_scatter"},{"location":"reference/ccg/ui/plot/#ccg.ui.plot.Plot.build_traces_from_tbl","text":"build trace from table. Source code in ccg\\ui\\plot.py 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 def build_traces_from_tbl ( self , tbl : Tbl , color : int = None ) -> list [ dict ]: \"\"\"build trace from table.\"\"\" ntrace = 1 # self.ntrace+1 Does it make sense to deal with multiple tbls in 1 plot? if tbl . unit is not None : unit = f \" [ { tbl . unit } ]\" else : unit = \"\" if tbl . n_dim == 2 : traces = self . build_2d_traces ( tbl , color , ntrace , unit ) elif tbl . n_dim == 1 : traces = self . build_1d_traces ( tbl , color , ntrace , unit ) elif tbl . n_dim == 0 : traces = self . build_0d_traces ( tbl , color , ntrace , unit ) else : raise NotImplementedError ( f \"Plot not implemented for n_dim = { tbl . n_dim } \" ) return traces","title":"build_traces_from_tbl"},{"location":"reference/ccg/ui/plot/#ccg.ui.plot.Plot.build_yaxes","text":"Build yaxes element for layout. Source code in ccg\\ui\\plot.py 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 1281 1282 1283 1284 1285 1286 1287 1288 def build_yaxes ( self ): \"\"\"Build yaxes element for layout.\"\"\" # tic = datetime.now() yaxes : dict [ str , dict ] = {} domain_min = 1 domain_min_name = \"y1\" # TODO: Handle domains better... for i , ( y_name , yaxis ) in enumerate ( self . yaxes . items ()): yaxis_tmp = copy . deepcopy ( yaxis ) # Since we will remove stuff from this later... name = y_name . replace ( \"y\" , \"yaxis\" ) if ( i % 2 ) == 0 : side = \"left\" pos = round ( i / 2 + 0.001 ) * self . fpos else : side = \"right\" pos = 1 - round ( i / 2 - 0.001 + 1 ) * self . fpos unit = yaxis_tmp . pop ( \"unit\" ) # Pop since its not a standard. _ = yaxis_tmp . pop ( \"dtype\" ) # not needed here data_range = [ yaxis_tmp . pop ( \"min\" ), yaxis_tmp . pop ( \"max\" )] if not yaxis_tmp . pop ( \"fixed_range\" ): data_range = False # Not sure im ready to use this yet. title = \"\" if unit is None else f \"[ { unit } ]\" ccg . util . merge_dict ( yaxes , { name : { \"title\" : { \"text\" : title }, \"overlaying\" : \"y1\" , \"anchor\" : \"x1\" , \"position\" : pos , \"color\" : yaxis_tmp [ \"color\" ], \"gridcolor\" : yaxis_tmp [ \"color\" ], \"showgrid\" : True , \"showline\" : True , \"mirror\" : True , \"side\" : side , \"spikesnap\" : \"hovered data\" , \"spikemode\" : \"across+marker\" , \"spikedash\" : \"solid\" , \"spikethickness\" : 1 , \"ticks\" : \"outside\" , \"ticklen\" : 3 , \"zerolinecolor\" : yaxis_tmp [ \"color\" ], \"zerolinewidth\" : 2 , } }, ) ccg . util . merge_dict ( yaxes [ name ], yaxis_tmp ) if data_range : ccg . util . merge_dict ( yaxes [ name ], { \"range\" : data_range , }, ) if i > 0 : del yaxes [ f \"yaxis { i } \" ][ \"anchor\" ] # to allow spacing multiple if \"domain\" in yaxis_tmp : if yaxis_tmp [ \"domain\" ][ 0 ] < domain_min : domain_min = yaxis_tmp [ \"domain\" ][ 0 ] domain_min_name = y_name if not yaxes : return del yaxes [ \"yaxis1\" ][ \"overlaying\" ] # to allow hover to work try : # TODO: Improve this for more domains del yaxes [ domain_min_name . replace ( \"y\" , \"yaxis\" )][ \"overlaying\" ] except KeyError : pass ccg . util . merge_dict ( self . plt_layout , yaxes ) self . plt_layout [ \"xaxis1\" ][ \"domain\" ] = [ ( round (( self . nyaxes ) / 2 + 0.001 ) - 1 ) * self . fpos , 1 - round ( self . nyaxes / 2 - 0.001 ) * self . fpos , ] # +0.001 since python is r-worded self . plt_layout [ \"xaxis1\" ][ \"anchor\" ] = domain_min_name","title":"build_yaxes"},{"location":"reference/ccg/ui/plot/#ccg.ui.plot.Plot.export2pdf","text":"Export plot to PDF. Source code in ccg\\ui\\plot.py 1399 1400 1401 1402 1403 1404 1405 def export2pdf ( self , filename : str | Path , width : int = None , height : int = None ): \"\"\"Export plot to PDF.\"\"\" self . build_yaxes () fig = go . Figure ( data = self . traces , layout = self . plt_layout ) pio . write_image ( fig = fig , file = filename , format = \"pdf\" , width = width , height = height )","title":"export2pdf"},{"location":"reference/ccg/ui/plot/#ccg.ui.plot.Plot.find_yaxis","text":"Check for matching y axes. Source code in ccg\\ui\\plot.py 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 1201 1202 1203 1204 def find_yaxis ( self , sig : Sig , yaxis : str = None ): \"\"\"Check for matching y axes.\"\"\" if sig . data_range is not None : sig_min = sig . data_range [ 0 ] sig_max = sig . data_range [ 1 ] fixed_range = True else : sig_min = sig . min sig_max = sig . max fixed_range = False if yaxis is not None : if yaxis in self . yaxes : try : if \"U\" in self . yaxes [ yaxis ][ \"dtype\" ]: # its a string type so no scaling info self . yaxes [ yaxis ][ \"color\" ] = self . WHITE # change to grey for multi return yaxis yrange = self . yaxes [ yaxis ][ \"max\" ] - self . yaxes [ yaxis ][ \"min\" ] sigrange = sig_max - sig_min if yrange == 0 : yrange = self . yaxes [ yaxis ][ \"min\" ] self . yaxes [ yaxis ][ \"color\" ] = self . WHITE # change to grey for multi # Should we update the max and min here? could let it expand to inf... # Maybe an average? if fixed_range : self . yaxes [ yaxis ][ \"fixed_range\" ] = fixed_range self . yaxes [ yaxis ][ \"min\" ] = ( self . yaxes [ yaxis ][ \"min\" ] + sig_min ) / 2 self . yaxes [ yaxis ][ \"max\" ] = ( self . yaxes [ yaxis ][ \"max\" ] + sig_max ) / 2 return yaxis except TypeError : # For the case of dtype=obj and not compat pass else : self . nyaxes += 1 self . yaxes [ yaxis ] = { \"unit\" : sig . unit , \"min\" : sig_min , \"max\" : sig_max , \"dtype\" : self . compat_types [ np . where ([ sig . data . dtype . kind in t for t in self . compat_types ])[ 0 ][ 0 ] # r-worded way to get the index of the match ], \"color\" : ccg . util . max_contrast ( self . THEME2 , ccg . util . shift_lightness ( self . TRACES [( self . ntrace + 1 ) % self . n_colors ], 1.4 ), ccg . util . shift_lightness ( self . TRACES [( self . ntrace + 1 ) % self . n_colors ], 0.4 ), ), \"fixed_range\" : fixed_range , } return yaxis else : if self . nyaxes > 0 : for yaxis , yaxis_def in self . yaxes . items (): if ( sig . data . dtype . kind in yaxis_def [ \"dtype\" ] and yaxis_def [ \"unit\" ] == sig . unit ): try : if \"U\" in yaxis_def [ \"dtype\" ]: # its a string type so no scaling info yaxis_def [ \"color\" ] = ( self . WHITE ) # change to grey for multi return yaxis yrange = yaxis_def [ \"max\" ] - yaxis_def [ \"min\" ] sigrange = sig_max - sig_min if yrange == 0 : yrange = yaxis_def [ \"min\" ] if ( sig_min > yaxis_def [ \"min\" ] - ( yrange * self . frange / 2 ) and sig_max < yaxis_def [ \"max\" ] + ( yrange * self . frange / 2 ) and sigrange < yrange * self . frange and sigrange > yrange / self . frange ): yaxis_def [ \"color\" ] = ( self . WHITE ) # change to grey for multi # Should we update the max and min here? could let it expand to inf... # Maybe an average? if fixed_range : yaxis_def [ \"fixed_range\" ] = fixed_range yaxis_def [ \"min\" ] = ( yaxis_def [ \"min\" ] + sig_min ) / 2 yaxis_def [ \"max\" ] = ( yaxis_def [ \"max\" ] + sig_max ) / 2 return yaxis except TypeError : # For the case of dtype=obj and not compat pass self . nyaxes += 1 yaxis = f \"y { self . nyaxes } \" self . yaxes [ yaxis ] = { \"unit\" : sig . unit , \"min\" : sig_min , \"max\" : sig_max , \"dtype\" : self . compat_types [ np . where ([ sig . data . dtype . kind in t for t in self . compat_types ])[ 0 ][ 0 ] # r-worded way to get the index of the match ], \"color\" : ccg . util . max_contrast ( self . THEME2 , ccg . util . shift_lightness ( self . TRACES [( self . ntrace + 1 ) % self . n_colors ], 1.4 ), ccg . util . shift_lightness ( self . TRACES [( self . ntrace + 1 ) % self . n_colors ], 0.4 ), ), \"fixed_range\" : fixed_range , } return yaxis","title":"find_yaxis"},{"location":"reference/ccg/ui/plot/#ccg.ui.plot.Plot.plot","text":"Plot. Source code in ccg\\ui\\plot.py 1368 1369 1370 1371 1372 1373 def plot ( self ): \"\"\"Plot.\"\"\" # fig = go.Figure(data=self.traces, layout=self.plt_layout) # fig.show() html_str = self . to_html () pbr . open_html_in_browser ( html_str )","title":"plot"},{"location":"reference/ccg/ui/plot/#ccg.ui.plot.Plot.save","text":"Save HTML. Source code in ccg\\ui\\plot.py 1375 1376 1377 1378 1379 1380 1381 1382 def save ( self , filename : str , open_after : bool = False ): \"\"\"Save HTML.\"\"\" html_str = self . to_html () path = Path ( filename ) path . write_text ( html_str , encoding = \"utf-8\" ) if open_after : url = path . absolute () . as_uri () webbrowser . open ( url )","title":"save"},{"location":"reference/ccg/ui/plot/#ccg.ui.plot.Plot.to_dict","text":"Return dictionary of plot Source code in ccg\\ui\\plot.py 1363 1364 1365 1366 def to_dict ( self ) -> dict : \"\"\"Return dictionary of plot\"\"\" self . build_yaxes () return { \"data\" : self . traces , \"layout\" : self . plt_layout }","title":"to_dict"},{"location":"reference/ccg/ui/plot/#ccg.ui.plot.Plot.to_fig","text":"Return the plotly figure and config dict. Source code in ccg\\ui\\plot.py 1357 1358 1359 1360 1361 def to_fig ( self ) -> tuple [ go . Figure , dict ]: \"\"\"Return the plotly figure and config dict.\"\"\" self . build_yaxes () fig = go . Figure ( data = self . traces , layout = self . plt_layout ) return fig , self . config","title":"to_fig"},{"location":"reference/ccg/ui/plot/#ccg.ui.plot.Plot.to_html","text":"Generate the HTML string for plot. Source code in ccg\\ui\\plot.py 1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 def to_html ( self ) -> str : \"\"\"Generate the HTML string for plot.\"\"\" tic = datetime . now () self . build_yaxes () fig = go . Figure ( data = self . traces , layout = self . plt_layout ) html_str : str = pio . to_html ( fig = fig , validate = True , config = self . config , ) html_str = html_str . replace ( json . dumps ( self . _copy_button [ \"click\" ]), self . _copyfunc ) toc = datetime . now () - tic _LOGGER . debug ( \"Generated plot HTML in %.3f [s]\" , toc . total_seconds ()) return html_str","title":"to_html"},{"location":"reference/ccg/ui/plot/#ccg.ui.plot.Plot.to_image","text":"Return image bytes. Source code in ccg\\ui\\plot.py 1384 1385 1386 1387 1388 1389 1390 1391 1392 1393 1394 1395 1396 1397 def to_image ( self , img_format : str = \"svg\" , width : int = None , height : int = None , as_b64 : bool = False , ) -> bytes : \"\"\"Return image bytes.\"\"\" self . build_yaxes () fig = go . Figure ( data = self . traces , layout = self . plt_layout ) res = pio . to_image ( fig = fig , format = img_format , width = width , height = height ) if as_b64 : res = b64encode ( res ) return res","title":"to_image"},{"location":"reference/ccg/ui/plot/#ccg.ui.plot.Plot.update_axis","text":"Update axis info. Source code in ccg\\ui\\plot.py 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 def update_axis ( self , axis : str = \"xaxis1\" , title : str = None , unit : str = None , min_range : float = None , max_range : float = None , ): \"\"\"Update axis info.\"\"\" if title is not None : if unit is not None : ccg . util . merge_dict ( self . plt_layout , { axis : { \"title\" : { \"text\" : f \" { title } [ { unit } ]\" }}} ) else : ccg . util . merge_dict ( self . plt_layout , { axis : { \"title\" : { \"text\" : f \" { title } \" }}} ) ccg . util . merge_dict ( self . plt_layout , { axis : { \"range\" : [ min_range , max_range ]}})","title":"update_axis"},{"location":"reference/ccg/ui/plot/#ccg.ui.plot.PlotConfig","text":"Plot configuration. Source code in ccg\\ui\\plot.py 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 class PlotConfig : \"\"\"Plot configuration.\"\"\" def __init__ ( self , name : str = None , traces : list [ dict ] = None , layout : dict = None , ): self . name = name if not isinstance ( traces , list ): traces = [ traces ] self . traces = traces self . layout = layout def to_dict ( self ): \"\"\"Returns a dictionary\"\"\" res = { \"name\" : self . name , \"traces\" : self . traces , \"layout\" : self . layout , } return res def __repr__ ( self ): \"\"\"repr.\"\"\" return json . dumps ( self . to_dict ())","title":"PlotConfig"},{"location":"reference/ccg/ui/plot/#ccg.ui.plot.PlotConfig.__repr__","text":"repr. Source code in ccg\\ui\\plot.py 56 57 58 def __repr__ ( self ): \"\"\"repr.\"\"\" return json . dumps ( self . to_dict ())","title":"__repr__"},{"location":"reference/ccg/ui/plot/#ccg.ui.plot.PlotConfig.to_dict","text":"Returns a dictionary Source code in ccg\\ui\\plot.py 47 48 49 50 51 52 53 54 def to_dict ( self ): \"\"\"Returns a dictionary\"\"\" res = { \"name\" : self . name , \"traces\" : self . traces , \"layout\" : self . layout , } return res","title":"to_dict"},{"location":"reference/ccg/ui/plot/#ccg.ui.plot.PlotConfigColl","text":"Collection of plot configurations. Source code in ccg\\ui\\plot.py 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 class PlotConfigColl : \"\"\"Collection of plot configurations.\"\"\" def __init__ ( self , plot_configs : list [ PlotConfig ] = None ): if not isinstance ( plot_configs , list ) and plot_configs is not None : plot_configs = [ plot_configs ] self . plot_configs = plot_configs def append ( self , plot : PlotConfig | list [ PlotConfig ]): \"\"\"append plot to collection.\"\"\" if not isinstance ( plot , list ): plot = [ plot ] if self . plot_configs is None : self . plot_configs = plot else : self . plot_configs . extend ( plot ) def build_plot ( self , frames : Frame | list [ Frame ]): \"\"\"build plot from plot config collection\"\"\" if not isinstance ( frames , list ): frames = [ frames ] plots = [] for plot_config in self . plot_configs : plot = Plot ( name = plot_config . name ) annot_list = [] annots = False n_annot = 0 if \"annotations\" in plot_config . layout : if any ( isinstance ( lyt [ \"x\" ], str ) or isinstance ( lyt [ \"y\" ], str ) for lyt in plot_config . layout [ \"annotations\" ] ): annots = plot_config . layout . pop ( \"annotations\" ) else : annot_list = plot_config . layout [ \"annotations\" ] for ref_trace in plot_config . traces : try : for frame in frames : trace = ref_trace group = { \"legendgroup\" : frame . name , \"legendgrouptitle\" : { \"text\" : frame . name }, } if \"x\" in trace : x = frame [ trace . pop ( \"x\" ) ] . data # pop out to not update later hov_temp = { \"hovertemplate\" : \"\"\"Y: % {y:.2f} % {yaxis.title.text} <br> X: % {x:.3f} % {xaxis.title.text} \"\"\" } else : if ( frame [ trace [ \"y\" ]] . tline [ 0 ] < 32000000 ): # apprx 1yr from epoch # assume this is an elapsed time instead x = frame [ trace [ \"y\" ]] . tline . unix hov_temp = { \"hovertemplate\" : \"\"\"Value: % {y:.2f} % {yaxis.title.text} <br> Time: % {x:.3f} % {xaxis.title.text} \"\"\" } else : x = frame [ trace [ \"y\" ]] . tline . iso hov_temp = { \"hovertemplate\" : \"\"\"Value: % {y:.2f} % {yaxis.title.text} <br> Time: %{x|%H:%M:%S.%L}\"\"\" } yname = trace [ \"y\" ] y = frame [ trace . pop ( \"y\" )] . data # pop out to not update later yaxis = trace [ \"yaxis\" ] if \"yaxis\" in trace else None plt_trace = plot . build_trace ( x = x , y = y , signame = yname , yaxis = yaxis ) ccg . util . merge_dict ( plt_trace , group ) ccg . util . merge_dict ( plt_trace , hov_temp ) ccg . util . merge_dict ( plt_trace , trace ) # Update with other settings in trace. plot . append_trace ( plt_trace ) if annots : # Calculate the annotation for note in annots : # pylint: disable=eval-used new_note = copy . deepcopy ( note ) if isinstance ( note [ \"x\" ], str ): txt = \"\" txt = re . findall ( r \"PARAM(?:\\.|\\[).*\" , note [ \"x\" ]) if txt : new_note [ \"x\" ] = eval ( txt [ 0 ] . replace ( \"PARAM\" , \"frame\" ) ) if isinstance ( note [ \"y\" ], str ): txt = \"\" txt = re . findall ( r \"PARAM(?:\\.|\\[).*\" , note [ \"y\" ]) if txt : new_note [ \"y\" ] = eval ( txt [ 0 ] . replace ( \"PARAM\" , \"frame\" ) ) # check text for fstring txt = \"\" txt = re . findall ( r \"f'.*'\" , note [ \"text\" ]) if txt : new_note [ \"text\" ] = eval ( txt [ 0 ] . replace ( \"PARAM\" , \"frame\" ) ) if \"ay\" in note : new_note [ \"ay\" ] = note [ \"ay\" ] * ( n_annot + 1 ) if \"arrowcolor\" not in note : new_note [ \"arrowcolor\" ] = plot . TRACES [ n_annot % len ( plot . TRACES ) ] if \"bordercolor\" not in note : new_note [ \"bordercolor\" ] = plot . TRACES [ n_annot % len ( plot . TRACES ) ] annot_list . append ( new_note ) n_annot += 1 except KeyError as err : _LOGGER . warning ( \" %s . Skipped %s .\" , err , \"trace\" ) layout = plot . plt_layout . copy () ccg . util . merge_dict ( layout , { \"annotations\" : annot_list }) # Need to extract y-axes from the layout since plot tools build the yaxes at the end tmp_yaxes = {} list_to_remove = [] for key in layout : if key . startswith ( \"yaxis\" ): tmp_yaxes [ key . replace ( \"yaxis\" , \"y\" )] = layout [ key ] list_to_remove . append ( key ) for key in list_to_remove : layout . pop ( key ) ccg . util . merge_dict ( plot . yaxes , tmp_yaxes ) ccg . util . merge_dict ( plot . plt_layout , layout ) plots . append ( plot ) return plots def to_dict ( self ) -> list [ dict ]: \"\"\"To dictionary.\"\"\" res = [] for plot in self . plot_configs : res . append ( plot . to_dict ()) return res def to_file ( self , filename : str | Path ): \"\"\"Save to file.\"\"\" if isinstance ( filename , str ): filename = Path ( filename ) coll = self . to_dict () with open ( filename . with_suffix ( \".plot_cfg.json\" ), \"w\" , encoding = \"utf8\" ) as file : json . dump ( coll , file , indent = 4 ) return filename . with_suffix ( \".plot_cfg.json\" ) def from_file ( self , filename : str | Path ) -> PlotConfigColl : \"\"\"Read from file.\"\"\" with open ( filename , \"r\" , encoding = \"utf8\" ) as file : data = json . load ( file ) plots = [] for plot in data : plots . append ( PlotConfig ( ** plot )) return PlotConfigColl ( plots ) def __iter__ ( self ): \"\"\"iter.\"\"\" return iter ( self . plot_configs ) def __repr__ ( self ): \"\"\"repr.\"\"\" return json . dumps ( self . to_dict ())","title":"PlotConfigColl"},{"location":"reference/ccg/ui/plot/#ccg.ui.plot.PlotConfigColl.__iter__","text":"iter. Source code in ccg\\ui\\plot.py 227 228 229 def __iter__ ( self ): \"\"\"iter.\"\"\" return iter ( self . plot_configs )","title":"__iter__"},{"location":"reference/ccg/ui/plot/#ccg.ui.plot.PlotConfigColl.__repr__","text":"repr. Source code in ccg\\ui\\plot.py 231 232 233 def __repr__ ( self ): \"\"\"repr.\"\"\" return json . dumps ( self . to_dict ())","title":"__repr__"},{"location":"reference/ccg/ui/plot/#ccg.ui.plot.PlotConfigColl.append","text":"append plot to collection. Source code in ccg\\ui\\plot.py 69 70 71 72 73 74 75 76 77 def append ( self , plot : PlotConfig | list [ PlotConfig ]): \"\"\"append plot to collection.\"\"\" if not isinstance ( plot , list ): plot = [ plot ] if self . plot_configs is None : self . plot_configs = plot else : self . plot_configs . extend ( plot )","title":"append"},{"location":"reference/ccg/ui/plot/#ccg.ui.plot.PlotConfigColl.build_plot","text":"build plot from plot config collection Source code in ccg\\ui\\plot.py 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 def build_plot ( self , frames : Frame | list [ Frame ]): \"\"\"build plot from plot config collection\"\"\" if not isinstance ( frames , list ): frames = [ frames ] plots = [] for plot_config in self . plot_configs : plot = Plot ( name = plot_config . name ) annot_list = [] annots = False n_annot = 0 if \"annotations\" in plot_config . layout : if any ( isinstance ( lyt [ \"x\" ], str ) or isinstance ( lyt [ \"y\" ], str ) for lyt in plot_config . layout [ \"annotations\" ] ): annots = plot_config . layout . pop ( \"annotations\" ) else : annot_list = plot_config . layout [ \"annotations\" ] for ref_trace in plot_config . traces : try : for frame in frames : trace = ref_trace group = { \"legendgroup\" : frame . name , \"legendgrouptitle\" : { \"text\" : frame . name }, } if \"x\" in trace : x = frame [ trace . pop ( \"x\" ) ] . data # pop out to not update later hov_temp = { \"hovertemplate\" : \"\"\"Y: % {y:.2f} % {yaxis.title.text} <br> X: % {x:.3f} % {xaxis.title.text} \"\"\" } else : if ( frame [ trace [ \"y\" ]] . tline [ 0 ] < 32000000 ): # apprx 1yr from epoch # assume this is an elapsed time instead x = frame [ trace [ \"y\" ]] . tline . unix hov_temp = { \"hovertemplate\" : \"\"\"Value: % {y:.2f} % {yaxis.title.text} <br> Time: % {x:.3f} % {xaxis.title.text} \"\"\" } else : x = frame [ trace [ \"y\" ]] . tline . iso hov_temp = { \"hovertemplate\" : \"\"\"Value: % {y:.2f} % {yaxis.title.text} <br> Time: %{x|%H:%M:%S.%L}\"\"\" } yname = trace [ \"y\" ] y = frame [ trace . pop ( \"y\" )] . data # pop out to not update later yaxis = trace [ \"yaxis\" ] if \"yaxis\" in trace else None plt_trace = plot . build_trace ( x = x , y = y , signame = yname , yaxis = yaxis ) ccg . util . merge_dict ( plt_trace , group ) ccg . util . merge_dict ( plt_trace , hov_temp ) ccg . util . merge_dict ( plt_trace , trace ) # Update with other settings in trace. plot . append_trace ( plt_trace ) if annots : # Calculate the annotation for note in annots : # pylint: disable=eval-used new_note = copy . deepcopy ( note ) if isinstance ( note [ \"x\" ], str ): txt = \"\" txt = re . findall ( r \"PARAM(?:\\.|\\[).*\" , note [ \"x\" ]) if txt : new_note [ \"x\" ] = eval ( txt [ 0 ] . replace ( \"PARAM\" , \"frame\" ) ) if isinstance ( note [ \"y\" ], str ): txt = \"\" txt = re . findall ( r \"PARAM(?:\\.|\\[).*\" , note [ \"y\" ]) if txt : new_note [ \"y\" ] = eval ( txt [ 0 ] . replace ( \"PARAM\" , \"frame\" ) ) # check text for fstring txt = \"\" txt = re . findall ( r \"f'.*'\" , note [ \"text\" ]) if txt : new_note [ \"text\" ] = eval ( txt [ 0 ] . replace ( \"PARAM\" , \"frame\" ) ) if \"ay\" in note : new_note [ \"ay\" ] = note [ \"ay\" ] * ( n_annot + 1 ) if \"arrowcolor\" not in note : new_note [ \"arrowcolor\" ] = plot . TRACES [ n_annot % len ( plot . TRACES ) ] if \"bordercolor\" not in note : new_note [ \"bordercolor\" ] = plot . TRACES [ n_annot % len ( plot . TRACES ) ] annot_list . append ( new_note ) n_annot += 1 except KeyError as err : _LOGGER . warning ( \" %s . Skipped %s .\" , err , \"trace\" ) layout = plot . plt_layout . copy () ccg . util . merge_dict ( layout , { \"annotations\" : annot_list }) # Need to extract y-axes from the layout since plot tools build the yaxes at the end tmp_yaxes = {} list_to_remove = [] for key in layout : if key . startswith ( \"yaxis\" ): tmp_yaxes [ key . replace ( \"yaxis\" , \"y\" )] = layout [ key ] list_to_remove . append ( key ) for key in list_to_remove : layout . pop ( key ) ccg . util . merge_dict ( plot . yaxes , tmp_yaxes ) ccg . util . merge_dict ( plot . plt_layout , layout ) plots . append ( plot ) return plots","title":"build_plot"},{"location":"reference/ccg/ui/plot/#ccg.ui.plot.PlotConfigColl.from_file","text":"Read from file. Source code in ccg\\ui\\plot.py 218 219 220 221 222 223 224 225 def from_file ( self , filename : str | Path ) -> PlotConfigColl : \"\"\"Read from file.\"\"\" with open ( filename , \"r\" , encoding = \"utf8\" ) as file : data = json . load ( file ) plots = [] for plot in data : plots . append ( PlotConfig ( ** plot )) return PlotConfigColl ( plots )","title":"from_file"},{"location":"reference/ccg/ui/plot/#ccg.ui.plot.PlotConfigColl.to_dict","text":"To dictionary. Source code in ccg\\ui\\plot.py 201 202 203 204 205 206 def to_dict ( self ) -> list [ dict ]: \"\"\"To dictionary.\"\"\" res = [] for plot in self . plot_configs : res . append ( plot . to_dict ()) return res","title":"to_dict"},{"location":"reference/ccg/ui/plot/#ccg.ui.plot.PlotConfigColl.to_file","text":"Save to file. Source code in ccg\\ui\\plot.py 208 209 210 211 212 213 214 215 216 def to_file ( self , filename : str | Path ): \"\"\"Save to file.\"\"\" if isinstance ( filename , str ): filename = Path ( filename ) coll = self . to_dict () with open ( filename . with_suffix ( \".plot_cfg.json\" ), \"w\" , encoding = \"utf8\" ) as file : json . dump ( coll , file , indent = 4 ) return filename . with_suffix ( \".plot_cfg.json\" )","title":"to_file"},{"location":"reference/ccg/ui/plot/#ccg.ui.plot.build_collection_traces","text":"Build traces for gate collection. Source code in ccg\\ui\\plot.py 1529 1530 1531 1532 1533 1534 1535 1536 1537 1538 1539 1540 1541 1542 1543 1544 1545 1546 1547 1548 1549 1550 1551 1552 1553 1554 1555 1556 1557 1558 1559 1560 1561 1562 1563 1564 1565 1566 1567 1568 1569 1570 1571 1572 1573 1574 1575 1576 1577 1578 1579 1580 1581 1582 1583 1584 1585 1586 1587 1588 1589 1590 1591 1592 1593 1594 1595 1596 1597 1598 1599 1600 1601 1602 1603 1604 1605 1606 1607 1608 1609 1610 1611 1612 1613 1614 def build_collection_traces ( gate : GateColl , frameorsig : Frame | Sig , tline : TLine = None , plot_def : Plot = None , andor : str = \"n/a\" , ): \"\"\"Build traces for gate collection.\"\"\" if plot_def is None : plot_def = Plot () if tline is None : plt_tline = gate . get_combined_tline ( frameorsig ) else : plt_tline = tline valid_axis = \"y1\" if plt_tline . tstart < 32000000 : times = [ plt_tline . tstart , plt_tline . tend , ] else : times = [ plt_tline . tstart_iso , plt_tline . tend_iso , ] trace = { \"type\" : \"scattergl\" , \"y\" : np . array ([ np . nan , np . nan ]), \"x\" : times , \"name\" : f \" { andor } (\" , \"mode\" : \"none\" , \"legendgroup\" : \"collection\" + str ( plot_def . n_col ), } plot_def . append_trace ( trace ) plot_def . n_col += 1 for cond in gate . conds : build_gate_plot ( cond , frameorsig , tline , plot_def ) trace = { \"type\" : \"scattergl\" , \"y\" : np . array ([ np . nan , np . nan ]), \"x\" : times , \"name\" : \")\" , \"mode\" : \"none\" , \"legendgroup\" : \"collection\" + str ( plot_def . n_col ), } plot_def . append_trace ( trace ) # Result plot # res = Sig( # data=gate.valid(frameorsig, tline) # * (1.0 + (plot_def.n_col + plot_def.n_cond) * 0.1), # tline=tline, # name=\"Result\", # interp_method=InterpMethod.ZOH, # ) # res.data = res.data * (1.0 + (plot_def.n_col + plot_def.n_cond) * 0.1) t_en , t_dis = gate . edges ( frameorsig , tline ) if len ( t_en ) == 0 : t_dis = [ plt_tline [ 0 ], plt_tline [ - 1 ]] data = np . concatenate ( ( np . ones ( len ( t_en )) * ( 1.0 + ( plot_def . n_col + plot_def . n_cond ) * 0.1 ), np . zeros ( len ( t_dis )), ) ) times = np . concatenate (( t_en , t_dis )) res = Sig ( data = data , tline = TLine ( data = times ), name = \"Result\" , interp_method = ccg . util . InterpMethod . ZOH , connect_gaps = True , ) res . sort_tline () trace = plot_def . build_trace_from_sig ( res , yaxis = valid_axis , color = plot_def . n_col + plot_def . n_cond ) plot_def . append_trace ( trace ) plot_def . n_col += 1","title":"build_collection_traces"},{"location":"reference/ccg/ui/plot/#ccg.ui.plot.build_gate_plot","text":"Plot validity and timer signals. Source code in ccg\\ui\\plot.py 1408 1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 1521 1522 1523 1524 1525 1526 def build_gate_plot ( gate : GateColl | GateCond , frame : Frame , tline : TLine = None , def_plot : Plot = None , ) -> Plot : \"\"\"Plot validity and timer signals.\"\"\" from ccg.data.gating import GateCollAND , GateCollOR , GateCond res_stack_factor = 0.05 valid_axis = \"y1\" if def_plot is None : if frame . name is None : name = \"Gate Condition\" else : name = f \"Gate Condition for { frame . name } \" def_plot = Plot ( name = name ) if isinstance ( gate , GateCollOR ): andor = \"OR\" build_collection_traces ( gate , frame , tline , def_plot , andor ) elif isinstance ( gate , GateCollAND ): andor = \"AND\" build_collection_traces ( gate , frame , tline , def_plot , andor ) elif isinstance ( gate , GateCond ): res = Sig ( gate . validate ( frame , tline )) # Copy # scale result so they stack res . data = res . data + (( def_plot . n_col + def_plot . n_cond ) * res_stack_factor ) trace = def_plot . build_trace_from_sig ( res , color = def_plot . n_cond , yaxis = valid_axis ) trace . update ({ \"legendgroup\" : \"Cond\" + str ( def_plot . n_cond )}) def_plot . append_trace ( trace ) def_plot . yaxes [ valid_axis ] . update ({ \"domain\" : [ 0.8 , 1 ]}) trace = def_plot . build_trace_from_sig ( frame [ gate . signame ], color = def_plot . n_cond ) trace . update ( { \"legendgroup\" : f \"Cond { def_plot . n_cond } \" , \"legendgrouptitle\" : { \"text\" : f \" { gate . min_limit } < { gate . signame } < { gate . max_limit } [ { gate . unit } ]\" }, } ) yaxis = trace [ \"yaxis\" ] def_plot . append_trace ( trace ) def_plot . yaxes [ yaxis ] . update ( { \"domain\" : [ 0 , 0.7875 ], \"overlaying\" : \"y2\" , \"showgrid\" : False } ) limits = [] min_limit = ccg . util . convert_units ( gate . min_limit , gate . unit , frame [ gate . signame ] . unit ) max_limit = ccg . util . convert_units ( gate . max_limit , gate . unit , frame [ gate . signame ] . unit ) if gate . min_limit == np . NINF : sig_range = frame [ gate . signame ] . max - frame [ gate . signame ] . min limits . extend ([ frame [ gate . signame ] . min - 0.1 * sig_range ] * 2 ) else : limits . extend ([ min_limit ] * 2 ) if gate . max_limit == np . inf : sig_range = frame [ gate . signame ] . max - frame [ gate . signame ] . min limits . extend ([ frame [ gate . signame ] . max + 0.1 * sig_range ] * 2 ) else : limits . extend ([ max_limit ] * 2 ) if frame [ gate . signame ] . tstart < 32000000 : times = np . array ( [ frame [ gate . signame ] . tstart , frame [ gate . signame ] . tend , frame [ gate . signame ] . tend , frame [ gate . signame ] . tstart , ] ) else : times = np . array ( [ frame [ gate . signame ] . tstart_iso , frame [ gate . signame ] . tend_iso , frame [ gate . signame ] . tend_iso , frame [ gate . signame ] . tstart_iso , ] ) trace = def_plot . build_trace ( x = times , y = limits , signame = f \" { gate . signame } _limits\" , yaxis = yaxis , color = def_plot . n_cond , connect_gaps = False , ) tmp_color = ccg . util . hex_to_rgb ( trace [ \"line\" ][ \"color\" ]) tmp_color_str = f \"rgba( { tmp_color [ 0 ] } , { tmp_color [ 1 ] } , { tmp_color [ 2 ] } ,0.2)\" trace . update ( { \"fill\" : \"toself\" , \"legendgroup\" : \"Cond\" + str ( def_plot . n_cond ), \"fillcolor\" : tmp_color_str , } ) def_plot . append_trace ( trace ) if def_plot . yaxes [ yaxis ][ \"color\" ] != def_plot . THEME3 : def_plot . yaxes [ yaxis ][ \"color\" ] = ccg . util . max_contrast ( def_plot . TRACES [ def_plot . n_cond % def_plot . n_colors ], ccg . util . shift_lightness ( def_plot . TRACES [ def_plot . n_cond % def_plot . n_colors ], 1.4 ), ccg . util . shift_lightness ( def_plot . TRACES [ def_plot . n_cond % def_plot . n_colors ], 0.4 ), ) def_plot . n_cond += 1 return def_plot","title":"build_gate_plot"},{"location":"reference/ccg/ui/plot_themes/","text":"","title":"plot_themes"},{"location":"reference/ccg/ui/plotgo/","text":"New Plotly Driver Plot New plot class, uses go.Figure() Source code in ccg\\ui\\plotgo.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 class Plot : \"\"\"New plot class, uses go.Figure()\"\"\" @profile def __init__ ( self , data : ccg . Frame | ccg . Sig | ccg . Tbl | ccg . ScatterData = None , name : str = None , ): self . nyaxes = 0 self . ntrace = - 1 self . n_cond = 0 # For use in gate diag plots self . n_col = 0 # For use in gate diag plots self . yaxes : dict = {} self . fig = go . Figure () self . fig = go . Figure () self . fig . update_layout ( template = plot_themes . ccg_tbl ) # Build traces if isinstance ( data , ccg . Frame ): traces = [] for sig in data : traces . append ( self . build_trace_from_sig ( sig )) self . append_trace ( traces ) self . build_yaxes () elif isinstance ( data , ccg . Sig ): traces = self . build_trace_from_sig ( data ) self . append_trace ( traces ) self . build_yaxes () elif isinstance ( data , ccg . Tbl ): traces = self . build_traces_from_tbl ( data ) self . append_trace ( traces ) self . ntrace -= 1 self . build_yaxes () elif isinstance ( data , ccg . ScatterData ): # self.append_trace_from_scatter(data) raise NotImplementedError elif data is None : pass else : raise NotImplementedError ( f \"Plot not implemented for { type ( data ) } \" ) if name is None : if data is not None and data . name is not None : name = data . name self . fig . update_layout ( title_text = name ) else : self . fig . update_layout ( layout_title_text = name ) # @profile # def append_trace_from_tbl(self, tbl: ccg.Tbl): # \"\"\"build trace from table and append\"\"\" # try: # trace = self.build_traces_from_tbl(tbl) # self.append_trace(trace) # except (NotImplementedError, KeyError) as err: # _LOGGER.warning(\"%s. Skipped %s.\", err, tbl.name) def build_traces_from_tbl ( self , tbl : ccg . Tbl , color : int = None ) -> list [ dict ]: \"\"\"build traces from table.\"\"\" ntrace = self . ntrace + 1 if tbl . unit is not None : unit = f \" [ { tbl . unit } ]\" else : unit = \"\" if tbl . n_dim == 2 : traces = self . build_2d_traces ( tbl , color , ntrace , unit ) elif tbl . n_dim == 1 : traces = self . build_1d_traces ( tbl , color , ntrace , unit ) elif tbl . n_dim == 0 : traces = self . build_0d_traces ( tbl , color , ntrace , unit ) else : raise NotImplementedError ( f \"Plot not implemented for n_dim = { tbl . n_dim } \" ) return traces @profile def append_trace ( self , trace : dict | list [ dict ]): \"Append trace to traces.\" if isinstance ( trace , list ): self . fig . add_traces ( trace ) else : self . fig . add_trace ( trace ) self . ntrace += 1 def build_0d_traces ( self , param : ccg . Tbl , color : int , ntrace : int , unit : str ): \"\"\"Build traces for 0d param\"\"\" traces = [] self . nyaxes = 1 # Ever a case for more than 1? yaxis = f \"y { self . nyaxes } \" hov_temp = ( f \"\"\" { param . name } : % {{ y:. { param . precision } f }} [ { unit } ]<extra></extra>\"\"\" ) try : tmp_trc = { \"type\" : \"scattergl\" , \"y\" : param . orig . data , \"name\" : param . orig . name , \"mode\" : \"markers\" , \"yaxis\" : yaxis , \"opacity\" : 1 , \"hovertemplate\" : hov_temp , \"marker\" : { \"size\" : 8 , \"color\" : plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ], \"line\" : { \"color\" : ccg . util . max_contrast ( self . fig . layout [ \"template\" ][ \"layout\" ][ \"plot_bgcolor\" ], ccg . util . shift_lightness ( plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ], 1.4 ), ccg . util . shift_lightness ( plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ], 0.4 ), ), \"width\" : 1 , }, }, \"hoverlabel\" : { \"bgcolor\" : plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ] }, \"showlegend\" : True , \"legendgroup\" : f \" { param . orig . name } _ { ntrace } \" , } traces . append ( tmp_trc ) ntrace += 1 except KeyError : pass if color is None : color = ntrace tmp_trc = { \"type\" : \"scattergl\" , \"y\" : param . data , \"name\" : param . name , \"mode\" : \"markers\" , \"hovertemplate\" : hov_temp , \"opacity\" : 1 , \"marker\" : { \"size\" : 8 , \"color\" : plot_themes . TRACES [ color % plot_themes . N_COLORS ], \"line\" : { \"color\" : ccg . util . max_contrast ( self . fig . layout [ \"template\" ][ \"layout\" ][ \"plot_bgcolor\" ], ccg . util . shift_lightness ( plot_themes . TRACES [ color % plot_themes . N_COLORS ], 1.4 ), ccg . util . shift_lightness ( plot_themes . TRACES [ color % plot_themes . N_COLORS ], 0.4 ), ), \"width\" : 1 , }, }, \"hoverlabel\" : { \"bgcolor\" : plot_themes . TRACES [ color % plot_themes . N_COLORS ]}, \"showlegend\" : True , \"legendgroup\" : f \" { param . name } _ { ntrace } \" , } traces . append ( tmp_trc ) ntrace += 1 nscatter = 0 for scatter in param . scatter_data : if scatter is not None : # plot the scatter data as well. nscatter += 1 tmp_trc = self . build_scatter_trace ( scatter = scatter , param = param , ntrace = ntrace , nscatter = nscatter ) traces . append ( tmp_trc ) ntrace += 1 self . yaxes [ yaxis ] = { \"unit\" : param . unit , \"min\" : param . data_range [ 0 ], \"max\" : param . data_range [ 1 ], \"dtype\" : plot_themes . COMPAT_TYPES [ np . where ( [ param . data . dtype . kind in t for t in plot_themes . COMPAT_TYPES ] )[ 0 ][ 0 ] # r-worded way to get the index of the match ], \"color\" : plot_themes . WHITE , \"fixed_range\" : False , } return traces @profile def build_1d_traces ( self , param : ccg . Tbl , color : int , ntrace : int , unit : str ): \"\"\"Build traces for 1d param\"\"\" traces = [] self . nyaxes = 1 # Ever case for more than 1? yaxis = f \"y { self . nyaxes } \" # TODO: Fix for multiple axes hov_temp = f \"\"\" { param . name } : % {{ y:. { param . precision } f }} [ { unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } f }} [ { param . axes [ 0 ] . unit } ]<extra></extra>\"\"\" try : tmp_trc = { \"type\" : \"scattergl\" , \"y\" : param . orig . data , \"x\" : param . orig . axes [ 0 ] . data , \"name\" : param . orig . name , \"mode\" : \"markers+lines\" , \"yaxis\" : yaxis , \"opacity\" : 1 , \"hovertemplate\" : hov_temp , \"marker\" : { \"size\" : np . array ([ 10 ] * param . orig . data . size ), \"color\" : plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ], \"line\" : { \"color\" : ccg . util . max_contrast ( self . fig . layout [ \"template\" ][ \"layout\" ][ \"plot_bgcolor\" ], ccg . util . shift_lightness ( plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ], 1.4 ), ccg . util . shift_lightness ( plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ], 0.4 ), ), \"width\" : 1 , }, }, \"line\" : { \"width\" : 1 , \"shape\" : plot_themes . LINESHAPE [ param . orig . axes [ 0 ] . interp_method ], \"color\" : plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ], }, \"hoverlabel\" : { \"bgcolor\" : plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ] }, \"showlegend\" : True , \"legendgroup\" : f \" { param . orig . name } _ { ntrace } \" , } traces . append ( tmp_trc ) ntrace += 1 except KeyError : pass if color is None : color = ntrace tmp_trc = { \"type\" : \"scattergl\" , \"y\" : param . data , \"x\" : param . axes [ 0 ] . data , \"name\" : param . name , \"mode\" : \"markers+lines\" , \"hovertemplate\" : hov_temp , \"opacity\" : 1 , \"marker\" : { \"size\" : np . array ([ 10 ] * param . data . size ), \"color\" : plot_themes . TRACES [ color % plot_themes . N_COLORS ], \"line\" : { \"color\" : ccg . util . max_contrast ( self . fig . layout [ \"template\" ][ \"layout\" ][ \"plot_bgcolor\" ], ccg . util . shift_lightness ( plot_themes . TRACES [ color % plot_themes . N_COLORS ], 1.4 ), ccg . util . shift_lightness ( plot_themes . TRACES [ color % plot_themes . N_COLORS ], 0.4 ), ), \"width\" : 1 , }, }, \"line\" : { \"width\" : 1 , \"shape\" : plot_themes . LINESHAPE [ param . axes [ 0 ] . interp_method ], \"color\" : plot_themes . TRACES [ color % plot_themes . N_COLORS ], }, \"hoverlabel\" : { \"bgcolor\" : plot_themes . TRACES [ color % plot_themes . N_COLORS ]}, \"showlegend\" : True , \"legendgroup\" : f \" { param . name } _ { ntrace } \" , } traces . append ( tmp_trc ) ntrace += 1 nscatter = 0 for scatter in param . scatter_data : if scatter is not None : # plot the scatter data as well. nscatter += 1 tmp_trc = self . build_scatter_trace ( scatter = scatter , param = param , ntrace = ntrace , nscatter = nscatter ) traces . append ( tmp_trc ) ntrace += 1 self . yaxes [ yaxis ] = { \"unit\" : param . unit , \"min\" : param . data_range [ 0 ], \"max\" : param . data_range [ 1 ], \"dtype\" : plot_themes . COMPAT_TYPES [ np . where ( [ param . data . dtype . kind in t for t in plot_themes . COMPAT_TYPES ] )[ 0 ][ 0 ] # r-worded way to get the index of the match ], \"color\" : plot_themes . WHITE , \"fixed_range\" : False , } return traces @profile def build_2d_traces ( self , param : ccg . Tbl , color : int , ntrace : int , unit : str ): \"\"\"build traces from 2d param\"\"\" traces = [] try : traces . extend ( self . build_surf_traces ( param . orig , ntrace , ntrace , unit , visible = True ) ) ntrace += 1 except KeyError : pass if color is None : color = ntrace traces . extend ( self . build_surf_traces ( param , color , ntrace , unit )) ntrace += 1 nscatter = 0 for scatter in param . scatter_data : if scatter is not None : # plot the scatter data as well. nscatter += 1 tmp_trc = self . build_scatter_trace ( scatter = scatter , param = param , ntrace = ntrace , nscatter = nscatter ) traces . append ( tmp_trc ) ntrace += 1 # TODO: Should edit the layout here... self . fig . layout [ \"scene\" ][ \"xaxis\" ] . update ( { \"title\" : { \"text\" : f \" { param . axes [ 0 ] . name } [ { param . axes [ 0 ] . unit } ]\" }} ) self . fig . layout [ \"scene\" ][ \"yaxis\" ] . update ( { \"title\" : { \"text\" : f \" { param . axes [ 1 ] . name } [ { param . axes [ 1 ] . unit } ]\" }} ) self . fig . layout [ \"scene\" ][ \"zaxis\" ] . update ( { \"title\" : { \"text\" : f \" { param . name } [ { param . unit } ]\" }} ) self . fig . layout [ \"scene\" ] . update ( { \"camera\" : { \"eye\" : { \"x\" : - 1.25 , \"y\" : - 1.25 , \"z\" : 1.1 }}, } ) # scene = { # \"scene\": { # \"xaxis\": xaxis, # \"yaxis\": yaxis, # \"zaxis\": zaxis, # \"camera\": {\"eye\": {\"x\": -1.25, \"y\": -1.25, \"z\": 1.1}}, # } # } return traces @profile def build_scatter_trace ( self , scatter : ccg . ScatterData , param : ccg . Tbl = None , ntrace : int = 1 , nscatter : int = 1 , ): \"\"\"Builds a scatter trace. ntrace and nscatter are counters for color increments\"\"\" ndim = scatter . ndim tmp_trc = { \"name\" : scatter . name , \"mode\" : \"markers\" , \"opacity\" : 1 , \"marker\" : { \"size\" : 3 , \"color\" : plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ], \"colorscale\" : [ plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ]] * 2 , \"showscale\" : False , }, \"hoverlabel\" : { \"bgcolor\" : plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ] }, \"showlegend\" : True , \"legendgroup\" : f \" { scatter . name } _ { ntrace } \" , } if scatter . color is not None : tmp = { \"marker\" : { \"color\" : scatter . color , \"colorscale\" : \"turbo\" , \"colorbar\" : { \"bgcolor\" : plot_themes . THEME3 , \"bordercolor\" : plot_themes . THEME4 , \"borderwidth\" : 1 , \"title\" : { \"text\" : f \" { scatter . color_label } [ { scatter . color_unit } ]\" , \"side\" : \"right\" , }, \"x\" : 0 , }, \"showscale\" : True , }, \"text\" : np . round ( scatter . color , scatter . color_precision ), } if scatter . color_range is not None : ccg . util . merge_dict ( tmp , { \"marker\" : { \"cmin\" : scatter . color_range [ 0 ], \"cmax\" : scatter . color_range [ 1 ], } }, ) # Need to move legend to clear color bar. tmp_lgnd = { \"xanchor\" : \"right\" , \"yanchor\" : \"top\" , \"x\" : 1 , \"y\" : 1 , } self . fig . update_legends ( tmp_lgnd ) ccg . util . merge_dict ( tmp_trc , tmp ) if ndim == 2 : if param is not None : if scatter . color is not None : hov_temp = f \"\"\" { scatter . name } : % {{ z:. { param . precision } f }} [ { param . unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } f }} [ { param . axes [ 0 ] . unit } ]<br> { param . axes [ 1 ] . name } : % {{ y:. { param . axes [ 1 ] . precision } f }} [ { param . axes [ 1 ] . unit } ]<br> { scatter . color_label } : % {{ marker.color:. { scatter . color_precision } f }} [ { scatter . color_unit } ] <extra></extra>\"\"\" else : hov_temp = f \"\"\" { scatter . name } : % {{ z:. { param . precision } d }} [ { param . unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } d }} [ { param . axes [ 0 ] . unit } ]<br> { param . axes [ 1 ] . name } : % {{ y:. { param . axes [ 1 ] . precision } d }} [ { param . axes [ 1 ] . unit } ] <extra></extra>\"\"\" else : if scatter . color is not None : hov_temp = \"\" tmp = { \"type\" : \"scatter3d\" , \"x\" : scatter . data [ 0 ], \"y\" : scatter . data [ 1 ], \"z\" : scatter . data [ 2 ], \"hovertemplate\" : hov_temp , } elif ndim == 1 : if param is not None : if scatter . color is not None : hov_temp = f \"\"\" { scatter . name } : % {{ y:. { param . precision } f }} [ { param . unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } f }} [ { param . axes [ 0 ] . unit } ]<br> { scatter . color_label } : % {{ marker.color:. { scatter . color_precision } f }} [ { scatter . color_unit } ] <extra></extra>\"\"\" else : hov_temp = f \"\"\" { scatter . name } : % {{ y:. { param . precision } d }} [ { param . unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } d }} [ { param . axes [ 0 ] . unit } ]<br> <extra></extra>\"\"\" else : hov_temp = \"\" tmp = { \"type\" : \"scattergl\" , \"x\" : scatter . data [ 0 ], \"y\" : scatter . data [ 1 ], \"hovertemplate\" : hov_temp , } elif ndim == 0 : if param is not None : if scatter . color is not None : hov_temp = f \"\"\" { scatter . name } : % {{ y:. { param . precision } f }} [ { param . unit } ]<br> { scatter . color_label } : % {{ marker.color:. { scatter . color_precision } f }} [ { scatter . color_unit } ] <extra></extra>\"\"\" else : hov_temp = f \"\"\" { scatter . name } : % {{ y:. { param . precision } d }} [ { param . unit } ]<br> <extra></extra>\"\"\" else : hov_temp = \"\" tmp = { \"type\" : \"scattergl\" , \"x\" : scatter . data [ 0 ] * 0 , \"y\" : scatter . data [ 1 ], \"hovertemplate\" : hov_temp , } else : raise NotImplementedError ccg . util . merge_dict ( tmp_trc , tmp ) if nscatter > 1 : ccg . util . merge_dict ( tmp_trc , { \"visible\" : \"legendonly\" }) return tmp_trc def build_surf_traces ( self , param : ccg . Tbl , color : int , ntrace : int , unit : str , visible : bool = True , ): \"\"\"Build 2d surface trace\"\"\" if not visible : visible = \"legendonly\" hov_temp = f \"\"\" { param . name } : % {{ z:. { param . precision } f }} [ { param . unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } f }} [ { param . axes [ 0 ] . unit } ]<br> { param . axes [ 1 ] . name } : % {{ y:. { param . axes [ 1 ] . precision } f }} [ { param . axes [ 1 ] . unit } ] <extra></extra>\"\"\" x , y = np . meshgrid ( param . axes [ 0 ] . data , param . axes [ 1 ] . data ) x = np . concatenate (( x , x [ - 1 , np . newaxis ])) y = np . concatenate (( y , y [ - 1 , np . newaxis ])) z = np . concatenate (( param . data . T , param . data . T [ - 1 , np . newaxis ] * np . NaN )) i = x . flatten ( \"F\" ) j = y . flatten ( \"F\" ) k = z . flatten ( \"F\" ) y , x = np . meshgrid ( param . axes [ 1 ] . data , param . axes [ 0 ] . data ) x = np . concatenate (( x , x [ - 1 , np . newaxis ])) y = np . concatenate (( y , y [ - 1 , np . newaxis ])) z = np . concatenate (( param . data , param . data [ - 1 , np . newaxis ] * np . NaN )) i = np . concatenate (( i , x . flatten ( \"F\" ))) j = np . concatenate (( j , y . flatten ( \"F\" ))) k = np . concatenate (( k , z . flatten ( \"F\" ))) traces = [ { \"type\" : \"surface\" , \"x\" : param . axes [ 0 ] . data , \"y\" : param . axes [ 1 ] . data , \"z\" : param . data . T , \"name\" : f \" { param . name }{ unit } \" , \"hovertemplate\" : hov_temp , \"hoverlabel\" : { \"bgcolor\" : plot_themes . TRACES [ color % plot_themes . N_COLORS ] }, \"opacity\" : 0.5 , \"colorscale\" : [ plot_themes . TRACES [ color % plot_themes . N_COLORS ]] * 2 , \"showlegend\" : True , \"legendgroup\" : f \" { param . name } _ { ntrace } \" , \"showscale\" : False , \"visible\" : visible , }, { \"type\" : \"scatter3d\" , \"x\" : i , \"y\" : j , \"z\" : k , \"name\" : f \" { param . name }{ unit } \" , \"hoverinfo\" : \"skip\" , \"opacity\" : 1 , \"marker\" : { \"color\" : np . array ( [ plot_themes . TRACES [ color % plot_themes . N_COLORS ]] * len ( i ) ), \"size\" : np . array ([ 10 ] * len ( i )), # \"line\": { # \"color\": ccg.util.max_contrast( # plot_themes.TRACES[color % plot_themes.N_COLORS], # ccg.util.shift_lightness( # plot_themes.TRACES[color % plot_themes.N_COLORS], 1.4 # ), # ccg.util.shift_lightness( # plot_themes.TRACES[color % plot_themes.N_COLORS], 0.4 # ), # ), # \"width\": 1, # }, }, \"line\" : { \"color\" : ccg . util . max_contrast ( plot_themes . TRACES [ color % plot_themes . N_COLORS ], ccg . util . shift_lightness ( plot_themes . TRACES [ color % plot_themes . N_COLORS ], 1.4 ), ccg . util . shift_lightness ( plot_themes . TRACES [ color % plot_themes . N_COLORS ], 0.4 ), ), \"width\" : 2 , }, \"showlegend\" : False , \"legendgroup\" : f \" { param . name } _ { ntrace } \" , \"connectgaps\" : False , \"visible\" : visible , }, ] return traces def build_trace_from_sig ( self , sig : ccg . Sig , color : int = None , yaxis : str = None ): \"\"\"Build Trace for plotly from a Sig.\"\"\" ntrace = self . ntrace + 1 if color is None : color = ntrace sig = sig . plot_prep () yaxis = self . find_yaxis ( sig , yaxis ) unit = \"\" if sig . unit is None else sig . unit if sig . tline [ 0 ] < 32000000 : # apprx 1yr from epoch # assume this is an elapsed time instead x = sig . tline . unix hov_temp = \"\"\" Value: % {y:.2f} % {yaxis.title.text} <br> Time: % {x:.3f} [s]\"\"\" self . fig . update_layout ({ \"xaxis1\" : { \"title\" : \"Elapsed Time [s]\" }}) else : x = sig . tline . iso hov_temp = \"\"\" Value: % {y:.2f} % {yaxis.title.text} <br> Time: %{x|%H:%M:%S.%L}\"\"\" self . fig . update_layout ({ \"xaxis1\" : { \"title\" : \"Date and Time\" }}) if sig . nsamples > 100000 : hov = \"skip\" # Disable hover since its too slow hov_temp = \"\" else : hov = \"all\" trace = { \"type\" : \"scattergl\" , \"y\" : sig . data , \"x\" : x , \"name\" : f \" { sig . name } [ { unit } ]\" , \"mode\" : \"markers+lines\" , \"hovertemplate\" : hov_temp , \"hoverinfo\" : hov , \"yaxis\" : yaxis , \"opacity\" : 1 , \"connectgaps\" : bool ( sig . connect_gaps ), # should work if connect_gaps is None \"marker\" : { # \"color\": TRACES[self.ntrace], \"size\" : [ 2 ] * len ( x ), \"line\" : { \"color\" : ccg . util . max_contrast ( self . fig . layout [ \"template\" ][ \"layout\" ][ \"plot_bgcolor\" ], ccg . util . shift_lightness ( plot_themes . TRACES [ color % plot_themes . N_COLORS ], 1.4 ), ccg . util . shift_lightness ( plot_themes . TRACES [ color % plot_themes . N_COLORS ], 0.4 ), ), \"width\" : 1 , }, }, \"line\" : { \"width\" : 1 , \"shape\" : plot_themes . LINESHAPE [ sig . interp_method ], \"color\" : plot_themes . TRACES [ color % plot_themes . N_COLORS ], }, } if sig . base_data is not None : ccg . util . merge_dict ( trace , { \"text\" : sig . base_data , \"hovertemplate\" : \"\"\"Value: % {text} <br> Time: %{x|%H:%M:%S.%L}\"\"\" , }, ) return trace def find_yaxis ( self , sig : ccg . Sig , yaxis : str = None ): \"\"\"Check for matching y axes.\"\"\" if sig . data_range is not None : sig_min = sig . data_range [ 0 ] sig_max = sig . data_range [ 1 ] fixed_range = True else : sig_min = sig . min sig_max = sig . max fixed_range = False if yaxis is not None : if yaxis in self . yaxes : try : if \"U\" in self . yaxes [ yaxis ][ \"dtype\" ]: # its a string type so no scaling info self . yaxes [ yaxis ][ \"color\" ] = plot_themes . WHITE # change to grey for multi return yaxis yrange = self . yaxes [ yaxis ][ \"max\" ] - self . yaxes [ yaxis ][ \"min\" ] sigrange = sig_max - sig_min if yrange == 0 : yrange = self . yaxes [ yaxis ][ \"min\" ] self . yaxes [ yaxis ][ \"color\" ] = plot_themes . WHITE # change to grey for multi # Should we update the max and min here? could let it expand to inf... # Maybe an average? if fixed_range : self . yaxes [ yaxis ][ \"fixed_range\" ] = fixed_range self . yaxes [ yaxis ][ \"min\" ] = ( self . yaxes [ yaxis ][ \"min\" ] + sig_min ) / 2 self . yaxes [ yaxis ][ \"max\" ] = ( self . yaxes [ yaxis ][ \"max\" ] + sig_max ) / 2 return yaxis except TypeError : # For the case of dtype=obj and not compat pass else : self . nyaxes += 1 self . yaxes [ yaxis ] = { \"unit\" : sig . unit , \"min\" : sig_min , \"max\" : sig_max , \"dtype\" : plot_themes . COMPAT_TYPES [ np . where ( [ sig . data . dtype . kind in t for t in plot_themes . COMPAT_TYPES ] )[ 0 ][ 0 ] # r-worded way to get the index of the match ], \"color\" : ccg . util . max_contrast ( plot_themes . THEME2 , ccg . util . shift_lightness ( plot_themes . TRACES [ ( self . ntrace + 1 ) % plot_themes . N_COLORS ], 1.4 , ), ccg . util . shift_lightness ( plot_themes . TRACES [ ( self . ntrace + 1 ) % plot_themes . N_COLORS ], 0.4 , ), ), \"fixed_range\" : fixed_range , } return yaxis else : if self . nyaxes > 0 : for yaxis , yaxis_def in self . yaxes . items (): if ( sig . data . dtype . kind in yaxis_def [ \"dtype\" ] and yaxis_def [ \"unit\" ] == sig . unit ): try : if \"U\" in yaxis_def [ \"dtype\" ]: # its a string type so no scaling info yaxis_def [ \"color\" ] = ( plot_themes . WHITE ) # change to grey for multi return yaxis yrange = yaxis_def [ \"max\" ] - yaxis_def [ \"min\" ] sigrange = sig_max - sig_min if yrange == 0 : yrange = yaxis_def [ \"min\" ] if ( sig_min > yaxis_def [ \"min\" ] - ( yrange * plot_themes . FRANGE / 2 ) and sig_max < yaxis_def [ \"max\" ] + ( yrange * plot_themes . FRANGE / 2 ) and sigrange < yrange * plot_themes . FRANGE and sigrange > yrange / plot_themes . FRANGE ): yaxis_def [ \"color\" ] = ( plot_themes . WHITE ) # change to grey for multi # Should we update the max and min here? could let it expand to inf... # Maybe an average? if fixed_range : yaxis_def [ \"fixed_range\" ] = fixed_range yaxis_def [ \"min\" ] = ( yaxis_def [ \"min\" ] + sig_min ) / 2 yaxis_def [ \"max\" ] = ( yaxis_def [ \"max\" ] + sig_max ) / 2 return yaxis except TypeError : # For the case of dtype=obj and not compat pass self . nyaxes += 1 yaxis = f \"y { self . nyaxes } \" self . yaxes [ yaxis ] = { \"unit\" : sig . unit , \"min\" : sig_min , \"max\" : sig_max , \"dtype\" : plot_themes . COMPAT_TYPES [ np . where ( [ sig . data . dtype . kind in t for t in plot_themes . COMPAT_TYPES ] )[ 0 ][ 0 ] # r-worded way to get the index of the match ], \"color\" : ccg . util . max_contrast ( plot_themes . THEME2 , ccg . util . shift_lightness ( plot_themes . TRACES [( self . ntrace + 1 ) % plot_themes . N_COLORS ], 1.4 , ), ccg . util . shift_lightness ( plot_themes . TRACES [( self . ntrace + 1 ) % plot_themes . N_COLORS ], 0.4 , ), ), \"fixed_range\" : fixed_range , } return yaxis def build_yaxes ( self ): \"\"\"Build yaxes element for layout.\"\"\" # tic = datetime.now() yaxes : dict [ str , dict ] = {} domain_min = 1 domain_min_name = \"y1\" # TODO: Handle domains better... for i , ( y_name , yaxis ) in enumerate ( self . yaxes . items ()): yaxis_tmp = copy . deepcopy ( yaxis ) # Since we will remove stuff from this later... name = y_name . replace ( \"y\" , \"yaxis\" ) if ( i % 2 ) == 0 : side = \"left\" pos = round ( i / 2 + 0.001 ) * plot_themes . FPOS else : side = \"right\" pos = 1 - round ( i / 2 - 0.001 + 1 ) * plot_themes . FPOS unit = yaxis_tmp . pop ( \"unit\" ) # Pop since its not a standard. _ = yaxis_tmp . pop ( \"dtype\" ) # not needed here data_range = [ yaxis_tmp . pop ( \"min\" ), yaxis_tmp . pop ( \"max\" )] if not yaxis_tmp . pop ( \"fixed_range\" ): data_range = False # Not sure im ready to use this yet. title = \"\" if unit is None else f \"[ { unit } ]\" ccg . util . merge_dict ( yaxes , { name : { \"title\" : { \"text\" : title }, \"overlaying\" : \"y1\" , \"anchor\" : \"x1\" , \"position\" : pos , \"color\" : yaxis_tmp [ \"color\" ], \"gridcolor\" : yaxis_tmp [ \"color\" ], \"showgrid\" : True , \"showline\" : True , \"mirror\" : True , \"side\" : side , \"spikesnap\" : \"hovered data\" , \"spikemode\" : \"across+marker\" , \"spikedash\" : \"solid\" , \"spikethickness\" : 1 , \"ticks\" : \"outside\" , \"ticklen\" : 3 , \"zerolinecolor\" : yaxis_tmp [ \"color\" ], \"zerolinewidth\" : 2 , } }, ) ccg . util . merge_dict ( yaxes [ name ], yaxis_tmp ) if data_range : ccg . util . merge_dict ( yaxes [ name ], { \"range\" : data_range , }, ) if i > 0 : del yaxes [ f \"yaxis { i } \" ][ \"anchor\" ] # to allow spacing multiple if \"domain\" in yaxis_tmp : if yaxis_tmp [ \"domain\" ][ 0 ] < domain_min : domain_min = yaxis_tmp [ \"domain\" ][ 0 ] domain_min_name = y_name if not yaxes : return del yaxes [ \"yaxis1\" ][ \"overlaying\" ] # to allow hover to work try : # TODO: Improve this for more domains del yaxes [ domain_min_name . replace ( \"y\" , \"yaxis\" )][ \"overlaying\" ] except KeyError : pass yaxes [ \"xaxis1\" ] = { \"domain\" : [ ( round (( self . nyaxes ) / 2 + 0.001 ) - 1 ) * plot_themes . FPOS , 1 - round ( self . nyaxes / 2 - 0.001 ) * plot_themes . FPOS , ], # +0.001 since python is r-worded} \"anchor\" : domain_min_name , } self . fig . update_layout ( yaxes ) append_trace ( trace ) Append trace to traces. Source code in ccg\\ui\\plotgo.py 94 95 96 97 98 99 100 101 @profile def append_trace ( self , trace : dict | list [ dict ]): \"Append trace to traces.\" if isinstance ( trace , list ): self . fig . add_traces ( trace ) else : self . fig . add_trace ( trace ) self . ntrace += 1 build_0d_traces ( param , color , ntrace , unit ) Build traces for 0d param Source code in ccg\\ui\\plotgo.py 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 def build_0d_traces ( self , param : ccg . Tbl , color : int , ntrace : int , unit : str ): \"\"\"Build traces for 0d param\"\"\" traces = [] self . nyaxes = 1 # Ever a case for more than 1? yaxis = f \"y { self . nyaxes } \" hov_temp = ( f \"\"\" { param . name } : % {{ y:. { param . precision } f }} [ { unit } ]<extra></extra>\"\"\" ) try : tmp_trc = { \"type\" : \"scattergl\" , \"y\" : param . orig . data , \"name\" : param . orig . name , \"mode\" : \"markers\" , \"yaxis\" : yaxis , \"opacity\" : 1 , \"hovertemplate\" : hov_temp , \"marker\" : { \"size\" : 8 , \"color\" : plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ], \"line\" : { \"color\" : ccg . util . max_contrast ( self . fig . layout [ \"template\" ][ \"layout\" ][ \"plot_bgcolor\" ], ccg . util . shift_lightness ( plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ], 1.4 ), ccg . util . shift_lightness ( plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ], 0.4 ), ), \"width\" : 1 , }, }, \"hoverlabel\" : { \"bgcolor\" : plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ] }, \"showlegend\" : True , \"legendgroup\" : f \" { param . orig . name } _ { ntrace } \" , } traces . append ( tmp_trc ) ntrace += 1 except KeyError : pass if color is None : color = ntrace tmp_trc = { \"type\" : \"scattergl\" , \"y\" : param . data , \"name\" : param . name , \"mode\" : \"markers\" , \"hovertemplate\" : hov_temp , \"opacity\" : 1 , \"marker\" : { \"size\" : 8 , \"color\" : plot_themes . TRACES [ color % plot_themes . N_COLORS ], \"line\" : { \"color\" : ccg . util . max_contrast ( self . fig . layout [ \"template\" ][ \"layout\" ][ \"plot_bgcolor\" ], ccg . util . shift_lightness ( plot_themes . TRACES [ color % plot_themes . N_COLORS ], 1.4 ), ccg . util . shift_lightness ( plot_themes . TRACES [ color % plot_themes . N_COLORS ], 0.4 ), ), \"width\" : 1 , }, }, \"hoverlabel\" : { \"bgcolor\" : plot_themes . TRACES [ color % plot_themes . N_COLORS ]}, \"showlegend\" : True , \"legendgroup\" : f \" { param . name } _ { ntrace } \" , } traces . append ( tmp_trc ) ntrace += 1 nscatter = 0 for scatter in param . scatter_data : if scatter is not None : # plot the scatter data as well. nscatter += 1 tmp_trc = self . build_scatter_trace ( scatter = scatter , param = param , ntrace = ntrace , nscatter = nscatter ) traces . append ( tmp_trc ) ntrace += 1 self . yaxes [ yaxis ] = { \"unit\" : param . unit , \"min\" : param . data_range [ 0 ], \"max\" : param . data_range [ 1 ], \"dtype\" : plot_themes . COMPAT_TYPES [ np . where ( [ param . data . dtype . kind in t for t in plot_themes . COMPAT_TYPES ] )[ 0 ][ 0 ] # r-worded way to get the index of the match ], \"color\" : plot_themes . WHITE , \"fixed_range\" : False , } return traces build_1d_traces ( param , color , ntrace , unit ) Build traces for 1d param Source code in ccg\\ui\\plotgo.py 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 @profile def build_1d_traces ( self , param : ccg . Tbl , color : int , ntrace : int , unit : str ): \"\"\"Build traces for 1d param\"\"\" traces = [] self . nyaxes = 1 # Ever case for more than 1? yaxis = f \"y { self . nyaxes } \" # TODO: Fix for multiple axes hov_temp = f \"\"\" { param . name } : % {{ y:. { param . precision } f }} [ { unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } f }} [ { param . axes [ 0 ] . unit } ]<extra></extra>\"\"\" try : tmp_trc = { \"type\" : \"scattergl\" , \"y\" : param . orig . data , \"x\" : param . orig . axes [ 0 ] . data , \"name\" : param . orig . name , \"mode\" : \"markers+lines\" , \"yaxis\" : yaxis , \"opacity\" : 1 , \"hovertemplate\" : hov_temp , \"marker\" : { \"size\" : np . array ([ 10 ] * param . orig . data . size ), \"color\" : plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ], \"line\" : { \"color\" : ccg . util . max_contrast ( self . fig . layout [ \"template\" ][ \"layout\" ][ \"plot_bgcolor\" ], ccg . util . shift_lightness ( plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ], 1.4 ), ccg . util . shift_lightness ( plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ], 0.4 ), ), \"width\" : 1 , }, }, \"line\" : { \"width\" : 1 , \"shape\" : plot_themes . LINESHAPE [ param . orig . axes [ 0 ] . interp_method ], \"color\" : plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ], }, \"hoverlabel\" : { \"bgcolor\" : plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ] }, \"showlegend\" : True , \"legendgroup\" : f \" { param . orig . name } _ { ntrace } \" , } traces . append ( tmp_trc ) ntrace += 1 except KeyError : pass if color is None : color = ntrace tmp_trc = { \"type\" : \"scattergl\" , \"y\" : param . data , \"x\" : param . axes [ 0 ] . data , \"name\" : param . name , \"mode\" : \"markers+lines\" , \"hovertemplate\" : hov_temp , \"opacity\" : 1 , \"marker\" : { \"size\" : np . array ([ 10 ] * param . data . size ), \"color\" : plot_themes . TRACES [ color % plot_themes . N_COLORS ], \"line\" : { \"color\" : ccg . util . max_contrast ( self . fig . layout [ \"template\" ][ \"layout\" ][ \"plot_bgcolor\" ], ccg . util . shift_lightness ( plot_themes . TRACES [ color % plot_themes . N_COLORS ], 1.4 ), ccg . util . shift_lightness ( plot_themes . TRACES [ color % plot_themes . N_COLORS ], 0.4 ), ), \"width\" : 1 , }, }, \"line\" : { \"width\" : 1 , \"shape\" : plot_themes . LINESHAPE [ param . axes [ 0 ] . interp_method ], \"color\" : plot_themes . TRACES [ color % plot_themes . N_COLORS ], }, \"hoverlabel\" : { \"bgcolor\" : plot_themes . TRACES [ color % plot_themes . N_COLORS ]}, \"showlegend\" : True , \"legendgroup\" : f \" { param . name } _ { ntrace } \" , } traces . append ( tmp_trc ) ntrace += 1 nscatter = 0 for scatter in param . scatter_data : if scatter is not None : # plot the scatter data as well. nscatter += 1 tmp_trc = self . build_scatter_trace ( scatter = scatter , param = param , ntrace = ntrace , nscatter = nscatter ) traces . append ( tmp_trc ) ntrace += 1 self . yaxes [ yaxis ] = { \"unit\" : param . unit , \"min\" : param . data_range [ 0 ], \"max\" : param . data_range [ 1 ], \"dtype\" : plot_themes . COMPAT_TYPES [ np . where ( [ param . data . dtype . kind in t for t in plot_themes . COMPAT_TYPES ] )[ 0 ][ 0 ] # r-worded way to get the index of the match ], \"color\" : plot_themes . WHITE , \"fixed_range\" : False , } return traces build_2d_traces ( param , color , ntrace , unit ) build traces from 2d param Source code in ccg\\ui\\plotgo.py 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 @profile def build_2d_traces ( self , param : ccg . Tbl , color : int , ntrace : int , unit : str ): \"\"\"build traces from 2d param\"\"\" traces = [] try : traces . extend ( self . build_surf_traces ( param . orig , ntrace , ntrace , unit , visible = True ) ) ntrace += 1 except KeyError : pass if color is None : color = ntrace traces . extend ( self . build_surf_traces ( param , color , ntrace , unit )) ntrace += 1 nscatter = 0 for scatter in param . scatter_data : if scatter is not None : # plot the scatter data as well. nscatter += 1 tmp_trc = self . build_scatter_trace ( scatter = scatter , param = param , ntrace = ntrace , nscatter = nscatter ) traces . append ( tmp_trc ) ntrace += 1 # TODO: Should edit the layout here... self . fig . layout [ \"scene\" ][ \"xaxis\" ] . update ( { \"title\" : { \"text\" : f \" { param . axes [ 0 ] . name } [ { param . axes [ 0 ] . unit } ]\" }} ) self . fig . layout [ \"scene\" ][ \"yaxis\" ] . update ( { \"title\" : { \"text\" : f \" { param . axes [ 1 ] . name } [ { param . axes [ 1 ] . unit } ]\" }} ) self . fig . layout [ \"scene\" ][ \"zaxis\" ] . update ( { \"title\" : { \"text\" : f \" { param . name } [ { param . unit } ]\" }} ) self . fig . layout [ \"scene\" ] . update ( { \"camera\" : { \"eye\" : { \"x\" : - 1.25 , \"y\" : - 1.25 , \"z\" : 1.1 }}, } ) # scene = { # \"scene\": { # \"xaxis\": xaxis, # \"yaxis\": yaxis, # \"zaxis\": zaxis, # \"camera\": {\"eye\": {\"x\": -1.25, \"y\": -1.25, \"z\": 1.1}}, # } # } return traces build_scatter_trace ( scatter , param = None , ntrace = 1 , nscatter = 1 ) Builds a scatter trace. ntrace and nscatter are counters for color increments Source code in ccg\\ui\\plotgo.py 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 @profile def build_scatter_trace ( self , scatter : ccg . ScatterData , param : ccg . Tbl = None , ntrace : int = 1 , nscatter : int = 1 , ): \"\"\"Builds a scatter trace. ntrace and nscatter are counters for color increments\"\"\" ndim = scatter . ndim tmp_trc = { \"name\" : scatter . name , \"mode\" : \"markers\" , \"opacity\" : 1 , \"marker\" : { \"size\" : 3 , \"color\" : plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ], \"colorscale\" : [ plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ]] * 2 , \"showscale\" : False , }, \"hoverlabel\" : { \"bgcolor\" : plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ] }, \"showlegend\" : True , \"legendgroup\" : f \" { scatter . name } _ { ntrace } \" , } if scatter . color is not None : tmp = { \"marker\" : { \"color\" : scatter . color , \"colorscale\" : \"turbo\" , \"colorbar\" : { \"bgcolor\" : plot_themes . THEME3 , \"bordercolor\" : plot_themes . THEME4 , \"borderwidth\" : 1 , \"title\" : { \"text\" : f \" { scatter . color_label } [ { scatter . color_unit } ]\" , \"side\" : \"right\" , }, \"x\" : 0 , }, \"showscale\" : True , }, \"text\" : np . round ( scatter . color , scatter . color_precision ), } if scatter . color_range is not None : ccg . util . merge_dict ( tmp , { \"marker\" : { \"cmin\" : scatter . color_range [ 0 ], \"cmax\" : scatter . color_range [ 1 ], } }, ) # Need to move legend to clear color bar. tmp_lgnd = { \"xanchor\" : \"right\" , \"yanchor\" : \"top\" , \"x\" : 1 , \"y\" : 1 , } self . fig . update_legends ( tmp_lgnd ) ccg . util . merge_dict ( tmp_trc , tmp ) if ndim == 2 : if param is not None : if scatter . color is not None : hov_temp = f \"\"\" { scatter . name } : % {{ z:. { param . precision } f }} [ { param . unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } f }} [ { param . axes [ 0 ] . unit } ]<br> { param . axes [ 1 ] . name } : % {{ y:. { param . axes [ 1 ] . precision } f }} [ { param . axes [ 1 ] . unit } ]<br> { scatter . color_label } : % {{ marker.color:. { scatter . color_precision } f }} [ { scatter . color_unit } ] <extra></extra>\"\"\" else : hov_temp = f \"\"\" { scatter . name } : % {{ z:. { param . precision } d }} [ { param . unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } d }} [ { param . axes [ 0 ] . unit } ]<br> { param . axes [ 1 ] . name } : % {{ y:. { param . axes [ 1 ] . precision } d }} [ { param . axes [ 1 ] . unit } ] <extra></extra>\"\"\" else : if scatter . color is not None : hov_temp = \"\" tmp = { \"type\" : \"scatter3d\" , \"x\" : scatter . data [ 0 ], \"y\" : scatter . data [ 1 ], \"z\" : scatter . data [ 2 ], \"hovertemplate\" : hov_temp , } elif ndim == 1 : if param is not None : if scatter . color is not None : hov_temp = f \"\"\" { scatter . name } : % {{ y:. { param . precision } f }} [ { param . unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } f }} [ { param . axes [ 0 ] . unit } ]<br> { scatter . color_label } : % {{ marker.color:. { scatter . color_precision } f }} [ { scatter . color_unit } ] <extra></extra>\"\"\" else : hov_temp = f \"\"\" { scatter . name } : % {{ y:. { param . precision } d }} [ { param . unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } d }} [ { param . axes [ 0 ] . unit } ]<br> <extra></extra>\"\"\" else : hov_temp = \"\" tmp = { \"type\" : \"scattergl\" , \"x\" : scatter . data [ 0 ], \"y\" : scatter . data [ 1 ], \"hovertemplate\" : hov_temp , } elif ndim == 0 : if param is not None : if scatter . color is not None : hov_temp = f \"\"\" { scatter . name } : % {{ y:. { param . precision } f }} [ { param . unit } ]<br> { scatter . color_label } : % {{ marker.color:. { scatter . color_precision } f }} [ { scatter . color_unit } ] <extra></extra>\"\"\" else : hov_temp = f \"\"\" { scatter . name } : % {{ y:. { param . precision } d }} [ { param . unit } ]<br> <extra></extra>\"\"\" else : hov_temp = \"\" tmp = { \"type\" : \"scattergl\" , \"x\" : scatter . data [ 0 ] * 0 , \"y\" : scatter . data [ 1 ], \"hovertemplate\" : hov_temp , } else : raise NotImplementedError ccg . util . merge_dict ( tmp_trc , tmp ) if nscatter > 1 : ccg . util . merge_dict ( tmp_trc , { \"visible\" : \"legendonly\" }) return tmp_trc build_surf_traces ( param , color , ntrace , unit , visible = True ) Build 2d surface trace Source code in ccg\\ui\\plotgo.py 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 def build_surf_traces ( self , param : ccg . Tbl , color : int , ntrace : int , unit : str , visible : bool = True , ): \"\"\"Build 2d surface trace\"\"\" if not visible : visible = \"legendonly\" hov_temp = f \"\"\" { param . name } : % {{ z:. { param . precision } f }} [ { param . unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } f }} [ { param . axes [ 0 ] . unit } ]<br> { param . axes [ 1 ] . name } : % {{ y:. { param . axes [ 1 ] . precision } f }} [ { param . axes [ 1 ] . unit } ] <extra></extra>\"\"\" x , y = np . meshgrid ( param . axes [ 0 ] . data , param . axes [ 1 ] . data ) x = np . concatenate (( x , x [ - 1 , np . newaxis ])) y = np . concatenate (( y , y [ - 1 , np . newaxis ])) z = np . concatenate (( param . data . T , param . data . T [ - 1 , np . newaxis ] * np . NaN )) i = x . flatten ( \"F\" ) j = y . flatten ( \"F\" ) k = z . flatten ( \"F\" ) y , x = np . meshgrid ( param . axes [ 1 ] . data , param . axes [ 0 ] . data ) x = np . concatenate (( x , x [ - 1 , np . newaxis ])) y = np . concatenate (( y , y [ - 1 , np . newaxis ])) z = np . concatenate (( param . data , param . data [ - 1 , np . newaxis ] * np . NaN )) i = np . concatenate (( i , x . flatten ( \"F\" ))) j = np . concatenate (( j , y . flatten ( \"F\" ))) k = np . concatenate (( k , z . flatten ( \"F\" ))) traces = [ { \"type\" : \"surface\" , \"x\" : param . axes [ 0 ] . data , \"y\" : param . axes [ 1 ] . data , \"z\" : param . data . T , \"name\" : f \" { param . name }{ unit } \" , \"hovertemplate\" : hov_temp , \"hoverlabel\" : { \"bgcolor\" : plot_themes . TRACES [ color % plot_themes . N_COLORS ] }, \"opacity\" : 0.5 , \"colorscale\" : [ plot_themes . TRACES [ color % plot_themes . N_COLORS ]] * 2 , \"showlegend\" : True , \"legendgroup\" : f \" { param . name } _ { ntrace } \" , \"showscale\" : False , \"visible\" : visible , }, { \"type\" : \"scatter3d\" , \"x\" : i , \"y\" : j , \"z\" : k , \"name\" : f \" { param . name }{ unit } \" , \"hoverinfo\" : \"skip\" , \"opacity\" : 1 , \"marker\" : { \"color\" : np . array ( [ plot_themes . TRACES [ color % plot_themes . N_COLORS ]] * len ( i ) ), \"size\" : np . array ([ 10 ] * len ( i )), # \"line\": { # \"color\": ccg.util.max_contrast( # plot_themes.TRACES[color % plot_themes.N_COLORS], # ccg.util.shift_lightness( # plot_themes.TRACES[color % plot_themes.N_COLORS], 1.4 # ), # ccg.util.shift_lightness( # plot_themes.TRACES[color % plot_themes.N_COLORS], 0.4 # ), # ), # \"width\": 1, # }, }, \"line\" : { \"color\" : ccg . util . max_contrast ( plot_themes . TRACES [ color % plot_themes . N_COLORS ], ccg . util . shift_lightness ( plot_themes . TRACES [ color % plot_themes . N_COLORS ], 1.4 ), ccg . util . shift_lightness ( plot_themes . TRACES [ color % plot_themes . N_COLORS ], 0.4 ), ), \"width\" : 2 , }, \"showlegend\" : False , \"legendgroup\" : f \" { param . name } _ { ntrace } \" , \"connectgaps\" : False , \"visible\" : visible , }, ] return traces build_trace_from_sig ( sig , color = None , yaxis = None ) Build Trace for plotly from a Sig. Source code in ccg\\ui\\plotgo.py 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 def build_trace_from_sig ( self , sig : ccg . Sig , color : int = None , yaxis : str = None ): \"\"\"Build Trace for plotly from a Sig.\"\"\" ntrace = self . ntrace + 1 if color is None : color = ntrace sig = sig . plot_prep () yaxis = self . find_yaxis ( sig , yaxis ) unit = \"\" if sig . unit is None else sig . unit if sig . tline [ 0 ] < 32000000 : # apprx 1yr from epoch # assume this is an elapsed time instead x = sig . tline . unix hov_temp = \"\"\" Value: % {y:.2f} % {yaxis.title.text} <br> Time: % {x:.3f} [s]\"\"\" self . fig . update_layout ({ \"xaxis1\" : { \"title\" : \"Elapsed Time [s]\" }}) else : x = sig . tline . iso hov_temp = \"\"\" Value: % {y:.2f} % {yaxis.title.text} <br> Time: %{x|%H:%M:%S.%L}\"\"\" self . fig . update_layout ({ \"xaxis1\" : { \"title\" : \"Date and Time\" }}) if sig . nsamples > 100000 : hov = \"skip\" # Disable hover since its too slow hov_temp = \"\" else : hov = \"all\" trace = { \"type\" : \"scattergl\" , \"y\" : sig . data , \"x\" : x , \"name\" : f \" { sig . name } [ { unit } ]\" , \"mode\" : \"markers+lines\" , \"hovertemplate\" : hov_temp , \"hoverinfo\" : hov , \"yaxis\" : yaxis , \"opacity\" : 1 , \"connectgaps\" : bool ( sig . connect_gaps ), # should work if connect_gaps is None \"marker\" : { # \"color\": TRACES[self.ntrace], \"size\" : [ 2 ] * len ( x ), \"line\" : { \"color\" : ccg . util . max_contrast ( self . fig . layout [ \"template\" ][ \"layout\" ][ \"plot_bgcolor\" ], ccg . util . shift_lightness ( plot_themes . TRACES [ color % plot_themes . N_COLORS ], 1.4 ), ccg . util . shift_lightness ( plot_themes . TRACES [ color % plot_themes . N_COLORS ], 0.4 ), ), \"width\" : 1 , }, }, \"line\" : { \"width\" : 1 , \"shape\" : plot_themes . LINESHAPE [ sig . interp_method ], \"color\" : plot_themes . TRACES [ color % plot_themes . N_COLORS ], }, } if sig . base_data is not None : ccg . util . merge_dict ( trace , { \"text\" : sig . base_data , \"hovertemplate\" : \"\"\"Value: % {text} <br> Time: %{x|%H:%M:%S.%L}\"\"\" , }, ) return trace build_traces_from_tbl ( tbl , color = None ) build traces from table. Source code in ccg\\ui\\plotgo.py 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 def build_traces_from_tbl ( self , tbl : ccg . Tbl , color : int = None ) -> list [ dict ]: \"\"\"build traces from table.\"\"\" ntrace = self . ntrace + 1 if tbl . unit is not None : unit = f \" [ { tbl . unit } ]\" else : unit = \"\" if tbl . n_dim == 2 : traces = self . build_2d_traces ( tbl , color , ntrace , unit ) elif tbl . n_dim == 1 : traces = self . build_1d_traces ( tbl , color , ntrace , unit ) elif tbl . n_dim == 0 : traces = self . build_0d_traces ( tbl , color , ntrace , unit ) else : raise NotImplementedError ( f \"Plot not implemented for n_dim = { tbl . n_dim } \" ) return traces build_yaxes () Build yaxes element for layout. Source code in ccg\\ui\\plotgo.py 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 def build_yaxes ( self ): \"\"\"Build yaxes element for layout.\"\"\" # tic = datetime.now() yaxes : dict [ str , dict ] = {} domain_min = 1 domain_min_name = \"y1\" # TODO: Handle domains better... for i , ( y_name , yaxis ) in enumerate ( self . yaxes . items ()): yaxis_tmp = copy . deepcopy ( yaxis ) # Since we will remove stuff from this later... name = y_name . replace ( \"y\" , \"yaxis\" ) if ( i % 2 ) == 0 : side = \"left\" pos = round ( i / 2 + 0.001 ) * plot_themes . FPOS else : side = \"right\" pos = 1 - round ( i / 2 - 0.001 + 1 ) * plot_themes . FPOS unit = yaxis_tmp . pop ( \"unit\" ) # Pop since its not a standard. _ = yaxis_tmp . pop ( \"dtype\" ) # not needed here data_range = [ yaxis_tmp . pop ( \"min\" ), yaxis_tmp . pop ( \"max\" )] if not yaxis_tmp . pop ( \"fixed_range\" ): data_range = False # Not sure im ready to use this yet. title = \"\" if unit is None else f \"[ { unit } ]\" ccg . util . merge_dict ( yaxes , { name : { \"title\" : { \"text\" : title }, \"overlaying\" : \"y1\" , \"anchor\" : \"x1\" , \"position\" : pos , \"color\" : yaxis_tmp [ \"color\" ], \"gridcolor\" : yaxis_tmp [ \"color\" ], \"showgrid\" : True , \"showline\" : True , \"mirror\" : True , \"side\" : side , \"spikesnap\" : \"hovered data\" , \"spikemode\" : \"across+marker\" , \"spikedash\" : \"solid\" , \"spikethickness\" : 1 , \"ticks\" : \"outside\" , \"ticklen\" : 3 , \"zerolinecolor\" : yaxis_tmp [ \"color\" ], \"zerolinewidth\" : 2 , } }, ) ccg . util . merge_dict ( yaxes [ name ], yaxis_tmp ) if data_range : ccg . util . merge_dict ( yaxes [ name ], { \"range\" : data_range , }, ) if i > 0 : del yaxes [ f \"yaxis { i } \" ][ \"anchor\" ] # to allow spacing multiple if \"domain\" in yaxis_tmp : if yaxis_tmp [ \"domain\" ][ 0 ] < domain_min : domain_min = yaxis_tmp [ \"domain\" ][ 0 ] domain_min_name = y_name if not yaxes : return del yaxes [ \"yaxis1\" ][ \"overlaying\" ] # to allow hover to work try : # TODO: Improve this for more domains del yaxes [ domain_min_name . replace ( \"y\" , \"yaxis\" )][ \"overlaying\" ] except KeyError : pass yaxes [ \"xaxis1\" ] = { \"domain\" : [ ( round (( self . nyaxes ) / 2 + 0.001 ) - 1 ) * plot_themes . FPOS , 1 - round ( self . nyaxes / 2 - 0.001 ) * plot_themes . FPOS , ], # +0.001 since python is r-worded} \"anchor\" : domain_min_name , } self . fig . update_layout ( yaxes ) find_yaxis ( sig , yaxis = None ) Check for matching y axes. Source code in ccg\\ui\\plotgo.py 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 def find_yaxis ( self , sig : ccg . Sig , yaxis : str = None ): \"\"\"Check for matching y axes.\"\"\" if sig . data_range is not None : sig_min = sig . data_range [ 0 ] sig_max = sig . data_range [ 1 ] fixed_range = True else : sig_min = sig . min sig_max = sig . max fixed_range = False if yaxis is not None : if yaxis in self . yaxes : try : if \"U\" in self . yaxes [ yaxis ][ \"dtype\" ]: # its a string type so no scaling info self . yaxes [ yaxis ][ \"color\" ] = plot_themes . WHITE # change to grey for multi return yaxis yrange = self . yaxes [ yaxis ][ \"max\" ] - self . yaxes [ yaxis ][ \"min\" ] sigrange = sig_max - sig_min if yrange == 0 : yrange = self . yaxes [ yaxis ][ \"min\" ] self . yaxes [ yaxis ][ \"color\" ] = plot_themes . WHITE # change to grey for multi # Should we update the max and min here? could let it expand to inf... # Maybe an average? if fixed_range : self . yaxes [ yaxis ][ \"fixed_range\" ] = fixed_range self . yaxes [ yaxis ][ \"min\" ] = ( self . yaxes [ yaxis ][ \"min\" ] + sig_min ) / 2 self . yaxes [ yaxis ][ \"max\" ] = ( self . yaxes [ yaxis ][ \"max\" ] + sig_max ) / 2 return yaxis except TypeError : # For the case of dtype=obj and not compat pass else : self . nyaxes += 1 self . yaxes [ yaxis ] = { \"unit\" : sig . unit , \"min\" : sig_min , \"max\" : sig_max , \"dtype\" : plot_themes . COMPAT_TYPES [ np . where ( [ sig . data . dtype . kind in t for t in plot_themes . COMPAT_TYPES ] )[ 0 ][ 0 ] # r-worded way to get the index of the match ], \"color\" : ccg . util . max_contrast ( plot_themes . THEME2 , ccg . util . shift_lightness ( plot_themes . TRACES [ ( self . ntrace + 1 ) % plot_themes . N_COLORS ], 1.4 , ), ccg . util . shift_lightness ( plot_themes . TRACES [ ( self . ntrace + 1 ) % plot_themes . N_COLORS ], 0.4 , ), ), \"fixed_range\" : fixed_range , } return yaxis else : if self . nyaxes > 0 : for yaxis , yaxis_def in self . yaxes . items (): if ( sig . data . dtype . kind in yaxis_def [ \"dtype\" ] and yaxis_def [ \"unit\" ] == sig . unit ): try : if \"U\" in yaxis_def [ \"dtype\" ]: # its a string type so no scaling info yaxis_def [ \"color\" ] = ( plot_themes . WHITE ) # change to grey for multi return yaxis yrange = yaxis_def [ \"max\" ] - yaxis_def [ \"min\" ] sigrange = sig_max - sig_min if yrange == 0 : yrange = yaxis_def [ \"min\" ] if ( sig_min > yaxis_def [ \"min\" ] - ( yrange * plot_themes . FRANGE / 2 ) and sig_max < yaxis_def [ \"max\" ] + ( yrange * plot_themes . FRANGE / 2 ) and sigrange < yrange * plot_themes . FRANGE and sigrange > yrange / plot_themes . FRANGE ): yaxis_def [ \"color\" ] = ( plot_themes . WHITE ) # change to grey for multi # Should we update the max and min here? could let it expand to inf... # Maybe an average? if fixed_range : yaxis_def [ \"fixed_range\" ] = fixed_range yaxis_def [ \"min\" ] = ( yaxis_def [ \"min\" ] + sig_min ) / 2 yaxis_def [ \"max\" ] = ( yaxis_def [ \"max\" ] + sig_max ) / 2 return yaxis except TypeError : # For the case of dtype=obj and not compat pass self . nyaxes += 1 yaxis = f \"y { self . nyaxes } \" self . yaxes [ yaxis ] = { \"unit\" : sig . unit , \"min\" : sig_min , \"max\" : sig_max , \"dtype\" : plot_themes . COMPAT_TYPES [ np . where ( [ sig . data . dtype . kind in t for t in plot_themes . COMPAT_TYPES ] )[ 0 ][ 0 ] # r-worded way to get the index of the match ], \"color\" : ccg . util . max_contrast ( plot_themes . THEME2 , ccg . util . shift_lightness ( plot_themes . TRACES [( self . ntrace + 1 ) % plot_themes . N_COLORS ], 1.4 , ), ccg . util . shift_lightness ( plot_themes . TRACES [( self . ntrace + 1 ) % plot_themes . N_COLORS ], 0.4 , ), ), \"fixed_range\" : fixed_range , } return yaxis","title":"plotgo"},{"location":"reference/ccg/ui/plotgo/#ccg.ui.plotgo.Plot","text":"New plot class, uses go.Figure() Source code in ccg\\ui\\plotgo.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 class Plot : \"\"\"New plot class, uses go.Figure()\"\"\" @profile def __init__ ( self , data : ccg . Frame | ccg . Sig | ccg . Tbl | ccg . ScatterData = None , name : str = None , ): self . nyaxes = 0 self . ntrace = - 1 self . n_cond = 0 # For use in gate diag plots self . n_col = 0 # For use in gate diag plots self . yaxes : dict = {} self . fig = go . Figure () self . fig = go . Figure () self . fig . update_layout ( template = plot_themes . ccg_tbl ) # Build traces if isinstance ( data , ccg . Frame ): traces = [] for sig in data : traces . append ( self . build_trace_from_sig ( sig )) self . append_trace ( traces ) self . build_yaxes () elif isinstance ( data , ccg . Sig ): traces = self . build_trace_from_sig ( data ) self . append_trace ( traces ) self . build_yaxes () elif isinstance ( data , ccg . Tbl ): traces = self . build_traces_from_tbl ( data ) self . append_trace ( traces ) self . ntrace -= 1 self . build_yaxes () elif isinstance ( data , ccg . ScatterData ): # self.append_trace_from_scatter(data) raise NotImplementedError elif data is None : pass else : raise NotImplementedError ( f \"Plot not implemented for { type ( data ) } \" ) if name is None : if data is not None and data . name is not None : name = data . name self . fig . update_layout ( title_text = name ) else : self . fig . update_layout ( layout_title_text = name ) # @profile # def append_trace_from_tbl(self, tbl: ccg.Tbl): # \"\"\"build trace from table and append\"\"\" # try: # trace = self.build_traces_from_tbl(tbl) # self.append_trace(trace) # except (NotImplementedError, KeyError) as err: # _LOGGER.warning(\"%s. Skipped %s.\", err, tbl.name) def build_traces_from_tbl ( self , tbl : ccg . Tbl , color : int = None ) -> list [ dict ]: \"\"\"build traces from table.\"\"\" ntrace = self . ntrace + 1 if tbl . unit is not None : unit = f \" [ { tbl . unit } ]\" else : unit = \"\" if tbl . n_dim == 2 : traces = self . build_2d_traces ( tbl , color , ntrace , unit ) elif tbl . n_dim == 1 : traces = self . build_1d_traces ( tbl , color , ntrace , unit ) elif tbl . n_dim == 0 : traces = self . build_0d_traces ( tbl , color , ntrace , unit ) else : raise NotImplementedError ( f \"Plot not implemented for n_dim = { tbl . n_dim } \" ) return traces @profile def append_trace ( self , trace : dict | list [ dict ]): \"Append trace to traces.\" if isinstance ( trace , list ): self . fig . add_traces ( trace ) else : self . fig . add_trace ( trace ) self . ntrace += 1 def build_0d_traces ( self , param : ccg . Tbl , color : int , ntrace : int , unit : str ): \"\"\"Build traces for 0d param\"\"\" traces = [] self . nyaxes = 1 # Ever a case for more than 1? yaxis = f \"y { self . nyaxes } \" hov_temp = ( f \"\"\" { param . name } : % {{ y:. { param . precision } f }} [ { unit } ]<extra></extra>\"\"\" ) try : tmp_trc = { \"type\" : \"scattergl\" , \"y\" : param . orig . data , \"name\" : param . orig . name , \"mode\" : \"markers\" , \"yaxis\" : yaxis , \"opacity\" : 1 , \"hovertemplate\" : hov_temp , \"marker\" : { \"size\" : 8 , \"color\" : plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ], \"line\" : { \"color\" : ccg . util . max_contrast ( self . fig . layout [ \"template\" ][ \"layout\" ][ \"plot_bgcolor\" ], ccg . util . shift_lightness ( plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ], 1.4 ), ccg . util . shift_lightness ( plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ], 0.4 ), ), \"width\" : 1 , }, }, \"hoverlabel\" : { \"bgcolor\" : plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ] }, \"showlegend\" : True , \"legendgroup\" : f \" { param . orig . name } _ { ntrace } \" , } traces . append ( tmp_trc ) ntrace += 1 except KeyError : pass if color is None : color = ntrace tmp_trc = { \"type\" : \"scattergl\" , \"y\" : param . data , \"name\" : param . name , \"mode\" : \"markers\" , \"hovertemplate\" : hov_temp , \"opacity\" : 1 , \"marker\" : { \"size\" : 8 , \"color\" : plot_themes . TRACES [ color % plot_themes . N_COLORS ], \"line\" : { \"color\" : ccg . util . max_contrast ( self . fig . layout [ \"template\" ][ \"layout\" ][ \"plot_bgcolor\" ], ccg . util . shift_lightness ( plot_themes . TRACES [ color % plot_themes . N_COLORS ], 1.4 ), ccg . util . shift_lightness ( plot_themes . TRACES [ color % plot_themes . N_COLORS ], 0.4 ), ), \"width\" : 1 , }, }, \"hoverlabel\" : { \"bgcolor\" : plot_themes . TRACES [ color % plot_themes . N_COLORS ]}, \"showlegend\" : True , \"legendgroup\" : f \" { param . name } _ { ntrace } \" , } traces . append ( tmp_trc ) ntrace += 1 nscatter = 0 for scatter in param . scatter_data : if scatter is not None : # plot the scatter data as well. nscatter += 1 tmp_trc = self . build_scatter_trace ( scatter = scatter , param = param , ntrace = ntrace , nscatter = nscatter ) traces . append ( tmp_trc ) ntrace += 1 self . yaxes [ yaxis ] = { \"unit\" : param . unit , \"min\" : param . data_range [ 0 ], \"max\" : param . data_range [ 1 ], \"dtype\" : plot_themes . COMPAT_TYPES [ np . where ( [ param . data . dtype . kind in t for t in plot_themes . COMPAT_TYPES ] )[ 0 ][ 0 ] # r-worded way to get the index of the match ], \"color\" : plot_themes . WHITE , \"fixed_range\" : False , } return traces @profile def build_1d_traces ( self , param : ccg . Tbl , color : int , ntrace : int , unit : str ): \"\"\"Build traces for 1d param\"\"\" traces = [] self . nyaxes = 1 # Ever case for more than 1? yaxis = f \"y { self . nyaxes } \" # TODO: Fix for multiple axes hov_temp = f \"\"\" { param . name } : % {{ y:. { param . precision } f }} [ { unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } f }} [ { param . axes [ 0 ] . unit } ]<extra></extra>\"\"\" try : tmp_trc = { \"type\" : \"scattergl\" , \"y\" : param . orig . data , \"x\" : param . orig . axes [ 0 ] . data , \"name\" : param . orig . name , \"mode\" : \"markers+lines\" , \"yaxis\" : yaxis , \"opacity\" : 1 , \"hovertemplate\" : hov_temp , \"marker\" : { \"size\" : np . array ([ 10 ] * param . orig . data . size ), \"color\" : plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ], \"line\" : { \"color\" : ccg . util . max_contrast ( self . fig . layout [ \"template\" ][ \"layout\" ][ \"plot_bgcolor\" ], ccg . util . shift_lightness ( plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ], 1.4 ), ccg . util . shift_lightness ( plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ], 0.4 ), ), \"width\" : 1 , }, }, \"line\" : { \"width\" : 1 , \"shape\" : plot_themes . LINESHAPE [ param . orig . axes [ 0 ] . interp_method ], \"color\" : plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ], }, \"hoverlabel\" : { \"bgcolor\" : plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ] }, \"showlegend\" : True , \"legendgroup\" : f \" { param . orig . name } _ { ntrace } \" , } traces . append ( tmp_trc ) ntrace += 1 except KeyError : pass if color is None : color = ntrace tmp_trc = { \"type\" : \"scattergl\" , \"y\" : param . data , \"x\" : param . axes [ 0 ] . data , \"name\" : param . name , \"mode\" : \"markers+lines\" , \"hovertemplate\" : hov_temp , \"opacity\" : 1 , \"marker\" : { \"size\" : np . array ([ 10 ] * param . data . size ), \"color\" : plot_themes . TRACES [ color % plot_themes . N_COLORS ], \"line\" : { \"color\" : ccg . util . max_contrast ( self . fig . layout [ \"template\" ][ \"layout\" ][ \"plot_bgcolor\" ], ccg . util . shift_lightness ( plot_themes . TRACES [ color % plot_themes . N_COLORS ], 1.4 ), ccg . util . shift_lightness ( plot_themes . TRACES [ color % plot_themes . N_COLORS ], 0.4 ), ), \"width\" : 1 , }, }, \"line\" : { \"width\" : 1 , \"shape\" : plot_themes . LINESHAPE [ param . axes [ 0 ] . interp_method ], \"color\" : plot_themes . TRACES [ color % plot_themes . N_COLORS ], }, \"hoverlabel\" : { \"bgcolor\" : plot_themes . TRACES [ color % plot_themes . N_COLORS ]}, \"showlegend\" : True , \"legendgroup\" : f \" { param . name } _ { ntrace } \" , } traces . append ( tmp_trc ) ntrace += 1 nscatter = 0 for scatter in param . scatter_data : if scatter is not None : # plot the scatter data as well. nscatter += 1 tmp_trc = self . build_scatter_trace ( scatter = scatter , param = param , ntrace = ntrace , nscatter = nscatter ) traces . append ( tmp_trc ) ntrace += 1 self . yaxes [ yaxis ] = { \"unit\" : param . unit , \"min\" : param . data_range [ 0 ], \"max\" : param . data_range [ 1 ], \"dtype\" : plot_themes . COMPAT_TYPES [ np . where ( [ param . data . dtype . kind in t for t in plot_themes . COMPAT_TYPES ] )[ 0 ][ 0 ] # r-worded way to get the index of the match ], \"color\" : plot_themes . WHITE , \"fixed_range\" : False , } return traces @profile def build_2d_traces ( self , param : ccg . Tbl , color : int , ntrace : int , unit : str ): \"\"\"build traces from 2d param\"\"\" traces = [] try : traces . extend ( self . build_surf_traces ( param . orig , ntrace , ntrace , unit , visible = True ) ) ntrace += 1 except KeyError : pass if color is None : color = ntrace traces . extend ( self . build_surf_traces ( param , color , ntrace , unit )) ntrace += 1 nscatter = 0 for scatter in param . scatter_data : if scatter is not None : # plot the scatter data as well. nscatter += 1 tmp_trc = self . build_scatter_trace ( scatter = scatter , param = param , ntrace = ntrace , nscatter = nscatter ) traces . append ( tmp_trc ) ntrace += 1 # TODO: Should edit the layout here... self . fig . layout [ \"scene\" ][ \"xaxis\" ] . update ( { \"title\" : { \"text\" : f \" { param . axes [ 0 ] . name } [ { param . axes [ 0 ] . unit } ]\" }} ) self . fig . layout [ \"scene\" ][ \"yaxis\" ] . update ( { \"title\" : { \"text\" : f \" { param . axes [ 1 ] . name } [ { param . axes [ 1 ] . unit } ]\" }} ) self . fig . layout [ \"scene\" ][ \"zaxis\" ] . update ( { \"title\" : { \"text\" : f \" { param . name } [ { param . unit } ]\" }} ) self . fig . layout [ \"scene\" ] . update ( { \"camera\" : { \"eye\" : { \"x\" : - 1.25 , \"y\" : - 1.25 , \"z\" : 1.1 }}, } ) # scene = { # \"scene\": { # \"xaxis\": xaxis, # \"yaxis\": yaxis, # \"zaxis\": zaxis, # \"camera\": {\"eye\": {\"x\": -1.25, \"y\": -1.25, \"z\": 1.1}}, # } # } return traces @profile def build_scatter_trace ( self , scatter : ccg . ScatterData , param : ccg . Tbl = None , ntrace : int = 1 , nscatter : int = 1 , ): \"\"\"Builds a scatter trace. ntrace and nscatter are counters for color increments\"\"\" ndim = scatter . ndim tmp_trc = { \"name\" : scatter . name , \"mode\" : \"markers\" , \"opacity\" : 1 , \"marker\" : { \"size\" : 3 , \"color\" : plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ], \"colorscale\" : [ plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ]] * 2 , \"showscale\" : False , }, \"hoverlabel\" : { \"bgcolor\" : plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ] }, \"showlegend\" : True , \"legendgroup\" : f \" { scatter . name } _ { ntrace } \" , } if scatter . color is not None : tmp = { \"marker\" : { \"color\" : scatter . color , \"colorscale\" : \"turbo\" , \"colorbar\" : { \"bgcolor\" : plot_themes . THEME3 , \"bordercolor\" : plot_themes . THEME4 , \"borderwidth\" : 1 , \"title\" : { \"text\" : f \" { scatter . color_label } [ { scatter . color_unit } ]\" , \"side\" : \"right\" , }, \"x\" : 0 , }, \"showscale\" : True , }, \"text\" : np . round ( scatter . color , scatter . color_precision ), } if scatter . color_range is not None : ccg . util . merge_dict ( tmp , { \"marker\" : { \"cmin\" : scatter . color_range [ 0 ], \"cmax\" : scatter . color_range [ 1 ], } }, ) # Need to move legend to clear color bar. tmp_lgnd = { \"xanchor\" : \"right\" , \"yanchor\" : \"top\" , \"x\" : 1 , \"y\" : 1 , } self . fig . update_legends ( tmp_lgnd ) ccg . util . merge_dict ( tmp_trc , tmp ) if ndim == 2 : if param is not None : if scatter . color is not None : hov_temp = f \"\"\" { scatter . name } : % {{ z:. { param . precision } f }} [ { param . unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } f }} [ { param . axes [ 0 ] . unit } ]<br> { param . axes [ 1 ] . name } : % {{ y:. { param . axes [ 1 ] . precision } f }} [ { param . axes [ 1 ] . unit } ]<br> { scatter . color_label } : % {{ marker.color:. { scatter . color_precision } f }} [ { scatter . color_unit } ] <extra></extra>\"\"\" else : hov_temp = f \"\"\" { scatter . name } : % {{ z:. { param . precision } d }} [ { param . unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } d }} [ { param . axes [ 0 ] . unit } ]<br> { param . axes [ 1 ] . name } : % {{ y:. { param . axes [ 1 ] . precision } d }} [ { param . axes [ 1 ] . unit } ] <extra></extra>\"\"\" else : if scatter . color is not None : hov_temp = \"\" tmp = { \"type\" : \"scatter3d\" , \"x\" : scatter . data [ 0 ], \"y\" : scatter . data [ 1 ], \"z\" : scatter . data [ 2 ], \"hovertemplate\" : hov_temp , } elif ndim == 1 : if param is not None : if scatter . color is not None : hov_temp = f \"\"\" { scatter . name } : % {{ y:. { param . precision } f }} [ { param . unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } f }} [ { param . axes [ 0 ] . unit } ]<br> { scatter . color_label } : % {{ marker.color:. { scatter . color_precision } f }} [ { scatter . color_unit } ] <extra></extra>\"\"\" else : hov_temp = f \"\"\" { scatter . name } : % {{ y:. { param . precision } d }} [ { param . unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } d }} [ { param . axes [ 0 ] . unit } ]<br> <extra></extra>\"\"\" else : hov_temp = \"\" tmp = { \"type\" : \"scattergl\" , \"x\" : scatter . data [ 0 ], \"y\" : scatter . data [ 1 ], \"hovertemplate\" : hov_temp , } elif ndim == 0 : if param is not None : if scatter . color is not None : hov_temp = f \"\"\" { scatter . name } : % {{ y:. { param . precision } f }} [ { param . unit } ]<br> { scatter . color_label } : % {{ marker.color:. { scatter . color_precision } f }} [ { scatter . color_unit } ] <extra></extra>\"\"\" else : hov_temp = f \"\"\" { scatter . name } : % {{ y:. { param . precision } d }} [ { param . unit } ]<br> <extra></extra>\"\"\" else : hov_temp = \"\" tmp = { \"type\" : \"scattergl\" , \"x\" : scatter . data [ 0 ] * 0 , \"y\" : scatter . data [ 1 ], \"hovertemplate\" : hov_temp , } else : raise NotImplementedError ccg . util . merge_dict ( tmp_trc , tmp ) if nscatter > 1 : ccg . util . merge_dict ( tmp_trc , { \"visible\" : \"legendonly\" }) return tmp_trc def build_surf_traces ( self , param : ccg . Tbl , color : int , ntrace : int , unit : str , visible : bool = True , ): \"\"\"Build 2d surface trace\"\"\" if not visible : visible = \"legendonly\" hov_temp = f \"\"\" { param . name } : % {{ z:. { param . precision } f }} [ { param . unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } f }} [ { param . axes [ 0 ] . unit } ]<br> { param . axes [ 1 ] . name } : % {{ y:. { param . axes [ 1 ] . precision } f }} [ { param . axes [ 1 ] . unit } ] <extra></extra>\"\"\" x , y = np . meshgrid ( param . axes [ 0 ] . data , param . axes [ 1 ] . data ) x = np . concatenate (( x , x [ - 1 , np . newaxis ])) y = np . concatenate (( y , y [ - 1 , np . newaxis ])) z = np . concatenate (( param . data . T , param . data . T [ - 1 , np . newaxis ] * np . NaN )) i = x . flatten ( \"F\" ) j = y . flatten ( \"F\" ) k = z . flatten ( \"F\" ) y , x = np . meshgrid ( param . axes [ 1 ] . data , param . axes [ 0 ] . data ) x = np . concatenate (( x , x [ - 1 , np . newaxis ])) y = np . concatenate (( y , y [ - 1 , np . newaxis ])) z = np . concatenate (( param . data , param . data [ - 1 , np . newaxis ] * np . NaN )) i = np . concatenate (( i , x . flatten ( \"F\" ))) j = np . concatenate (( j , y . flatten ( \"F\" ))) k = np . concatenate (( k , z . flatten ( \"F\" ))) traces = [ { \"type\" : \"surface\" , \"x\" : param . axes [ 0 ] . data , \"y\" : param . axes [ 1 ] . data , \"z\" : param . data . T , \"name\" : f \" { param . name }{ unit } \" , \"hovertemplate\" : hov_temp , \"hoverlabel\" : { \"bgcolor\" : plot_themes . TRACES [ color % plot_themes . N_COLORS ] }, \"opacity\" : 0.5 , \"colorscale\" : [ plot_themes . TRACES [ color % plot_themes . N_COLORS ]] * 2 , \"showlegend\" : True , \"legendgroup\" : f \" { param . name } _ { ntrace } \" , \"showscale\" : False , \"visible\" : visible , }, { \"type\" : \"scatter3d\" , \"x\" : i , \"y\" : j , \"z\" : k , \"name\" : f \" { param . name }{ unit } \" , \"hoverinfo\" : \"skip\" , \"opacity\" : 1 , \"marker\" : { \"color\" : np . array ( [ plot_themes . TRACES [ color % plot_themes . N_COLORS ]] * len ( i ) ), \"size\" : np . array ([ 10 ] * len ( i )), # \"line\": { # \"color\": ccg.util.max_contrast( # plot_themes.TRACES[color % plot_themes.N_COLORS], # ccg.util.shift_lightness( # plot_themes.TRACES[color % plot_themes.N_COLORS], 1.4 # ), # ccg.util.shift_lightness( # plot_themes.TRACES[color % plot_themes.N_COLORS], 0.4 # ), # ), # \"width\": 1, # }, }, \"line\" : { \"color\" : ccg . util . max_contrast ( plot_themes . TRACES [ color % plot_themes . N_COLORS ], ccg . util . shift_lightness ( plot_themes . TRACES [ color % plot_themes . N_COLORS ], 1.4 ), ccg . util . shift_lightness ( plot_themes . TRACES [ color % plot_themes . N_COLORS ], 0.4 ), ), \"width\" : 2 , }, \"showlegend\" : False , \"legendgroup\" : f \" { param . name } _ { ntrace } \" , \"connectgaps\" : False , \"visible\" : visible , }, ] return traces def build_trace_from_sig ( self , sig : ccg . Sig , color : int = None , yaxis : str = None ): \"\"\"Build Trace for plotly from a Sig.\"\"\" ntrace = self . ntrace + 1 if color is None : color = ntrace sig = sig . plot_prep () yaxis = self . find_yaxis ( sig , yaxis ) unit = \"\" if sig . unit is None else sig . unit if sig . tline [ 0 ] < 32000000 : # apprx 1yr from epoch # assume this is an elapsed time instead x = sig . tline . unix hov_temp = \"\"\" Value: % {y:.2f} % {yaxis.title.text} <br> Time: % {x:.3f} [s]\"\"\" self . fig . update_layout ({ \"xaxis1\" : { \"title\" : \"Elapsed Time [s]\" }}) else : x = sig . tline . iso hov_temp = \"\"\" Value: % {y:.2f} % {yaxis.title.text} <br> Time: %{x|%H:%M:%S.%L}\"\"\" self . fig . update_layout ({ \"xaxis1\" : { \"title\" : \"Date and Time\" }}) if sig . nsamples > 100000 : hov = \"skip\" # Disable hover since its too slow hov_temp = \"\" else : hov = \"all\" trace = { \"type\" : \"scattergl\" , \"y\" : sig . data , \"x\" : x , \"name\" : f \" { sig . name } [ { unit } ]\" , \"mode\" : \"markers+lines\" , \"hovertemplate\" : hov_temp , \"hoverinfo\" : hov , \"yaxis\" : yaxis , \"opacity\" : 1 , \"connectgaps\" : bool ( sig . connect_gaps ), # should work if connect_gaps is None \"marker\" : { # \"color\": TRACES[self.ntrace], \"size\" : [ 2 ] * len ( x ), \"line\" : { \"color\" : ccg . util . max_contrast ( self . fig . layout [ \"template\" ][ \"layout\" ][ \"plot_bgcolor\" ], ccg . util . shift_lightness ( plot_themes . TRACES [ color % plot_themes . N_COLORS ], 1.4 ), ccg . util . shift_lightness ( plot_themes . TRACES [ color % plot_themes . N_COLORS ], 0.4 ), ), \"width\" : 1 , }, }, \"line\" : { \"width\" : 1 , \"shape\" : plot_themes . LINESHAPE [ sig . interp_method ], \"color\" : plot_themes . TRACES [ color % plot_themes . N_COLORS ], }, } if sig . base_data is not None : ccg . util . merge_dict ( trace , { \"text\" : sig . base_data , \"hovertemplate\" : \"\"\"Value: % {text} <br> Time: %{x|%H:%M:%S.%L}\"\"\" , }, ) return trace def find_yaxis ( self , sig : ccg . Sig , yaxis : str = None ): \"\"\"Check for matching y axes.\"\"\" if sig . data_range is not None : sig_min = sig . data_range [ 0 ] sig_max = sig . data_range [ 1 ] fixed_range = True else : sig_min = sig . min sig_max = sig . max fixed_range = False if yaxis is not None : if yaxis in self . yaxes : try : if \"U\" in self . yaxes [ yaxis ][ \"dtype\" ]: # its a string type so no scaling info self . yaxes [ yaxis ][ \"color\" ] = plot_themes . WHITE # change to grey for multi return yaxis yrange = self . yaxes [ yaxis ][ \"max\" ] - self . yaxes [ yaxis ][ \"min\" ] sigrange = sig_max - sig_min if yrange == 0 : yrange = self . yaxes [ yaxis ][ \"min\" ] self . yaxes [ yaxis ][ \"color\" ] = plot_themes . WHITE # change to grey for multi # Should we update the max and min here? could let it expand to inf... # Maybe an average? if fixed_range : self . yaxes [ yaxis ][ \"fixed_range\" ] = fixed_range self . yaxes [ yaxis ][ \"min\" ] = ( self . yaxes [ yaxis ][ \"min\" ] + sig_min ) / 2 self . yaxes [ yaxis ][ \"max\" ] = ( self . yaxes [ yaxis ][ \"max\" ] + sig_max ) / 2 return yaxis except TypeError : # For the case of dtype=obj and not compat pass else : self . nyaxes += 1 self . yaxes [ yaxis ] = { \"unit\" : sig . unit , \"min\" : sig_min , \"max\" : sig_max , \"dtype\" : plot_themes . COMPAT_TYPES [ np . where ( [ sig . data . dtype . kind in t for t in plot_themes . COMPAT_TYPES ] )[ 0 ][ 0 ] # r-worded way to get the index of the match ], \"color\" : ccg . util . max_contrast ( plot_themes . THEME2 , ccg . util . shift_lightness ( plot_themes . TRACES [ ( self . ntrace + 1 ) % plot_themes . N_COLORS ], 1.4 , ), ccg . util . shift_lightness ( plot_themes . TRACES [ ( self . ntrace + 1 ) % plot_themes . N_COLORS ], 0.4 , ), ), \"fixed_range\" : fixed_range , } return yaxis else : if self . nyaxes > 0 : for yaxis , yaxis_def in self . yaxes . items (): if ( sig . data . dtype . kind in yaxis_def [ \"dtype\" ] and yaxis_def [ \"unit\" ] == sig . unit ): try : if \"U\" in yaxis_def [ \"dtype\" ]: # its a string type so no scaling info yaxis_def [ \"color\" ] = ( plot_themes . WHITE ) # change to grey for multi return yaxis yrange = yaxis_def [ \"max\" ] - yaxis_def [ \"min\" ] sigrange = sig_max - sig_min if yrange == 0 : yrange = yaxis_def [ \"min\" ] if ( sig_min > yaxis_def [ \"min\" ] - ( yrange * plot_themes . FRANGE / 2 ) and sig_max < yaxis_def [ \"max\" ] + ( yrange * plot_themes . FRANGE / 2 ) and sigrange < yrange * plot_themes . FRANGE and sigrange > yrange / plot_themes . FRANGE ): yaxis_def [ \"color\" ] = ( plot_themes . WHITE ) # change to grey for multi # Should we update the max and min here? could let it expand to inf... # Maybe an average? if fixed_range : yaxis_def [ \"fixed_range\" ] = fixed_range yaxis_def [ \"min\" ] = ( yaxis_def [ \"min\" ] + sig_min ) / 2 yaxis_def [ \"max\" ] = ( yaxis_def [ \"max\" ] + sig_max ) / 2 return yaxis except TypeError : # For the case of dtype=obj and not compat pass self . nyaxes += 1 yaxis = f \"y { self . nyaxes } \" self . yaxes [ yaxis ] = { \"unit\" : sig . unit , \"min\" : sig_min , \"max\" : sig_max , \"dtype\" : plot_themes . COMPAT_TYPES [ np . where ( [ sig . data . dtype . kind in t for t in plot_themes . COMPAT_TYPES ] )[ 0 ][ 0 ] # r-worded way to get the index of the match ], \"color\" : ccg . util . max_contrast ( plot_themes . THEME2 , ccg . util . shift_lightness ( plot_themes . TRACES [( self . ntrace + 1 ) % plot_themes . N_COLORS ], 1.4 , ), ccg . util . shift_lightness ( plot_themes . TRACES [( self . ntrace + 1 ) % plot_themes . N_COLORS ], 0.4 , ), ), \"fixed_range\" : fixed_range , } return yaxis def build_yaxes ( self ): \"\"\"Build yaxes element for layout.\"\"\" # tic = datetime.now() yaxes : dict [ str , dict ] = {} domain_min = 1 domain_min_name = \"y1\" # TODO: Handle domains better... for i , ( y_name , yaxis ) in enumerate ( self . yaxes . items ()): yaxis_tmp = copy . deepcopy ( yaxis ) # Since we will remove stuff from this later... name = y_name . replace ( \"y\" , \"yaxis\" ) if ( i % 2 ) == 0 : side = \"left\" pos = round ( i / 2 + 0.001 ) * plot_themes . FPOS else : side = \"right\" pos = 1 - round ( i / 2 - 0.001 + 1 ) * plot_themes . FPOS unit = yaxis_tmp . pop ( \"unit\" ) # Pop since its not a standard. _ = yaxis_tmp . pop ( \"dtype\" ) # not needed here data_range = [ yaxis_tmp . pop ( \"min\" ), yaxis_tmp . pop ( \"max\" )] if not yaxis_tmp . pop ( \"fixed_range\" ): data_range = False # Not sure im ready to use this yet. title = \"\" if unit is None else f \"[ { unit } ]\" ccg . util . merge_dict ( yaxes , { name : { \"title\" : { \"text\" : title }, \"overlaying\" : \"y1\" , \"anchor\" : \"x1\" , \"position\" : pos , \"color\" : yaxis_tmp [ \"color\" ], \"gridcolor\" : yaxis_tmp [ \"color\" ], \"showgrid\" : True , \"showline\" : True , \"mirror\" : True , \"side\" : side , \"spikesnap\" : \"hovered data\" , \"spikemode\" : \"across+marker\" , \"spikedash\" : \"solid\" , \"spikethickness\" : 1 , \"ticks\" : \"outside\" , \"ticklen\" : 3 , \"zerolinecolor\" : yaxis_tmp [ \"color\" ], \"zerolinewidth\" : 2 , } }, ) ccg . util . merge_dict ( yaxes [ name ], yaxis_tmp ) if data_range : ccg . util . merge_dict ( yaxes [ name ], { \"range\" : data_range , }, ) if i > 0 : del yaxes [ f \"yaxis { i } \" ][ \"anchor\" ] # to allow spacing multiple if \"domain\" in yaxis_tmp : if yaxis_tmp [ \"domain\" ][ 0 ] < domain_min : domain_min = yaxis_tmp [ \"domain\" ][ 0 ] domain_min_name = y_name if not yaxes : return del yaxes [ \"yaxis1\" ][ \"overlaying\" ] # to allow hover to work try : # TODO: Improve this for more domains del yaxes [ domain_min_name . replace ( \"y\" , \"yaxis\" )][ \"overlaying\" ] except KeyError : pass yaxes [ \"xaxis1\" ] = { \"domain\" : [ ( round (( self . nyaxes ) / 2 + 0.001 ) - 1 ) * plot_themes . FPOS , 1 - round ( self . nyaxes / 2 - 0.001 ) * plot_themes . FPOS , ], # +0.001 since python is r-worded} \"anchor\" : domain_min_name , } self . fig . update_layout ( yaxes )","title":"Plot"},{"location":"reference/ccg/ui/plotgo/#ccg.ui.plotgo.Plot.append_trace","text":"Append trace to traces. Source code in ccg\\ui\\plotgo.py 94 95 96 97 98 99 100 101 @profile def append_trace ( self , trace : dict | list [ dict ]): \"Append trace to traces.\" if isinstance ( trace , list ): self . fig . add_traces ( trace ) else : self . fig . add_trace ( trace ) self . ntrace += 1","title":"append_trace"},{"location":"reference/ccg/ui/plotgo/#ccg.ui.plotgo.Plot.build_0d_traces","text":"Build traces for 0d param Source code in ccg\\ui\\plotgo.py 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 def build_0d_traces ( self , param : ccg . Tbl , color : int , ntrace : int , unit : str ): \"\"\"Build traces for 0d param\"\"\" traces = [] self . nyaxes = 1 # Ever a case for more than 1? yaxis = f \"y { self . nyaxes } \" hov_temp = ( f \"\"\" { param . name } : % {{ y:. { param . precision } f }} [ { unit } ]<extra></extra>\"\"\" ) try : tmp_trc = { \"type\" : \"scattergl\" , \"y\" : param . orig . data , \"name\" : param . orig . name , \"mode\" : \"markers\" , \"yaxis\" : yaxis , \"opacity\" : 1 , \"hovertemplate\" : hov_temp , \"marker\" : { \"size\" : 8 , \"color\" : plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ], \"line\" : { \"color\" : ccg . util . max_contrast ( self . fig . layout [ \"template\" ][ \"layout\" ][ \"plot_bgcolor\" ], ccg . util . shift_lightness ( plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ], 1.4 ), ccg . util . shift_lightness ( plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ], 0.4 ), ), \"width\" : 1 , }, }, \"hoverlabel\" : { \"bgcolor\" : plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ] }, \"showlegend\" : True , \"legendgroup\" : f \" { param . orig . name } _ { ntrace } \" , } traces . append ( tmp_trc ) ntrace += 1 except KeyError : pass if color is None : color = ntrace tmp_trc = { \"type\" : \"scattergl\" , \"y\" : param . data , \"name\" : param . name , \"mode\" : \"markers\" , \"hovertemplate\" : hov_temp , \"opacity\" : 1 , \"marker\" : { \"size\" : 8 , \"color\" : plot_themes . TRACES [ color % plot_themes . N_COLORS ], \"line\" : { \"color\" : ccg . util . max_contrast ( self . fig . layout [ \"template\" ][ \"layout\" ][ \"plot_bgcolor\" ], ccg . util . shift_lightness ( plot_themes . TRACES [ color % plot_themes . N_COLORS ], 1.4 ), ccg . util . shift_lightness ( plot_themes . TRACES [ color % plot_themes . N_COLORS ], 0.4 ), ), \"width\" : 1 , }, }, \"hoverlabel\" : { \"bgcolor\" : plot_themes . TRACES [ color % plot_themes . N_COLORS ]}, \"showlegend\" : True , \"legendgroup\" : f \" { param . name } _ { ntrace } \" , } traces . append ( tmp_trc ) ntrace += 1 nscatter = 0 for scatter in param . scatter_data : if scatter is not None : # plot the scatter data as well. nscatter += 1 tmp_trc = self . build_scatter_trace ( scatter = scatter , param = param , ntrace = ntrace , nscatter = nscatter ) traces . append ( tmp_trc ) ntrace += 1 self . yaxes [ yaxis ] = { \"unit\" : param . unit , \"min\" : param . data_range [ 0 ], \"max\" : param . data_range [ 1 ], \"dtype\" : plot_themes . COMPAT_TYPES [ np . where ( [ param . data . dtype . kind in t for t in plot_themes . COMPAT_TYPES ] )[ 0 ][ 0 ] # r-worded way to get the index of the match ], \"color\" : plot_themes . WHITE , \"fixed_range\" : False , } return traces","title":"build_0d_traces"},{"location":"reference/ccg/ui/plotgo/#ccg.ui.plotgo.Plot.build_1d_traces","text":"Build traces for 1d param Source code in ccg\\ui\\plotgo.py 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 @profile def build_1d_traces ( self , param : ccg . Tbl , color : int , ntrace : int , unit : str ): \"\"\"Build traces for 1d param\"\"\" traces = [] self . nyaxes = 1 # Ever case for more than 1? yaxis = f \"y { self . nyaxes } \" # TODO: Fix for multiple axes hov_temp = f \"\"\" { param . name } : % {{ y:. { param . precision } f }} [ { unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } f }} [ { param . axes [ 0 ] . unit } ]<extra></extra>\"\"\" try : tmp_trc = { \"type\" : \"scattergl\" , \"y\" : param . orig . data , \"x\" : param . orig . axes [ 0 ] . data , \"name\" : param . orig . name , \"mode\" : \"markers+lines\" , \"yaxis\" : yaxis , \"opacity\" : 1 , \"hovertemplate\" : hov_temp , \"marker\" : { \"size\" : np . array ([ 10 ] * param . orig . data . size ), \"color\" : plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ], \"line\" : { \"color\" : ccg . util . max_contrast ( self . fig . layout [ \"template\" ][ \"layout\" ][ \"plot_bgcolor\" ], ccg . util . shift_lightness ( plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ], 1.4 ), ccg . util . shift_lightness ( plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ], 0.4 ), ), \"width\" : 1 , }, }, \"line\" : { \"width\" : 1 , \"shape\" : plot_themes . LINESHAPE [ param . orig . axes [ 0 ] . interp_method ], \"color\" : plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ], }, \"hoverlabel\" : { \"bgcolor\" : plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ] }, \"showlegend\" : True , \"legendgroup\" : f \" { param . orig . name } _ { ntrace } \" , } traces . append ( tmp_trc ) ntrace += 1 except KeyError : pass if color is None : color = ntrace tmp_trc = { \"type\" : \"scattergl\" , \"y\" : param . data , \"x\" : param . axes [ 0 ] . data , \"name\" : param . name , \"mode\" : \"markers+lines\" , \"hovertemplate\" : hov_temp , \"opacity\" : 1 , \"marker\" : { \"size\" : np . array ([ 10 ] * param . data . size ), \"color\" : plot_themes . TRACES [ color % plot_themes . N_COLORS ], \"line\" : { \"color\" : ccg . util . max_contrast ( self . fig . layout [ \"template\" ][ \"layout\" ][ \"plot_bgcolor\" ], ccg . util . shift_lightness ( plot_themes . TRACES [ color % plot_themes . N_COLORS ], 1.4 ), ccg . util . shift_lightness ( plot_themes . TRACES [ color % plot_themes . N_COLORS ], 0.4 ), ), \"width\" : 1 , }, }, \"line\" : { \"width\" : 1 , \"shape\" : plot_themes . LINESHAPE [ param . axes [ 0 ] . interp_method ], \"color\" : plot_themes . TRACES [ color % plot_themes . N_COLORS ], }, \"hoverlabel\" : { \"bgcolor\" : plot_themes . TRACES [ color % plot_themes . N_COLORS ]}, \"showlegend\" : True , \"legendgroup\" : f \" { param . name } _ { ntrace } \" , } traces . append ( tmp_trc ) ntrace += 1 nscatter = 0 for scatter in param . scatter_data : if scatter is not None : # plot the scatter data as well. nscatter += 1 tmp_trc = self . build_scatter_trace ( scatter = scatter , param = param , ntrace = ntrace , nscatter = nscatter ) traces . append ( tmp_trc ) ntrace += 1 self . yaxes [ yaxis ] = { \"unit\" : param . unit , \"min\" : param . data_range [ 0 ], \"max\" : param . data_range [ 1 ], \"dtype\" : plot_themes . COMPAT_TYPES [ np . where ( [ param . data . dtype . kind in t for t in plot_themes . COMPAT_TYPES ] )[ 0 ][ 0 ] # r-worded way to get the index of the match ], \"color\" : plot_themes . WHITE , \"fixed_range\" : False , } return traces","title":"build_1d_traces"},{"location":"reference/ccg/ui/plotgo/#ccg.ui.plotgo.Plot.build_2d_traces","text":"build traces from 2d param Source code in ccg\\ui\\plotgo.py 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 @profile def build_2d_traces ( self , param : ccg . Tbl , color : int , ntrace : int , unit : str ): \"\"\"build traces from 2d param\"\"\" traces = [] try : traces . extend ( self . build_surf_traces ( param . orig , ntrace , ntrace , unit , visible = True ) ) ntrace += 1 except KeyError : pass if color is None : color = ntrace traces . extend ( self . build_surf_traces ( param , color , ntrace , unit )) ntrace += 1 nscatter = 0 for scatter in param . scatter_data : if scatter is not None : # plot the scatter data as well. nscatter += 1 tmp_trc = self . build_scatter_trace ( scatter = scatter , param = param , ntrace = ntrace , nscatter = nscatter ) traces . append ( tmp_trc ) ntrace += 1 # TODO: Should edit the layout here... self . fig . layout [ \"scene\" ][ \"xaxis\" ] . update ( { \"title\" : { \"text\" : f \" { param . axes [ 0 ] . name } [ { param . axes [ 0 ] . unit } ]\" }} ) self . fig . layout [ \"scene\" ][ \"yaxis\" ] . update ( { \"title\" : { \"text\" : f \" { param . axes [ 1 ] . name } [ { param . axes [ 1 ] . unit } ]\" }} ) self . fig . layout [ \"scene\" ][ \"zaxis\" ] . update ( { \"title\" : { \"text\" : f \" { param . name } [ { param . unit } ]\" }} ) self . fig . layout [ \"scene\" ] . update ( { \"camera\" : { \"eye\" : { \"x\" : - 1.25 , \"y\" : - 1.25 , \"z\" : 1.1 }}, } ) # scene = { # \"scene\": { # \"xaxis\": xaxis, # \"yaxis\": yaxis, # \"zaxis\": zaxis, # \"camera\": {\"eye\": {\"x\": -1.25, \"y\": -1.25, \"z\": 1.1}}, # } # } return traces","title":"build_2d_traces"},{"location":"reference/ccg/ui/plotgo/#ccg.ui.plotgo.Plot.build_scatter_trace","text":"Builds a scatter trace. ntrace and nscatter are counters for color increments Source code in ccg\\ui\\plotgo.py 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 @profile def build_scatter_trace ( self , scatter : ccg . ScatterData , param : ccg . Tbl = None , ntrace : int = 1 , nscatter : int = 1 , ): \"\"\"Builds a scatter trace. ntrace and nscatter are counters for color increments\"\"\" ndim = scatter . ndim tmp_trc = { \"name\" : scatter . name , \"mode\" : \"markers\" , \"opacity\" : 1 , \"marker\" : { \"size\" : 3 , \"color\" : plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ], \"colorscale\" : [ plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ]] * 2 , \"showscale\" : False , }, \"hoverlabel\" : { \"bgcolor\" : plot_themes . TRACES [ ntrace % plot_themes . N_COLORS ] }, \"showlegend\" : True , \"legendgroup\" : f \" { scatter . name } _ { ntrace } \" , } if scatter . color is not None : tmp = { \"marker\" : { \"color\" : scatter . color , \"colorscale\" : \"turbo\" , \"colorbar\" : { \"bgcolor\" : plot_themes . THEME3 , \"bordercolor\" : plot_themes . THEME4 , \"borderwidth\" : 1 , \"title\" : { \"text\" : f \" { scatter . color_label } [ { scatter . color_unit } ]\" , \"side\" : \"right\" , }, \"x\" : 0 , }, \"showscale\" : True , }, \"text\" : np . round ( scatter . color , scatter . color_precision ), } if scatter . color_range is not None : ccg . util . merge_dict ( tmp , { \"marker\" : { \"cmin\" : scatter . color_range [ 0 ], \"cmax\" : scatter . color_range [ 1 ], } }, ) # Need to move legend to clear color bar. tmp_lgnd = { \"xanchor\" : \"right\" , \"yanchor\" : \"top\" , \"x\" : 1 , \"y\" : 1 , } self . fig . update_legends ( tmp_lgnd ) ccg . util . merge_dict ( tmp_trc , tmp ) if ndim == 2 : if param is not None : if scatter . color is not None : hov_temp = f \"\"\" { scatter . name } : % {{ z:. { param . precision } f }} [ { param . unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } f }} [ { param . axes [ 0 ] . unit } ]<br> { param . axes [ 1 ] . name } : % {{ y:. { param . axes [ 1 ] . precision } f }} [ { param . axes [ 1 ] . unit } ]<br> { scatter . color_label } : % {{ marker.color:. { scatter . color_precision } f }} [ { scatter . color_unit } ] <extra></extra>\"\"\" else : hov_temp = f \"\"\" { scatter . name } : % {{ z:. { param . precision } d }} [ { param . unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } d }} [ { param . axes [ 0 ] . unit } ]<br> { param . axes [ 1 ] . name } : % {{ y:. { param . axes [ 1 ] . precision } d }} [ { param . axes [ 1 ] . unit } ] <extra></extra>\"\"\" else : if scatter . color is not None : hov_temp = \"\" tmp = { \"type\" : \"scatter3d\" , \"x\" : scatter . data [ 0 ], \"y\" : scatter . data [ 1 ], \"z\" : scatter . data [ 2 ], \"hovertemplate\" : hov_temp , } elif ndim == 1 : if param is not None : if scatter . color is not None : hov_temp = f \"\"\" { scatter . name } : % {{ y:. { param . precision } f }} [ { param . unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } f }} [ { param . axes [ 0 ] . unit } ]<br> { scatter . color_label } : % {{ marker.color:. { scatter . color_precision } f }} [ { scatter . color_unit } ] <extra></extra>\"\"\" else : hov_temp = f \"\"\" { scatter . name } : % {{ y:. { param . precision } d }} [ { param . unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } d }} [ { param . axes [ 0 ] . unit } ]<br> <extra></extra>\"\"\" else : hov_temp = \"\" tmp = { \"type\" : \"scattergl\" , \"x\" : scatter . data [ 0 ], \"y\" : scatter . data [ 1 ], \"hovertemplate\" : hov_temp , } elif ndim == 0 : if param is not None : if scatter . color is not None : hov_temp = f \"\"\" { scatter . name } : % {{ y:. { param . precision } f }} [ { param . unit } ]<br> { scatter . color_label } : % {{ marker.color:. { scatter . color_precision } f }} [ { scatter . color_unit } ] <extra></extra>\"\"\" else : hov_temp = f \"\"\" { scatter . name } : % {{ y:. { param . precision } d }} [ { param . unit } ]<br> <extra></extra>\"\"\" else : hov_temp = \"\" tmp = { \"type\" : \"scattergl\" , \"x\" : scatter . data [ 0 ] * 0 , \"y\" : scatter . data [ 1 ], \"hovertemplate\" : hov_temp , } else : raise NotImplementedError ccg . util . merge_dict ( tmp_trc , tmp ) if nscatter > 1 : ccg . util . merge_dict ( tmp_trc , { \"visible\" : \"legendonly\" }) return tmp_trc","title":"build_scatter_trace"},{"location":"reference/ccg/ui/plotgo/#ccg.ui.plotgo.Plot.build_surf_traces","text":"Build 2d surface trace Source code in ccg\\ui\\plotgo.py 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598 599 600 601 602 603 604 605 606 def build_surf_traces ( self , param : ccg . Tbl , color : int , ntrace : int , unit : str , visible : bool = True , ): \"\"\"Build 2d surface trace\"\"\" if not visible : visible = \"legendonly\" hov_temp = f \"\"\" { param . name } : % {{ z:. { param . precision } f }} [ { param . unit } ]<br> { param . axes [ 0 ] . name } : % {{ x:. { param . axes [ 0 ] . precision } f }} [ { param . axes [ 0 ] . unit } ]<br> { param . axes [ 1 ] . name } : % {{ y:. { param . axes [ 1 ] . precision } f }} [ { param . axes [ 1 ] . unit } ] <extra></extra>\"\"\" x , y = np . meshgrid ( param . axes [ 0 ] . data , param . axes [ 1 ] . data ) x = np . concatenate (( x , x [ - 1 , np . newaxis ])) y = np . concatenate (( y , y [ - 1 , np . newaxis ])) z = np . concatenate (( param . data . T , param . data . T [ - 1 , np . newaxis ] * np . NaN )) i = x . flatten ( \"F\" ) j = y . flatten ( \"F\" ) k = z . flatten ( \"F\" ) y , x = np . meshgrid ( param . axes [ 1 ] . data , param . axes [ 0 ] . data ) x = np . concatenate (( x , x [ - 1 , np . newaxis ])) y = np . concatenate (( y , y [ - 1 , np . newaxis ])) z = np . concatenate (( param . data , param . data [ - 1 , np . newaxis ] * np . NaN )) i = np . concatenate (( i , x . flatten ( \"F\" ))) j = np . concatenate (( j , y . flatten ( \"F\" ))) k = np . concatenate (( k , z . flatten ( \"F\" ))) traces = [ { \"type\" : \"surface\" , \"x\" : param . axes [ 0 ] . data , \"y\" : param . axes [ 1 ] . data , \"z\" : param . data . T , \"name\" : f \" { param . name }{ unit } \" , \"hovertemplate\" : hov_temp , \"hoverlabel\" : { \"bgcolor\" : plot_themes . TRACES [ color % plot_themes . N_COLORS ] }, \"opacity\" : 0.5 , \"colorscale\" : [ plot_themes . TRACES [ color % plot_themes . N_COLORS ]] * 2 , \"showlegend\" : True , \"legendgroup\" : f \" { param . name } _ { ntrace } \" , \"showscale\" : False , \"visible\" : visible , }, { \"type\" : \"scatter3d\" , \"x\" : i , \"y\" : j , \"z\" : k , \"name\" : f \" { param . name }{ unit } \" , \"hoverinfo\" : \"skip\" , \"opacity\" : 1 , \"marker\" : { \"color\" : np . array ( [ plot_themes . TRACES [ color % plot_themes . N_COLORS ]] * len ( i ) ), \"size\" : np . array ([ 10 ] * len ( i )), # \"line\": { # \"color\": ccg.util.max_contrast( # plot_themes.TRACES[color % plot_themes.N_COLORS], # ccg.util.shift_lightness( # plot_themes.TRACES[color % plot_themes.N_COLORS], 1.4 # ), # ccg.util.shift_lightness( # plot_themes.TRACES[color % plot_themes.N_COLORS], 0.4 # ), # ), # \"width\": 1, # }, }, \"line\" : { \"color\" : ccg . util . max_contrast ( plot_themes . TRACES [ color % plot_themes . N_COLORS ], ccg . util . shift_lightness ( plot_themes . TRACES [ color % plot_themes . N_COLORS ], 1.4 ), ccg . util . shift_lightness ( plot_themes . TRACES [ color % plot_themes . N_COLORS ], 0.4 ), ), \"width\" : 2 , }, \"showlegend\" : False , \"legendgroup\" : f \" { param . name } _ { ntrace } \" , \"connectgaps\" : False , \"visible\" : visible , }, ] return traces","title":"build_surf_traces"},{"location":"reference/ccg/ui/plotgo/#ccg.ui.plotgo.Plot.build_trace_from_sig","text":"Build Trace for plotly from a Sig. Source code in ccg\\ui\\plotgo.py 608 609 610 611 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 def build_trace_from_sig ( self , sig : ccg . Sig , color : int = None , yaxis : str = None ): \"\"\"Build Trace for plotly from a Sig.\"\"\" ntrace = self . ntrace + 1 if color is None : color = ntrace sig = sig . plot_prep () yaxis = self . find_yaxis ( sig , yaxis ) unit = \"\" if sig . unit is None else sig . unit if sig . tline [ 0 ] < 32000000 : # apprx 1yr from epoch # assume this is an elapsed time instead x = sig . tline . unix hov_temp = \"\"\" Value: % {y:.2f} % {yaxis.title.text} <br> Time: % {x:.3f} [s]\"\"\" self . fig . update_layout ({ \"xaxis1\" : { \"title\" : \"Elapsed Time [s]\" }}) else : x = sig . tline . iso hov_temp = \"\"\" Value: % {y:.2f} % {yaxis.title.text} <br> Time: %{x|%H:%M:%S.%L}\"\"\" self . fig . update_layout ({ \"xaxis1\" : { \"title\" : \"Date and Time\" }}) if sig . nsamples > 100000 : hov = \"skip\" # Disable hover since its too slow hov_temp = \"\" else : hov = \"all\" trace = { \"type\" : \"scattergl\" , \"y\" : sig . data , \"x\" : x , \"name\" : f \" { sig . name } [ { unit } ]\" , \"mode\" : \"markers+lines\" , \"hovertemplate\" : hov_temp , \"hoverinfo\" : hov , \"yaxis\" : yaxis , \"opacity\" : 1 , \"connectgaps\" : bool ( sig . connect_gaps ), # should work if connect_gaps is None \"marker\" : { # \"color\": TRACES[self.ntrace], \"size\" : [ 2 ] * len ( x ), \"line\" : { \"color\" : ccg . util . max_contrast ( self . fig . layout [ \"template\" ][ \"layout\" ][ \"plot_bgcolor\" ], ccg . util . shift_lightness ( plot_themes . TRACES [ color % plot_themes . N_COLORS ], 1.4 ), ccg . util . shift_lightness ( plot_themes . TRACES [ color % plot_themes . N_COLORS ], 0.4 ), ), \"width\" : 1 , }, }, \"line\" : { \"width\" : 1 , \"shape\" : plot_themes . LINESHAPE [ sig . interp_method ], \"color\" : plot_themes . TRACES [ color % plot_themes . N_COLORS ], }, } if sig . base_data is not None : ccg . util . merge_dict ( trace , { \"text\" : sig . base_data , \"hovertemplate\" : \"\"\"Value: % {text} <br> Time: %{x|%H:%M:%S.%L}\"\"\" , }, ) return trace","title":"build_trace_from_sig"},{"location":"reference/ccg/ui/plotgo/#ccg.ui.plotgo.Plot.build_traces_from_tbl","text":"build traces from table. Source code in ccg\\ui\\plotgo.py 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 def build_traces_from_tbl ( self , tbl : ccg . Tbl , color : int = None ) -> list [ dict ]: \"\"\"build traces from table.\"\"\" ntrace = self . ntrace + 1 if tbl . unit is not None : unit = f \" [ { tbl . unit } ]\" else : unit = \"\" if tbl . n_dim == 2 : traces = self . build_2d_traces ( tbl , color , ntrace , unit ) elif tbl . n_dim == 1 : traces = self . build_1d_traces ( tbl , color , ntrace , unit ) elif tbl . n_dim == 0 : traces = self . build_0d_traces ( tbl , color , ntrace , unit ) else : raise NotImplementedError ( f \"Plot not implemented for n_dim = { tbl . n_dim } \" ) return traces","title":"build_traces_from_tbl"},{"location":"reference/ccg/ui/plotgo/#ccg.ui.plotgo.Plot.build_yaxes","text":"Build yaxes element for layout. Source code in ccg\\ui\\plotgo.py 824 825 826 827 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899 900 901 902 903 904 905 906 907 908 def build_yaxes ( self ): \"\"\"Build yaxes element for layout.\"\"\" # tic = datetime.now() yaxes : dict [ str , dict ] = {} domain_min = 1 domain_min_name = \"y1\" # TODO: Handle domains better... for i , ( y_name , yaxis ) in enumerate ( self . yaxes . items ()): yaxis_tmp = copy . deepcopy ( yaxis ) # Since we will remove stuff from this later... name = y_name . replace ( \"y\" , \"yaxis\" ) if ( i % 2 ) == 0 : side = \"left\" pos = round ( i / 2 + 0.001 ) * plot_themes . FPOS else : side = \"right\" pos = 1 - round ( i / 2 - 0.001 + 1 ) * plot_themes . FPOS unit = yaxis_tmp . pop ( \"unit\" ) # Pop since its not a standard. _ = yaxis_tmp . pop ( \"dtype\" ) # not needed here data_range = [ yaxis_tmp . pop ( \"min\" ), yaxis_tmp . pop ( \"max\" )] if not yaxis_tmp . pop ( \"fixed_range\" ): data_range = False # Not sure im ready to use this yet. title = \"\" if unit is None else f \"[ { unit } ]\" ccg . util . merge_dict ( yaxes , { name : { \"title\" : { \"text\" : title }, \"overlaying\" : \"y1\" , \"anchor\" : \"x1\" , \"position\" : pos , \"color\" : yaxis_tmp [ \"color\" ], \"gridcolor\" : yaxis_tmp [ \"color\" ], \"showgrid\" : True , \"showline\" : True , \"mirror\" : True , \"side\" : side , \"spikesnap\" : \"hovered data\" , \"spikemode\" : \"across+marker\" , \"spikedash\" : \"solid\" , \"spikethickness\" : 1 , \"ticks\" : \"outside\" , \"ticklen\" : 3 , \"zerolinecolor\" : yaxis_tmp [ \"color\" ], \"zerolinewidth\" : 2 , } }, ) ccg . util . merge_dict ( yaxes [ name ], yaxis_tmp ) if data_range : ccg . util . merge_dict ( yaxes [ name ], { \"range\" : data_range , }, ) if i > 0 : del yaxes [ f \"yaxis { i } \" ][ \"anchor\" ] # to allow spacing multiple if \"domain\" in yaxis_tmp : if yaxis_tmp [ \"domain\" ][ 0 ] < domain_min : domain_min = yaxis_tmp [ \"domain\" ][ 0 ] domain_min_name = y_name if not yaxes : return del yaxes [ \"yaxis1\" ][ \"overlaying\" ] # to allow hover to work try : # TODO: Improve this for more domains del yaxes [ domain_min_name . replace ( \"y\" , \"yaxis\" )][ \"overlaying\" ] except KeyError : pass yaxes [ \"xaxis1\" ] = { \"domain\" : [ ( round (( self . nyaxes ) / 2 + 0.001 ) - 1 ) * plot_themes . FPOS , 1 - round ( self . nyaxes / 2 - 0.001 ) * plot_themes . FPOS , ], # +0.001 since python is r-worded} \"anchor\" : domain_min_name , } self . fig . update_layout ( yaxes )","title":"build_yaxes"},{"location":"reference/ccg/ui/plotgo/#ccg.ui.plotgo.Plot.find_yaxis","text":"Check for matching y axes. Source code in ccg\\ui\\plotgo.py 684 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717 718 719 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809 810 811 812 813 814 815 816 817 818 819 820 821 822 def find_yaxis ( self , sig : ccg . Sig , yaxis : str = None ): \"\"\"Check for matching y axes.\"\"\" if sig . data_range is not None : sig_min = sig . data_range [ 0 ] sig_max = sig . data_range [ 1 ] fixed_range = True else : sig_min = sig . min sig_max = sig . max fixed_range = False if yaxis is not None : if yaxis in self . yaxes : try : if \"U\" in self . yaxes [ yaxis ][ \"dtype\" ]: # its a string type so no scaling info self . yaxes [ yaxis ][ \"color\" ] = plot_themes . WHITE # change to grey for multi return yaxis yrange = self . yaxes [ yaxis ][ \"max\" ] - self . yaxes [ yaxis ][ \"min\" ] sigrange = sig_max - sig_min if yrange == 0 : yrange = self . yaxes [ yaxis ][ \"min\" ] self . yaxes [ yaxis ][ \"color\" ] = plot_themes . WHITE # change to grey for multi # Should we update the max and min here? could let it expand to inf... # Maybe an average? if fixed_range : self . yaxes [ yaxis ][ \"fixed_range\" ] = fixed_range self . yaxes [ yaxis ][ \"min\" ] = ( self . yaxes [ yaxis ][ \"min\" ] + sig_min ) / 2 self . yaxes [ yaxis ][ \"max\" ] = ( self . yaxes [ yaxis ][ \"max\" ] + sig_max ) / 2 return yaxis except TypeError : # For the case of dtype=obj and not compat pass else : self . nyaxes += 1 self . yaxes [ yaxis ] = { \"unit\" : sig . unit , \"min\" : sig_min , \"max\" : sig_max , \"dtype\" : plot_themes . COMPAT_TYPES [ np . where ( [ sig . data . dtype . kind in t for t in plot_themes . COMPAT_TYPES ] )[ 0 ][ 0 ] # r-worded way to get the index of the match ], \"color\" : ccg . util . max_contrast ( plot_themes . THEME2 , ccg . util . shift_lightness ( plot_themes . TRACES [ ( self . ntrace + 1 ) % plot_themes . N_COLORS ], 1.4 , ), ccg . util . shift_lightness ( plot_themes . TRACES [ ( self . ntrace + 1 ) % plot_themes . N_COLORS ], 0.4 , ), ), \"fixed_range\" : fixed_range , } return yaxis else : if self . nyaxes > 0 : for yaxis , yaxis_def in self . yaxes . items (): if ( sig . data . dtype . kind in yaxis_def [ \"dtype\" ] and yaxis_def [ \"unit\" ] == sig . unit ): try : if \"U\" in yaxis_def [ \"dtype\" ]: # its a string type so no scaling info yaxis_def [ \"color\" ] = ( plot_themes . WHITE ) # change to grey for multi return yaxis yrange = yaxis_def [ \"max\" ] - yaxis_def [ \"min\" ] sigrange = sig_max - sig_min if yrange == 0 : yrange = yaxis_def [ \"min\" ] if ( sig_min > yaxis_def [ \"min\" ] - ( yrange * plot_themes . FRANGE / 2 ) and sig_max < yaxis_def [ \"max\" ] + ( yrange * plot_themes . FRANGE / 2 ) and sigrange < yrange * plot_themes . FRANGE and sigrange > yrange / plot_themes . FRANGE ): yaxis_def [ \"color\" ] = ( plot_themes . WHITE ) # change to grey for multi # Should we update the max and min here? could let it expand to inf... # Maybe an average? if fixed_range : yaxis_def [ \"fixed_range\" ] = fixed_range yaxis_def [ \"min\" ] = ( yaxis_def [ \"min\" ] + sig_min ) / 2 yaxis_def [ \"max\" ] = ( yaxis_def [ \"max\" ] + sig_max ) / 2 return yaxis except TypeError : # For the case of dtype=obj and not compat pass self . nyaxes += 1 yaxis = f \"y { self . nyaxes } \" self . yaxes [ yaxis ] = { \"unit\" : sig . unit , \"min\" : sig_min , \"max\" : sig_max , \"dtype\" : plot_themes . COMPAT_TYPES [ np . where ( [ sig . data . dtype . kind in t for t in plot_themes . COMPAT_TYPES ] )[ 0 ][ 0 ] # r-worded way to get the index of the match ], \"color\" : ccg . util . max_contrast ( plot_themes . THEME2 , ccg . util . shift_lightness ( plot_themes . TRACES [( self . ntrace + 1 ) % plot_themes . N_COLORS ], 1.4 , ), ccg . util . shift_lightness ( plot_themes . TRACES [( self . ntrace + 1 ) % plot_themes . N_COLORS ], 0.4 , ), ), \"fixed_range\" : fixed_range , } return yaxis","title":"find_yaxis"},{"location":"reference/ccg/ui/web/","text":"Simple util to open browser in app mode. Inspired by https://github.com/python-eel/Eel/tree/main launch_browser ( start_url ) Launches a browser window in app mode. Requires Chrome or MS Edge. Parameters: start_url ( str ) \u2013 URL to launch. Returns: Popen \u2013 The subprocess object representing the launched browser. Source code in ccg\\ui\\web.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 def launch_browser ( start_url : str ) -> sps . Popen | None : \"\"\"Launches a browser window in app mode. Requires Chrome or MS Edge. Parameters ---------- start_url : str URL to launch. Returns ------- sps.Popen The subprocess object representing the launched browser. \"\"\" path = None for app in BROWSERS : path = _find_path ( app ) if path : break if path : proc = sps . Popen ( f \" { path } --app= { start_url } --guest --window-size=1200,800s\" , stdout = sps . PIPE , stderr = sps . PIPE , stdin = sps . PIPE , ) return proc launch_browser_async ( start_url ) async Launches a browser window in app mode asynchronously. Requires Chrome or MS Edge. Parameters: start_url ( str ) \u2013 URL to launch. Source code in ccg\\ui\\web.py 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 async def launch_browser_async ( start_url : str ) -> None : \"\"\"Launches a browser window in app mode asynchronously. Requires Chrome or MS Edge. Parameters ---------- start_url : str URL to launch. \"\"\" path = None for app in BROWSERS : path = _find_path ( app ) if path : break if path : proc = await asyncio . create_subprocess_shell ( f \" { path } --app= { start_url } --guest --window-size=1200,800s\" , stdout = asyncio . subprocess . PIPE , stderr = asyncio . subprocess . PIPE , ) # You can also capture output and errors if needed stdout , stderr = await proc . communicate ()","title":"web"},{"location":"reference/ccg/ui/web/#ccg.ui.web.launch_browser","text":"Launches a browser window in app mode. Requires Chrome or MS Edge. Parameters: start_url ( str ) \u2013 URL to launch. Returns: Popen \u2013 The subprocess object representing the launched browser. Source code in ccg\\ui\\web.py 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 def launch_browser ( start_url : str ) -> sps . Popen | None : \"\"\"Launches a browser window in app mode. Requires Chrome or MS Edge. Parameters ---------- start_url : str URL to launch. Returns ------- sps.Popen The subprocess object representing the launched browser. \"\"\" path = None for app in BROWSERS : path = _find_path ( app ) if path : break if path : proc = sps . Popen ( f \" { path } --app= { start_url } --guest --window-size=1200,800s\" , stdout = sps . PIPE , stderr = sps . PIPE , stdin = sps . PIPE , ) return proc","title":"launch_browser"},{"location":"reference/ccg/ui/web/#ccg.ui.web.launch_browser_async","text":"Launches a browser window in app mode asynchronously. Requires Chrome or MS Edge. Parameters: start_url ( str ) \u2013 URL to launch. Source code in ccg\\ui\\web.py 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 async def launch_browser_async ( start_url : str ) -> None : \"\"\"Launches a browser window in app mode asynchronously. Requires Chrome or MS Edge. Parameters ---------- start_url : str URL to launch. \"\"\" path = None for app in BROWSERS : path = _find_path ( app ) if path : break if path : proc = await asyncio . create_subprocess_shell ( f \" { path } --app= { start_url } --guest --window-size=1200,800s\" , stdout = asyncio . subprocess . PIPE , stderr = asyncio . subprocess . PIPE , ) # You can also capture output and errors if needed stdout , stderr = await proc . communicate ()","title":"launch_browser_async"}]}